<!DOCTYPE html>





<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 3.9.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.4.0">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.4.0">
  <link rel="mask-icon" href="/images/logo.svg?v=7.4.0" color="#222">
  <link rel="alternate" href="/atom.xml" title="Snow" type="application/atom+xml">

<link rel="stylesheet" href="/css/main.css?v=7.4.0">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.7.0">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">
  <link rel="stylesheet" href="/lib/pace/pace-theme-center-atom.min.css?v=1.0.2">
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '7.4.0',
    exturl: false,
    sidebar: {"position":"left","width":300,"display":"post","offset":12,"onmobile":false},
    copycode: {"enable":true,"show_result":true,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":true},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},
    path: 'search.xml',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    translation: {
      copy_button: '复制',
      copy_success: '复制成功',
      copy_failure: '复制失败'
    },
    sidebarPadding: 40
  };
</script>
  <meta name="description" content="主要内容： torchtext预处理流程： 1. 定义Field： 2. 定义Dataset： 3. 建立vocab： 4. 构造迭代器：   实操 1. 下载数据： 读取文件，查看文件 train.tsv test.tsv     2. 划分验证集 3. 定义Field 4. 定义Dataset 5. 建立vocab 6. 构造迭代器 迭代器使用   7. 完整代码">
<meta name="keywords" content="转载,python,python模块学习">
<meta property="og:type" content="article">
<meta property="og:title" content="python_torchtext学习笔记_2">
<meta property="og:url" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/index.html">
<meta property="og:site_name" content="Snow">
<meta property="og:description" content="主要内容： torchtext预处理流程： 1. 定义Field： 2. 定义Dataset： 3. 建立vocab： 4. 构造迭代器：   实操 1. 下载数据： 读取文件，查看文件 train.tsv test.tsv     2. 划分验证集 3. 定义Field 4. 定义Dataset 5. 建立vocab 6. 构造迭代器 迭代器使用   7. 完整代码">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-33-59.png">
<meta property="og:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-34-45.png">
<meta property="og:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-44-39.png">
<meta property="og:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-47-31.png">
<meta property="og:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-21-32-04.png">
<meta property="og:updated_time" content="2023-04-03T13:58:20.641Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python_torchtext学习笔记_2">
<meta name="twitter:description" content="主要内容： torchtext预处理流程： 1. 定义Field： 2. 定义Dataset： 3. 建立vocab： 4. 构造迭代器：   实操 1. 下载数据： 读取文件，查看文件 train.tsv test.tsv     2. 划分验证集 3. 定义Field 4. 定义Dataset 5. 建立vocab 6. 构造迭代器 迭代器使用   7. 完整代码">
<meta name="twitter:image" content="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-33-59.png">
  <link rel="canonical" href="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true,
    isPage: false,
    isArchive: false
  };
</script>

  <title>python_torchtext学习笔记_2 | Snow</title>
  








  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">
  <div class="container use-motion">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Snow</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">光而不耀</p>
      
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
      
      
      
        
        <li class="menu-item menu-item-home">
      
    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>首页</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-about">
      
    

    <a href="/about/" rel="section"><i class="menu-item-icon fa fa-fw fa-user"></i> <br>关于</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-tags">
      
    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>标签</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-categories">
      
    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>分类</a>

  </li>
      
      
      
        
        <li class="menu-item menu-item-archives">
      
    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a href="javascript:;" class="popup-trigger">
        
          <i class="menu-item-icon fa fa-search fa-fw"></i> <br>搜索</a>
      </li>
    
  </ul>

</nav>
  <div class="site-search">
    <div class="popup search-popup">
    <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocorrect="off" autocapitalize="none"
           placeholder="搜索..." spellcheck="false"
           type="text" id="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result"></div>

</div>
<div class="search-pop-overlay"></div>

  </div>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

  <a href="https://github.com/behappy00" class="github-corner" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
            

          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
      <article itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block post">
    <link itemprop="mainEntityOfPage" href="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Snow">
      <meta itemprop="description" content="计算机 Hiter">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Snow">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">python_torchtext学习笔记_2

          
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              
                
              

              <time title="创建时间：2021-01-03 19:53:46" itemprop="dateCreated datePublished" datetime="2021-01-03T19:53:46+08:00">2021-01-03</time>
            </span>
          
            

            
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2023-04-03 21:58:20" itemprop="dateModified" datetime="2023-04-03T21:58:20+08:00">2023-04-03</time>
              </span>
            
          
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/学习笔记/" itemprop="url" rel="index"><span itemprop="name">学习笔记</span></a></span>

                
                
              
            </span>
          

          
            <span id="/2021/01/03/python_torchtext学习笔记_2/" class="post-meta-item leancloud_visitors" data-flag-title="python_torchtext学习笔记_2" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="leancloud-visitors-count"></span>
            </span>
          
            <span class="post-meta-item" title="阅读次数">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="fa fa-comment-o"></i>
      </span>
        
      
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/01/03/python_torchtext学习笔记_2/#comments" itemprop="discussionUrl"><span class="post-comments-count valine-comment-count" data-xid="/2021/01/03/python_torchtext学习笔记_2/" itemprop="commentCount"></span></a>
  </span>
  
  
          <br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
              
                <span class="post-meta-item-text">本文字数：</span>
              
              <span>12k</span>
            </span>
          
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
              
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              
              <span>11 分钟</span>
            </span>
          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <hr><ul>
<li><a href="#主要内容">主要内容：</a><ul>
<li><a href="#torchtext预处理流程">torchtext预处理流程：</a><ul>
<li><a href="#1-定义field">1. 定义Field：</a></li>
<li><a href="#2-定义dataset">2. 定义Dataset：</a></li>
<li><a href="#3-建立vocab">3. 建立vocab：</a></li>
<li><a href="#4-构造迭代器">4. 构造迭代器：</a></li>
</ul>
</li>
<li><a href="#实操">实操</a><ul>
<li><a href="#1-下载数据">1. 下载数据：</a><ul>
<li><a href="#读取文件查看文件">读取文件，查看文件</a><ul>
<li><a href="#traintsv">train.tsv</a></li>
<li><a href="#testtsv">test.tsv</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#2-划分验证集">2. 划分验证集</a></li>
<li><a href="#3-定义field">3. 定义Field</a></li>
<li><a href="#4-定义dataset">4. 定义Dataset</a></li>
<li><a href="#5-建立vocab">5. 建立vocab</a></li>
<li><a href="#6-构造迭代器">6. 构造迭代器</a><ul>
<li><a href="#迭代器使用">迭代器使用</a></li>
</ul>
</li>
<li><a href="#7-完整代码">7. 完整代码</a></li>
</ul>
</li>
</ul>
</li>
</ul><a id="more"></a>
<!-- TOC -->

<!-- /TOC -->
<hr>
<h2 id="主要内容："><a href="#主要内容：" class="headerlink" title="主要内容："></a>主要内容：</h2><ul>
<li>如何使用torchtext建立语料库</li>
<li>如何使用torchtext将词转下标，下标转词，词转词向量</li>
<li>如何建立相应的迭代器</li>
</ul>
<h3 id="torchtext预处理流程："><a href="#torchtext预处理流程：" class="headerlink" title="torchtext预处理流程："></a>torchtext预处理流程：</h3><h4 id="1-定义Field："><a href="#1-定义Field：" class="headerlink" title="1. 定义Field："></a>1. 定义Field：</h4><blockquote>
<p>声明如何处理数据</p>
<h4 id="2-定义Dataset："><a href="#2-定义Dataset：" class="headerlink" title="2. 定义Dataset："></a>2. 定义Dataset：</h4><p>得到数据集，此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 wordlist</p>
<h4 id="3-建立vocab："><a href="#3-建立vocab：" class="headerlink" title="3. 建立vocab："></a>3. 建立vocab：</h4><p>在这一步建立词汇表，词向量(word embeddings)</p>
<h4 id="4-构造迭代器："><a href="#4-构造迭代器：" class="headerlink" title="4. 构造迭代器："></a>4. 构造迭代器：</h4><p>构造迭代器，用来分批次训练模型</p>
</blockquote>
<h3 id="实操"><a href="#实操" class="headerlink" title="实操"></a>实操</h3><h4 id="1-下载数据："><a href="#1-下载数据：" class="headerlink" title="1. 下载数据："></a>1. 下载数据：</h4><p><a href="https://links.jianshu.com/go?to=https%3A%2F%2Fwww.kaggle.com%2Fc%2Fmovie-review-sentiment-analysis-kernels-only%2Fdata" target="_blank" rel="noopener">kaggle：Movie Review Sentiment Analysis (Kernels Only)</a><br>train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence.</p>
<p>test.tsv contains just phrases. You must assign a sentiment label to each phrase.</p>
<p>The sentiment labels are:<br>0 - negative<br>1 - somewhat negative<br>2 - neutral<br>3 - somewhat positive<br>4 - positive</p>
<p>下载得到：train.tsv和test.tsv</p>
<h5 id="读取文件，查看文件"><a href="#读取文件，查看文件" class="headerlink" title="读取文件，查看文件"></a>读取文件，查看文件</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd  </span><br><span class="line">data = pd.read_csv(<span class="string">'train.tsv'</span>, sep=<span class="string">'\t'</span>)  </span><br><span class="line">test = pd.read_csv(<span class="string">'test.tsv'</span>, sep=<span class="string">'\t'</span>)</span><br></pre></td></tr></table></figure>
<h6 id="train-tsv"><a href="#train-tsv" class="headerlink" title="train.tsv"></a>train.tsv</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-33-59.png" alt></p>
<h6 id="test-tsv"><a href="#test-tsv" class="headerlink" title="test.tsv"></a>test.tsv</h6><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test[:<span class="number">5</span>]</span><br></pre></td></tr></table></figure>
<p><img src="/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-34-45.png" alt></p>
<h4 id="2-划分验证集"><a href="#2-划分验证集" class="headerlink" title="2. 划分验证集"></a>2. 划分验证集</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split  </span><br><span class="line"><span class="comment"># create train and validation set  </span></span><br><span class="line">  </span><br><span class="line">train, val = train_test_split(data, test_size=<span class="number">0.2</span>)  </span><br><span class="line">train.to_csv(<span class="string">"train.csv"</span>, index=<span class="literal">False</span>)  </span><br><span class="line">val.to_csv(<span class="string">"val.csv"</span>, index=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="3-定义Field"><a href="#3-定义Field" class="headerlink" title="3. 定义Field"></a>3. 定义Field</h4><p>首先导入需要的包和定义pytorch张量使用的DEVICE</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy  </span><br><span class="line"><span class="keyword">import</span> torch  </span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets  </span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> Vectors  </span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init  </span><br><span class="line"></span><br><span class="line">DEVICE = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br></pre></td></tr></table></figure>
<p>Torchtext采用了一种声明式的方法来加载数据：你来告诉Torchtext你希望的数据是什么样子的，剩下的由torchtext来处理。<br>实现这种声明的是Field，Field确定了一种你想要怎么去处理数据。<br>data.Field(…)</p>
<p>Field的参数如下：</p>
<ul>
<li><p>sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True.</p>
</li>
<li><p>use_vocab: Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True.</p>
</li>
<li><p>init_token: A token that will be prepended to every example using this field, or None for no initial token. Default: None.</p>
</li>
<li><p>eos_token: A token that will be appended to every example using this field, or None for no end-of-sentence token. Default: None.</p>
</li>
<li><p>fix_length: A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. Default: None.</p>
</li>
<li><p>dtype: The torch.dtype class that represents a batch of examples of this kind of data. Default: torch.long.</p>
</li>
<li><p>preprocessing: The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None.</p>
</li>
<li><p>postprocessing: A Pipeline that will be applied to examples using this field after numericalizing but before the numbers are turned into a Tensor. The pipeline function takes the batch as a list, and the field’s Vocab. Default: None.</p>
</li>
<li><p>lower: Whether to lowercase the text in this field. Default: False.</p>
</li>
<li><p>tokenize: The function used to tokenize strings using this field into sequential examples. If “spacy”, the SpaCy tokenizer is used. If a non-serializable function is passed as an argument, the field will not be able to be serialized. Default: string.split.</p>
</li>
<li><p>tokenizer_language: The language of the tokenizer to be constructed. Various languages currently supported only in SpaCy.</p>
</li>
<li><p>include_lengths: Whether to return a tuple of a padded minibatch and a list containing the lengths of each examples, or just a padded minibatch. Default: False.</p>
</li>
<li><p>batch_first: Whether to produce tensors with the batch dimension first. Default: False.</p>
</li>
<li><p>pad_token: The string token used as padding. Default: “</p>
</li>
<li><p>unk_token: The string token used to represent OOV words. Default: “</p>
</li>
<li><p>pad_first: Do the padding of the sequence at the beginning. Default: False.</p>
</li>
<li><p>truncate_first: Do the truncating of the sequence at the beginning. Default: False</p>
</li>
<li><p>stop_words: Tokens to discard during the preprocessing step. Default: None</p>
</li>
<li><p>is_target: Whether this field is a target variable. Affects iteration over batches. Default: False</p>
</li>
</ul>
<p>例：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">spacy_en = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(text)</span>:</span> <span class="comment"># create a tokenizer function</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    定义分词操作</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">field在默认的情况下都期望一个输入是一组单词的序列，并且将单词映射成整数。</span></span><br><span class="line"><span class="string">这个映射被称为vocab。如果一个field已经被数字化了并且不需要被序列化，</span></span><br><span class="line"><span class="string">可以将参数设置为use_vocab=False以及sequential=False。</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">LABEL = data.Field(sequential=<span class="literal">False</span>, use_vocab=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">TEXT = data.Field(sequential=<span class="literal">True</span>, tokenize=tokenizer, lower=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h4 id="4-定义Dataset"><a href="#4-定义Dataset" class="headerlink" title="4. 定义Dataset"></a>4. 定义Dataset</h4><p>The fields知道当给定原始数据的时候要做什么。现在，我们需要告诉fields它需要处理什么样的数据。这个功能利用Datasets来实现。</p>
<p><strong>TabularDataset官网介绍: Defines a Dataset of columns stored in CSV, TSV, or JSON format.</strong></p>
<p>对于csv/tsv类型的文件，TabularDataset很容易进行处理，故我们选它来生成Dataset</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">我们不需要 'PhraseId' 和 'SentenceId'这两列, 所以我们给他们的field传递 None</span></span><br><span class="line"><span class="string">如果你的数据有列名，如我们这里的'Phrase','Sentiment',...</span></span><br><span class="line"><span class="string">设置skip_header=True,不然它会把列名也当一个数据处理</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">train,val = data.TabularDataset.splits(</span><br><span class="line">        path=<span class="string">'.'</span>, train=<span class="string">'train.csv'</span>,validation=<span class="string">'val.csv'</span>, format=<span class="string">'csv'</span>,skip_header=<span class="literal">True</span>,</span><br><span class="line">        fields=[(<span class="string">'PhraseId'</span>,<span class="literal">None</span>),(<span class="string">'SentenceId'</span>,<span class="literal">None</span>),(<span class="string">'Phrase'</span>, TEXT), (<span class="string">'Sentiment'</span>, LABEL)])</span><br><span class="line"></span><br><span class="line">test = data.TabularDataset(<span class="string">'test.tsv'</span>, format=<span class="string">'tsv'</span>,skip_header=<span class="literal">True</span>,</span><br><span class="line">        fields=[(<span class="string">'PhraseId'</span>,<span class="literal">None</span>),(<span class="string">'SentenceId'</span>,<span class="literal">None</span>),(<span class="string">'Phrase'</span>, TEXT)])</span><br></pre></td></tr></table></figure>
<p><strong>注意：传入的(name, field)必须与列的顺序相同。</strong></p>
<p>查看生成的dataset：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">print(train[<span class="number">5</span>])  </span><br><span class="line">print(train[<span class="number">5</span>].__dict__.keys())  </span><br><span class="line">print(train[<span class="number">5</span>].Phrase,train[<span class="number">0</span>].Sentiment)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-44-39.png" alt></p>
<h4 id="5-建立vocab"><a href="#5-建立vocab" class="headerlink" title="5. 建立vocab"></a>5. 建立vocab</h4><p>我们可以看到第6行的输入，它是一个Example对象。Example对象绑定了一行中的所有属性，可以看到，句子已经被分词了，但是没有转化为数字。</p>
<p>这是因为我们还没有建立vocab，我们将在下一步建立vocab。</p>
<p>Torchtext可以将词转化为数字，但是它需要被告知需要被处理的全部范围的词。我们可以用下面这行代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">TEXT.build_vocab(train, vectors=<span class="string">'glove.6B.100d'</span>)<span class="comment">#, max_size=30000)</span></span><br><span class="line"><span class="comment"># 当 corpus 中有的 token 在 vectors 中不存在时 的初始化方式.</span></span><br><span class="line">TEXT.vocab.vectors.unk_init = init.xavier_uniform</span><br></pre></td></tr></table></figure>
<p>这行代码使得 Torchtext遍历 <strong>训练集</strong> 中的绑定TEXT<br>field的数据，将单词注册到vocabulary，并自动构建embedding矩阵。</p>
<p><strong>‘glove.6B.100d’ 为torchtext支持的词向量名字，第一次使用是会自动下载并保存在当前目录的 .vector_cache里面。</strong></p>
<p><strong>torchtext支持的词向量</strong></p>
<ul>
<li>charngram.100d</li>
<li>fasttext.en.300d</li>
<li>fasttext.simple.300d</li>
<li>glove.42B.300d</li>
<li>glove.840B.300d</li>
<li>glove.twitter.27B.25d</li>
<li>glove.twitter.27B.50d</li>
<li>glove.twitter.27B.100d</li>
<li>glove.twitter.27B.200d</li>
<li>glove.6B.50d</li>
<li>glove.6B.100d</li>
<li>glove.6B.200d</li>
<li>glove.6B.300d</li>
</ul>
<p>例：<br>如果打算使用fasttext.en.300d词向量，只需把上面的代码里的vector=’…’里面的词向量名字换一下即可，具体如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TEXT.build_vocab(train, vectors=&apos;fasttext.en.300d&apos;)</span><br></pre></td></tr></table></figure>
<p>到这一步，我们已经可以把 <strong>词转为数字，数字转为词，词转为词向量</strong> 了</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">print(TEXT.vocab.itos[<span class="number">1510</span>])</span><br><span class="line">print(TEXT.vocab.stoi[<span class="string">'bore'</span>])</span><br><span class="line"><span class="comment"># 词向量矩阵: TEXT.vocab.vectors</span></span><br><span class="line">print(TEXT.vocab.vectors.shape)</span><br><span class="line">word_vec = TEXT.vocab.vectors[TEXT.vocab.stoi[<span class="string">'bore'</span>]]</span><br><span class="line">print(word_vec.shape)</span><br><span class="line">print(word_vec)</span><br></pre></td></tr></table></figure>
<p>输出：<br><img src="/2021/01/03/python_torchtext学习笔记_2/2021-01-15-20-47-31.png" alt></p>
<h4 id="6-构造迭代器"><a href="#6-构造迭代器" class="headerlink" title="6. 构造迭代器"></a>6. 构造迭代器</h4><p>我们日常使用pytorch训练网络时，每次训练都是输入一个batch，那么，我们怎么把前面得到的dataset转为迭代器，然后遍历迭代器获取batch输入呢？下面将介绍torchtext时怎么实现这一功能的。</p>
<p>和Dataset一样，torchtext有大量内置的迭代器，我们这里选择的是BucketIterator，官网对它的介绍如下：</p>
<ul>
<li><p>Defines an iterator that batches examples of similar lengths together.</p>
</li>
<li><p>Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch.</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">train_iter = data.BucketIterator(train, batch_size=<span class="number">128</span>, sort_key=<span class="keyword">lambda</span> x: len(x.Phrase), shuffle=<span class="literal">True</span>,device=DEVICE)</span><br><span class="line"></span><br><span class="line">val_iter = data.BucketIterator(val, batch_size=<span class="number">128</span>, sort_key=<span class="keyword">lambda</span> x: len(x.Phrase), shuffle=<span class="literal">True</span>,device=DEVICE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序</span></span><br><span class="line">test_iter = data.Iterator(dataset=test, batch_size=<span class="number">128</span>, train=<span class="literal">False</span>, sort=<span class="literal">False</span>, device=DEVICE)</span><br></pre></td></tr></table></figure>
<h5 id="迭代器使用"><a href="#迭代器使用" class="headerlink" title="迭代器使用"></a>迭代器使用</h5><p><strong>方法一</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">batch = next(iter(train_iter))  </span><br><span class="line">data = batch.Phrase  </span><br><span class="line">label = batch.Sentiment  </span><br><span class="line">print(batch.Phrase.shape)  </span><br><span class="line">print(batch.Phrase)</span><br></pre></td></tr></table></figure></p>
<p>输出结果：<br><img src="/2021/01/03/python_torchtext学习笔记_2/2021-01-15-21-32-04.png" alt></p>
<p>可以发现，它输出的是word index，后面的128是batch size</p>
<p><strong>方法二</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> batch <span class="keyword">in</span> train_iter:  </span><br><span class="line">    data = batch.Phrase  </span><br><span class="line">    label = batch.Sentiment</span><br></pre></td></tr></table></figure></p>
<h4 id="7-完整代码"><a href="#7-完整代码" class="headerlink" title="7. 完整代码"></a>7. 完整代码</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> spacy</span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">from</span> torchtext <span class="keyword">import</span> data, datasets</span><br><span class="line"><span class="keyword">from</span> torchtext.vocab <span class="keyword">import</span> Vectors</span><br><span class="line"><span class="keyword">from</span> torch.nn <span class="keyword">import</span> init</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line">DEVICE = torch.device(<span class="string">"cuda"</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">"cpu"</span>)</span><br><span class="line"></span><br><span class="line">data = pd.read_csv(<span class="string">'train.tsv'</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line">test = pd.read_csv(<span class="string">'test.tsv'</span>, sep=<span class="string">'\t'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># create train and validation set </span></span><br><span class="line">train, val = train_test_split(data, test_size=<span class="number">0.2</span>)</span><br><span class="line">train.to_csv(<span class="string">"train.csv"</span>, index=<span class="literal">False</span>)</span><br><span class="line">val.to_csv(<span class="string">"val.csv"</span>, index=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">spacy_en = spacy.load(<span class="string">'en'</span>)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">tokenizer</span><span class="params">(text)</span>:</span> <span class="comment"># create a tokenizer function</span></span><br><span class="line">    <span class="keyword">return</span> [tok.text <span class="keyword">for</span> tok <span class="keyword">in</span> spacy_en.tokenizer(text)]</span><br><span class="line"><span class="comment"># Field</span></span><br><span class="line">TEXT = data.Field(sequential=<span class="literal">True</span>, tokenize=tokenizer, lower=<span class="literal">True</span>)</span><br><span class="line">LABEL = data.Field(sequential=<span class="literal">False</span>, use_vocab=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Dataset</span></span><br><span class="line">train,val = data.TabularDataset.splits(</span><br><span class="line">        path=<span class="string">'.'</span>, train=<span class="string">'train.csv'</span>,validation=<span class="string">'val.csv'</span>, format=<span class="string">'csv'</span>,skip_header=<span class="literal">True</span>,</span><br><span class="line">        fields=[(<span class="string">'PhraseId'</span>,<span class="literal">None</span>),(<span class="string">'SentenceId'</span>,<span class="literal">None</span>),(<span class="string">'Phrase'</span>, TEXT), (<span class="string">'Sentiment'</span>, LABEL)])</span><br><span class="line"></span><br><span class="line">test = data.TabularDataset(<span class="string">'test.tsv'</span>, format=<span class="string">'tsv'</span>,skip_header=<span class="literal">True</span>,</span><br><span class="line">        fields=[(<span class="string">'PhraseId'</span>,<span class="literal">None</span>),(<span class="string">'SentenceId'</span>,<span class="literal">None</span>),(<span class="string">'Phrase'</span>, TEXT)])</span><br><span class="line"><span class="comment"># build vocab</span></span><br><span class="line">TEXT.build_vocab(train, vectors=<span class="string">'glove.6B.100d'</span>)<span class="comment">#, max_size=30000)</span></span><br><span class="line">TEXT.vocab.vectors.unk_init = init.xavier_uniform</span><br><span class="line"></span><br><span class="line"><span class="comment"># Iterator</span></span><br><span class="line">train_iter = data.BucketIterator(train, batch_size=<span class="number">128</span>, sort_key=<span class="keyword">lambda</span> x: len(x.Phrase), </span><br><span class="line">                                shuffle=<span class="literal">True</span>,device=DEVICE)</span><br><span class="line"></span><br><span class="line">val_iter = data.BucketIterator(val, batch_size=<span class="number">128</span>, sort_key=<span class="keyword">lambda</span> x: len(x.Phrase), </span><br><span class="line">                                shuffle=<span class="literal">True</span>,device=DEVICE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序</span></span><br><span class="line">test_iter = data.Iterator(dataset=test, batch_size=<span class="number">128</span>, train=<span class="literal">False</span>,</span><br><span class="line">                          sort=<span class="literal">False</span>, device=DEVICE)</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">由于目的是学习torchtext的使用，所以只定义了一个简单模型</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">len_vocab = len(TEXT.vocab)</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Enet</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        super(Enet, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(len_vocab,<span class="number">100</span>)</span><br><span class="line">        self.lstm = nn.LSTM(<span class="number">100</span>,<span class="number">128</span>,<span class="number">3</span>,batch_first=<span class="literal">True</span>)<span class="comment">#,bidirectional=True)</span></span><br><span class="line">        self.linear = nn.Linear(<span class="number">128</span>,<span class="number">5</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        batch_size,seq_num = x.shape</span><br><span class="line">        vec = self.embedding(x)</span><br><span class="line">        out, (hn, cn) = self.lstm(vec)</span><br><span class="line">        out = self.linear(out[:,<span class="number">-1</span>,:])</span><br><span class="line">        out = F.softmax(out,<span class="number">-1</span>)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Enet()</span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">将前面生成的词向量矩阵拷贝到模型的embedding层</span></span><br><span class="line"><span class="string">这样就自动的可以将输入的word index转为词向量</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line">model.embedding.weight.data.copy_(TEXT.vocab.vectors)   </span><br><span class="line">model.to(DEVICE)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练</span></span><br><span class="line">optimizer = optim.Adam(model.parameters())<span class="comment">#,lr=0.000001)</span></span><br><span class="line"></span><br><span class="line">n_epoch = <span class="number">20</span></span><br><span class="line"></span><br><span class="line">best_val_acc = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> range(n_epoch):</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> batch_idx, batch <span class="keyword">in</span> enumerate(train_iter):</span><br><span class="line">        data = batch.Phrase</span><br><span class="line">        target = batch.Sentiment</span><br><span class="line">        target = torch.sparse.torch.eye(<span class="number">5</span>).index_select(dim=<span class="number">0</span>, index=target.cpu().data)</span><br><span class="line">        target = target.to(DEVICE)</span><br><span class="line">        data = data.permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line"></span><br><span class="line">        out = model(data)</span><br><span class="line">        loss = -target*torch.log(out)-(<span class="number">1</span>-target)*torch.log(<span class="number">1</span>-out)</span><br><span class="line">        loss = loss.sum(<span class="number">-1</span>).mean()</span><br><span class="line"></span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (batch_idx+<span class="number">1</span>) %<span class="number">200</span> == <span class="number">0</span>:</span><br><span class="line">            _,y_pre = torch.max(out,<span class="number">-1</span>)</span><br><span class="line">            acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float)))</span><br><span class="line">            print(<span class="string">'epoch: %d \t batch_idx : %d \t loss: %.4f \t train acc: %.4f'</span></span><br><span class="line">                  %(epoch,batch_idx,loss,acc))</span><br><span class="line">    </span><br><span class="line">    val_accs = []</span><br><span class="line">    <span class="keyword">for</span> batch_idx, batch <span class="keyword">in</span> enumerate(val_iter):</span><br><span class="line">        data = batch.Phrase</span><br><span class="line">        target = batch.Sentiment</span><br><span class="line">        target = torch.sparse.torch.eye(<span class="number">5</span>).index_select(dim=<span class="number">0</span>, index=target.cpu().data)</span><br><span class="line">        target = target.to(DEVICE)</span><br><span class="line">        data = data.permute(<span class="number">1</span>,<span class="number">0</span>)</span><br><span class="line">        out = model(data)</span><br><span class="line">        </span><br><span class="line">        _,y_pre = torch.max(out,<span class="number">-1</span>)</span><br><span class="line">        acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float)))</span><br><span class="line">        val_accs.append(acc)</span><br><span class="line">    </span><br><span class="line">    acc = np.array(val_accs).mean()</span><br><span class="line">    <span class="keyword">if</span> acc &gt; best_val_acc:</span><br><span class="line">        print(<span class="string">'val acc : %.4f &gt; %.4f saving model'</span>%(acc,best_val_acc))</span><br><span class="line">        torch.save(model.state_dict(), <span class="string">'params.pkl'</span>)</span><br><span class="line">        best_val_acc = acc</span><br><span class="line">    print(<span class="string">'val acc: %.4f'</span>%(acc))</span><br></pre></td></tr></table></figure>
<p>转载<a href="https://blog.csdn.net/JWoswin/article/details/92821752" target="_blank" rel="noopener">Torchtext使用教程</a></p>

    </div>

    
    
    

	
        
      
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>Snow</li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/" title="python_torchtext学习笔记_2">https://behappy00.github.io/2021/01/03/python_torchtext学习笔记_2/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！</li>
</ul>
</div>

      

      <footer class="post-footer">
          
            
          
          <div class="post-tags">
            
              <a href="/tags/转载/" rel="tag"># 转载</a>
            
              <a href="/tags/python/" rel="tag"># python</a>
            
              <a href="/tags/python模块学习/" rel="tag"># python模块学习</a>
            
          </div>
        

        

          <div class="post-nav">
            <div class="post-nav-next post-nav-item">
              
                <a href="/2021/01/03/pytorch_torchtext学习笔记_2/" rel="next" title="pytorch_torchtext学习笔记_2">
                  <i class="fa fa-chevron-left"></i> pytorch_torchtext学习笔记_2
                </a>
              
            </div>

            <span class="post-nav-divider"></span>

            <div class="post-nav-prev post-nav-item">
              
                <a href="/2021/01/03/python_torchtext学习笔记_1/" rel="prev" title="python_torchtext学习笔记_1">
                  python_torchtext学习笔记_1 <i class="fa fa-chevron-right"></i>
                </a>
              
            </div>
          </div>
        
      </footer>
    
  </div>
  
  
  
  </article>

  </div>


          </div>
          
    
    <div class="comments" id="comments"></div>
  

        </div>
          
  
		
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">
        
        
        
        
      

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#主要内容："><span class="nav-number">1.</span> <span class="nav-text">主要内容：</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#torchtext预处理流程："><span class="nav-number">1.1.</span> <span class="nav-text">torchtext预处理流程：</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-定义Field："><span class="nav-number">1.1.1.</span> <span class="nav-text">1. 定义Field：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-定义Dataset："><span class="nav-number">1.1.2.</span> <span class="nav-text">2. 定义Dataset：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-建立vocab："><span class="nav-number">1.1.3.</span> <span class="nav-text">3. 建立vocab：</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-构造迭代器："><span class="nav-number">1.1.4.</span> <span class="nav-text">4. 构造迭代器：</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#实操"><span class="nav-number">1.2.</span> <span class="nav-text">实操</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#1-下载数据："><span class="nav-number">1.2.1.</span> <span class="nav-text">1. 下载数据：</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#读取文件，查看文件"><span class="nav-number">1.2.1.1.</span> <span class="nav-text">读取文件，查看文件</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#train-tsv"><span class="nav-number">1.2.1.1.1.</span> <span class="nav-text">train.tsv</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#test-tsv"><span class="nav-number">1.2.1.1.2.</span> <span class="nav-text">test.tsv</span></a></li></ol></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#2-划分验证集"><span class="nav-number">1.2.2.</span> <span class="nav-text">2. 划分验证集</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#3-定义Field"><span class="nav-number">1.2.3.</span> <span class="nav-text">3. 定义Field</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#4-定义Dataset"><span class="nav-number">1.2.4.</span> <span class="nav-text">4. 定义Dataset</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#5-建立vocab"><span class="nav-number">1.2.5.</span> <span class="nav-text">5. 建立vocab</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#6-构造迭代器"><span class="nav-number">1.2.6.</span> <span class="nav-text">6. 构造迭代器</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#迭代器使用"><span class="nav-number">1.2.6.1.</span> <span class="nav-text">迭代器使用</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-完整代码"><span class="nav-number">1.2.7.</span> <span class="nav-text">7. 完整代码</span></a></li></ol></li></ol></li></ol></div>
        
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Snow</p>
  <div class="site-description" itemprop="description">计算机 Hiter</div>
</div>
  <nav class="site-state motion-element">
      <div class="site-state-item site-state-posts">
        
          <a href="/archives/">
        
          <span class="site-state-item-count">150</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-categories">
        
          
            <a href="/categories/">
          
        
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span>
        </a>
      </div>
    
      
      
      <div class="site-state-item site-state-tags">
        
          
            <a href="/tags/">
          
        
        <span class="site-state-item-count">50</span>
        <span class="site-state-item-name">标签</span>
        </a>
      </div>
    
  </nav>
  <div class="feed-link motion-element">
    <a href="/atom.xml" rel="alternate">
      <i class="fa fa-rss"></i>RSS
    </a>
  </div>



      </div>

	 <!-- 添加近期文章 -->
	 
	   <div class="links-of-blogroll motion-element links-of-blogroll-block">
		 <div class="links-of-blogroll-title">
		   <!-- modify icon to fire by szw -->
		   <i class="fa fa-history fa-" aria-hidden="true"></i>
		   近期文章
		 </div>
		 <ul class="links-of-blogroll-list">
		   
		   
			 <li>
			   <a href="/2023/10/15/vue在线预览word的五种姿态/" title="vue在线预览word的五种姿态" target="_blank">vue在线预览word的五种姿态</a>
			 </li>
		   
			 <li>
			   <a href="/2023/10/15/vue3页面加载完成后获取宽度和高度/" title="vue3页面加载完成后获取宽度和高度" target="_blank">vue3页面加载完成后获取宽度和高度</a>
			 </li>
		   
			 <li>
			   <a href="/2023/10/15/java中用springboot连接oracle数据库/" title="java中用springboot连接oracle数据库" target="_blank">java中用springboot连接oracle数据库</a>
			 </li>
		   
			 <li>
			   <a href="/2023/10/12/BT知识科普/" title="BT知识科普" target="_blank">BT知识科普</a>
			 </li>
		   
			 <li>
			   <a href="/2023/10/03/Java截取（提取）子字符串/" title="Java截取（提取）子字符串" target="_blank">Java截取（提取）子字符串</a>
			 </li>
		   
		 </ul>
	   </div>
	 
	  
	  <!-- 添加网易云播放歌曲 -->
	  <div id="music163player">
		<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=110 src="//music.163.com/outchain/player?type=0&id=5457006033&auto=0&height=90"></iframe>
		</iframe>
	  </div>
  
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; 2018 – <span itemprop="copyrightYear">2023</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Snow</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">587k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">8:54</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="我的第 undefined 位朋友">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  
    <span class="post-meta-divider">|</span>
  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="历经 undefined 次回眸才与你相遇">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>












        
      </div>
    </footer>
  </div>

  


  <script src="/lib/anime.min.js?v=3.1.0"></script>
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@2.1.3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
<script src="/js/utils.js?v=7.4.0"></script><script src="/js/motion.js?v=7.4.0"></script>
<script src="/js/schemes/pisces.js?v=7.4.0"></script>
<script src="/js/next-boot.js?v=7.4.0"></script>



  








  <script src="/js/local-search.js?v=7.4.0"></script>














  

  

  

  


  <!--

<script>
  $(document).ready(function () {
    $(".header-inner").animate({padding: "25px 0 25px"}, 1000);
  });
</script>



  <script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"></script>
  <script>
    function timer() {
      var ages = moment.preciseDiff(moment(),moment(20190628,"YYYYMMDD"));
      ages = ages.replace(/years?/, "年");
      ages = ages.replace(/months?/, "月");
      ages = ages.replace(/days?/, "天");
      ages = ages.replace(/hours?/, "小时");
      ages = ages.replace(/minutes?/, "分");
      ages = ages.replace(/seconds?/, "秒");
      ages = ages.replace(/\d+/g, '<span style="color:#1094e8">$&</span>');
      div.innerHTML = `我已在此等候你 ${ages}`;
    }
    var div = document.createElement("div");
    //插入到copyright之后
    var copyright = document.querySelector(".copyright");
    document.querySelector(".footer-inner").insertBefore(div, copyright.nextSibling);
    timer();
    setInterval("timer()",1000)
  </script>
-->

<script>
NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
  var GUEST = ['nick', 'mail', 'link'];
  var guest = 'nick,mail';
  guest = guest.split(',').filter(item => {
    return GUEST.includes(item);
  });
  new Valine({
    el: '#comments',
    verify: false,
    notify: false,
    appId: 'nClDgsEbJJCRM7oMK99qaGCi-MdYXbMMI',
    appKey: 'IHpqCV0C6qKHHw7TnYT4gHHl',
    placeholder: 'Just go go',
    avatar: 'mm',
    meta: guest,
    pageSize: '10' || 10,
    visitor: true,
    lang: 'zh-CN' || 'zh-cn',
    path: location.pathname
  });
}, window.Valine);
</script>

  
  <!--页面点击出现富强民主文明和谐-->
 <script type="text/javascript" src="/js/words-click.js"></script > 

  <!-- 代码块复制功能 -->
  <script type="text/javascript" src="/js/src/clipboard.min.js"></script>  
  <!--
  <script type="text/javascript" src="/js/src/clipboard-use.js"></script>
  -->
  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"scale":1,"hHeadPos":0.5,"vHeadPos":0.618,"jsonPath":"/live2dw/assets/hijiki.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true,"scale":0.05},"react":{"opacityDefault":0.7,"opacityOnHover":0.2}});</script></body>
</html>

