<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[markdown汇总]]></title>
    <url>%2F2023%2F10%2F03%2Fmarkdown%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1.Markdown使用TOC自动生成导航栏 2.markdown让文字居中和带颜色 3.markdown 文本内跳转,生成目录 4.Markdown 前景色、背景色 5.Markdown-图片设置（大小，居中） 6.MarkDown语法进阶（三）（文字居中、图片处理、插入视频音乐、标准字体） 7.VSCode之Markdown自动生成目录#TOC#解决目录不整齐问题 8.MarkDown设置图片居中显示并调整大小 9.Markdown公式、特殊字符、上下标、求和/积分、分式/根式、字体 10.Markdown 最全数学符号与公式速查 11.Markdown mermaid种草(3)_ 流程图 12.用markdown来画流程图 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1.Markdown使用TOC自动生成导航栏 2.markdown让文字居中和带颜色 3.markdown 文本内跳转,生成目录 4.Markdown 前景色、背景色 5.Markdown-图片设置（大小，居中） 6.MarkDown语法进阶（三）（文字居中、图片处理、插入视频音乐、标准字体） 7.VSCode之Markdown自动生成目录#TOC#解决目录不整齐问题 8.MarkDown设置图片居中显示并调整大小 9.Markdown公式、特殊字符、上下标、求和/积分、分式/根式、字体 10.Markdown 最全数学符号与公式速查 11.Markdown mermaid种草(3)_ 流程图 12.用markdown来画流程图]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客搜索显示异样]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E6%90%9C%E7%B4%A2%E6%98%BE%E7%A4%BA%E5%BC%82%E6%A0%B7%2F</url>
    <content type="text"><![CDATA[问题描述 问题分析 解决 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 问题描述今天发现自己博客搜索出来的文章标题显示有些奇怪，如下图 问题分析通过F12查看发现类别为 search-result-title 然后通过VSCODE打开NEXT主题文件夹，在next主题中全局搜索 search-result-title 找到文件*\source\js\local-search.js 最后修改相应结果 12添加如下字符.replace(&apos;]]&gt;&apos;, &apos;&apos;) 解决]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown使用TOC自动生成导航栏]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown%E4%BD%BF%E7%94%A8TOC%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E5%AF%BC%E8%88%AA%E6%A0%8F%2F</url>
    <content type="text"><![CDATA[0x00 安装 0x01 命令行 0x02 亮点 0x03 用法 0x04 API 0x05 选项 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/demonxian3/p/11001295.html 自己写的基本思路就是 轮询监听滚动条的位置，通过抛锚和跳锚实现 插件 markdown-toc 0x00 安装TOC = Table of content ， 将内容制作成导航 这个插件是基于 nodejs 的，因此需要安装 node 和 npm ，这里同样采用nvm的形式安装 123nvm list -remotenvm install v10.16.0node -v 安装好nvm后，就可以使用npm 安装插件了 1npm install --save markdown-toc 0x01 命令行这个插件带Cli命令，使用帮助如下 1markdown-doc \[选项\] &lt;输入&gt; &lt;输入&gt; 表示需要使用 TOC 的 markdown 文件，可以通过标准输入读取 [选项] -i直接往 &lt;输入&gt; 的文件注入TOC标识符： &lt;!-- toc --&gt;，如果没有这个参数就输出到屏幕，不修改md文件--json通过json格式打印TOC--append在字符串的后面追加TOC--bullets指定需要被生成TOC项的标识符号，可以指定多个： --bullets "*" --bullets "+"--maxdepthTOC最大深度，就是可以折叠多少层，默认6层--no-stripHeadingTags在强力功能前，不删去标题无关的HTML标签 0x02 亮点特点： 1. 可根据自己的需求生成TOC模板 2. 对重复标题生效 3. 默认采用sane，也可以自己定制 4. 过滤器可以筛掉你不想要的标题 5. 导入期可以导入你想加入的标题 6. 可以使用强劲的函数来改变链接生成 7. 可作为 remarkable 的插件使用 很安全： 不会像其他TOC生成器一样，破坏前面的内容，或将前面的内容属性误认为标题 0x03 用法123456var toc = require(&apos;markdown-toc&apos;);toc(&apos;# One\\n\\n# Two&apos;).content;// Results in:// - \[One\](#one)// - \[Two\](#two) 为了自定义输出，下面有几个属性将会返回 - content 自动生成导航导航的内容，你可以自定义样式 - highest 找到最高的等级标题，用于重新调整缩进 - tokens 可自定义的标题符号 0x04 API1 - toc.plugin 作为 remarkable 插件使用，如下： 12345678var Remarkable = require(&apos;remarkable&apos;);var toc = require(&apos;markdown-toc&apos;);function render(str, options) &#123; return new Remarkable() .use(toc.plugin(options)) // &lt;= register the plugin .render(str);&#125; 使用实例 1var results = render(&apos;# AAA\\n# BBB\\n# CCC\\nfoo\\nbar\\nbaz&apos;); 2 - toc.json 可生成json格式的TOC对象 123456toc(&apos;# AAA\\n## BBB\\n### CCC\\nfoo&apos;).json;// results in\[ &#123; content: &apos;AAA&apos;, slug: &apos;aaa&apos;, lvl: 1 &#125;, &#123; content: &apos;BBB&apos;, slug: &apos;bbb&apos;, lvl: 2 &#125;, &#123; content: &apos;CCC&apos;, slug: &apos;ccc&apos;, lvl: 3 &#125; \] 3 - toc.insert 在想插入TOC的位置写上 或者 内容 (使用注释作为占位符可以避免破坏原本的代码) 1234567891011&lt;!-- toc --&gt;- old toc 1- old toc 2- old toc 3&lt;!-- tocstop --&gt;## abcThis is a b c.## xyzThis is x y z. 结果是 12345678910&lt;!-- toc --&gt;- \[abc\](#abc)\- \[xyz\](#xyz)&lt;!-- tocstop --&gt;## abcThis is a b c.## xyzThis is x y z. 4 - 通用函数 为了方便给想定制TOC的用户folk一份，插件提供了一些通用函数 toc.bullets(): 通过数组获取标题标记符 toc.linkify(): 链接到一个标题字符 toc.slugify(): 从标题字符中应用强力函数 toc.strip(): 从标题字符中去掉某些字符 例子 123456var result = toc(&apos;# AAA\\n## BBB\\n### CCC\\nfoo&apos;);var str = &apos;&apos;;result.json.forEach(function(heading) &#123; str += toc.linkify(heading.content);&#125;); 0x05 选项1 - 追加 (append) 追加一些字符串到匹配的标题标识符后面 1toc(str, &#123;append: &apos;\\n\_(TOC generated by Verb)\_&apos;&#125;); 2 - 过滤 (filter) 类型： 函数 默认: undefined 参数： str 命中的标题字符串 ele 标题记号对象 arr 所有的标题对象 过滤掉一些极端的匹配命中的标题，如下就是一个坏标题 1\[.aaa(\[foo\], ...) another bad heading\](#-aaa--foo--------another-bad-heading) 为了去除这种极端的情况，可以使用过滤器筛掉 123456function removeJunk(str, ele, arr) &#123; return str.indexOf(&apos;...&apos;) === -1;&#125;var result = toc(str, &#123;filter: removeJunk&#125;);//\=&gt; beautiful TOC 3 - 强劲(slugify) 类型: 函数 默认: 默认替换掉特殊符号 例子 1var str = toc(&apos;# Some Article&apos;, &#123;slugify: require(&apos;uslug&apos;)&#125;); 4 - 符号(bullet) 类型： 字符或者数组 默认： * 就是层叠的列表符号，传入数组 [‘*‘, ‘-‘, ‘+’] 5 - 首项 (first1) 类型：布尔 默认： true 排除文件中的第一个h1级标题。这样可以防止自述文件中的第一个标题出现在TOC中 6 - 最大深度 (first1) 类型： 数字 默认： 6 最大深度 6 - 去除头部标签(stripHeadingTags) 类型:布尔 默认: true 去除多余的标记，类似github 的 markdown 表现 本文转自 https://www.cnblogs.com/demonxian3/p/11001295.html，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>自动导航栏</tag>
        <tag>插件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown让文字居中和带颜色]]></title>
    <url>%2F2023%2F10%2F02%2Fmarkdown%E8%AE%A9%E6%96%87%E5%AD%97%E5%B1%85%E4%B8%AD%E5%92%8C%E5%B8%A6%E9%A2%9C%E8%89%B2%2F</url>
    <content type="text"><![CDATA[1.说明 2.文字的居中 3.文字的字体及颜色 3.1 字体更换 3.2 大小更换 3.3 颜色替换 4 总结 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/bigmagic/p/3301b25e8b0b8ef8b9415379385a798c.html 1.说明本文主要叙述如何写出更加优美的markdown文档。在我们观看文档的过程中，良好的格式将会带来很大的收益。对于不同颜色的字体也并不会显得花里胡哨，只会让我们表达的内容更加的清晰。下面来具体的看一下操作的流程。 2.文字的居中对于标准的markdown文本，是不支持居中对齐的。还好markdown支持html语言，所以我们采用html语法格式即可。 1&lt;center&gt;这一行需要居中&lt;/center&gt; 下面就是排版后的结果 这一行需要居中 3.文字的字体及颜色3.1 字体更换同样我们也需要遵照其标准的语法格式 1&lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt; 下面是测试结果 3.2 大小更换大小为size 1&lt;font face=&quot;黑体&quot; size=10&gt;我是黑体字&lt;/font&gt; 3.3 颜色替换对于html语音中，颜色是用color来表示，所以可以表示如下 1&lt;font color=red size=72&gt;颜色&lt;/font&gt; 效果如下 4 总结善用markdown语法，记住markdown语法是兼容html预言的，这很重要。 本文转自 https://www.cnblogs.com/bigmagic/p/3301b25e8b0b8ef8b9415379385a798c.html，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>文字居中</tag>
        <tag>图片颜色</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown 文本内跳转,生成目录]]></title>
    <url>%2F2023%2F10%2F02%2Fmarkdown-%E6%96%87%E6%9C%AC%E5%86%85%E8%B7%B3%E8%BD%AC-%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95%2F</url>
    <content type="text"><![CDATA[1.生成目录的方法 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/dss_dssssd/article/details/82959037 1.生成目录的方法12345678910111213141516171819* [一.数据集获取及预处理](#1) * [1 数据集导入](#1.1) * [2数据集划分](#1.2) * [二、binary classification 二元分类器](#2) * [自己实现交叉验证函数](#2.1) * [confusion matrix](#2.2) * [precision/recall tradeoff](#2.3) * [Precision/Recall曲线](#2.4) * [ ROC 曲线](#2.5) * [AUC](#2.6) * [ 三、Multiclass Classification](#3) * [Error Analysis](#3.1) * [numpy broadcast](#3.2) * [四、 Multilabel Classification 多标签分类](#4) * [五、Multioutput Classification](#5) 在正文中，只要将章节标题的id对应上去即可: 1234### &lt;h2 id=&quot;1&quot;&gt;一.数据集获取及预处理&lt;/h2&gt;#### &lt;h2 id=&quot;1.1&quot;&gt;1. 数据集导入&lt;/h2&gt;#### &lt;h2 id=&quot;1.2&quot;&gt;2.数据集划分&lt;/h2&gt; 以下为实现效果图： 一.数据集获取及预处理 1 数据集导入 2数据集划分 二、binary classification 二元分类器 自己实现交叉验证函数 confusion matrix precision/recall tradeoff Precision/Recall曲线 ROC 曲线 AUC 三、Multiclass Classification Error Analysis numpy broadcast 四、 Multilabel Classification 多标签分类 五、Multioutput Classification 本文转自 https://blog.csdn.net/dss_dssssd/article/details/82959037，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>自动导航栏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 前景色、背景色]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown-%E5%89%8D%E6%99%AF%E8%89%B2%E3%80%81%E8%83%8C%E6%99%AF%E8%89%B2%2F</url>
    <content type="text"><![CDATA[1. 前言 2. 语法详解 2.1 前景色 2.2 背景色 3. 使用场景及应用实例 小结 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： Markdown 入门教程 10 Markdown 字体字号 12 Markdown 行内代码 1. 前言颜色可以使普通文字表达出更深刻的含义，比如红色用于醒目与警示、绿色用于表达良好与正常等。 Markdown 使普通文本具有格式，但它的原生语法并不支持修改前景色和背景色。为了实现丰富文本颜色的需求，我们需要通过增加 HTML 标签实现此类效果。 环境说明：考虑到 Markdown 工具之间的不兼容，有的内容直接从页面复制粘贴到本地不会正常显示，大家学习时自己动手写是肯定没问题的。本节所有实例代码及演示效果均使用 Typora 工具完成。本节所有截图均为 Typora 导出为 HTML 后渲染效果。 2. 语法详解2.1 前景色在 Markdown 文件中，建议使用 &lt;font&gt; 标签的 color 属性修改文字颜色。 实例 1： 123456789#### 使用 `&lt;font&gt;` 的标签的修改文字前景色&lt;font color=&quot;red&quot;&gt;红色&lt;/font&gt;&lt;font color=&quot;green&quot;&gt;绿色&lt;/font&gt;&lt;font color=&quot;blue&quot;&gt;蓝色&lt;/font&gt;&lt;font color=&quot;rgb(200, 100, 100)&quot;&gt;使用 rgb 颜色值&lt;/font&gt;&lt;font color=&quot;#FF00BB&quot;&gt;使用十六进制颜色值&lt;/font&gt; 渲染结果如下： 除了修改 color 属性外，还可以使用 style 样式属性修改文字颜色。 实例 2： 123456789#### 使用 `style` 的标签的修改文字前景色&lt;font style=&quot;color: red&quot;&gt;红色&lt;/font&gt;&lt;font style=&quot;color: green&quot;&gt;绿色&lt;/font&gt;&lt;font style=&quot;color: blue&quot;&gt;蓝色&lt;/font&gt;&lt;font style=&quot;color: rgb(200,100,100)&quot;&gt;使用 rgb 颜色值&lt;/font&gt;&lt;font style=&quot;color: #FF00BB&quot;&gt;使用十六进制颜色值&lt;/font&gt; 其渲染结果如下： 2.2 背景色Markdown 文档中定义文字背景色需要通过修改 style 样式实现。 实例 3： 123456789#### 使用 `style` 属性修改文字的背景色&lt;font style=&quot;background: red&quot;&gt;红色&lt;/font&gt;&lt;font style=&quot;background: green&quot;&gt;绿色&lt;/font&gt;&lt;font style=&quot;background: blue&quot;&gt;蓝色&lt;/font&gt;&lt;font style=&quot;background: rgb(200,100,100)&quot;&gt;使用 rgb 颜色值&lt;/font&gt;&lt;font style=&quot;background: #FF00BB&quot;&gt;使用十六进制颜色值&lt;/font&gt; 其渲染结果如下： 实例 4： 利用 style 的丰富样式，我们可以定义出丰富的文字形式。 123456789#### 更丰富背景样式## &lt;font style=&quot;background: url(&apos;http://www.wenliku.com/d/file/patterns/2019-06-26/d8fac26c38c9b2a7e2393fc9af766e8f.jpg&apos;) &quot;&gt;I wish you a Merry Christmas&lt;/font&gt;使用图片作背景## &lt;font style=&quot;background: linear-gradient( to right, #ff1616, #ff7716, #ffdc16, #36c945, #10a5ce, #0f0096, #a51eff, #ff1616);&quot;&gt;太阳太阳，给我们带来，七色光彩&lt;/font&gt;渐变背景色 其渲染结果如下： 3. 使用场景及应用实例利用前景色和背景色、以及字体字号等样式，我们可以定义出丰富的渲染主题，以适应不同的设备或阅读需求，比如阅读类 APP 中常见的夜晚模式、笔记类 APP 的更换纸张的效果等。 实例 5： 夜晚模式效果。 1234567891011121314#### 夜读模式##### 《春》 朱自清盼望着，盼望着，东风来了，春天的脚步近了。一切都像刚睡醒的样子，欣欣然张开了眼。山朗润起来了，水涨起来了，太阳的脸红起来了。小草偷偷地从土里钻出来，嫩嫩的，绿绿的。园子里，田野里，瞧去，一大片一大片满是的。坐着，躺着，打两个滚，踢几脚球，赛几趟跑，捉几回迷藏。风轻悄悄的，草软绵绵的。&lt;style&gt;body &#123; background-color: #000 !important; &#125;h1,h2,h3,h4,h5,h6,h7,p &#123; color: #999 !important; &#125;&lt;/style&gt; 其渲染结果如下： 小结 同一颜色值在不同显示器上会有色差，选取颜色时尽量使用安全色。 为了确保整篇文章的整体风格一致，通常只需要配置全局的前景色和背景色即可。 对于颜色，请尽量使用柔和的颜色，防止刺伤眼睛。 本文转自 http://www.imooc.com/wiki/markdownlesson/markdowncolor.html，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>背景色</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown-图片设置（大小，居中）]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown-%E5%9B%BE%E7%89%87%E8%AE%BE%E7%BD%AE%EF%BC%88%E5%A4%A7%E5%B0%8F%EF%BC%8C%E5%B1%85%E4%B8%AD%EF%BC%89%2F</url>
    <content type="text"><![CDATA[图片位置-居左/居中/居右 图片大小 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/qq_35451572/article/details/79443467 图片位置-居左/居中/居右利用markdown在编写文档时插入图片是默认靠左，有些时候将图片设置为居中时可以更加的美观，这时就需要在图片的信息前边添加如下程序 1&lt;div align=center&gt;![这里写图片描述](http:...) 如果想将图片位于右侧，只需要将center改为right 1&lt;div align=right&gt;![这里写图片描述](http:...) 图片大小1&lt;img src=&quot;http:...&quot; width = &quot;100&quot; height = &quot;100&quot; div align=right /&gt; 如上格式，在图片的最后添加 width = “100” height = “100”，就可以设置图片的大小。也可以在后边输入百分比为多少，如 width = 20% height = 20% 1&lt;img src=&quot;http:...&quot; width = 30% height = 30% /&gt; 本文转自 https://blog.csdn.net/qq_35451572/article/details/79443467，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>图片</tag>
        <tag>居中</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown语法进阶（三）（文字居中、图片处理、插入视频音乐、标准字体）]]></title>
    <url>%2F2023%2F10%2F02%2FMarkDown%E8%AF%AD%E6%B3%95%E8%BF%9B%E9%98%B6%EF%BC%88%E4%B8%89%EF%BC%89%EF%BC%88%E6%96%87%E5%AD%97%E5%B1%85%E4%B8%AD%E3%80%81%E5%9B%BE%E7%89%87%E5%A4%84%E7%90%86%E3%80%81%E6%8F%92%E5%85%A5%E8%A7%86%E9%A2%91%E9%9F%B3%E4%B9%90%E3%80%81%E6%A0%87%E5%87%86%E5%AD%97%E4%BD%93%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1、文字居中： 2、插入图片及图片居中、定义大小 3、插入音乐 4、插入视频 5、跳转链接 6、使用标准字体 7、多种矩阵形式输入 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/m0_37925202/article/details/80461714 Markdown编辑器本身是内容写作工具，本身并不支持文字排版，理论上它只是指出哪些内容是表格、哪些内容是标题、哪些是正文图片代码超链。 但是由于markdown需要输出，自带html/css整合，因此需要指定格式时可以通过内嵌html或者内嵌css来实现。 如果对Markdown 语法不够熟悉，可以查看下面两篇博客： MarkDown下载以及入门语法（一） Markdown字体大小颜色、大小、背景色 （二） 1、文字居中：1&lt;center&gt;诶嘿&lt;/center&gt; 左对齐： 1&lt;p align=&quot;left&quot;&gt;诶嘿&lt;/p&gt; 2、插入图片及图片居中、定义大小 让图片靠左 显示 基本形式是：![这里放图片描述](这里放图片链接)例子：![这里描述了***样的图片](https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE4wHfY?ver=4766) 定义尺寸 &lt;img width = &#39;150&#39; height =&#39;150&#39; src =&quot;https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE4wHfY?ver=4766&quot;/&gt; 定义大小并居中显示 &lt;div align=center&gt;&lt;img width = &#39;150&#39; height =&#39;150&#39; src =&quot;https://img-prod-cms-rt-microsoft-com.akamaized.net/cms/api/am/imageFileData/RE4wHfY?ver=4766&quot;/&gt;&lt;/div&gt; 3、插入音乐&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;//music.163.com/outchain/player?type=2&amp;id=528478901&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt; 4、插入视频 不支持优酷，可以用youtube。 &lt;iframe width=&quot;560&quot; height=&quot;315&quot; src=&quot;https://www.youtube.com/embed/Ilg3gGewQ5U&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt; 5、跳转链接12345&lt;a href=&quot;http://askunix.top/&quot; target=&quot;_blank&quot;&gt;跳到自己博客列表&lt;/a&gt;跳到自己博客列表：&lt;a href=&quot;http://askunix.top/&quot; target=&quot;_blank&quot;&gt;http://askunix.top/&lt;/a&gt; 跳到自己博客列表跳到自己博客列表：http://askunix.top/ 6、使用标准字体123&lt;font face=&quot;黑体&quot;&gt;我是黑体字&lt;/font&gt;&lt;font face=&quot;微软雅黑&quot;&gt;我是微软雅黑&lt;/font&gt;&lt;font face=&quot;STCAIYUN&quot;&gt;我是华文彩云&lt;/font&gt; 7、多种矩阵形式输入 不带括号的： 1234$$\begin&#123;matrix&#125;1&amp;2 \\ 3&amp;4 \\ 5&amp;6\end&#123;matrix&#125;$$ 带大括号的： 123456$$\left\&#123;\begin&#123;matrix&#125;1&amp;2 \\ 3&amp;4 \\ 5&amp;6\end&#123;matrix&#125;\right\&#125;$$ 带中括号的 123456$$\left[\begin&#123;matrix&#125;1&amp;2 \\ 3&amp;4 \\ 5&amp;6\end&#123;matrix&#125;\right]$$ 本文转自 https://blog.csdn.net/m0_37925202/article/details/80461714，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>图片</tag>
        <tag>文字</tag>
        <tag>居中</tag>
        <tag>视频</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VSCode之Markdown自动生成目录#TOC#解决目录不整齐问题]]></title>
    <url>%2F2023%2F10%2F02%2FVSCode%E4%B9%8BMarkdown%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95-TOC-%E8%A7%A3%E5%86%B3%E7%9B%AE%E5%BD%95%E4%B8%8D%E6%95%B4%E9%BD%90%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[一 、下载插件 二、生成目录 三、可能出现的问题及解决 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/qq_34243930/article/details/104144428 一 、下载插件（1）在扩展里，搜索“Markdown”，在列表里选择Markdown的插件。（2）例如“Markdown TOC”，这是一个专门生产目录的插件。点击安装 二、生成目录在你想添加目录的地方右击选择“Markdown TOC:Insert/Update” 三、可能出现的问题及解决VSCode中Markdown目录显示异常TOC标签格式异常出现如下auto的文字 原因：默认行尾字符格式问题。解决：1、点击界面左下方的设置按钮2、选择设置进入到用户设置界面。3、打开用户设置之后在搜索设置里面搜索Eol。4、找到文件的Eol可以看到默认行尾字符设置为auto。 点击选项框然后将auto更改为\n换行符即可。 回到Markdown编辑界面然后重新生成Markdown目录就能显示正常了 本文转自 https://blog.csdn.net/qq_34243930/article/details/104144428，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>自动导航栏</tag>
        <tag>插件</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown设置图片居中显示并调整大小]]></title>
    <url>%2F2023%2F10%2F02%2FMarkDown%E8%AE%BE%E7%BD%AE%E5%9B%BE%E7%89%87%E5%B1%85%E4%B8%AD%E6%98%BE%E7%A4%BA%E5%B9%B6%E8%B0%83%E6%95%B4%E5%A4%A7%E5%B0%8F%2F</url>
    <content type="text"><![CDATA[Markdown图片的一般格式 一行代码让图片显示居中 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://yunlong.blog.csdn.net/article/details/107575128?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control Markdown图片的一般格式1! [] () ” [] “中是图片描述 ” () “是图片的URL(本地或网络). 显示出来的效果(未居中和更改大小) 一行代码让图片显示居中1&lt;div align=center&gt;&lt;img src=&quot;url&quot; width=&quot; &quot;&gt;&lt;/div&gt; 其中url是要插入的图片的链接，width是修改图片的尺寸，去掉该选项后图片则以原画显示。 带有调整尺寸的居中显示 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot; width=&quot;200&quot;&gt;&lt;/div&gt; 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot; width=&quot;300&quot;&gt;&lt;/div&gt; 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot; width=&quot;400&quot;&gt;&lt;/div&gt; 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot; width=&quot;500&quot;&gt;&lt;/div&gt; 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot; width=&quot;600&quot;&gt;&lt;/div&gt; 去掉调整尺寸的原画居中显示 1&lt;div align=center&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/20200725104000982.png&quot;&gt;&lt;/div&gt; 本文转自 https://yunlong.blog.csdn.net/article/details/107575128?utm_medium=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control&amp;depth_1-utm_source=distribute.pc_relevant_t0.none-task-blog-BlogCommendFromBaidu-1.control，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown公式、特殊字符、上下标、求和/积分、分式/根式、字体]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown%E5%85%AC%E5%BC%8F%E3%80%81%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6%E3%80%81%E4%B8%8A%E4%B8%8B%E6%A0%87%E3%80%81%E6%B1%82%E5%92%8C-%E7%A7%AF%E5%88%86%E3%80%81%E5%88%86%E5%BC%8F-%E6%A0%B9%E5%BC%8F%E3%80%81%E5%AD%97%E4%BD%93%2F</url>
    <content type="text"><![CDATA[1. 公式标记 2. 特殊字符 3. 上标/下标 4. 括号 5. 求和/积分 6. 分式/根式 7. 字体 8. 居中 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/weixin_42546496/article/details/88115095 1. 公式标记Markdown两种输入公式的方法：一是行内公式（inline），用一对美元符号“$”包裹。二是整行公式（displayed），用一对紧挨的两个美元符号“ $$ ”包裹。 这是一个行内公式： ( W 1 − W 2 ) x + b 1 − b 2 = 0 (W_1−W_2)x+b_1−b_2=0 (W1​−W2​)x+b1​−b2​\=0写法是：$(W_1−W_2)x+b_1−b_2=0$ 这是一个整行公式：( W 1 − W 2 ) x + b 1 − b 2 = 0 (W_1−W_2)x+b_1−b_2=0 (W1​−W2​)x+b1​−b2​\=0写法是： (W\_1−W\_2)x+b\_1−b\_2=0 2. 特殊字符 名称 大写 写法 小写 写法 alpha A A α \alpha beta B B β \beat gamma Γ \Gamma γ \gamma delta Δ \Delta δ \delta epsilon E E ϵ \epsilon zeta Z Z ζ \zeta eta H H η \eta theta Θ \Theta θ \theta iota I I ι \iota kappa K K κ \kappa lambda Λ \Lambda λ \lambda mu M M μ \mu nu N N ν \nu xi Ξ \Xi ξ \xi omicron O O ο \omicron pi Π \Pi π \pi rho P P ρ \rho sigma Σ \Sigma σ \sigma tau T T τ \tau upsilon Υ \Upsilon υ \upsilon phi Φ \Phi ϕ \phi chi X X χ \chi psi Ψ \Psi ψ \psi omega Ω \Omega ω \omega 3. 上标/下标上标和下标分别使用^和_来实现。例如:$x_i^2$ == x i 2 x_i^2 xi2​$log_2^x$ == l o g 2 x log_2^x log2x​ 默认情况下，上下标符号仅仅对下一个字符作用。一组字符使用{}包裹起来的内容。也就是说，如果使用$10^10$会得到 1 0 1 0 10^10 1010，而$10^{10}$ 才是 1 0 10 10^{10} 1010。同时，大括号还能消除二义性，如$x^5^6$ 会显示错误，必须使用大括号来界定^ 的结合性，如${x^5}^6$ == x 5 6 {x^5}^6 x56或者$x^{5^6}$ == x 5 6 x^{5^6} x56。 另外，如果要在左右两边都有上下标，可以写为 ${^1_2}A{^3_4}$== 2 1 A 4 3 {^1_2}A{^3_4} 21​A43​ 4. 括号小括号与方括号：使用原始的()和[]即可。如$(2+3)[4+4]$== ( 2 + 3 ) [ 4 + 4 ] (2+3)[4+4] (2+3)[4+4]。大括号：由于大括号{}被用来分组，因此需要使用”\“转义字符\{和\}表示大括号。如$\{a*b\}$ == { a ∗ b } \{a∗b\} {a∗b}。尖括号：使用\langle和\rangle分别表示左尖括号和右尖括号。如$\langle x \rangle$ == ⟨ x ⟩ \langle x \rangle ⟨x⟩。上取整：使用\lceil和\rceil表示。如$\lceil x \rceil$ == ⌈ x ⌉ \lceil x \rceil ⌈x⌉。下取整：使用\lfloor和\rfloor表示。如$\lfloor x \rfloor$ == ⌊ x ⌋ \lfloor x \rfloor ⌊x⌋。 需要注意的是，原始括号并不会随着公式的大小自动缩放。如$(\frac12)$ == ( 1 2 ) (\frac12) (21​)。可以使用\left( …\right)来自适应的调整括号。如$\left( \frac12 \right)$ == ( 1 2 ) \left( \frac12 \right) (21​)。可以明显看出，后一组公式中的括号是经过缩放的。 5. 求和/积分\sum用来表示求和符号，其下标表示求和下限，上标表示上线。如$\sum_1^n$ == ∑ 1 n \sum_1^n ∑1n​。 \int用来表示积分符号，同样地，其上下标表示积分的上下限。如$\int_1^\infty$ == ∫ 1 ∞ \int_1^\infty ∫1∞​ 。 与此类似的符号还有：$\prod$ == ∏ \prod ∏$\bigcup$ == ⋃ \bigcup ⋃$\bigcap$ == ⋂ \bigcap ⋂$\iint$ == ∬ \iint ∬ 6. 分式/根式分式有两种表示方法。第一种：使用$\frac ab$，结果为 a b \frac ab ba​。如果分子或分母不是单个字符，需要使用{}来分组。第二种：使用\over来分隔一个组的前后两部分，如${a+1\over b+1}$ == a + 1 b + 1 {a+1\over b+1} b+1a+1​。 根式使用$\sqrt[a]b$来表示。其中，方括号内的值用来表示开几次方，省略方括号则表示开方，如$\sqrt[4]{\frac xy}$ == x y 4 \sqrt[4]{\frac xy} 4yx​ ​ ，$\sqrt{x^3}$ == x 3 \sqrt{x^3} x3 ​。 7. 字体 语法 效果 我是黑体字 我是黑体字 我是微软雅黑 我是微软雅黑 我是华文彩云 我是华文彩云 我是红色 我是红色 我是绿色 我是绿色 我是蓝色 我是蓝色 我是尺寸 我是尺寸 我是黑体，绿色，尺寸为5 我是黑体，绿色，尺寸为5 8. 居中居中语法：1&lt;center&gt; 串口通信程序&lt;br&gt;&lt;br&gt;&lt;/center &gt; 居中效果： 串口通信程序&lt;/center &gt; 本文转自 https://blog.csdn.net/weixin_42546496/article/details/88115095，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>居中</tag>
        <tag>公式字符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown 最全数学符号与公式速查]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown-%E6%9C%80%E5%85%A8%E6%95%B0%E5%AD%A6%E7%AC%A6%E5%8F%B7%E4%B8%8E%E5%85%AC%E5%BC%8F%E9%80%9F%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[1. 字母 1.1 希腊字母 1.2 数学模式重音符 1.3 字体转换 2. 关系符与运算符 2.1 二元关系符 2.2 二元运算符 2.3 其他符号 3. 公式 4. 其他 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/apr15/article/details/105597907 Markdown是一种可以使用普通文本编辑器编写的标记语言，通过简单的标记语法，它可以使普通文本内容具有一定的格式。Markdown中书写数学符号与公式时，只需在数学符号与公式前后同时添加“$”（不要留有空格）或“$$”即可。 1. 字母1.1 希腊字母小写 显示 语法 语法 语法 语法 语法 语法 语法 α \alpha α \alpha θ \theta θ \theta o o o o υ \upsilon υ \upsilon β \beta β \beta ϑ \vartheta ϑ \vartheta π \pi π \pi ϕ \phi ϕ \phi γ \gamma γ \gamma ι \iota ι \iota ϖ \varpi ϖ \varpi φ \varphi φ \varphi δ \delta δ \delta κ \kappa κ \kappa ρ \rho ρ \rho χ \chi χ \chi ϵ \epsilon ϵ \epsilon λ \lambda λ \lambda ϱ \varrho ϱ \varrho ψ \psi ψ \psi ε \varepsilon ε \varepsilon μ \mu μ \mu σ \sigma σ \sigma ω \omega ω \omega ζ \zeta ζ \zeta ν \nu ν \nu ς \varsigma ς \varsigma η \eta η \eta ξ \xi ξ \xi τ \tau τ \tau 大写 显示 语法 显示 语法 显示 语法 显示 语法 Γ \Gamma Γ \Gamma Λ \Lambda Λ \Lambda Σ \Sigma Σ \Sigma Ψ \Psi Ψ \Psi Δ \Delta Δ \Delta Ξ \Xi Ξ \Xi Υ \Upsilon Υ \Upsilon Ω \Omega Ω \Omega Θ \Theta Θ \Theta Π \Pi Π \Pi Φ \Phi Φ \Phi 1.2 数学模式重音符 显示 语法 显示 语法 显示 语法 显示 语法 x ˉ \bar{x} xˉ \bar{x} x ˊ \acute{x} xˊ \acute{x} x ˇ \check{x} xˇ \check{x} x ˋ \grave{x} xˋ \grave{x} x ^ \hat{x } x^ \hat{x} x ~ \tilde{x } x~ \tilde{x} x ˙ \dot{x} x˙ \dot{x} x ¨ \ddot{x } x¨ \ddot{x} x ˘ \breve{x } x˘ \breve{x} x ⃗ \vec{x } x \vec{x} X ^ \widehat{X } X \widehat{X} X ~ \widetilde{X } X \widetilde{X} 1.3 字体转换一般情况下，公式默认为意大利体，直体为罗马体。 显示 语法 说明 X \rm X X \rm 罗马体 X \mathcal X X \mathcal 花体 X \it X X \it 斜体（默认，意大利体） X \mathit X X \mathit 数学斜体 X \Bbb X X \Bbb 黑板粗体 X \bf X X \bf 粗体 X \sf X X \sf 等线体 X \mathscr X X \mathscr 手写体 X \tt X X \tt 打字机体 X \frak X X \frak 旧德式字体 X \boldsymbol X X \boldsymbol 黑体 X \bold X X \bb 直版黑体 2. 关系符与运算符2.1 二元关系符 显示 语法 &lt; &lt; &lt; &lt; > &gt; > > ≥ \geq ≥ \geq或\ge ≤ \leq ≤ \leq或\le ≫ \gg ≫ \gg ≪ \ll ≪ \ll ∝ \propto ∝ \propto \= = \= \= ≠ \neq \= \neq ≡ \equiv ≡ \equiv ≜ \triangleq ≜ \triangleq ∼ \sim ∼ \sim ≃ \simeq ≃ \simeq ≅ \cong ≅ \cong ≈ \approx ≈ \approx ∣ \mid ∣ \mid ∥ \parallel ∥ \parallel : : : : ⊂ \subset ⊂ \subset ⊃ \supset ⊃ \supset ⊇ \supseteq ⊇ \supseteq ⊆ \subseteq ⊆ \subseteq ∈ \in ∈ \in ∉ \notin ∈/ \notin ∋ \ni ∋ \ni或\owns 2.2 二元运算符 显示 语法 + + + + − - − - ∓ \mp ∓ \mp ± \pm ± \pm × \times × \times ÷ \div ÷ \div ∖ \setminus ∖ \setminus ¬ \lnot ¬ \lnot ∪ \cup ∪ \cup ∩ \cap ∩ \cap ∨ \vee ∨ \vee或\lor ∧ \wedge ∧ \wedge或\land ⊙ \odot ⊙ \odot ⊕ \oplus ⊕ \oplus ⊗ \otimes ⊗ \otimes ⊖ \ominus ⊖ \ominus ⊘ \oslash ⊘ \oslash ⋅ \cdot ⋅ \cdot ⋆ \star ⋆ \star ∘ \circ ∘ \circ ∙ \bullet ∙ \bullet ∗ \ast ∗ \ast ⋃ \bigcup ⋃ \bigcup ⋂ \bigcap ⋂ \bigcap ⋁ \bigvee ⋁ \bigvee ⋀ \bigwedge ⋀ \bigwedge ⨂ \bigotimes ⨂ \bigotimes ⨁ \bigoplus ⨁ \bigoplus ⨀ \bigodot ⨀ \bigodot ⋈ \Join ⋈ \Join ⋈ \bowtie ⋈ \bowtie 2.3 其他符号 显示 语法 ∵ \because ∵ \because ∴ \therefore ∴ \therefore … \dots … \dots ⋯ \cdots ⋯ \cdots ⋮ \vdots ⋮ \vdots ⋱ \ddots ⋱ \ddots ′ \prime ′ \prime ∀ \forall ∀ \forall ∃ \exists ∃ \exists ∂ \partial ∂ \partial ∇ \nabla ∇ \nabla ∅ \emptyset ∅ \emptyset ∞ \infty ∞ \infty ⊥ \bot ⊥ \bot ⊤ \top ⊤ \top ∠ \angle ∠ \angle √ \surd √ \surd ⋄ \diamond ⋄ ·\diamond ◃ \triangleleft ◃ \triangleleft ▹ \triangleright ▹ \triangleright △ \bigtriangleup △ \bigtriangleup ▽ \bigtriangledown ▽ \bigtriangledown ◯ \bigcirc ◯ \bigcirc ♢ \diamondsuit ♢ \diamondsuit ♡ \heartsuit ♡ \heartsuit ♣ \clubsuit ♣ \clubsuit ♠ \spadesuit ♠ \spadesuit ⌊ x ⌋ \lfloor x \rfloor ⌊x⌋ \lfloor x \rfloor ⌈ x ⌉ \lceil x \rceil ⌈x⌉ \lceil x \rceil 箭头 显示 语法 ← \leftarrow ← \leftarrow或\gets ⟵ \longleftarrow ⟵ \longleftarrow → \rightarrow → \rightarrow或\to ⟶ \longrightarrow ⟶ \longrightarrow ↑ \uparrow ↑ \uparrow ↓ \downarrow ↓ \downarrow ⟸ \Longleftarrow ⟸ \Longleftarrow ⇑ \Uparrow ⇑ \Uparrow ⇓ \Downarrow ⇓ \Downarrow ⟹ \Longrightarrow ⟹ \Longrightarrow ⇔ \Leftrightarrow ⇔ \Leftrightarrow ⇕ \Updownarrow ⇕ \Updownarrow ↗ \nearrow ↗ \nearrow ↘ \searrow ↘ \searrow ↙ \swarrow ↙ \swarrow ↖ \nwarrow ↖ \nwarrow ↼ \leftharpoonup ↼ \leftharpoonup ⇀ \rightharpoonup ⇀ \rightharpoonup ↽ \leftharpoondown ↽ \leftharpoondown ⇁ \rightharpoondown ⇁ \rightharpoondown ⇌ \rightleftharpoons ⇌ \iff 3. 公式 功能 显示 语法 上下标 f ( x ) = x 1 2 + x 2 2 f(x) = x_1^2 + {x}_{2}^{2} f(x)\=x12​+x22​ f(x) = x_1^2 + {x}_{2}^{2} 分数 a − 1 b − 1 \frac{a-1}{b-1} b−1a−1​ \frac{a-1}{b-1} 开方 2 3 n \sqrt{2} \quad \sqrt[n]{3} 2 ​n3 ​ \sqrt{2} \quad \sqrt[n]{3} 求和 ∑ k = 1 N k 2 \sum_{k=1}^N k^2 k\=1∑N​k2 \sum_{k=1}^N k^2 求积 ∏ i = 1 N x i \prod_{i=1}^N x_i i\=1∏N​xi​ \prod_{i=1}^N x_i 积分 ∫ − N N e x d x \int_{-N}^{N} e^x\, dx ∫−NN​exdx \int_{-N}^{N} e^x\, dx 双重积分 ∬ − N N e x d x \iint_{-N}^{N} e^x\, dx ∬−NN​exdx \iint_{-N}^{N} e^x\, dx 闭合曲线、曲面积分 ∮ C x 3 d x + 4 y 2 d y \oint_{C} x^3\, dx + 4y^2\, dy ∮C​x3dx+4y2dy \oint_{C} x^3\, dx + 4y^2\, dy 极限 lim ⁡ n → + ∞ 1 n ( n + 1 ) \lim_{n \to +\infty} \frac{1}{n(n+1)} n→+∞lim​n(n+1)1​ \lim_{n \to +\infty} \frac{1}{n(n+1)} 上括号 a + b + c ⏞ + d \overbrace{a+b+c}+d a+b+c ​+d \overbrace{a+b+c}+d 下括号 a + b + c ⏟ + d \underbrace{a+b+c}+d a+b+c​+d \overbrace{a+b+c}+d 上横线 a + b + c + d ‾ \overline{a+b+c+d} a+b+c+d​ \overline{a+b+c+d} 下横线 a + b + c + d ‾ \underline{a+b+c+d} a+b+c+d​ \underline{a+b+c+d} 箭头备注 → f \xrightarrow{f} f ​ \xrightarrow{f} 上备注 \= d e f \overset{def}{=} \=def \overset{def}{=} 下备注 m a x x ∈ S \underset{x\in S}{max} x∈Smax​ \underset{x\in S}{max} 省略号 \= x 1 2 + x 2 2 + ⋯ ⏟ n o t e 2 + x n 2 = x_1^2 + x_2^2 + \underbrace{\cdots}_{\rm note2} + x_n^2 \=x12​+x22​+note2 ⋯​​+xn2​ = x_1^2 + x_2^2 + \underbrace{\cdots}_{\rm note2} + x_n^2 矩阵：\begin{bmatrix}x &amp; y \\z &amp; v\end{bmatrix}[ x y z v ] \begin{bmatrix}x &amp; y \\z &amp; v\end{bmatrix} [xz​yv​]\begin{vmatrix}x &amp; y \\z &amp; v \end{vmatrix}∣ x y z v ∣ \begin{vmatrix} x &amp; y \\ z &amp; v \end{vmatrix} ∣ ∣​xz​yv​∣ ∣​条件定义： f(n) = \begin{cases} n/2, & if \qquad n\geq 0 \\ 3n+1, & if \qquad n < 0 \end{cases}f ( n ) = { n / 2 , i f n ≥ 0 3 n + 1 , i f n &lt; 0 f(n) = \begin{cases} n/2, &amp; if \qquad n\geq 0 \\ 3n+1, &amp; if \qquad n &lt; 0 \end{cases} f(n)\={n/2,3n+1,​ifn≥0ifn&lt;0​ 4. 其他公式中的空格\;：空 1 / 4 1/4 1/4格\quad：空一格\qquad：空两格 例：a \quad b \qquad c\;da b c d a \quad b \qquad c\;d abcd &amp;nbsp;：不换行空格，全称是 No-Break Space，是按下space键产生的空格。&amp;ensp;：半角空格，全称是 En Space，en是字体排印学的计量单位，为em宽度的一半。根据定义，它等同于字体度的一半（如16px字体中就是8px）。名义上是小写字母n的宽度。此空格有个相当稳健的特性，就是其占据的宽度正好是1/2个中文宽度，且基本不受字体影响。&amp;emsp;：全角空格，全称是 Em Space，em是字体排印学的计量单位，相当于当前指定的点数（如1em在16px的字体中就是16px）。此空格也有个相当稳健的特性，就是其占据的宽度正好是1个中文宽度，且基本不受字体影响。 公式编号： $$$ f(\boldsymbol x_i) = \boldsymbol w^T \boldsymbol x_i + b \tag {3}$$$f ( x i ) = w T x i + b (3) f(\boldsymbol x_i) = \boldsymbol w^T \boldsymbol x_i + b \tag {3} f(xi​)\=wTxi​+b(3) 转义字符：当某些特殊字符与Markdown语法冲突时，使用转义字符可以使字符强制显示。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown mermaid种草(3)_ 流程图]]></title>
    <url>%2F2023%2F10%2F02%2FMarkdown-mermaid%E7%A7%8D%E8%8D%89-3-%E6%B5%81%E7%A8%8B%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[1 流程图 2 绘制语法及参数 2.1 绘图方向 2.2 节点定义和形状 2.3 连接线及箭头 2.3.1 连接线类型 2.3.2 多种类型的箭头 2.3.3 连接线上的文字标注 2.3.4 改变连接线的长度 2.3.5 多连接线 2.4 子图及子图连接 2.5 节点上的超链接 2.6 节点样式编辑 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/horsee/article/details/113353413?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&amp;spm=1001.2101.3001.4242 1 流程图​ 流程图经常用以描述业务流程，是产品经理和项目经理的最爱. ​ mermaid的流程图分为两种：graph和flowchart. ​ 这两者的使用方式大体是一致的. 所不同的是flowchart比graph应用了更多类型的箭头. 2 绘制语法及参数2.1 绘图方向举例：以graph或flowchart关键字为开始，后面跟上的是流图的绘制方向； 接下来写的是节点 连接线 节点 12graph TD start ---&gt; stop 编号 绘图方向 绘图代码 备注 1 从上到下 TD TB Top-Down/Top-Bottom 2 从左到右 LR Left-Right 3 从右到左 RL Right-Left 4 从下到上 BT Bottom-Top Tips: “从上到下”既可以是TD也可以是TB，但是“从下到上”只能是BT，真“变态”. 2.2 节点定义和形状​ 从刚才那个例子里能够看出，节点的定义方法就是在graph/flowchart后面跟上“从节点到节点”的描述.此处节点可以按照上述的示例中，直接以变量的名称给出（此时图形上节点的内容将会和变量的名称保持一致）: 1节点1 ​ 这种方式存在一个缺点，即节点如果被反复指向时，则需要反复书写变量的名称，因此也可以采用另一种方式：如下例所示： 1id1[节点1] ​ 可以将长串的内容用方括号括起来，而用一个较短的变量名来指代节点.在下例中就能体现出这种节点定义方式的优点： 12345678910graph TD id1[名称非常非常长的节点1] id2[节点2] id3[节点3] id4[节点4] id5[节点5] id1 --&gt; id2 id1 --&gt; id3 id1 --&gt; id4 id1 --&gt; id5 ​ 节点的默认形状是直角矩形，mermaid提供了多种形状的节点： 123456789101112graph LR id0[普通节点] id1&#123;菱形节点&#125; id2[/平行四边形节点/] id3[\反平行四边形节点\] id4[/正梯形节点\] id5[\反梯形节点/] id6((圆形节点)) id7[(圆柱节点)] id8[[子流程节点]] id9&gt;不对称节点] id10 &#123;&#123;六边形节点&#125;&#125; 编号 节点形状 编码 1 普通形状 [] 2 菱形 {} 3 正平行四边形 [//] 4 反平行四边形 [\\] 5 正梯形 [/\] 6 反梯形 [/] 7 圆形 (()) 8 圆柱形 [()] 9 子流程（双线） [[]] 10 不对称 &gt;] 11 六边形 2个{和2个} ​ 节点中的文字如果有特殊字符，例如括号，这些特殊字符会导致代码在解释时发生歧义，此时只需要把文本内容用双引号括起来即可避免问题的发生： 12graph TD id1[&quot;这是一个非常(特别)的文本&quot;] 2.3 连接线及箭头​ 接下来本小白带各位来学习一下连接线和箭头. 这里无非是线型、箭头型、粗细以及长度等等. 2.3.1 连接线类型​ 连接线类型包括：实线、虚线、加粗线、无箭头线等. 12graph LR id1 --&gt; id2 12graph LR id1 -.-&gt; id2 12graph LR id1 ==&gt; id2 1234graph LR id1 --- id2 id1 -.- id3 id1 === id4 2.3.2 多种类型的箭头​ 想使用多种类型的箭头，需要使用flowchart替换graph. 普通箭头 12flowchart LR id1 --&gt; id2 球形箭头 12flowchart LR id1 --o id2 叉形箭头 12flowchart LR id1 --x id2 双向箭头 1234flowchart LR id1 &lt;--&gt; id2 id3 o--o id4 id5 x--x id6 Tips: 双向箭头两边的箭头需要一致，目前测试mermaid还不支持混搭箭头. 2.3.3 连接线上的文字标注​ 节点之间的连接线有时需要进行文字标注，对连接线进行文字标注有两种方式，一种是直接在连接线中间书写文字，另一种是以||将文字内容括住. 123456789flowchart LR id1 --yes--&gt; id2 id2 --&gt;|no|id3 id3 -. yes .-&gt; id4 id4 -.-&gt;|no| id5 id5 --yes--- id6 id6 ---|no| id7 id7 ==yes==&gt; id8 id8 ==&gt;|no| id9 Tips: 注意如果是纯连接线，则右侧要增加一条短线，去替换原本属于箭头的标识. 2.3.4 改变连接线的长度​ 以上讲述的部分，连接线的长度都是一致的，即最短长度，那么如果我们需要不同长度的时候，则只需要添加短划线的个数即可，若是虚线，则添加其中的点，若是粗线，则添加等于号： 123flowchart LR id1 --&gt; id2 id1 ---&gt; id3 123flowchart LR id1 -.- id2 id1 -..- id3 123flowchart LR id1 ==&gt; id2 id1 ===&gt; id3 再来一个综合一点的例子作为此处的小结： 123456graph LR A[Start] --&gt; B&#123;Is it?&#125;; B --&gt;|Yes| C[OK]; C --&gt; D[(Rethink)]; D --&gt; B; B ----&gt;|No| E[End]; 2.3.5 多连接线​ 还有一种高级的用法，本小白目前也还没有完全参透，可以用简洁的方式把节点间的多连接关系直接表示出来： 串行多连接 12graph LR A -- text --&gt; B -- text2 --&gt; C 并行多连接 12graph LR a --&gt; b &amp; c --&gt; d 网络多连接 12graph TB A &amp; B--&gt; C &amp; D 2.4 子图及子图连接​ 流程有时候需要切分成子模块，此时需要用到子图和子图连接的概念. ​ 子图的标准写法如下所示： 123subgraph title graph definitionend 1234567891011graph TB c1--&gt;a2 subgraph one a1--&gt;a2 end subgraph two b1--&gt;b2 end subgraph three c1--&gt;c2 end ​ 像节点一样，也可以使用id的方式给子图命名. 12345graph TB c1--&gt;a2 subgraph ide1 [one] a1--&gt;a2 end 1234567891011121314flowchart TB c1--&gt;a2 subgraph one a1--&gt;a2 end subgraph two b1--&gt;b2 end subgraph three c1--&gt;c2 end one --&gt; two three --&gt; two two --&gt; c2 2.5 节点上的超链接​ 流程图中的节点可以添加超链接，这是一个高级的功能，对于markdown编辑器来说，仅支持部分语法，而更高阶的功能，因为本小白没有html的技能，所以在html中内嵌使用超链接的功能就先略过了，感兴趣的童鞋可以去mermaid官方页面去学习. 12345graph LR; A--&gt;B; B--&gt;C; click A &quot;http://www.github.com&quot; _blank click B &quot;http://www.github.com&quot; &quot;Open this in a new tab&quot; _blank 2.6 节点样式编辑​ 节点除了形状可以进行修改以外，还可以对节点的颜色、边框的颜色和线型进行修改. 1234graph LR id1(Start)--&gt;id2(Stop) style id1 fill:#f9f,stroke:#333,stroke-width:4px style id2 fill:#bbf,stroke:#f66,stroke-width:2px,color:#fff,stroke-dasharray: 5 5 ​ 用一个style起头来引导对节点形状的设置语句. ​ 后面跟着的是节点的名称. ​ fill表示设置填充的颜色，#号后面引导16位RGB色阶标注，例如#f9f表明RGB通道是15，9，15. ​ stroke表示字体的设置，颜色标注方式和fill的表示方法一致. ​ stroke-width表示线框的粗细，px表示像素，color表示设置线框的颜色. ​ stroke-dasharray表示的是线框的虚线线型，用两个数来表示段落的划分数量.]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>流程图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用markdown来画流程图]]></title>
    <url>%2F2023%2F10%2F02%2F%E7%94%A8markdown%E6%9D%A5%E7%94%BB%E6%B5%81%E7%A8%8B%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[代码 效果 说明 定义元素的语法 连接元素的语法 实际应用 代码 效果 原文 参考 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.jianshu.com/p/02a5a1bf1096 一直在用markdown（不得不说markdown语法真的太强大太简洁了，效果也太优美，没学过markdown语法的可以自己学下）写东西，知道用markdown可以画出来很性感的流程图，遂决定学下如何用markdown来画流程图。 代码12345678flowst=&gt;start: Startop=&gt;operation: Your Operationcond=&gt;condition: Yes or No?e=&gt;endst-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op 效果 说明这样几行简单的代码就生成了一个优雅的流程图。流程图大致分为两段，第一段是定义元素，第二段是定义元素之间的走向。 定义元素的语法1tag=&gt;type: content:&gt;url tag就是元素名字， type是这个元素的类型，有6中类型，分别为： start # 开始 end # 结束 operation # 操作 subroutine # 子程序 condition # 条件 inputoutput # 输入或产出 content就是在框框中要写的内容，注意type后的冒号与文本之间一定要有个空格。 url是一个连接，与框框中的文本相绑定 连接元素的语法用-&gt;来连接两个元素，需要注意的是condition类型，因为他有yes和no两个分支，所以要写成 12c2(yes)-&gt;io-&gt;e c2(no)-&gt;op2-&gt;e 实际应用下边献上我的拙作，这是一个爬取某网站的商品评论数据，然后进行情感分析的小项目，有四个模块：获取待爬取商品id，爬取代理，爬取评论，情感分析 代码1234567891011121314151617181920212223242526272829303132flowst=&gt;start: Start|past:&gt;http://www.google.com[blank]e=&gt;end: End:&gt;http://www.google.comop1=&gt;operation: get_hotel_ids|pastop2=&gt;operation: get_proxy|currentsub1=&gt;subroutine: get_proxy|currentop3=&gt;operation: save_comment|currentop4=&gt;operation: set_sentiment|currentop5=&gt;operation: set_record|currentcond1=&gt;condition: ids_remain空?cond2=&gt;condition: proxy_list空?cond3=&gt;condition: ids_got空?cond4=&gt;condition: 爬取成功??cond5=&gt;condition: ids_remain空?io1=&gt;inputoutput: ids-remainio2=&gt;inputoutput: proxy_listio3=&gt;inputoutput: ids-gotst-&gt;op1(right)-&gt;io1-&gt;cond1cond1(yes)-&gt;sub1-&gt;io2-&gt;cond2cond2(no)-&gt;op3cond2(yes)-&gt;sub1cond1(no)-&gt;op3-&gt;cond4cond4(yes)-&gt;io3-&gt;cond3cond4(no)-&gt;io1cond3(no)-&gt;op4cond3(yes, right)-&gt;cond5cond5(yes)-&gt;op5cond5(no)-&gt;cond3op5-&gt;e 效果 这个流程图有个问题，我希望ids_remain的两个条件都为空，但是markdown语法没法实现我这需求（不知道我这需求是不是有毛病），只能先这样画着了。 原文http://jlan.me/2016/09/09/%E7%94%A8markdown%E6%9D%A5%E7%94%BB%E6%B5%81%E7%A8%8B%E5%9B%BE/ 参考 https://www.zybuluo.com/mdeditor? http://weibo.com/ghosert http://meta.math.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>markdown</tag>
        <tag>流程图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Springboot web项目Dependencies飘红]]></title>
    <url>%2F2023%2F10%2F02%2FSpringboot-web%E9%A1%B9%E7%9B%AEDependencies%E9%A3%98%E7%BA%A2%2F</url>
    <content type="text"><![CDATA[问题描述 解决方法 1.找到当前项目的tomcat的版本号 2.修改tomcat版本信息 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 问题描述刚创建了一个Springboot web项目时，pom.xml文件没有标红，但刷新maven时，Dependencies多出标红。 控制台显示Cannot resolve org.apache.tomcat.embed:tomcat-embed-core:9.0.60。 根据提示，应该是tomcat的版本号不一致导致依赖加载失败。 解决方法1.找到当前项目的tomcat的版本号springboot中的starter类中标注了很多依赖版本号，我们可以从中找到tomcat的版本号。 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; （ctrl+左键）点击spring-boot-starter-web，进入到spring-boot-start-web-2.6.6.pom文件中，其中2.6.6是当前项目的spring boot版本号。找到spring-boot-starter-tomcat的依赖。 123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 同样，（ctrl+左键）点击spring-boot-starter-tomcat，进入到spring-boot-start-tomcat-2.6.6.pom文件中。找到tomcat-embed-el对应的版本号9.0.60。 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.tomcat.embed&lt;/groupId&gt; &lt;artifactId&gt;tomcat-embed-el&lt;/artifactId&gt; &lt;version&gt;9.0.60&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt; &lt;/dependency&gt; 2.修改tomcat版本信息返回当前项目的pom.xml文件中，修改properties的配置信息。原始配置为： 123&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt;&lt;/properties&gt; 修改后： 1234&lt;properties&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;tomcat.version&gt;9.0.60&lt;/tomcat.version&gt; &lt;/properties&gt;]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>SpringBoot项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客修改时间轴样式]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E4%BF%AE%E6%94%B9%E6%97%B6%E9%97%B4%E8%BD%B4%E6%A0%B7%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1. hexo博客修改时间轴样式 问题描述 问题解决 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： 1. hexo博客修改时间轴样式 问题描述不知道为什么打开的时间轴突然出现时间和题名重叠，如下如图所示 可能是添加什么东西的是否产生了样式冲突？时间久远，不进行考证 问题解决查找时间轴样式，并进行微调具体位置如下：**\themes\next\source\css_common\components\post\post-collapse.styl 将 .post-title 的 margin-left 修改为1margin-left: $font-size-medium * 5; 如下图 修改后如下]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客下一页跳转问题]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E4%B8%8B%E4%B8%80%E9%A1%B5%E8%B7%B3%E8%BD%AC%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 底部下一页跳转问题 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 底部下一页跳转问题鱼叔在建立博客的时候发现底部下一页跳转按钮没有正常显示，如下图 修改方式： 打开主题 layout/_partials/pagination.swg 进行修改，将“i class”模块删除修改成如下模式(其中prev 和 next可以自定字样)： 1234567891011&#123;% if page.prev or page.next %&#125; &lt;nav class=&quot;pagination&quot;&gt; &#123;&#123; paginator(&#123; prev\_text: &apos;prev&apos;, next\_text: &apos;next&apos;, mid\_size: 1 &#125;) &#125;&#125; &lt;/nav&gt; &#123;% endif %&#125; 修改后结果为下图，实现正常的跳转按钮：]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客增加评论功能]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E5%A2%9E%E5%8A%A0%E8%AF%84%E8%AE%BA%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1. 增加评论功能 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 增加评论功能目前比较流行的两种评论系统是Valine 和 Giement，这里主要讲Valine的配置。 1. 注册leancloud，leancloud注册网址 注册登陆后，访问控制台，创建应用，选择开发版，创建好之后就生成了对应的id和key 2. 在主题配置文件中进行修改 Valine. 3. 最后效果]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客配置搜索功能]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E9%85%8D%E7%BD%AE%E6%90%9C%E7%B4%A2%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1. 配置搜索功能 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 配置搜索功能next自带一个搜索功能，可以实现对站内内容的搜索。 首先需要通过如下命令安装对应的搜索插件： 然后在全局的配置文件（hexoblog目录下的_config.yml）中，增加配置如下内容： 123456\# Search Config search: path: search.xml field: post format: html limit: 100 然后在git hash 中加载相应的插件： 12npm install hexo-generator-search --save npm install hexo-generator-searchdb --save 打开主题内的配置文件，找到 local_search 属性，配置开启本地搜索功能。 1234567local\_search: enable: true # if auto, trigger search by changing input # if manual, trigger search by pressing enter key or search button trigger: auto # show top n results per article, show all results by setting to -1 top\_n\_per\_article: 1]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客让首页文章部分显示]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E8%AE%A9%E9%A6%96%E9%A1%B5%E6%96%87%E7%AB%A0%E9%83%A8%E5%88%86%E6%98%BE%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[1. 如何让首页文章部分显示 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 如何让首页文章部分显示next主题默认的是将你的文章全篇显示在自己的首页上，这就会导致一个问题，首页各个文章太长了不利于翻阅，那如何部分显示自己的文章呢？很简单，只要在个人的文章Markdown 中在想要显示的文章部分下面加上代码&lt;!--more--&gt;，即可只在首页显示所需的文章部分。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客增加阅读时长和字数统计功能]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E5%A2%9E%E5%8A%A0%E9%98%85%E8%AF%BB%E6%97%B6%E9%95%BF%E5%92%8C%E5%AD%97%E6%95%B0%E7%BB%9F%E8%AE%A1%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[1. next自带阅读时长和字数统计插件，我们所需要做的就是调用这两个工具。首先在主题的配置文件中修改： 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： 1. next自带阅读时长和字数统计插件，我们所需要做的就是调用这两个工具。首先在主题的配置文件中修改： 123456post\_wordcount: item\_text: true wordcount: true # 单篇 字数统计 min2read: true # 单篇 阅读时长 totalcount: false # 网站 字数统计 separated\_meta: true 完成配置后，我们需要安装word-count 插件，在git bash中输入： 1npm i --save hexo-wordcount 完成插件安装后，为了更好的显示，我们可以打开xxx_blog/themes/next/layout/_macro/post.swig ，在对应地方添加字words 和 min。可以通过搜索‘wordcount’ 和 ‘min2read’ 来定位。 1234567&lt;span title=&quot;&#123;&#123; \_\_(&apos;post.wordcount&apos;) &#125;&#125;&quot;&gt; &#123;&#123; wordcount(post.content) &#125;&#125; words &lt;/span&gt; &lt;span title=&quot;&#123;&#123; \_\_(&apos;post.min2read&apos;) &#125;&#125;&quot;&gt; &#123;&#123; min2read(post.content) &#125;&#125; min &lt;/span&gt;]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客修改头像]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E4%BF%AE%E6%94%B9%E5%A4%B4%E5%83%8F%2F</url>
    <content type="text"><![CDATA[1. 修改头像问题 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 修改头像问题将自己的头像复制到blog文件夹中的\themes\next\source\images中覆盖原来的avatar.png 文件即可。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客修改菜单栏]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E4%BF%AE%E6%94%B9%E8%8F%9C%E5%8D%95%E6%A0%8F%2F</url>
    <content type="text"><![CDATA[1. 菜单栏修改问题 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 菜单栏修改问题Next在主题的_config.yml文件中提供菜单栏的修改，只要搜索menu就可以找到，通过去除注释即可以在网页上进行渲染。然而在修改next中的menu时可能会发现存在这样的报错 “cannot get %20” — 无法找到相应的菜单。出现的原因是官方给的代码中多加了一个空格，导致网页无法渲染，个人除了删除注释外，要将“||”前的空格删除不然会导致菜单没法跳转。 1234567menu: home: /|| home about: /about/|| user tags: /tags/|| tags categories: /categories/|| th archives: /archives/|| archive #schedule: /schedule/ || calendar #官方给的代码 || 前多加了空格]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客修改站点icon]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E4%BF%AE%E6%94%B9%E7%AB%99%E7%82%B9icon%2F</url>
    <content type="text"><![CDATA[1. 修改站点icon 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 修改站点icon当套用完next主题后，个人博客的站点图标会自动为next的logo，作为博主当然不能忍这个logo啦，那怎么修改呢？ 我们打开next的主题配置文件会发现有这样的设定： 12345favicon: small: /images/favicon-16x16-next.png medium: /images/favicon-32x32-next.png apple\_touch\_icon: /images/apple-touch-icon-next.png safari\_pinned\_tab: /images/logo.svg 这就可以很清晰地发现去哪里修改了，只要在对应的路径上把原有的图片文件给替换成我们需要的文件就行了。这里给大家提供一个网站用于生成所需的icon同尺寸图像：favicon-generator]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客出现Cannot GET/tags or categories错误”]]></title>
    <url>%2F2023%2F10%2F02%2Fhexo%E5%8D%9A%E5%AE%A2%E5%87%BA%E7%8E%B0Cannot-GET-tags-or-categories%E9%94%99%E8%AF%AF%E2%80%9D%2F</url>
    <content type="text"><![CDATA[1. Hexo博客出现“Cannot GET/tags or categories”错误 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. Hexo博客出现“Cannot GET/tags or categories”错误next提供了标签和分类功能，但是在实现这个功能时常常会遇到”cannot get” 的问题，这是因为我们没有对它们进行初始化。具体解决方法如下： 在git bash 中输入以下代码创建相应的page： 123hexo new page &quot;tags&quot;hexo new page &quot;categories&quot; 在第一步完成后会在source文件夹中出现tags和categories的文件夹，在各自的文件夹里打开index.md文件进行修改(多加上一个type属性)： 1234567title: categoriesdate: 2022-03-15 14:19:53type: &quot;categories&quot;​title: tagsdate: 2021-03-15 14:20:32type: &quot;tags&quot;]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo博客相关汇总]]></title>
    <url>%2F2023%2F10%2F02%2FHexo%E5%8D%9A%E5%AE%A2%E7%9B%B8%E5%85%B3%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[一、搭建 1. 记录生活，分享点滴：通过 Hexo 搭建与使用个人博客 二、优化 1. hexo博客增加评论功能 2. hexo博客配置搜索功能 3. hexo博客让首页文章部分显示 4. hexo博客增加阅读时长和字数统计功能 5. hexo博客修改头像 6. hexo博客修改菜单栏 7. hexo博客修改站点icon 8. hexo写文章创建文件自动打开编辑器！ 9. NEXT主题美化 三、问题解决 1. hexo博客下一页跳转问题 2. hexo博客出现Cannot GET/tags or categories错误” 3. 彻底解决hexo s 启动服务后 打开localhost:4000 无响应的问题 4. hexo博客修改时间轴样式 5. hexo博客搜索显示异样 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： Next 官方指南 一、搭建1. 记录生活，分享点滴：通过 Hexo 搭建与使用个人博客二、优化1. hexo博客增加评论功能2. hexo博客配置搜索功能3. hexo博客让首页文章部分显示4. hexo博客增加阅读时长和字数统计功能5. hexo博客修改头像6. hexo博客修改菜单栏7. hexo博客修改站点icon8. hexo写文章创建文件自动打开编辑器！9. NEXT主题美化三、问题解决1. hexo博客下一页跳转问题2. hexo博客出现Cannot GET/tags or categories错误”3. 彻底解决hexo s 启动服务后 打开localhost:4000 无响应的问题4. hexo博客修改时间轴样式5. hexo博客搜索显示异样]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底解决hexo s 启动服务后 打开localhost:4000 无响应的问题]]></title>
    <url>%2F2023%2F10%2F02%2F%E5%BD%BB%E5%BA%95%E8%A7%A3%E5%86%B3hexo-s-%E5%90%AF%E5%8A%A8%E6%9C%8D%E5%8A%A1%E5%90%8E-%E6%89%93%E5%BC%80localhost-4000-%E6%97%A0%E5%93%8D%E5%BA%94%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. 问题 2. 解决 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/AndyNikolas/article/details/80247317 1. 问题使用 hexo s 命令启动服务后，打开浏览器localhost:4000 地址发现没有反应，出错。页面显示不出来，显示空白且停止加载。 2. 解决用 管理员身份 打开dos命令窗口输入一下命令 1netstat -o -n -a | findstr :4000 查看一下4000端口的详细情况。如下图所示: 发现4000端口存在大量的连接。但是页面却显示不出来，关机重启后，也不行，问了下DBA的朋友，原来是进程被添加到系统服务里面了。 后面我打算将4000端口这个进程结束掉。使用如下命令 1taskkill /F /PID 3628 3628是最后一列的值，也就是进程号，你们的进程号可能不一样，自己看看写上对应的进程号就好。 然后在dos命令窗口中，重新输入 1hexo s 就可以在浏览器打开localhost:4000的地址了 PS: hexo 可以指定特定端口，比如4000端口出现问题，我们可以使用 1hexo s -p 5000 开启localhost:5000的服务。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下ttf-mscorefonts-installer安装问题]]></title>
    <url>%2F2023%2F10%2F02%2FUbuntu%E4%B8%8Bttf-mscorefonts-installer%E5%AE%89%E8%A3%85%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1. Ubuntu系统中在安装ttf-mscorefonts-installer时（或者wine、ubuntu-restricted-extras等）会弹出如下窗口，导致安装过程阻塞。 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/fickyou/article/details/50957414 1. Ubuntu系统中在安装ttf-mscorefonts-installer时（或者wine、ubuntu-restricted-extras等）会弹出如下窗口，导致安装过程阻塞。 方法1： 按Tab键，选中ok，然后按Enter键。 方法2（如果使用脚本，这种就很方便）： 123echo ttf-mscorefonts-installer msttcorefonts/accepted-mscorefonts-eula select true | sudo debconf-set-selectionssudo apt-get install ttf-mscorefonts-installer]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ubuntu遇到的问题-An error occurred,please run Package Manager...]]></title>
    <url>%2F2023%2F10%2F02%2F%E4%BD%BF%E7%94%A8ubuntu%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98-An-error-occurred-please-run-Package-Manager%2F</url>
    <content type="text"><![CDATA[1. 报错信息 2. 理由分析 3. 解决 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/idealcitier/article/details/78294137 1. 报错信息最近在使用Ubuntu的过程中遇到提示一些错误。提示：An error occurred,please run Package Manager from the right-click menu or apt-get in a terminal to see what is wrong.The error message was: &#39;Error:BrokenCount&gt;0&#39;This usually means that your installed packages have umnet dependencies 2. 理由分析出现这样的提示就是在安装软件的过程中，出现了错误，缺少相应的依赖包。 3. 解决可以使用一下的方法进行解决。 打开Terminal 输入sudo apt-get upgrade 输入sudo apt-get install -f/sudo apt-get -f install 通过以上的命令，缺失的安依赖包也就安装完成了，相应的提示也就消失了。 本文转自 https://blog.csdn.net/idealcitier/article/details/78294137，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[iPad成为Windows系统的第二屏幕 - 疯疯月]]></title>
    <url>%2F2023%2F10%2F02%2FiPad%E6%88%90%E4%B8%BAWindows%E7%B3%BB%E7%BB%9F%E7%9A%84%E7%AC%AC%E4%BA%8C%E5%B1%8F%E5%B9%95-%E7%96%AF%E7%96%AF%E6%9C%88%2F</url>
    <content type="text"><![CDATA[一、Windows端软件准备 1、Splashtop Wired XDisplay Agent 2、iTunes 二、iPad端软件准备 Splashtop Wired XDisplay HD-显示器扩展与镜像 三、连接 1、跟着提示使得iPad可以正常连接iTunes 2、电脑端和iPad端都打开Splashtop，iPad会自动成为扩展屏 四、常见问题 1、可能有些朋友的iPad默认是“复制屏”，即使按 CTRL+P 键调整成了扩展屏，依然无效。 2、iPad只是Windows桌面，不能打开应用 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/fengfengyue/p/12198273.html#top 一、Windows端软件准备1、Splashtop Wired XDisplay Agent（官网下载 快速下载​） 2、iTunes（点击此处跳转至微软应用商店） 二、iPad端软件准备Splashtop Wired XDisplay HD-显示器扩展与镜像（注意是蓝色图标的） 三、连接1、跟着提示使得iPad可以正常连接iTunes 2、电脑端和iPad端都打开Splashtop，iPad会自动成为扩展屏四、常见问题1、可能有些朋友的iPad默认是“复制屏”，即使按 CTRL+P 键调整成了扩展屏，依然无效。解决办法：取消勾选“启用镜射模式”，可能一次不成功，多试几次。 2、iPad只是Windows桌面，不能打开应用解决办法：习惯来讲，我们的扩展屏都是放在左边，即当有软件需要使用扩展屏打开时，我们习惯上将该软件从主屏的左侧（扩展屏的右侧）拉到扩展屏，但是iPad成为iPad的扩展屏时，默认作为右边的屏，即与我们的操作习惯相反。 设置—-系统—-显示—-高级显示设置——显示2：iPad设备]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github 搜索技巧]]></title>
    <url>%2F2023%2F10%2F02%2FGithub-%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7%2F</url>
    <content type="text"><![CDATA[1. Search 2. Trending 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.jianshu.com/p/7321caea2a08 Github 的资源对于广大开发者来说真是个宝藏，那么除了在搜索框里输入关键字再回车之外，我们还可以怎么用呢？一般来说，我们找资源最常用的两个功能是 search 和 trending, 这里简单介绍一下一些初级功能，详细教程见Github Help。 1. Search 如何查看一门语言的 Repository 排行榜（按 stars 数量排）？如图所示，以 Objective-C 为例，直接在输入框中输入 language:Objective-C stars:&gt;0， 然后再在右侧排名选项中选择 Most stars。 按 stars 数量排名(以 Objective-C 为例).png 为什么有些数据模糊搜索不到？比如，输入搜索关键字 “collectionView”，然后在左侧边栏 Languages 中选择 Objective-C ，发现搜索结果中没有 “PSTCollectionView” 这个Repository，实际上，如果搜索的是 “PSTCollectionView” 的话，确实是能搜索到的。从搜索结果中来看，“collectionView” 是被作为一个单词整体来进行搜索的，所以搜到的结果都是 Repository name 或者 description 中出现以 “collectionView” 开头或者包含 “-collectionView” 的单词的 Repository。所以为了能搜索到更多想要的结果，我们最好以单词为单位，用 OR 将各个关键字拼接起来进行搜索，例如，搜 “CollectionView OR UICollectionView OR collection” 而不是 “collectionView”。下面是两种搜索词的结果对比。 搜索“collectionView”.png 搜索”collectionView OR UICollectionView”.png Github 有高级搜索吗？在上图中，我们可以看到左侧边栏的下方有两个可点击的选项 Advanced search 和 Cheat sheet，点击 Advanced search 即可进行自定义条件的高级搜索了，点击 Cheat sheet 则可以查看一些有关搜索的帮助信息。哪里不会点哪里，妈妈再也不用担心我的学习了！ Advanced search.png 2. Trending作为一枚程序猿，除了有目的的搜索之外，我们有时也需要去“瞎逛逛”，开阔一下眼界。如果你有空，不妨去 Github 的 Trending 看看最近发生了什么。*See what the GitHub community is most excited about today! * 在这里你可以看到各种不同开发语言的每天/周/月的最热门的 Repositories 和 Developers。比如前一段时间走红的 YYKit，苹果最近开源的 CareKit，等等。 Trending.png 本文转自 https://www.jianshu.com/p/7321caea2a08，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub搜索技巧整理_github怎么搜索中文]]></title>
    <url>%2F2023%2F10%2F02%2FGitHub%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7%E6%95%B4%E7%90%86-github%E6%80%8E%E4%B9%88%E6%90%9C%E7%B4%A2%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[登录后搜索 不同类别区别 流行趋势 最热主题 借助插件 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/fengbingchun/article/details/88625374 经常会在GitHub上搜索代码、项目或查找相关主题，最简单常用的方法是在GitHub主页搜索框中直接输入相关信息进行查找，如下图所示，但是这样搜到的结果很多都不是自己希望的，这里总结下搜索技巧及常用操作说明： 登录后搜索 GitHub的搜素支持各种不同的操作，详细见https://help.github.com/en/articles/about-searching-on-github ，常用操作如下：注意：在搜索前最好已登录，这样才能在所有公共仓库中搜索**code**，不登录和登录的search结果差异如下： (1). 基本搜索(Basic search)： A．查找stars数超过100的”cat”仓库：cat stars:&gt;100 B．搜索用户名为fengbingchun的所有仓库：user:fengbingchun 搜索结果如下图所示，左上侧显示fengbingchun有多少个仓库(Repositories)、Issues数等信息，想查看特定信息可以进一步点击；左下侧显示仓库中包含哪些开发语言，如C++、C、Python等，也可点击对应的只查看指定语言的仓库；右上侧显示这些仓库按哪种方式进行排序，包括最多stars数、最多fork数、按最近更新日期等。 C. 搜索地址在” San Francisco, CA”的用户名包含tom的所有仓库：tom location:”San Francisco, CA” D. 搜索不包含”cat”的所有仓库：NOT cat (2). 仓库搜索(Repository search)： A. 查找stars数超过100的”cat”仓库：cat stars:&gt;100 B. 搜索用户名为fengbingchun的所有仓库：user:fengbingchun C. 搜索名为”node.js”并fork数少于200的所有仓库：node.js forks:&lt;200 D. 搜索名为”jquery”并库大小在1024至4089KB之间的所有仓库：jquery size:1024..4089 E. 搜索用户名为fengbingchun并且开发语言为C++的所有仓库：language:c++ user:fengbingchun F. 搜索用户名为fengbingchun并且stars数大于等于10的所有仓库：user:fengbingchun followers:&gt;=10 G. 搜索开发语言为C++且stars数大于10000的所有仓库：language:c++ stars:&gt;10000 H. 搜索用户名为fengbingchun并且仓库在2019年1月1日后有更新的所有仓库：user:fengbingchun pushed:&gt;2019-01-01 (3). 代码搜索(Code search)： A. 搜索用户名为fengbingchun并且文件中含有”cv::Mat”的所有文件：cv::Mat user:fengbingchun B. 搜索文件大小大于1000KB并文件中包含”system”的所有文件：system size:&gt;1000 C. 搜索在/docs/路径下文件中含有”examples”的所有文件：examples path:/docs/ (4). (问题搜索)Issue search： A. 搜索用户名为fengbingchun并issue中含有”opencv”字段的所有issues：opencv user:fengbingchun B. 搜索issue是open状态并且issue中含有”fengbingchun”字段的所有issues：fengbingchun is:open C. 搜素issue中comments数大于4次且含有”fengbingchun”字段的所有issues：fengbingchun comments:&gt;4 D. 搜索issue创建者是fengbingchun的所有issues：author:fengbingchun E. 搜索issue在2019年2月15日后创建的且含有”opencv”字段的所有issues：opencv created:&gt;2019-03-15 (5). 用户名搜索(User search)： A. 搜索用户全名为”Bingchun Feng”的用户：fullname:”Bingchun Feng” B. 搜索地址在” San Francisco, CA”的用户名包含tom的所有仓库：tom location:”San Francisco, CA” (6). 高级搜索(Advanced search)：说明见https://github.com/search/advanced 注意： (1). 冒号两侧不能有空格； (2). 不区分大小写； (3). 不能将以下通配符用作搜索查询的一部分，搜索将忽略这些符号：. , : ; / \ ` ‘ “ = * ! ? # $ &amp; + ^ | ~ &lt; &gt; ( ) { } [ ]**；** (4). 搜索默认为master**分支。** 不同类别区别2. 进入到某个项目的主页后，你会发现有Watch、Star、 Fork、Issues、Pull requests等按钮选项，如下图所示： Watch：默认是处于Not watching的状态即未关注，当选择Watching后，表示你以后会关注这个项目的所有状态，以后只要这个项目发生变动，如被别人提交了Pull requests、别人发起了新的Issue、或Issue中有新的讨论等等情况，你都会在自己的个人通知中心，收到一条通知，如果你设置了个人邮箱，那么你的邮箱也可能收到响应的邮件。你也可以选择Release only，只有当此项目有新的发布版本或参与某个Issue讨论，或被别人@时你才会收到通知；选择Ignoring，则不会收到任何通知；选择Not watching，只有当参与此项目时，如参与某个Issue，Pull requests或commit的讨论，或被别人@后，才会收到相关通知。 Star：点击Star表示你喜欢这个项目。你可以通过点击个人GitHub主页上的Stars按钮来查看自己star过哪些项目。 Fork：如果你点击了Fork，相当于你自己有了一份原项目的拷贝，即复制原项目到自己的GitHub仓库中，你可以基于此做调整、修改，但是如果后续原项目发生了改变，你必须通过其它的方式去同步。 Issues：如果你对此项目有任何疑问或问题，都可以通过创建新issue方式提出。 Pull requests：如果你对原项目进行了bug fix或增加了新功能，都可以通过创建新pull request方式提交。 流行趋势3. GitHub Trending页面：https://github.com/trending ，此页面可查看每天或每周或每月最热门的开发项目(Repositories)或开发者(Developers)，也可按开发语言过滤选择，如下图所示： 最热主题4. GitHub Topics页面：https://github.com/topics ，此页面显示最新和最流行的讨论主题，如下图所示： 借助插件5. GitHub插件：如Octotree、OctoLinker、Sourcegraph GitHub： https://github.com/fengbingchun 本文转自 https://blog.csdn.net/fengbingchun/article/details/88625374，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在 GitHub 上快速找到实用软件资源]]></title>
    <url>%2F2023%2F10%2F02%2F%E5%9C%A8%20GitHub%20%E4%B8%8A%E5%BF%AB%E9%80%9F%E6%89%BE%E5%88%B0%E5%AE%9E%E7%94%A8%E8%BD%AF%E4%BB%B6%E8%B5%84%E6%BA%90%2F</url>
    <content type="text"><![CDATA[搜热门：GitHub Trend 和 GitHub Topic 搜开发者 搜项目 结语 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://sspai.com/post/46061 GitHub 作为目前广大程序猿最大的游乐场，在今年 6 月被 微软 以 75 亿美元价值的微软股票收购，GitHub 再次成为业界讨论的焦点。GitHub 以自由开放的定位吸引了相当多的个人开发者和企业，不断发布和更新相当好用的软件和工具。之前少数派曾经为大家整理和推荐了 GitHub 上免费好用的 Windows、macOS 平台的软件： GitHub 上那些免费好用的 Windows 软件 GitHub 中那些不错的免费软件 对于使用者，我不禁好奇：面对如此海量的 GitHub 项目，究竟怎样才能这个平台发现一些优秀的软件和工具。秉着这样的疑问，我收集和总结了下面这几个搜索技巧。 搜热门：GitHub Trend 和 GitHub Topic GitHub Trend 页面总结了每天/每周/每月周期的热门 Repositories 和 Developers，你可以看到在某个周期处于热门状态的开发项目和开发者。而 GitHub Topic 展示了最新和最流行的讨论主题，在这里你不仅能够看到开发项目，还能看到更多非开发技术的讨论主题，比如 Job、Chrome 浏览器等。 GitHub Trend GitHub Topic 搜开发者坊间传闻人事招聘开发类员工时，招聘对象在 GitHub 贡献会是重要的参考指标之一。GitHub 作为优秀国产开源软件的集散地之一，埋藏了不少出色的开发者，所以在寻找国产软件的时候，可以尝试先找国内开发者。利用 GitHub 强大的搜索功能，增加几个搜索参数即可轻松找到「目标人物」。 （注：GitHub 官方还支持很多搜索条件，在 这里 可以查看官方出品的搜索技巧。） Github 搜索技巧 - 找开发者 比如需要寻找国产软件，首先想到的应该是在 GituHub 上找国内开发者，搜索时设置 location 为 China，如果你要寻找使用 javascript 语言开发者，则再增加 language 为 javascript，整个搜索条件就是：language:javascript location:china，从搜索结果来看，我们找到了近 17000 名地区信息填写为 china 的 javascript 开发者，朋友们熟悉的阮一峰老师排在前列。根据官方指引，搜索 GitHub 用户时还支持使用 followers、in:fullname 组合条件进行搜索。 使用组合条件进行搜索 搜索条件 搜项目我们需要在 GitHub 上找到优秀的项目和工具，同样，通过关键字或者设置搜索条件帮助你事半功倍找到好资源。我的使用习惯是先用某些关键词搜索，得到的搜索结果优先展示一些现成的软件和工具。 GitHub 搜索技巧 - 找项目 Awesome + 关键字 Awesome 似乎已经成为不少 GitHub 项目喜爱的命名之一，比如前面提及要找到优秀的 Windows 软件，可以尝试搜索 Awesome windows，得到这样的搜索结果： Awesome windows 搜索结果 排名前列的结果出现了 Windows/Awesome 项目，这里集合了 Windows 上优质和精选的最佳应用程序及工具列表。在这里，我收集了这些 Awesome 主题的优秀项目：The awesome manifesto、Awesome iOS frameworks、Awesome wesome Android libraries and resources。 设置搜索条件 如果你明确需要寻找某类特定的项目，比如用某种语言开发、Stars 数量需要达到标准的项目，在搜索框中直接输入搜索条件即可。其中用于发现项目，我的用法是灵活运用下面几个搜索条件：stars:、language:、forks:，其实就是设置项目收藏、开发语言、派生的搜索条件，比如输入 stars:&gt;=500 language:javascript，得到的结果 就是收藏大于和等于 500 的 javascript 项目，排名前列是开源代码库和课程项目 freeCodeCamp、大热门的 Vue 和 React 项目。 搜索条件=500 language:javascript&gt; 如果觉得记住这些搜索条件略显繁琐的话，使用 GitHub 提供的 高级搜索功能，同样可用自定义条件进行搜索。或者参考官方给出的帮助指南 Searching on GitHub ，里面有更多关于项目、代码、评论、问题等搜索技巧。 GitHub 高级搜索功能 下面是 GitHub 上影响力颇大的项目，仅列举部分： free-programming-books：整理了所有和编程相关的免费书籍，同时也有 中文版项目。 github-cheat-sheet：集合了使用 GitHub 的各种技巧。 android-open-project：涵盖 Android 开发的优秀开源项目。 chinese-independent-developer：聚合所有中国独立开发者的项目。 结语GitHub 网站拥有很多优秀的开源项目，用好 GitHub 的搜索功能，我们既可以使用官方提供的高级搜索和 Topic、Trend 专题页面，也可以学习组合使用搜索条件的方法，主动发现更多好用的项目和工具。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub 上 57 款最流行的开源深度学习项目 - OSCHINA]]></title>
    <url>%2F2023%2F10%2F02%2FGitHub-%E4%B8%8A-57-%E6%AC%BE%E6%9C%80%E6%B5%81%E8%A1%8C%E7%9A%84%E5%BC%80%E6%BA%90%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE-OSCHINA%2F</url>
    <content type="text"><![CDATA[1.TensorFlow 2.Caffe 3.Neural style 4.deepdream 5.Keras 6.RocAlphaGo 7.TensorFlow Models 8.Neural Doodle 9.CNTK 10.TensorFlow Examples 11.ConvNet JS 12.Torch 13.OpenFace 14.MXNet 15.Theano 16.Leaf 17.Char RNN 18.Neural Talk 19.deeplearning4j 20.TFLearn 21.TensorFlow Playground 22.OpenAI Gym 23.Magenta 24.Colornet 25.Synaptic 26.Neural Talk 2 27.Image Analogies 28.TensorFlow Tutorials 29.Lasagne 30.PyLearn2 31.LISA-lab Deep Learning Tutorials 32.Neon 33.Matlab Deep Learning Toolbox 34.Deep Learning Flappy Bird 35.dl-setup 36.Chainer 37.Neural Story Teller 38.DIGITS 39.Deep Jazz 40.Tiny DNN 41.Brainstorm 42.dl-docker 43.Darknet 44.Theano Tutorials 45.RNN Music Composition 46.Blocks 47.TDB 48.Scikit Neural Net 49.Veles 50.Deep Detect 51.TensorFlow DeepQ 52.Caffe on Spark 53.Nolearn 54.DCGAN TensorFlow 56.DeepCL 57.Visual Search Server 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.oschina.net/news/79500/57-most-popular-deep-learning-project-at-github 本文整理了 GitHub 上最流行的 57 款深度学习项目（按 stars 排名）。最后更新：2016.08.09 1.TensorFlowStars：29622 使用数据流图计算可扩展机器学习问题 TensorFlow 是谷歌的第二代机器学习系统，按照谷歌所说，在某些基准测试中，TensorFlow 的表现比第一代的 DistBelief 快了2倍。 TensorFlow 内建深度学习的扩展支持，任何能够用计算流图形来表达的计算，都可以使用 TensorFlow。任何基于梯度的机器学习算法都能够受益于 TensorFlow 的自动分 化（auto-differentiation）。通过灵活的 Python 接口，要在 TensorFlow 中表达想法也会很容易。 2.CaffeStars：11799 Caffe是一个高效的开源深度学习框架。由表达式，速度和模块化组成。 3.Neural styleStars：10148 Torch实现的神经网络算法。 Neural style 是让机器模仿已有画作的绘画风格来把一张图片重新绘制的算法。 4.deepdreamStars：9042 Deep Dream，一款图像识别工具 5.KerasStars：7502 一款Python实现的深度学习库，包括卷积神经网络、递归神经网络等。运行在Theano和TensorFlow之上。 Keras是一个极简的、高度模块化的神经网络库，采用Python（Python 2.7-3.5.）开发，能够运行在TensorFlow和Theano任一平台，好项目旨在完成深度学习的快速开发。 6.RocAlphaGoStars：7170 学生主导的一个独立项目，从新实现了 DeepMind在2016 Nature发表的内容， 《用深度神经网络和树搜索学习围棋》 (Nature 529, 484-489, 28 Jan 2016). 7.TensorFlow ModelsStars：6671 基于TensorFlow开发的模型 8.Neural DoodleStars：6275 运用深度神经网络将涂鸦变为优雅的艺术品，从照片生成无缝纹理，转变图片风格，进行基于实例的提升，等等…还有更多！（语义风格传递的实现） 9.CNTKStars：5957 深度学习工具包 。来自微软公司的CNTK工具包的效率，“比我们所见过的都要疯狂”。 这部分归功于CNTK可借助图形处理单元（GPU）的能力，微软自称是唯一公开“可扩展GPU”功能的公司。（从单机上的1个、延伸至超算上的多个） 在与该公司的网络化GPU系统（称之为Azure GPU Lab）匹配之后，它将能够训练深度神经网络来识别语音，让Cortana虚拟助理的速度达到以前的十倍。 10.TensorFlow ExamplesStars：5872 适合初学者的 TensorFlow 教程和代码示例，做了相关笔记和代码解释。 11.ConvNet JSStars：5231 ConvNetJS 是用 JavaScript 实现的神经网络，同时还有基于浏览器的 demo。 12.TorchStars：5133 Torch7，深度学习库。 Torch7 是一个科学计算框架，支持机器学习算法。易用而且提供高效的算法实现，得益于 LuaJIT 和一个底层的 C 实现。 13.OpenFaceStars：4855 基于深度学习网络的面部识别。 14.MXNetStars：4685 轻巧、便携、灵活的分布式/移动深度学习框架，支持Python, R, Julia, Scala, Go, Javascript等等语言。 MXNet是一款设计为效率和灵活性的深度学习框架。它允许你混合符号编程和命令式编程，从而最大限度提高效率和生产力。在其核心是一个动态的依赖调度，它能够自动并行符号和命令的操作。一个图形优化层，使得符号执行速度快，内存使用高效。这个库便携，轻量，而且能够扩展到多个GPU和多台机器。 15.TheanoStars：4286 Theano 是一个 Python 库，用来定义、优化和模拟数学表达式计算，用于高效的解决多维数组的计算问题。 16.LeafStars：4281 黑客的开源机器智能框架。 17.Char RNNStars：3820 多层递归神经网络的字符级别语言模型，基于Torch开发。 18.Neural TalkStars：3694 NeuralTalk是一个Python+numpy项目，用多模式递归神经网络描述图像。 19.deeplearning4jStars：3673 基于Hadoop 和 Spark的Java, Scala &amp; Clojure深度学习工具。 Deeplearning4j（简称DL4J）是为Java和Scala编写的首个商业级开源分布式深度学习库。DL4J与Hadoop和Spark集成，为商业环境（而非研究工具目的）所设计。Skymind是DL4J的商业支持机构。 Deeplearning4j 技术先进，以即插即用为目标，通过更多预设的使用，避免太多配置，让非研究人员也能够进行快速的原型制作。DL4J同时可以规模化定制。DL4J遵循Apache 2.0许可协议，一切以其为基础的衍生作品均属于衍生作品的作者。 20.TFLearnStars：3368 深度学习库，包括高层次的TensorFlow接口。 21.TensorFlow PlaygroundStars：3352 神经网络模型示例。 22.OpenAI GymStars：3020 一种用于开发和比较强化学习算法的工具包。 23.MagentaStars：2914 Magenta: 音乐和艺术的生成与机器智能 Google Brain团队的一组研究人员发布了一个项目Project Magenta，其主要目标是利用机器学习创作艺术和谱写曲子。Project Magenta使用了 TensorFlow系统，研究人员在GitHub上开源了他们的模型和工具。 研究人员称，机器生成的音乐已经存在了许多年，但它们在都缺乏长的叙事艺术。Project Magenta就试图将故事作为机器生成音乐的重要部分。Google公布了一个DEMO（MP3）表现Magenta项目的成果。 24.ColornetStars：2798 用神经网络模型给灰度图上色。 25.SynapticStars：2666 基于node.js和浏览器的免架构神经网络库。 26.Neural Talk 2Stars：2550 Torch开发的图像简介生成代码，运行在GPU上。 27.Image AnalogiesStars：2540 使用神经匹配和融合生成相似图形。 28.TensorFlow TutorialsStars：2413 Tensorflow，从基础原理到应用。 29.LasagneStars：2355 基于Theano训练和构建神经网络的轻型函数库。 30.PyLearn2Stars：2153 基于Theano的机器学习库。 31.LISA-lab Deep Learning TutorialsStars：2134 深度学习教程笔记和代码。详情参见wiki页面。 32.NeonStars：2121 Nervana™开发的一款快速、可扩展、易上手的Python深度学习框架. neon 是 Nervana System 的深度学习软件。根据Facebook一位研究者的基准测试，Nervana的软件比业界知名的深度学习工具性能都要高，包括Facebook自己的Torch7和Nvidia的cuDNN。 33.Matlab Deep Learning ToolboxStars：2032 Matlab/Octave的深度学习工具箱。包括深度信念网络、自动编码机、卷积神经网络、卷积自动编码机和vanilla神经网络等。每种方法都有入门示例。 34.Deep Learning Flappy BirdStars：1721 使用深度强化学习破解Flappy Bird游戏(深度 Q-学习). 35.dl-setupStars：1607 在深度学习机上设置软件说明。 36.ChainerStars：1573 一款灵活的深度学习神经网络框架。 Chainer是深度学习的框架，Chainer在深度学习的理论算法和实际应用之间架起一座桥梁。它的特点是强大、灵活、直观，被认为是深度学习的灵活框架。 37.Neural Story TellerStars：1514 看图讲故事的递归神经网络模型。 38.DIGITSStars：1353 深度学习GPU训练系统。 39.Deep JazzStars：1229 基于Keras和Theano生成jazz的深度学习模型！ 40.Tiny DNNStars：1183 仅引用头文件，无依赖且使用 C ++ 11 的深度学习框架 41.BrainstormStars：1143 快速、灵活、有趣的神经网络。 42.dl-dockerStars：1044 一个用于深度学习的一体化 Docker 镜像。 包含所有流行的 DL 框架（TensorFlow，Theano，Torch，Caffe等）。 43.DarknetStars：937 C语言版本的开源神经网络。 44.Theano TutorialsStars：904 基于Theano的机器学习入门教程，从线性回归到卷积神经网络。 45.RNN Music CompositionStars：904 一款生成古典音乐的递归神经网络工具。 46.BlocksStars：866 用于构建和训练神经网络模型的Theano框架 47.TDBStars：860 TensorFlow的交互式、节点调试和可视化的工具。 TensorDebugger (TDB) 是深度学习调试器，使用断点和计算机图形化实时数据流可视化扩展 TensorFlow（谷歌的深度学习框架）。特别的是，TDB 是一个 Python 库和 一个 Jupyter Notebook 扩展的结合，构建 Google 的 TensorFlow 框架。 48.Scikit Neural NetStars：849 深度神经网络入门工具，类似scikit-learn的分类器和回归模型。 49.VelesStars：760 分布式机器学习平台(Python, CUDA, OpenCL) VELES 是分布式深度学习应用系统，用户只需要提供参数，剩下的都可以交给 VELES。VELES 使用 Python 编写，使用 OpenCL 或者 CUDA，利用基于 Flow 的编程。它是三星开发的另一个 TensorFlow。 50.Deep DetectStars：759 基于C++11的深度学习接口和服务器，与Python绑定并支持Caffe。 51.TensorFlow DeepQStars：759 基于Google Tensorflow的深度Q学习演示。 52.Caffe on SparkStars：724 基于Spark的Caffe。 雅虎认为，深度学习应该与现有的支持特征工程和传统（非深度）机器学习的数据处理管道在同一个集群中，创建CaffeOnSpark意在使得深度学习训练和测试能被嵌入到Spark应用程序中。CaffeOnSpark被设计成为一个Spark深度学习包。 53.NolearnStars：702 神经网络库的抽象，著名的Lasagne。 54.DCGAN TensorFlowStars：568 基于tensorflow实现的深度卷积生成对抗网络。 55.MatConvNet Stars：479 MATLAB CNN 计算机视觉应用工具箱。 56.DeepCLStars：413 用于训练深度卷积神经网络模型的OpenCL库。 57.Visual Search ServerStars：304 可视化搜索服务器。一个简单使用TensorFlow，InceptionV3模型和AWS GPU实例实现的视觉搜索服务器。 代码实现两个方法，一个处理图像搜索的服务器和一个提取pool3功能的简单索引器。 最近邻搜索可以使用近似（更快）或使用精确方法（更慢）以近似方式执行。 来源：Top Deep Learning Projects 本文转自 https://www.oschina.net/news/79500/57-most-popular-deep-learning-project-at-github，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github代码搜索技巧_github 1,000 files.]]></title>
    <url>%2F2023%2F10%2F02%2Fgithub%E4%BB%A3%E7%A0%81%E6%90%9C%E7%B4%A2%E6%8A%80%E5%B7%A7-github-1-000-files%2F</url>
    <content type="text"><![CDATA[代码搜索网站 Github代码搜索技巧 1、按star数目搜索 2、follow一些github上面的大牛 3、Awesome + 你的关键字：搜索一些优秀的框架、教程、项目等 4、看一些搜索技巧，设定条件进行搜索 5、通过readme看看人家是否发出pull request 6、看explore推荐 7、看看其他 8、直接github上搜fackbook或者其他，可以看到他们的最新作品 Searching code Considerations for code search Scope the search fields Search by language Search by the number of forks the parent repository has Search by code size Search by the location of a file within the repository Search by filename Search by the file extension Search within a user’s or organization’s repositories 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/shuimuzy/article/details/55506706 代码搜索网站 代码：GitHubCodaseOhlohkrugleMerobase Component FinderGoogle Code Archive SymbolHound可以搜索特殊符号的搜索引擎，程序员的福音，遇到 Bash、正则之类的问题时候的利器！ HoogleHaskell 的专用函数搜索引擎，妈妈再也不用担心我的 Functional Programming RSeek.org R-project Search EngineR 语言专用搜索。 findjar.comJAR 搜索引擎，对 Java 编程有帮助。 Microsoft Research微软内部搜索，好东西多多，经常会发现 Google 学术搜不到的技术文献 针对 SEO 排名的知识搜索引擎：SEO优化网，完全在线学习 + 公式化结构化的 SEO 搜索算法 CA App Synthetic Monitor网站监控服务从世界各地查询网站的 Ping 结果。 Github代码搜索技巧很多人搜索github，但是芸芸众生，要找到自己想要的项目犹如海底捞针一般，今天教大家几项神技，可以快速找到自己想要的内容。 1、按star数目搜索比如JavaScript，要求星数，这样就能获取star数目最多的项目 2、follow一些github上面的大牛请登录：https://github-ranking.com/ 国内大牛：http://outofmemory.cn/github/ 这里是搜索名人的网址：https://github.com/search 高级搜索：https://github.com/search/advanced 3、Awesome + 你的关键字：搜索一些优秀的框架、教程、项目等 4、看一些搜索技巧，设定条件进行搜索地址：https://help.github.com/articles/searching-repositories/ 5、通过readme看看人家是否发出pull request看看这篇文章：http://blog.csdn.net/qianlong4526888/article/details/11529981 6、看explore推荐https://github.com/explore 7、看看其他http://blog.sina.com.cn/s/blog\_4e60b09d0102vcso.html 8、直接github上搜fackbook或者其他，可以看到他们的最新作品Searching code代码搜索 To search for code, use the following search qualifiers in any combination. Tip: There’s a list of search syntaxes you can add to any search qualifier to further improve your results. Considerations for code searchDue to the complexity of searching code, there are a few restrictions on how searches are performed: Only the default branch is considered. In most cases, this will be the master branch. Only files smaller than 384 KB are searchable. You must always include at least one search term when searching source code. For example, searching for language:go is not valid, while amazinglanguage:go is. At most, search results can show two fragments from the same file, but there may be more results within the file. You can’t use the following wildcard characters as part of your search query:., : ; / \ ` &#39; &quot; = * ! ? # $ &amp; + ^ | ~ &lt; &gt; ( ) { } []. The search will simply ignore these symbols. 以上是代码搜索中需要注意的一些问题 默认搜索是从master分支搜索代码 只有小于384k的代码才是可以搜索到的 搜索的时候必须包含至少一个搜索关键词 如amazing language:go 搜索语句不能有特殊字符如., : ; / \ ` &#39; &quot; = * ! ? # $ &amp; + ^ | ~ &lt; &gt; ( ) { } []. Scope the search fields指定搜索方式 octocat in:file Matches code where “octocat” appears in the file contents. 搜索文件中有octocat的代码 octocat in:path Matches code where “octocat” appears in the path name. 搜索路径中有octocat的代码 octocat in:file,path Matches code where “octocat” appears in the file contents or the path name. 搜索路径中有octocat的代码或者文件中有octocat的代码 display language:scss Matches code with the word “display,” that’s marked as being SCSS. 搜索用scss写的包含display的代码 Integer Matches code with the word “Integer”. 搜索包含Integer的字段 Search by language通过语言搜索代码 You can search for code based on what language it’s written in. For example: element language:xml size:100 Matches code with the word “element” that’s marked as being XML and has exactly 100 bytes. 搜索大小为100字节的xml代码 user:mozilla language:markdown Matches code from all @mozilla’s repositories that’s marked as Markdown. 搜索mozilla用户下用markdown写的代码 Search by the number of forks the parent repository has通过fork的数量或者是否有父节点的方式搜索 If you would like forked results to appear, add the fork:true qualifier. For example: android language:java fork:true Matches code in a forked repository with the word “android” that’s written in Java. 搜索用java写的 android相关的代码并且被fork过 Search by code sizeThe size qualifier filters results based on the size of the file in which the code is found. For example: function size:&gt;10000 language:python Matches code with the word “function,” written in Python, in files that are larger than 10 KB. 搜索与function相关的python代码，文件大小超过10kb Search by the location of a file within the repository按照目录结构搜索 By including the path qualifier, you specify that resulting source code must appear at a specific location in a repository. Subfolders are considered during the search, so be as specific as possible. For example: console path:app/public language:javascript Finds JavaScript files with the word “console” in an app/public directory (even if they reside in app/public/js/form-validators). 在 app/public directory目录下搜索console关键字 form path:cgi-bin language:perl Finds Perl files under cgi-bin with the word “form” in them. 搜索cgi-bin目录下包含form的perl代码 Search by filename通过文件名搜索 You can use the filename qualifier if there’s a specific file you’re looking for. For example: filename:.vimrc commands Finds *.vimrc* files with the word “commands” in them. 搜索 文件名匹配*.vimrc* 并且包含commands的代码 minitest filename:test_helper path:test language:ruby Finds Ruby files containing the word “minitest” named *test_helper* within the *test* directory. 在test目录中搜索包含minitest且文件名匹配”*test_helper*“的代码 Search by the file extension根据扩展名来搜索代码 The extension qualifier matches code files with a certain extension. For example: form path:cgi-bin extension:pm Matches code with the word “form,” under cgi-bin, with the .pm extension. 搜索cgi-bin目录下以pm为扩展名的代码 icon size:&gt;200000 extension:css Finds files larger than 200 KB that end in .css and have the word “icon” in them. 搜索超过200kb包含icon的css代码 Search within a user’s or organization’s repositories通过用户或者组织来查找 To grab a list of code from all repositories owned by a certain user or organization, you can use the usersyntax. For getting a list of code from a specific repository, you can use the repo syntax. For example: user:github extension:rb 本文转自 https://blog.csdn.net/shuimuzy/article/details/55506706，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitHub网页版删除分支_github 删除分支]]></title>
    <url>%2F2023%2F10%2F02%2FGitHub%E7%BD%91%E9%A1%B5%E7%89%88%E5%88%A0%E9%99%A4%E5%88%86%E6%94%AF-github-%E5%88%A0%E9%99%A4%E5%88%86%E6%94%AF%2F</url>
    <content type="text"><![CDATA[1，在网页版登录，进入你的工程项目，点击代码上方的“branch”按钮，如图。 2，之后你可以看到所有分支，点击垃圾筒图标删除你想删除的分支即可，如图。 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/yanhanhui1/article/details/82819665 1，在网页版登录，进入你的工程项目，点击代码上方的“branch”按钮，如图。 2，之后你可以看到所有分支，点击垃圾筒图标删除你想删除的分支即可，如图。 本文转自 https://blog.csdn.net/yanhanhui1/article/details/82819665，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gerrit: remote rejected HEAD->refs/for/master (change closed) 的问题 - 夜行过客]]></title>
    <url>%2F2023%2F10%2F02%2FGerrit-remote-rejected-HEAD-refs-for-master-change-closed-%E7%9A%84%E9%97%AE%E9%A2%98-%E5%A4%9C%E8%A1%8C%E8%BF%87%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[一. 错误现象 二. 解决办法 三. 扩展阅读（Git 合并多个Commit 提交） 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/yongdaimi/p/12583189.html 好久没有提交code了，主要最近一直在测试，今天把分支的代码merge一下，提交了一版code, 结果Gerrit来了个这么个问题，搞了大半天终于解决了，为了避免下次再遇到所以记录下。现象是这个样子的： 一. 错误现象 如图：Gerrit 扔了一个 ! [remote rejected] HEAD -&gt; refs/for/master (change http://btsw5.sdlc.rd.realtek.com/gerrit/2323 closed)error: failed to push some refs to ‘ssh://nisha_chen@btsw5.sdlc.rd.realtek.com:29418/8761BUR/app’ 的错误，我第一眼看到这个错误，直觉就是是不是哪次commit没有了？因为Gerrit上提示了：change http://btsw5.sdlc.rd.realtek.com/gerrit/2323 closed ， 然后我就到Gerrit 的web 页面上找2323的这次commit, 果不其然，这次commit 已经被别人merge了： 而且我注意到，这次commit已经不是最新的了，因为别的同事已经在这次commit之后，提交了新的代码： 那怎么办呢，虽然我Gerrit不敢说用的有多熟练，但是平时commit 成功的情况都是：本地的commit必须基于Gerrit的最新commit这样才能正常push 过去的。但是我的现在的commit却不是这个样子的：通过执行 git log —oneline 命令发现 我本地的commit 日志是这个样子的： 而Gerrit 服务器上最新的提交日志是这个样子的： 从图上很明显可以看出来，我的commit记录和Gerrit服务器上的commit记录已经完全不对应了，我本地merge代码后最新的commit记录是 65f6931,(因为之前已经拉过Gerrit上的代码) ，而Gerrit上的最新记录 是de5164e，且Gerrit上 efce048, ef08223, 34fbd21 这几次提交记录都是位于 de5164e这条提交记录之下的，我本地则刚好相反， efce048, ef08223, 34fbd21 这几次提交记录都是位于de5164e这条提交记录之上的。这就尴尬了，提交记录都不对应，合不进去是肯定的。那怎么解决呢，总不能把工作目录拷贝一份，然后从Gerrit上拉最新代码，然后再把不同的文件覆盖掉，再提交吧，我改了好多东西呢，这样太麻烦了。万般无奈，只能求助于Google： 二. 解决办法在Google上搜索“[remote rejected] head -&gt; refs/for/master (change closed)”，发现匹配的结果确实有不少，看来有不少人像我一样遇到过这个问题呀 打开第一条搜索结果：https://stackoverflow.com/questions/11972384/git-push-remote-rejected-change-closed ， 发现这哥们出错的结果与我很类似： 底下的高赞答案建议这么修改： 12I got the same message. And it was because I have managed to get the same Change-Id for two commits. Maybe due to some cherry-picking or similar between my local branches. Solved by removing the Change-Id from the commit message, a new Id then was added by the commit hook. 大概意思就是删除commit message中的 Change id, 我想那行呀，于是执行git commit —amend, 找到Change-Id, 把 Change-id 删了再次提交，结果很遗憾，错误还是一样，不行。 打开第二条搜索结果：https://blog.csdn.net/u014418064/article/details/79039332 ， 看着他描述的错误信息跟我是一样的，但是不知道他说直接abandon掉，不知道要abandon什么，看不懂，不行。 打开第三条搜索结果：https://www.cnblogs.com/yanchengwang/p/6947221.html ， 这哥们直接采用 git push -f 命令，姑且先不说行不行，git push -f 命令我是很不喜欢用的，具体什么原因大家都清楚，强行push commit 一般在公司里是不允许的，可能会引发很严重的问题。 翻来翻去没什么特别好的答案，大多数都是像第一条搜索结果一样，建议直接删除 Change id, 再次push, 可我试了，不行呀。百无聊赖之下，重新打开第一条搜索记录，找找看有没有什么其它的解决办法，我一般看StackOverFlow, 如果高赞答案解决不了问题的时候，喜欢往下再看几条，有时候有些低赞答案才是解决问题的关键，毕竟每个人遇到的问题都不一样，解决途径肯定也不一样。看着看着，有一条结果引起了我的兴趣： 他给的解决方案大概是说，合并最近的几次提交为一个，合并完了之后再删除合并完的 Commit Message的 Change id, 我想了想，他说的也有道理，我最近的几次提交中有几个已经被Gerrit merge了，但是在我本地看，这些已经被merge的commit 却在Gerrit最新的提交记录之上，要是能把它们合并成一条记录，这样如果将来真的能够push 成功，最起码能够保证 Gerrit 的commit 记录上不会出现一些相同的Commit Message, 那就试试吧，反正死马当活马医呗，实在不行用git reset —hard 恢复就行了。 使用 git log —oneline 命令查看，目前在我本地位于Gerrit最新的Commit之上的记录一共有4条： 合并这四条记录 git rebase -i HEAD~4 : 执行该命令之后，Git出现如下界面，让你选择针对每次提交的操作方式： 我选择的合并策略是保留第一次提交的记录，并且丢掉后面几次提交的Commit 记录（注意，仅仅是丢掉commit的日志，这条记录对应的修改仍然会被应用，所以不必担心这几次提交的修改会丢失）,也就是 102ab44 记录我仍然保持为Pick , 35e44af, 4e45785, 65f6931 这几条记录我修改为 f，修改完毕之后使用wq退出保存： Git 提示合并已经成功，这个时候git log 再看一下本地的log记录： ！！！ 那几条已经被Merge 的记录没有了！而且我本地的最新记录位于Gerrit的最新提交记录之上！这才是正常的提交现象嘛，平时都是这样才能push 成功的，满怀心喜的又提交了一次，结果： Why? 看起来不是已经正常了么？怎么Gerrit还是拒绝我提交呀，满怀失落的我再次运行git log 看了一下： 无意中发现这条Change-Id 怎么这么眼熟？好像在哪里见过似的，于是打开Gerrit 的web 界面， 找到那个已经被别人Merge的Change-ID: 居然一模一样！那肯定是不行的，Change-Id 必须是唯一的，这条Commit既然已经被Merge了，再提交一个相同Change-Id的Commit肯定是不行的呀。于是我突然明白了最开始看的那条高赞答案删除Change-Id的意义，它删除Change-Id的目的原来是为了生成一个新的Change-Id,如果新的Change-Id和已Merge的那条记录的Change-id不一样，那么有可能会成功的。于是我用git commit —amend 再次打开最后一次提交的记录 对之前的Commit信息进行再一次修改之后，删除这里的Change-Id: wq, 保存退出，再次push : 看到Git提示终于成功了，打开Gerrit 的web管理界面： 界面显示我本次的提交处于：Need Verfied Label 状态，这样才对嘛，我平时看到的提交成功之后的状态就是这个样子。 问题解决完了，心里还是很佩服Git/Gerrit的设计者, 其实工作中遇到的Git问题Git基本都有解，只是一些Git的命令或者是操作方式我们自己不知道罢了，还是那句话，有事不明多Google， 通过这次踩坑之旅我又一次见识了Git的强大。 三. 扩展阅读（Git 合并多个Commit 提交）这篇文章讲解了如何使用 git rebase 指令来合并多个Commit, 个人觉得还不错，特此分享过来，URL： https://www.jianshu.com/p/29bb983ec48a, 不过他的文章里有些小问题，我会在后面指出。 当你提交代码进行代码审查时或者创建一次pull request (这在开源项目中经常发生)，你的代码在被接受之前会被要求做一些变更。于是你进行了变更，并且直到下一次审查之前你没有再次被要求进行变更过。在你知道又要进行变更之前，你已经有了一些额外的commit。理想情况下，你可以用rebase命令把多个commit压缩成一个。 1git rebase -i HEAD~\[number\_of\_commits\] 如果你想要压缩最后三个commit，你需要运行下列命令（注意：如果一共有4次提交，则只能压缩后3次提交！不能执行 git rebase -i HEAD~4 ）： 1git rebase -i HEAD~3 为了模拟实际git rebase效果，我们先在git上提交两个修改。git log如下： 123commit 7b16b280f22fe4ff57c1879867a624f6f0f14398Author: pan Date: Sun Apr 22 08:55:32 2018 +0800 update3commit a7186d862b95efc5cc1d7c98277af4c72bac335dAuthor: pan Date: Sun Apr 22 08:55:16 2018 +0800 update2 commit 16a9a4749f8ee25ab617c46925f57c2fa8a4937eAuthor: pan Date: Sun Apr 22 08:54:55 2018 +0800 update1 假设合并这3个提交，可以按照下面过程 1git rebase -i HEAD~3 执行命令后终端会出输出： (注意：这里输出的顺序刚好和执行git log命令输出的顺序是相反的！【也就是说 ，旧Commit在前，新的Commit在后】笔者做了多次实验，得出的结果依然如此，而且通过commit id也可以看出来，原文作者在这里是有问题的，大家不要被误导) 123456789101112131415161718192021pick 16a9a47 update1 pick a7186d8 update2pick 7b16b28 update3 # Rebase a9269a3..7b16b28 onto a9269a3 (3 commands) # # Commands: # p, pick \= use commit # r, reword \= use commit, but edit the commit message# e, edit \= use commit, but stop for amending# s, squash \= use commit, but meld into previous commit# f, fixup \= like &quot;squash&quot;, but discard this commit&apos;s log message# x, exec = run command (the rest of the line) using shell# d, drop \= remove commit## These lines can be re\-ordered; they are executed from top to bottom.## If you remove a line here THAT COMMIT WILL BE LOST.## However, if you remove everything, the rebase will be aborted.## Note that empty commits are commented out~ 注： 第一列是rebase具体执行的操作，其中操作可以选择，其中含义如下： 选择pick操作，git会应用这个补丁，以同样的提交信息（commit message）保存提交 选择reword操作，git会应用这个补丁，但需要重新编辑提交信息 选择edit操作，git会应用这个补丁，但会因为amending而终止 选择squash操作，git会应用这个补丁，但会与之前的提交合并 选择fixup操作，git会应用这个补丁，但会丢掉提交日志 选择exec操作，git会在shell中运行这个命令 对比之前的两个提交提交，我觉得第一个提交可以保留，第二个和第三个合并到第一个就可以了。 将第二个和第三个pick改成squash或者s，然后保存退出。如下： 123pick 16a9a47 update1 s a7186d8 update2s 7b16b28 update3 此时git会自动将第二个提交合并到第一个提交，并弹出合并提示信息，如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243\# This is a combination of 3 commits.# This is the 1st commit message:update1 # This is the commit message #2: update2 # This is the commit message #3: update3 # Please enter the commit message for your changes. Lines starting# with &apos;#&apos; will be ignored, and an empty message aborts the commit.## Date: Sun Apr 22 08:54:55 2018 +0800## interactive rebase in progress; onto a9269a3# Last commands done (3 commands done):# s a7186d8 update# s 7b16b28 update6666# No commands remaining.如果需要修改下提交信息，如果不需要直接保存退出即可。# This is a combination of 3 commits. 合并提交测试# Please enter the commit message for your changes. Lines starting # with &apos;#&apos; will be ignored, and an empty message aborts the commit. # # Date: Sun Apr 22 08:54:55 2018 +0800 # # interactive rebase in progress; onto a9269a3 # Last commands done (3 commands done): # s a7186d8 update # s 7b16b28 update6666 # No commands remaining. 此时我们已经完成了将两个提交合并为一个的处理，可以通过git log查看 123commit 4a51759fae9bbd84904029473fe09f8a77f143edAuthor: pan Date: Sun Apr 22 08:54:55 2018 +0800 合并提交测试 -————————————————- 2020/7/29 更新-—————————————————————— 有几点需要特别强调下： 比如当前的提交顺序是： 123Update 1 // 最老的提交Update 2Update 3 // 最新的提交 1. 不能对Update1 执行 squash 或者是 fixup 操作，原因上面已经说过了，squash 操作需要与之前的提交合并，但是很明显在合并的这三个提交中，Update 1没有之前的提交；fixup 与 squash 类似，也需要与之前的提交合并，只是会丢弃 comment message。如果此时你对Update 1执行了上述两种操作，git 会报： 123error: cannot &apos;fixup&apos; without a previous commitYou can fix this with &apos;git rebase --edit-todo&apos; and then run &apos;git rebase --continue&apos;.Or you can abort the rebase with &apos;git rebase --abort&apos;. 诸如此类的错误。 如果只是想合并这三个提交，个人觉得在选择合并策略时，最优的合并方式应该是： 123r Update1 // 应用这次提交，但是需要重新编辑Comment messagef Update2 // 丢弃Update2的Comment Message, 与Update1合并f Update3 // 丢弃Update3的Comment Message，与Update2合并 这样只需要在接下来重新编辑下合并后的Comment Message就可以了，不会出现像上面原文作者那样一大堆的 comment message, 事实上既然是合并操作，那单条Commit的 Message肯定有很多是不需要的。 总结 注意本文仅仅介绍了我遇到的多个提交合并的问题，关于git rebase用法，建议参考Git Community Book 中文版-rebase和参考资料中的介绍。 多数情况下git rebase仅限在本地使用，也就是在提交到远程分支之前。 参考链接 1. StackOverFlow: Git push remote rejected {change ### closed} 简书：Git 合并多个Commit提交 本文转自 https://www.cnblogs.com/yongdaimi/p/12583189.html，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Failed to connect to github.com port 443: Connection refused]]></title>
    <url>%2F2023%2F10%2F02%2FFailed-to-connect-to-github-com-port-443-Connection-refused%2F</url>
    <content type="text"><![CDATA[问题现象: 问题原因: 问题解决 第一步记录github.com的ip地址，通过IP地址查询可查询 第二步通过路径找到hosts文件: 第三步找到红色箭头的hosts文件: 第四步重新git拉代码 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://juejin.cn/post/6999811900368224263 问题现象:12近期在使用git拉代码的时候,发现代码无法clone下来,后来又尝试使用GitHub Desktop工具进行桌面端拉代码问题还是一样,无法拉代码提示错误如下: Failed to connect to github.com port 443: Connection refused 问题原因:12一般产生这种原因的可能都是因为开了梯子或者其他代理工具导致的,刚开始也是这种想法,就用了重置代理或者取消代理的方式进行尝试解决! 12git config --global http.proxy &apos;socks5://127.0.0.1:1080&apos;git config --global https.proxy &apos;socks5://127.0.0.1:1080&apos; 12git config --global --unset http.proxygit config --global --unset https.proxy 1234但是做了上述尝试之后发现并没有效果还是提示上述报错,根本没法解决问题,即使关闭了梯子发现问题还是一样存在,那么估计产生的问题也并非可能是代理产生的,也许是DNS解析这块,于是开始尝试修改hosts文件,修改ip地址和域名的映射关系,在DNS解析前先会尝试走hosts然后在找不到的的情况下再DNS解析,修改hosts文件域名解析就会先走hosts中的ip和域名的映射关系 问题解决第一步记录github.com的ip地址，通过IP地址查询可查询复制地址以下地址 1github.com IP地址查询 将复制好的github.com域名复制上查询到对应的ip地址 复制红色标志的是github的IP地址 第二步通过路径找到hosts文件:复制地址以下路径 1C:\Windows\System32\drivers\etc 第三步找到红色箭头的hosts文件: 第四步重新git拉代码 本文转自 https://juejin.cn/post/6999811900368224263，如有侵权，请联系删除。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mock的基础用法及安装]]></title>
    <url>%2F2023%2F10%2F02%2Fmock%E7%9A%84%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95%E5%8F%8A%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[mock的基础用法及安装 如何安装mock？ 找到所需要安装的位置,安装mock 使用 定义规则，拦截请求，返回数据 在main.js中 导入mock 请求数据 mock常用的语法 @cname生成姓名 随机生成1-100之间 随机生成25-50之间小数点后2-5位 随机生成1-5个★ 随机生成8-14位的标题 随机生成段落 随机ture或false 随机从数组中生成2-10个数据的Array 随机从Object中生成2个数据的Object 随机生成1开头11位的字符串 随机生成邮箱 随机生成函数内的数据并运行函数 随机生成日期 随机生成时间 随机生成城市地点 随机生成200x180图例 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://codeantenna.com/a/2aPWyigHYM#:~:text=%E6%88%91%E4%BB%AC%E4%BD%BF%E7%94%A8mock,%E6%95%B0%E6%8D%AE%EF%BC%8C%E4%BB%A5%E6%A8%A1%E6%8B%9F%E6%8E%A5%E5%8F%A3 mock的基础用法及安装为什么要使用mock 其实是后端接口未完成编写，此时前端无法使用接口，这时mock就派上极大的用途。 我们使用mock进行数据拦截（数据未发出之前就被mock拦截）同时返回特定的数据，以模拟接口 如何安装mock？找到所需要安装的位置,安装mock1npm i mockjs 使用定义规则，拦截请求，返回数据建了一个@/utils/mock.js文件12345678910// 导入mockimport Mock from &quot;mockjs&quot;;//拦截Ajax请求生成伪数据// 只要网络地址匹配到这个正则就会拦截Mock.mock(/\\/v5\\/list/, &#123; name: &apos;baize&apos;, age: 18&#125;) 在main.js中 导入mock1import &quot;@/utils/mock&quot; 请求数据12345678910111213import axios from &quot;axios&quot;export default&#123;created()&#123;axios.get(&quot;/v5/list&quot;) .then(res =&gt; &#123; console.log(&quot;模拟数据&quot;, res.data) &#125;) .catch(err =&gt; &#123; console.log(err); &#125;) &#125;&#125; mock常用的语法@cname生成姓名1 &quot;name&quot;: &quot;@cname&quot;, 随机生成1-100之间1 &quot;agel1-100&quot;: 1, 随机生成25-50之间小数点后2-5位1 &quot;price|25-50.2-5&quot;: 1, 随机生成1-5个★1 &quot;score|1-5&quot;: &quot;★&quot;, 随机生成8-14位的标题1 &quot;title&quot;: &quot;@ctitle(8,14)&quot;, 随机生成段落1 &quot;description&quot;: &quot;@cparagraph&quot;, 随机ture或false1 &quot;isLog|1&quot;: true, 随机从数组中生成2-10个数据的Array1 &quot;friend | 2-10&quot;: \[&quot;小红&quot;, &quot;小绿&quot;, &quot;小蓝&quot;\], 随机从Object中生成2个数据的Object123456789 &quot;des|2&quot;: &#123; &quot;eye&quot;: 1, &quot;hand&quot;: 2, &quot;job&quot;: &quot;teacher&quot; &#125;, 随机生成1开头11位的字符串1 &quot;tel&quot;: /1\\d&#123;10&#125;/, 随机生成邮箱1 &quot;email&quot;: /\[a-z\]&#123;2,6\]@(126|163|qq)\\.(com|cn|net)/, 随机生成函数内的数据并运行函数1234567 &quot;canMerry&quot;: function () &#123; if (this.age &gt; 22) &#123; return true; &#125; else &#123; return false; &#125; &#125;, 随机生成日期1 &quot;day&quot;: &quot;@date( &apos;yyyy-MM-dd&apos; )&quot;, 随机生成时间1 &quot;time&quot;: &quot;@time( &apos;HH:mm:ss&apos; )&quot;, 随机生成城市地点1 &quot;add&quot;: &quot;@county(true)&quot;, 随机生成200x180图例1 &quot;avatar&quot;: &quot;@dataImage(&apos;200x180&apos;,&apos;图例&apos;)&quot; 更多相关推荐 php namespace及use的用法Mock.js相关知识点NumPy基础及取值操作 educoder头歌实践作业CMD的几个常用用法python 下划线的不同用法 文章随机推荐 Pytorch的to(device)用法 数组的获取及赋值 JavaScript的基础学习(一) python if not的用法 redis基础用法 【niubi-job——一个分布式的任务调度框架】——niubi-j… 解决python中’chromedriver’ executable needs to be… 基于ELman神经网络的税收预测模型-统计与决策 机器学习-距离度量 （六）：spring bean的注入方式 【转载】6个Async/Await优于Promise的方面 python 倒数两列_这20个常规Python语法你都搞明白了吗… Ubuntu 14.04 内核升级 详细步骤 【Linux】七个运行级别 mate9 android8.0 rom,华为Mate9 8.0降级：EMUI8.0回… 修改文件使2000 server运行非专业版的卡巴斯基 C语言面试题精粹（一） php无法导出excel,PHPExcel导出无法正常工作：显示“无… linux笔记：软件包管理-软件包简介 Response.End出现终止线程]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>前端</tag>
        <tag>mock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[7款最好用的bilibili视频下载线上工具推荐]]></title>
    <url>%2F2023%2F10%2F02%2F7%E6%AC%BE%E6%9C%80%E5%A5%BD%E7%94%A8%E7%9A%84bilibili%E8%A7%86%E9%A2%91%E4%B8%8B%E8%BD%BD%E7%BA%BF%E4%B8%8A%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90%2F</url>
    <content type="text"><![CDATA[插件 1、ByClick Downloader 2、VideoFK 3、Video To Save 4、Tube Offline 5、9xBuddy 6、FetchFile 7、哔哩哔哩bilibili影片下载工具 其他问题 1、从bilibili下载的视频可以作为商业用途吗？ 2、bilibili视频下载后会存放在哪里？ 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://zhuanlan.zhihu.com/p/474482997 插件1、ByClick DownloaderByClick Downloader ByClick Downloader是一款B站视频下载工具，它具有操作直接的使用界面，能够帮你快速从B站下载视频，并把视频以MP3和MP4的格式输出。 同时它也具有一些额外功能，例如下载B站播放列表、字幕等。ByClick Downloader还能让你在浏览器上观看视频时，自动识别出视频并在右下角显示下载提示框。 优点： 支持B站视频下载功能 能下载B站播放列表 提供多种视频画质选择，包括1080p、720p、4K和8K 具备自动检测B站视频的功能 缺点： 免费功能有限，需要付费才能使用完整功能 只支持Windows系统 价格： 年费7.99欧元 终身9.99欧元 2、VideoFKVideoFK 其次，推荐我最喜欢的B站视频下载工具——VideoFK，不需要安装任何应用程序和外挂，只要把B站视频链接复制粘贴，然后再注册一个账号就可以开始下载。 它最大的有点事除了支持B站下载外，也支持下载火山、抖音、快手、微博、腾讯视频等热门平台的视频内容。 不过它虽然支持下载的平台多，但还是有一个缺点就是视频储存格式只有一种-MP4格式，幸好这个问题很好处理，只要使用视频格式转换软件，就可以轻松将MP4格式转换成FLV、AVI等其它格式。 顺带提一下，下载时会进入一个视频播放器，你只要点选右上角“三点”图示就会有下载选项可以选择。 优点： 容易使用 简洁的使用界面 缺点： 视频输出格式只有MP4一种 需要注册 价格： 免费 3、Video To SaveVideo To Save Video To Save也是一款线上工具，你只需要将视频URL复制粘贴到输入框中，即可从B站下载视频。这是一个免费工具，你可以使用它下载MP4或flv格式的视频文件。 使用此工具从B站下载视频时，你不需要安装任何第三方软件或注册，只需要粘贴视频链接并按下载按钮，即可开始使用。 在下载视频前，你还可以检查视频的大小（以MB为单位）和视频格式。 优点： 无需注册 简单的复制粘贴，即可使用 简洁的用户界面 下载前可检查文件大小 缺点： 有时它不会显示文件格式 价格： 免费 4、Tube OfflineTube Offline Tube Offline是另一款不错的B站下载工具，你只需要在工具中放上B站视频的链接，即可开始使用。该工具为你提供下载前选择视频画质和视频格式的选项。 共有三种画质选项，分别为“正常”、“最佳”和“低画质”，而你可以下载五种格式的B站视频，这些格式分别为MP4、FLV、AVI、WMV和MP3。 不过这个工具有个比较大的缺点、就是整个过程速度比较慢。 优点： 提供画质和视频格式选项 使用方便 无需注册 缺点： 使用界面差 广告很多 执行速度慢 价格： 免费 5、9xBuddy9xBuddy 9xBuddy是非常方便的B站视频下载线上工具，因为使用这款工具下载B站视频非常容易。你可以通过两种方式来下载视频。让我们一一介绍。 第一种方法就是简单的将B站视频的URL复制并粘贴到这个工具上，然后你将获得可下载的文件，只需要点击下载按钮即可下载该视频。 第二种方法非常有趣，在这个方法中，你只需要打开B站并播放要下载的视频即可。进入下载视频页面后，你必须在地址栏中编辑链接，只需在URL的开头加上“http://9xbud.com/”,你就会被重定向到可以下载视频的界面。 例如，如果你的视频链接是“https：//http://www.bilibili.com/video/ED1q …”则编辑后的链接将是“http://9xbud.com/www.bilibili.com/video/ED1q …” 此外，在下载B站视频之前，你还可以检查要下载的视频大小和格式。 优点： 提供两种下载视频的方法 下载前可检查视频大小和格式 无需注册 缺点： 缺乏自定义选项 价格： 免费 6、FetchFileFetchFile FetchFile是一款免费的线上工具，你可以使用该工具从B站下载视频，它提供不同的视频格式，例如MP4、WebM、Audio、3GPP和X-FLV。 它还支持各种视频画质选项，例如1080P、HD、FullHD和UltraHD。 优点： 使用方便 无需注册 缺点： 有广告 没有中文界面 价格： 免费 7、哔哩哔哩bilibili影片下载工具 哔哩哔哩bilibili影片下载工具是一个Chrome浏览器扩展程序，它非常易于使用，只要安装之后打开要下载的哔哩哔哩视频，你就会在右下角看到一个下载图表，点击就可以直接下载。 优点： Chrome扩展程序很方便 无需注册 缺点： 需要安装谷歌Chrome浏览器 价格： 免费 其他问题1、从bilibili下载的视频可以作为商业用途吗？从bilibili下载视频必须要CCO授权，或联系视频作者取得使用许可，才能够将视频使用在商业用途，不然将会面临侵犯著作权的问题。 2、bilibili视频下载后会存放在哪里？使用浏览器从bilibili下载视频时，视频会自动存储到浏览器预设的下载文件夹中。如果你忘记预设路径在哪里，可以在浏览器设置选项中查找。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[跨域报错，When allowCredentials is true, allowedOrigins cannot contain the special value]]></title>
    <url>%2F2023%2F10%2F02%2F%E8%B7%A8%E5%9F%9F%E6%8A%A5%E9%94%99%EF%BC%8CWhen-allowCredentials-is-true-allowedOrigins-cannot-contain-the-special-value%2F</url>
    <content type="text"><![CDATA[1. 跨域报错 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://zhuanlan.zhihu.com/p/358946657 1. 跨域报错参考文档： 报错信息如下： 1234When allowCredentials is true, allowedOrigins cannot contain the special value &quot;*“since that cannot be set on the “Access-Control-Allow-Origin” response header. To allow credentials to a set of origins, list them explicitly or consider using&quot;allowedOriginPatterns” instead. 翻译如下 当allowCredentials为true时，allowedOrigins不能包含特殊值“*”，因为不能在“Access Control Allow Origin”响应头上设置该值。要允许凭据指向一组源，请显式列出它们，或者考虑改用“allowedOriginPatterns”。 解决办法：跨域配置报错，将.allowedOrigins替换成.allowedOriginPatterns即可。 12345678910111213141516171819@Configurationpublic class WebMvcConfig implements WebMvcConfigurer &#123; /** * 开启跨域 */ @Override public void addCorsMappings(CorsRegistry registry) &#123; // 设置允许跨域的路由 registry.addMapping(&quot;/**&quot;) // 设置允许跨域请求的域名------------修改此行 .allowedOriginPatterns(&quot;*&quot;) // 是否允许证书（cookies） .allowCredentials(true) // 设置允许的方法 .allowedMethods(&quot;*&quot;) // 跨域允许时间 .maxAge(3600); &#125;&#125;]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>前后端分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Node.js安装详细步骤教程(Windows版) - 码探长]]></title>
    <url>%2F2023%2F10%2F02%2FNode-js%E5%AE%89%E8%A3%85%E8%AF%A6%E7%BB%86%E6%AD%A5%E9%AA%A4%E6%95%99%E7%A8%8B-Windows%E7%89%88-%E7%A0%81%E6%8E%A2%E9%95%BF%2F</url>
    <content type="text"><![CDATA[什么是Node.js？ 安装教程 1.下载安装包 2.安装 3.配置npm在安装全局模块时的路径和缓存cache的路径 4.测试 总结 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/matanzhang/p/11441693.html 什么是Node.js？简单的说 Node.js 就是运行在服务端的 JavaScript。 Node.js是一个基于 Chrome V8 引擎的 JavaScript 运行环境； Node.js使用一个事件驱动、非阻塞式 I/O 的模型，使其轻量且高效； Node.js的软件包生态系统npm是全球最大的开源库生态系统。 安装教程本机环境：Windows 7 旗舰版 64bit操作系统 1.下载安装包Node.js 官方网站下载：https://nodejs.org/en/download/ 下载完成，安装包如下： 2.安装双击打开安装，下一步下一步即可（笔者安装路径为“D:\Program Files\nodejs”）： …… 安装成功，测试安装是否成功，运行CMD，分别输入node -v 和 npm -v 分别查看node和npm的版本号，如下图所示： 安装完成后系统目录如图所示（其中，npm随安装程序自动安装，作用就是对Node.js依赖的包进行管理）： 3.配置npm在安装全局模块时的路径和缓存cache的路径因为在执行例如npm install webpack -g等命令全局安装的时候，默认会将模块安装在C:\Users\用户名\AppData\Roaming路径下的npm和npm_cache中，不方便管理且占用C盘空间， 所以这里配置自定义的全局模块安装目录，在node.js安装目录下新建两个文件夹 node_global和node_cache，如图所示： 然后在cmd命令下执行如下两个命令： 123npm config set prefix &quot;D:\\Program Files\\nodejs\\node\_global&quot;npm config set cache &quot;D:\\Program Files\\nodejs\\node\_cache&quot; 执行命令，如下图所示： 执行完后，配置环境变量，如下： “环境变量” -&gt; “系统变量”：新建一个变量名为 “NODE_PATH”， 值为“D:\Program Files\nodejs\node_global\node_modules**”，如下图： “环境变量” -&gt; “用户变量”：编辑用户变量里的Path，将相应npm的路径（“C:\Users\用户名\AppData\Roaming\npm”）改为：“D:\Program Files\nodejs\node_global”，如下： 配置完成。 4.测试 在cmd命令下执行 npm install webpack -g 安装webpack，如下图所示： 安装成功，自定义文件夹如下所示： 在cmd命令下执行 webpack -v 查看webpack版本，如下图所示： 总结以上node.js的安装，笔者已亲测可用，希望本篇博客对您有所帮助，在安装配置过程中，若遇到问题，欢迎留言交流！]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue 3.x 全局引入axios 方法]]></title>
    <url>%2F2023%2F10%2F02%2FVue%203.x%20%E5%85%A8%E5%B1%80%E5%BC%95%E5%85%A5axios%20%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. vue 全局引入 axios 大概会在网上找到下面两种方案： 一、改写Vue的原型属性 二、使用vue-axios插件 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/semishigure/p/14705215.html 1. vue 全局引入 axios 大概会在网上找到下面两种方案：一、改写Vue的原型属性方法是在main.js中写入 12345import &#123; createApp &#125; from &apos;vue&apos;import App from &apos;./App.vue&apos;import axios from &apos;axios&apos;const app = createApp(App)app.prototype.$http= axios 经过踩坑，发现vue3.0取消了Vue.prototype，官方文档推荐使用globalProperties于是main.js改写成 12345import &#123; createApp &#125; from &apos;vue&apos;import App from &apos;./App.vue&apos;import axios from &apos;axios&apos;const app = createApp(App)app.config.globalProperties.$http = axios 然后在组件中引用 1234this.$http.get(&apos;api/getNewsList&apos;).then((response)=&gt;&#123; console.log(response)&#125;) 继续踩坑 vue3.0中是没有this的。使用getCurrentInstance来获取上下文const { proxy } = getCurrentInstance() 这里的proxy相当于this 12345const &#123; proxy &#125; = getCurrentInstance()proxy.$http.get(&apos;api/getNewsList&apos;).then((response)=&gt;&#123; console.log(response)&#125;) 二、使用vue-axios插件首先在主入口文件main.js中引用： 123456import &#123; createApp &#125; from &apos;vue&apos;import App from &apos;./App.vue&apos;import axios from &apos;axios&apos;import VueAxios from &apos;vue-axios&apos;const app = createApp(App)app.use(VueAxios,axios); 然后在组件中引用，注意vue3.x没有this 1234axios.get(&apos;api/getNewsList&apos;).then((response)=&gt;&#123; console.log(response)&#125;)]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>js</tag>
        <tag>VUE</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vue 未登录或登录失效重定向到登录页，登录后再回到登录前的页面]]></title>
    <url>%2F2023%2F10%2F02%2Fvue%20%E6%9C%AA%E7%99%BB%E5%BD%95%E6%88%96%E7%99%BB%E5%BD%95%E5%A4%B1%E6%95%88%E9%87%8D%E5%AE%9A%E5%90%91%E5%88%B0%E7%99%BB%E5%BD%95%E9%A1%B5%EF%BC%8C%E7%99%BB%E5%BD%95%E5%90%8E%E5%86%8D%E5%9B%9E%E5%88%B0%E7%99%BB%E5%BD%95%E5%89%8D%E7%9A%84%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[1. Vue实现登录拦截 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://www.cnblogs.com/duanzhenzhen/p/13042201.html 1. Vue实现登录拦截实现思路： 1.router中给需要登录后才能访问的页面配置meta:{needLogin:true} 2.登录页面，调用登录接口成功后，给cookie中存入用户信息（我这里是存uuid和sessionid相关内容） 3.request.js的接口请求拦截器中，根据接口返回的code值判断用户是否登录或登录是否已失效（我这里是未登录和已失效code==1000），失效的话，将cookie中的用户信息移除 4. main.js中使用router.beforeEach，步骤1设置的需登录才能访问的页面中，通过判断cookie中是否有用户的uuid和sessionid信息，确定用户是否已登录（未登录时uuid信息肯定不存在，但登录失效时uuid是存在的，所以要在步骤3中通过判断code值，清除uuid新增）。当用户未登录时跳转到登录页，并将当前页面的重定向路径带到登录页面地址中 1.router index.js 配置哪些页面需要登录才能访问 2.main.js判断用户是否已登录（我用的cookie存储的用户信息，存储方法在auth.js里。） 12import Vue from &apos;vue&apos; import \* as auth from &apos;@/utils/auth&apos; 123456789101112131415161718192021 //判断是否登录router.beforeEach(function (to, from, next) &#123; if (to.meta.needLogin) &#123; //从cookie中获取用户信息，判断是否已登录 if (auth.getAdminInfo().userUuid) &#123; next(); //表示已经登录 &#125; else &#123; //未登录 //next可以传递一个路由对象作为参数 表示需要跳转到的页面 next(&#123; name: &quot;login&quot;, query: &#123;redirect: to.meta.redirect&#125; //登录后再跳回此页面时要做的配置 &#125;); &#125; &#125; else &#123; //表示不需要登录 next(); //继续往后走 &#125;&#125;); 3.auth.js里代码，重点部分标红 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677import Cookies from &apos;js-cookie&apos;const TokenKey \= &apos;Admin-Token&apos;const rolesName \= &quot;adminRoles&quot;**const adminInfo = &quot;adminInfo&quot;**// 存储数据localStorage（数组对象格式）export function setStorageObj(key,obj) &#123; var str = JSON.stringify(obj); return localStorage.setItem(key,str);&#125;//获取数据（数组对象格式）export function getStorageObj(key) &#123; return JSON.parse(localStorage.getItem(key));&#125;//存储数据（字符串）export function setStorage(key,data) &#123; return localStorage.setItem(key,data);&#125;//获取数据（字符串）export function getStorage(key) &#123; return localStorage.getItem(key)&#125;//清除数据（所有格式）export function removeStorage(key) &#123; return localStorage.removeItem(key);&#125;//存储tokenexport function getToken() &#123; return Cookies.get(TokenKey)&#125;export function setToken(token) &#123; return Cookies.set(TokenKey, token)&#125;export function removeToken() &#123; return Cookies.remove(TokenKey)&#125;//存储角色export function getAdminRoles() &#123; const roles \= Cookies.get(rolesName) if(roles)&#123; console.log(roles) return JSON.parse(roles) &#125; return &apos;&apos;&#125;export function setAdminRoles(roles) &#123; return Cookies.set(rolesName, JSON.stringify(roles))&#125;//获取用户信息**export function getAdminInfo() &#123; console.log(&apos;获取用户信息&apos;) const admin = Cookies.get(adminInfo) if(admin)&#123; return JSON.parse(admin) &#125; return &apos;&apos;&#125;**//存储用户信息export function setAdminInfo(admin) &#123; return Cookies.set(adminInfo, JSON.stringify(admin))&#125;//移除用户信息export function removeAdminInfo() &#123; return Cookies.remove(adminInfo)&#125; 4.login.vue页面 123456789101112131415161718methods: &#123; //登录 login(formName)&#123; this.$refs\[formName\].validate((valid) =&gt; &#123; if (valid) &#123; console.log(&apos;登录&apos;,this.form) this.$store.dispatch(&apos;user/getUserLogin&apos;,this.form).then(() =&gt; &#123; this.$router.push(&#123; path: this.redirect || &apos;/&apos; &#125;) &#125;).catch(() =&gt; &#123; this.loading = false &#125;) &#125; else &#123; console.log(&apos;error submit!!&apos;); return false; &#125; &#125;); &#125; &#125; 5.vuex（调用登录接口成功后，存储用户信息） 6.vuex登出 7.请求拦截 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394import axios from &apos;axios&apos;import &#123; MessageBox, Message&#125; from &apos;element-ui&apos;**import store from &apos;@/store&apos;**import ElementUI from &apos;element-ui&apos;import QS from &apos;qs&apos;import \* as auth from &apos;@/utils/auth&apos;// import router from &apos;@/router&apos;// const hostUrl = &apos;http://192.168.0.189:8888&apos;// create an axios instanceconst service = axios.create(&#123; // baseURL: hostUrl, timeout: 50000 // request timeout&#125;)//请求头配置service.defaults.headers.post\[&apos;Content-Type&apos;\] = &apos;application/json;charset=UTF-8&apos;;// request interceptorservice.interceptors.request.use( config \=&gt; &#123; //给请求头添加内容的话，从这里配置 // if (store.getters.token) &#123; // config.headers\[&apos;Authorization&apos;\] = getToken() // &#125; return config &#125;, error \=&gt; &#123; console.log(error) // for debug return Promise.reject(error) &#125;)// response interceptorservice.interceptors.response.use( response \=&gt; &#123; //未登录、登录过期code==1000 **if(response.data.code == 1000)&#123; store.dispatch(&apos;user/logout&apos;).then(() =&gt; &#123; location.reload() &#125;) &#125;** //其他错误，根据接口返回数据的规律调整 if(response.data.code != 200 &amp;&amp; (response.data.code != 1000))&#123; ElementUI.Message(&#123; type:&apos;error&apos;, message:response.data.message &#125;) return Promise.reject(&apos;error&apos;) &#125; return Promise.resolve(response.data) &#125;, error \=&gt; &#123; console.log(&apos;error&apos;,error); Message(&#123; message: &apos;服务器内部错误&apos;, type: &apos;error&apos;, duration: 3 \* 1000 &#125;) return Promise.reject(error) &#125; )class http &#123; static async getPage(url, params)&#123; return service.get(url, &#123; params: params &#125;) &#125; static async post(url, params)&#123; return service.post(url, QS.stringify(params)) &#125; static async postItem(url, params)&#123; if(!params)&#123; params \= &#123;&#125;; &#125; // params\[&apos;userUuid&apos;\]=&apos;9E396DE798B240FA8D2162BFE6AC494C&apos;; // params\[&apos;sessionId&apos;\]=&apos;16e413064c97466c9bef6d9f9e69c5aa&apos;; // 获取userUuid和sessionId params\[&apos;userUuid&apos;\] = auth.getAdminInfo().userUuid; params\[&apos;sessionId&apos;\] = auth.getAdminInfo().sessionId; return service.post(url, params) &#125;static async postNew(url, params)&#123; return service.post(url, params)&#125;&#125; export default http]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>js</tag>
        <tag>VUE</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何在win10系统上使用旧版本的IE浏览器_旧版ie浏览器]]></title>
    <url>%2F2023%2F10%2F02%2F%E5%A6%82%E4%BD%95%E5%9C%A8win10%E7%B3%BB%E7%BB%9F%E4%B8%8A%E4%BD%BF%E7%94%A8%E6%97%A7%E7%89%88%E6%9C%AC%E7%9A%84IE%E6%B5%8F%E8%A7%88%E5%99%A8-%E6%97%A7%E7%89%88ie%E6%B5%8F%E8%A7%88%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1. 在win10系统上使用旧版本的IE浏览器 第一步： 第二步： 第三步： 报错解决：开发人员工具在IE模式下不可用。若要调试页面，请在IE11中将其打开。 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/weixin_50902406/article/details/130125357 1. 在win10系统上使用旧版本的IE浏览器 win10系统打开IE浏览器自动变成了Edge浏览器，切换成IE模式时，IE浏览器的版本默认为IE11（注：Edge浏览器只支持IE11），有些网站只能使用IE浏览器打开或者在做一些兼容性测试时，需要使用到不同版本的浏览器。下面介绍一下，如何在win10系统上使用旧版本的IE浏览器： 第一步：使用Edge浏览器打开网站，点击右上角的…图标，选择选项在IE模式下重新加载（打开以后，这个IE浏览器的版本是IE11） 第二步：在弹出提示栏中勾选“在兼容性视图中打开此页面”、“下次在IE模式下打开此页面”（如果下次不想使用IE打开此页面，也可以不勾选这个选项） 第三步：按f12进入开发者模式，找到仿真，可修改IE浏览器的版本 报错解决：开发人员工具在IE模式下不可用。若要调试页面，请在IE11中将其打开。 后面通过查看资料，找到的解决办法是： （1）使用win+r打开“运行”对话框，输入cmd，点击确定 （2）输入“%systemroot%\system32\f12\IEChooser.exe”，回车 （3）在 IEChooser 中，选择“IE 模式”选项卡的条目 （4）进入到仿真页面，可选择不同的IE浏览器版本]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java压缩优化]]></title>
    <url>%2F2023%2F10%2F02%2FJava%E5%8E%8B%E7%BC%A9%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[1. 前言 第一天 第二天 第三天 第四天 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://zhuanlan.zhihu.com/p/364142487 1. 前言— 最近在做数据导出的功能，由于要支持批量导出且导出的文件都巨大3GB起，所以决定在导出最终结果时进行压缩 第一天java压缩，emmm…首先想到的就是java.util.zip下面的各种api，直接上代码： 1234567891011121314151617181920212223242526272829303132333435363738394041/*** 批量压缩文件 v1.0* * @param fileNames 需要压缩的文件名称列表(包含相对路径) * @param zipOutName 压缩后的文件名称**/public static void batchZipFiles(List&lt;String&gt; fileNames, String zipOutName) &#123; //设置读取数据缓存大小 byte[] buffer = new byte[4096]; ZipOutputStream zipOut = null; try &#123; zipOut = new ZipOutputStream(new FileOutputStream(zipOutName)); for (String fileName : fileNames) &#123; File inputFile = new File(fileName); if (inputFile.exists()) &#123; BufferedInputStream bis = new BufferedInputStream(new FileInputStream(inputFile)); //将文件写入zip内，即将文件进行打包 zipOut.putNextEntry(new ZipEntry(inputFile.getName())); //写入文件的方法，同上 int size = 0; //设置读取数据缓存大小 while ((size = bis.read(buffer)) &gt;= 0) &#123; zipOut.write(buffer, 0, size); &#125; //关闭输入输出流 zipOut.closeEntry(); bis.close(); &#125; &#125; &#125; catch (Exception e) &#123; log.error(&quot;batchZipFiles error:sourceFileNames:&quot; + JSONObject.toJSONString(fileNames), e); &#125; finally &#123; if (null != zipOut) &#123; try &#123; zipOut.close(); &#125; catch (Exception e) &#123; log.error(&quot;batchZipFiles error:sourceFileNames:&quot; + JSONObject.toJSONString(fileNames), e); &#125; &#125; &#125; &#125; 首先利用BufferedInputStream读取文件内容，ZipOutputStream的putNextEntry方法对每一个文件进行压缩写入。 最后将所有压缩后的文件写入到最终的zipOutName文件中。由于用了BufferedInputStream缓冲输入流，文件的读取和写入都是从缓存区(内存)中也就是代码里面对应的byte数组获取，相比较普通的FileInputStream提升了较大的效率。但是不够！耗时如下： 压缩三个大小为3.5GB的文件 第二天想到了NIO，传统的IO叫BIO(上面代码)是同步阻塞的，读写都在一个线程中。NIO则是同步非阻塞的,核心是channel(通道),buffer(缓冲区),Selector(选择器)。 其实说的通俗易懂点就是NIO在密集型计算下效率之所以比BIO高的原因是NIO是多路复用，用更少的线程最更多的事情，相对于BIO大大减少了线程切换，竞争带来的资源损耗。不多BB了，上代码： 123456789101112131415161718192021222324252627282930313233343536/** * 批量压缩文件 v2.0 * * @param fileNames 需要压缩的文件名称列表(包含相对路径) * @param zipOutName 压缩后的文件名称 **/ public static void batchZipFiles(List&lt;String&gt; fileNames, String zipOutName) throws Exception &#123; ZipOutputStream zipOutputStream = null; WritableByteChannel writableByteChannel = null; ByteBuffer buffer = ByteBuffer.allocate(2048); try &#123; zipOutputStream = new ZipOutputStream(new FileOutputStream(zipOutName)); writableByteChannel = Channels.newChannel(zipOutputStream); for (String sourceFile : fileNames) &#123; File source = new File(sourceFile); zipOutputStream.putNextEntry(new ZipEntry(source.getName())); FileChannel fileChannel = new FileInputStream(sourceFile).getChannel(); while (fileChannel.read(buffer) != -1) &#123; //更新缓存区位置 buffer.flip(); while (buffer.hasRemaining()) &#123; writableByteChannel.write(buffer); &#125; buffer.rewind(); &#125; fileChannel.close(); &#125; &#125; catch (Exception e) &#123; log.error(&quot;batchZipFiles error fileNames:&quot; + JSONObject.toJSONString(fileNames), e); &#125; finally &#123; zipOutputStream.close(); writableByteChannel.close(); buffer.clear(); &#125; &#125; 还是利用java.nio包下面的api，首先用Channels.newChannel()方法将zipOutputStream输出流创建一个写的通道通道，在读取文件内容的时候直接用FileInputStream.getChannel() 获取当前文件读的通道，然后从读的通道中通过ByteBuffer(缓冲区)读取文件内容写入writableByteChannel写通道中，一定记得反转缓冲区buffer.flip()，否则读取的内容就是文件最后的内容byte=0时的。这种方法相较于上面的速度如下图所示： 压缩三个大小为3.5GB的文件 第三天继续优化，听说用上内存映射文件的方式更快！那还等什么，让我来try一try！撸代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * 批量压缩文件 v3.0 * * @param fileNames 需要压缩的文件名称列表(包含相对路径) * @param zipOutName 压缩后的文件名称 **/public static void batchZipFiles(List&lt;String&gt; fileNames, String zipOutName) &#123; ZipOutputStream zipOutputStream = null; WritableByteChannel writableByteChannel = null; MappedByteBuffer mappedByteBuffer = null; try &#123; zipOutputStream = new ZipOutputStream(new FileOutputStream(zipOutName)); writableByteChannel = Channels.newChannel(zipOutputStream); for (String sourceFile : fileNames) &#123; File source = new File(sourceFile); long fileSize = source.length(); zipOutputStream.putNextEntry(new ZipEntry(source.getName())); int count = (int) Math.ceil((double) fileSize / Integer.MAX_VALUE); long pre = 0; long read = Integer.MAX_VALUE; //由于一次映射的文件大小不能超过2GB，所以分次映射 for (int i = 0; i &lt; count; i++) &#123; if (fileSize - pre &lt; Integer.MAX_VALUE) &#123; read = fileSize - pre; &#125; mappedByteBuffer = new RandomAccessFile(source, &quot;r&quot;).getChannel() .map(FileChannel.MapMode.READ_ONLY, pre, read); writableByteChannel.write(mappedByteBuffer); pre += read; &#125; //释放资源 Method m = FileChannelImpl.class.getDeclaredMethod(&quot;unmap&quot;, MappedByteBuffer.class); m.setAccessible(true); m.invoke(FileChannelImpl.class, mappedByteBuffer); mappedByteBuffer.clear(); &#125; &#125; catch (Exception e) &#123; log.error(&quot;zipMoreFile error fileNames:&quot; + JSONObject.toJSONString(fileNames), e); &#125; finally &#123; try &#123; if (null != zipOutputStream) &#123; zipOutputStream.close(); &#125; if (null != writableByteChannel) &#123; writableByteChannel.close(); &#125; if (null != mappedByteBuffer) &#123; mappedByteBuffer.clear(); &#125; &#125; catch (Exception e) &#123; log.error(&quot;zipMoreFile error fileNames:&quot; + JSONObject.toJSONString(fileNames), e); &#125; &#125; &#125; 这里有两个坑的地方是： 1.利用MappedByteBuffer.map文件时如果文件太大超过了Integer.MAX时(大约是2GB)就会报错： 所以这里需要分次将要写入的文件映射为内存文件。 2.这里有个bug，就是将文件映射到内存后，在写完就算clear了mappedByteBuffer，也不会释放内存，这时候就需要手动去释放，详细见上代码。 看速度！ 压缩三个大小为3.5GB的文件 肯定是我的打开方式有问题，为什么反而是最慢的。。难道是文件太大了吗？我的机器内存太小了？还是我用的有问题，让我思考一下。。希望留言区讨论一下。 第四天我在想批量压缩文件这么慢是不是因为是串行的，如果改成多线程并行那不是会快了？说干就干，本来想自己写的，后来在google上查资料发现apache-commons有现成的，那果断不重复造轮子，上代码： 12345678910111213141516171819202122232425262728293031323334/** * 批量压缩文件 v4.0 * * @param fileNames 需要压缩的文件名称列表(包含相对路径) * @param zipOutName 压缩后的文件名称 **/public static void compressFileList(String zipOutName, List&lt;String&gt; fileNameList) throws IOException, ExecutionException, InterruptedException &#123; ThreadFactory factory = new ThreadFactoryBuilder().setNameFormat(&quot;compressFileList-pool-&quot;).build(); ExecutorService executor = new ThreadPoolExecutor(5, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(20), factory); ParallelScatterZipCreator parallelScatterZipCreator = new ParallelScatterZipCreator(executor); OutputStream outputStream = new FileOutputStream(zipOutName); ZipArchiveOutputStream zipArchiveOutputStream = new ZipArchiveOutputStream(outputStream); zipArchiveOutputStream.setEncoding(&quot;UTF-8&quot;); for (String fileName : fileNameList) &#123; File inFile = new File(fileName); final InputStreamSupplier inputStreamSupplier = () -&gt; &#123; try &#123; return new FileInputStream(inFile); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); return new NullInputStream(0); &#125; &#125;; ZipArchiveEntry zipArchiveEntry = new ZipArchiveEntry(inFile.getName()); zipArchiveEntry.setMethod(ZipArchiveEntry.DEFLATED); zipArchiveEntry.setSize(inFile.length()); zipArchiveEntry.setUnixMode(UnixStat.FILE_FLAG | 436); parallelScatterZipCreator.addArchiveEntry(zipArchiveEntry, inputStreamSupplier); &#125; parallelScatterZipCreator.writeTo(zipArchiveOutputStream); zipArchiveOutputStream.close(); outputStream.close(); log.info(&quot;ParallelCompressUtil-&gt;ParallelCompressUtil-&gt; info:&#123;&#125;&quot;, JSONObject.toJSONString(parallelScatterZipCreator.getStatisticsMessage())); &#125; 先看结果： 压缩三个大小为3.5GB的文件 果然还是并行的快！ 原文作者：tinyOrange原文地址：https://juejin.cn/post/6949355730814107661]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>Java编码实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java导入，导出，多层文件夹压缩]]></title>
    <url>%2F2023%2F10%2F02%2FJava%E5%AF%BC%E5%85%A5%EF%BC%8C%E5%AF%BC%E5%87%BA%EF%BC%8C%E5%A4%9A%E5%B1%82%E6%96%87%E4%BB%B6%E5%A4%B9%E5%8E%8B%E7%BC%A9%2F</url>
    <content type="text"><![CDATA[1. Zip工具类 1.导入excel 2.导出excel 3.导出zip 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/qq_42207808/article/details/106927101 1. Zip工具类123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130package com.pty.bip.common.util;import java.io.*;import java.util.List;import java.util.zip.ZipEntry;import java.util.zip.ZipOutputStream;public class ZipUtils &#123; private static final int BUFFER_SIZE = 2 * 1024; /** * 压缩成ZIP 方法1 * @param srcDir 压缩文件夹路径 * @param out 压缩文件输出流 * @param KeepDirStructure 是否保留原来的目录结构,true:保留目录结构; * false:所有文件跑到压缩包根目录下(注意：不保留目录结构可能会出现同名文件,会压缩失败) * @throws RuntimeException 压缩失败会抛出运行时异常 */ public static void toZip(String srcDir, OutputStream out, boolean KeepDirStructure) throws RuntimeException&#123; long start = System.currentTimeMillis(); ZipOutputStream zos = null ; try &#123; zos = new ZipOutputStream(out); File sourceFile = new File(srcDir); compress(sourceFile,zos,sourceFile.getName(),KeepDirStructure); long end = System.currentTimeMillis(); System.out.println(&quot;压缩完成，耗时：&quot; + (end - start) +&quot; ms&quot;); &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;zip error from ZipUtils&quot;,e); &#125;finally&#123; if(zos != null)&#123; try &#123; zos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 压缩成ZIP 方法2 * @param srcFiles 需要压缩的文件列表 * @param out 压缩文件输出流 * @throws RuntimeException 压缩失败会抛出运行时异常 */ public static void toZipList(List&lt;File&gt; srcFiles , OutputStream out)throws RuntimeException &#123; long start = System.currentTimeMillis(); ZipOutputStream zos = null ; try &#123; zos = new ZipOutputStream(out); for (File srcFile : srcFiles) &#123; byte[] buf = new byte[BUFFER_SIZE]; zos.putNextEntry(new ZipEntry(srcFile.getName())); int len; FileInputStream in = new FileInputStream(srcFile); while ((len = in.read(buf)) != -1)&#123; zos.write(buf, 0, len); &#125; zos.closeEntry(); in.close(); &#125; long end = System.currentTimeMillis(); System.out.println(&quot;压缩完成，耗时：&quot; + (end - start) +&quot; ms&quot;); &#125; catch (Exception e) &#123; throw new RuntimeException(&quot;zip error from ZipUtils&quot;,e); &#125;finally&#123; if(zos != null)&#123; try &#123; zos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; &#125; /** * 递归压缩方法 * @param sourceFile 源文件 * @param zos zip输出流 * @param name 压缩后的名称 * @param KeepDirStructure 是否保留原来的目录结构,true:保留目录结构; * false:所有文件跑到压缩包根目录下(注意：不保留目录结构可能会出现同名文件,会压缩失败) * @throws Exception */ private static void compress(File sourceFile, ZipOutputStream zos, String name, boolean KeepDirStructure) throws Exception&#123; byte[] buf = new byte[BUFFER_SIZE]; if(sourceFile.isFile())&#123; // 向zip输出流中添加一个zip实体，构造器中name为zip实体的文件的名字 zos.putNextEntry(new ZipEntry(name)); // copy文件到zip输出流中 int len; FileInputStream in = new FileInputStream(sourceFile); while ((len = in.read(buf)) != -1)&#123; zos.write(buf, 0, len); &#125; // Complete the entry zos.closeEntry(); in.close(); &#125; else &#123; File[] listFiles = sourceFile.listFiles(); if(listFiles == null || listFiles.length == 0)&#123; // 需要保留原来的文件结构时,需要对空文件夹进行处理 if(KeepDirStructure)&#123; // 空文件夹的处理 zos.putNextEntry(new ZipEntry(name + &quot;/&quot;)); // 没有文件，不需要文件的copy zos.closeEntry(); &#125; &#125;else &#123; for (File file : listFiles) &#123; // 判断是否需要保留原来的文件结构 if (KeepDirStructure) &#123; // 注意：file.getName()前面需要带上父文件夹的名字加一斜杠, // 不然最后压缩包中就不能保留原来的文件结构,即：所有文件都跑到压缩包根目录下了 compress(file, zos, name + &quot;/&quot; + file.getName(),KeepDirStructure); &#125; else &#123; compress(file, zos, file.getName(),KeepDirStructure); &#125; &#125; &#125; &#125; &#125;&#125; 1.导入excel12345678910111213141516171819202122232425262728293031323334353637383940 //表头下载@GetMapping(path = &quot;/excelExport/&#123;id&#125;&quot;)@ApiOperation(value = &quot;表头下载&quot;)@SuppressWarnings(&quot;resource&quot;)public void ExcelExport(@PathVariable(&quot;id&quot;) String id, HttpServletResponse response, HttpServletRequest request) &#123; HashMap&lt;String, Object&gt; params = (HashMap) cacheManager.getCache(ehcacheExcelName).get(id).get(); if (null == params) &#123; try &#123; response.getWriter().write(&quot;&quot;); return; &#125; catch (IOException e) &#123; log.error(&quot;查询导出excel参数异常:&#123;&#125;&quot;, e.getMessage()); &#125; &#125; List list = (List&lt;ExcelExportVo&gt;) params.get(&quot;title&quot;); BipDepCheckRef bipDepCheckRef = new BipDepCheckRef(); bipDepCheckRef.setKeyword(params.get(&quot;keyword&quot;).toString()); bipDepCheckRef.setFiscal(params.get(&quot;fiscal&quot;).toString()); checkRefService.excelExport(list,bipDepCheckRef,response, request);&#125; @PostMapping(path = &quot;/uploadExcel&quot;)@ApiOperation(value = &quot;导入excle&quot;)public Response uploadExcel(HttpServletRequest request, ExcelExportVo excelExportBean) &#123; MultipartHttpServletRequest multiRequest = (MultipartHttpServletRequest) request; Iterator iterator = multiRequest.getFileNames(); // 解析文件 if (iterator.hasNext()) &#123; String name = (String) iterator.next(); MultipartFile file = multiRequest.getFile(name); CheckMsg check = checkRefService.uploadExcel(file, excelExportBean); if (check.isSuccess()) &#123; return Response.success().setMsg(check.getMsgInfo()); &#125; else &#123; return Response.fail().setMsg(check.getMsgInfo()); &#125; &#125; return null;&#125; 12//导入excel CheckMsg uploadExcel(MultipartFile file, ExcelExportVo excelExportBean); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104import org.apache.poi.hssf.usermodel.*;import org.apache.poi.ss.usermodel.*;import org.apache.poi.xssf.usermodel.XSSFWorkbook; import java.io.File;import java.io.FileInputStream;import java.io.InputStream;import java.io.OutputStream;import java.net.URLEncoder; @Override @Transactional public CheckMsg uploadExcel(MultipartFile file, ExcelExportVo params) &#123; try &#123; JSONArray jsonArray = JSONArray.fromObject(params.getExcelExportVoList()); List&lt;ExcelExportVo&gt; list2 = (List) JSONArray.toCollection(jsonArray, ExcelExportVo.class); File excel = null; if (file.equals(&quot;&quot;) || file.getSize() &lt;= 0) &#123; file = null; &#125; else &#123; InputStream ins = file.getInputStream(); excel = new File(file.getOriginalFilename()); BipBasicExpService.inputStreamToFile(ins, excel); &#125; if (excel.isFile() &amp;&amp; excel.exists()) &#123; //判断文件是否存在 String[] split = excel.getName().split(&quot;\\.&quot;); //.是特殊字符，需要转义！！！！！ Workbook wb = null; //根据文件后缀（xls/xlsx）进行判断 if (&quot;xls&quot;.equals(split[1])) &#123; FileInputStream fis = new FileInputStream(excel); //文件流对象 wb = new HSSFWorkbook(fis); &#125; else if (&quot;xlsx&quot;.equals(split[1])) &#123; wb = new XSSFWorkbook(excel); &#125; else &#123; return null; &#125; //开始解析 Sheet sheet = wb.getSheetAt(0); //读取sheet 0 //读取第一行 Row row1 = sheet.getRow(0); //获取总列数 short lastCellNum = row1.getLastCellNum(); //如果表头与导入excel列数不一致，则模板错误 if (list2.size() != lastCellNum) &#123; return CheckMsg.fail(&quot;模板格式错误，请选择正确的模板重新导入&quot;); &#125; //循环判断表头与excel列表头是否一致 for (int i = 0; i &lt; list2.size(); i++) &#123; Cell cell1 = row1.getCell(i); if (!list2.get(i).getDesc().equals(String.valueOf(cell1))) &#123; return CheckMsg.fail(&quot;模板格式错误，请选择正确的模板重新导入&quot;); &#125; &#125; int firstRowIndex = sheet.getFirstRowNum() + 1; //第一行是列名，所以不读 int lastRowIndex = sheet.getLastRowNum(); List&lt;BipDepCheckRef&gt; checkRefs = new ArrayList&lt;&gt;(); //遍历行 就证明有 新增多少条数据 for (int rIndex = firstRowIndex; rIndex &lt;= lastRowIndex; rIndex++) &#123; BipDepCheckRef checkRef = new BipDepCheckRef(); checkRef.setFiscal(params.getFiscal()); checkRef.setRefId(IDGenerator.UUID()); Row row = sheet.getRow(rIndex); if (row != null) &#123; // 根据 遍历的 表头 跟 每列的值 进行 一会计划 赋值 for (int a = 0; a &lt; list2.size(); a++) &#123; //遍历列 // cell 相当于每个 单元格的值。 Cell cell = row.getCell(a); if (cell != null) &#123; cell.setCellType(CellType.STRING); String stringCellValue = cell.getStringCellValue(); BeanUtils.setProperty(checkRef, list2.get(a).getValue(), stringCellValue); &#125; &#125; File del = new File(excel.toURI()); del.delete(); checkRefs.add(checkRef); &#125; &#125; if (checkRefs.size() &gt; 0) &#123; BipDepCheckRef checkRef = new BipDepCheckRef(); checkRef.setFiscal(params.getFiscal()); depCheckRefDao.del(checkRef); //分批批量插入，oracle10g只支持coulum*size&lt;=1000 int insertLength = checkRefs.size(); int i = 0; while (insertLength &gt; 20) &#123; depCheckRefDao.insertBatch(checkRefs.subList(i, i + 20)); i = i + 20; insertLength = insertLength - 20; &#125; if (insertLength &gt; 0) &#123; depCheckRefDao.insertBatch(checkRefs.subList(i, i + insertLength)); &#125; return CheckMsg.success(&quot;成功导入&quot; + checkRefs.size() + &quot;条&quot;); &#125; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return CheckMsg.fail(&quot;找不到指定的文件&quot;); &#125; 2.导出excel1234567891011121314151617181920212223242526272829303132333435363738394041424344import org.springframework.cache.CacheManager;import java.io.IOException;@Autowiredprivate CacheManager cacheManager;private final String ehcacheExcelName = &quot;excel&quot;;//缓存 表头数据@ApiOperation(value = &quot;缓存请求参数数据&quot;, notes = &quot;缓存导出excel请求参数数据&quot;)@PostMapping(value = &quot;/excelParams&quot;)public Response saveExcelParams(@RequestBody HashMap&lt;String, Object&gt; params) &#123; String id = StringUtil.getUUID(); cacheManager.getCache(ehcacheExcelName).put(id, params); return Response.success().setData(id);&#125;//表头下载@GetMapping(path = &quot;/excelExport/&#123;id&#125;&quot;)@ApiOperation(value = &quot;表头下载&quot;)@SuppressWarnings(&quot;resource&quot;)public void ExcelExport(@PathVariable(&quot;id&quot;) String id, HttpServletResponse response, HttpServletRequest request) &#123; HashMap&lt;String, Object&gt; params = (HashMap) cacheManager.getCache(ehcacheExcelName).get(id).get(); if (null == params) &#123; try &#123; response.getWriter().write(&quot;&quot;); return; &#125; catch (IOException e) &#123; log.error(&quot;查询导出excel参数异常:&#123;&#125;&quot;, e.getMessage()); &#125; &#125; List&lt;ExcelExportVo&gt; list = (List&lt;ExcelExportVo&gt;) params.get(&quot;title&quot;); List&lt;BipSchePlan&gt; value = (List&lt;BipSchePlan&gt;) params.get(&quot;value&quot;); String userCode = (String) params.get(&quot;userCode&quot;); String agyCode = (String) params.get(&quot;agyCode&quot;); Integer fiscal = (Integer) params.get(&quot;fiscal&quot;); Integer agyType = (Integer) params.get(&quot;agyType&quot;); String fundType = (String)params.get(&quot;fundType&quot;); budSchePlanService.excelToExport(list, value, agyType,fundType, fiscal, response, request);&#125; 123//导出excelvoid excelToExport(List title, List value, Integer agyType,String fundType, Integer fiscal, HttpServletResponse response, HttpServletRequest request); 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213import java.util.*;import java.util.stream.Collectors;import java.util.zip.ZipEntry;import java.util.zip.ZipOutputStream; import java.io.*;import org.apache.poi.hssf.usermodel.HSSFCell;import org.apache.poi.hssf.usermodel.HSSFCellStyle;import org.apache.poi.hssf.usermodel.HSSFFont;import org.apache.poi.hssf.usermodel.HSSFRow;import org.apache.poi.hssf.usermodel.HSSFSheet;import org.apache.poi.hssf.usermodel.HSSFWorkbook;import org.apache.poi.hssf.util.HSSFColor;import org.apache.poi.ss.usermodel.CellStyle;import org.apache.poi.ss.util.CellRangeAddress; @Override public void excelToExport(List title, List value, Integer agyType,String fundType, Integer fiscal, HttpServletResponse response, HttpServletRequest request) &#123; try &#123; HSSFWorkbook wb = new HSSFWorkbook(); HSSFSheet sheet = wb.createSheet(&quot;导出excel&quot;); // 第一行 HSSFRow row = sheet.createRow(0); HSSFRow row1 = sheet.createRow(1); HSSFRow row2 = sheet.createRow(2); HSSFRow row3 = sheet.createRow(3); HSSFRow row5 = sheet.createRow(4); //CellStyle style = CatalogExcelUtil.getHeadStyle(wb); String fundTypeName; if(&quot;1&quot;.equals(fundType))&#123; fundTypeName=&quot;当年&quot;; &#125;else &#123; fundTypeName=&quot;上年&quot;; &#125; HSSFFont font = wb.createFont(); font.setFontHeightInPoints((short) 12); font.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD);//粗体显示 font.setFontName(&quot;新宋体&quot;); font.setColor(HSSFColor.RED.index); font.setBoldweight((short) 10); HSSFCellStyle border = wb.createCellStyle(); border.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 border.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 border.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 border.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 //1.生成字体对象 HSSFCellStyle cellFontStyle = wb.createCellStyle(); cellFontStyle.setFont(font); HSSFCellStyle cellStyleRight = wb.createCellStyle(); cellStyleRight.setAlignment(HSSFCellStyle.ALIGN_RIGHT);//right HSSFCellStyle setFont2 = wb.createCellStyle(); HSSFFont font2 = wb.createFont(); font2.setFontName(&quot;仿宋_GB2312&quot;); font2.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD);//粗体显示 font2.setFontHeightInPoints((short) 18); HSSFCellStyle cellStyle = wb.createCellStyle(); cellStyle.setAlignment(HSSFCellStyle.ALIGN_CENTER); // 居中 cellStyle.setFont(font2); HSSFCellStyle setBorder = wb.createCellStyle(); setBorder.setWrapText(true);//设置自动换行 setBorder.setVerticalAlignment(HSSFCellStyle.VERTICAL_CENTER);//垂直居中 setBorder.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 setBorder.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 setBorder.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 setBorder.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 sheet.addMergedRegion(new CellRangeAddress(0, 0, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(1, 1, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(2, 2, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(3, 3, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(4, 4, 0, 5)); sheet.addMergedRegion(new CellRangeAddress(4, 4, 30, 31)); HSSFCell cell = row.createCell(0); cell.setCellValue(&quot;1、绿色表格部分公式已设定，请勿随意改动。&quot;); cell.setCellStyle(cellFontStyle); HSSFCell cell1 = row1.createCell(0); cell1.setCellValue(&quot;2、请各单位按照表式认真填列，不得有空项。&quot;); cell1.setCellStyle(cellFontStyle); HSSFCell cell2 = row2.createCell(0); if(&quot;1&quot;.equals(fundType))&#123; cell2.setCellValue(&quot;3、单位整体6月累计执行计划不低于45%；8月不低于66%；10月不低于83%；全年累计执行计划达到100%。&quot;); &#125; else &#123; cell2.setCellValue(&quot;&quot;); &#125; cell2.setCellStyle(cellFontStyle); HSSFCell cell3 = row3.createCell(0); cell3.setCellValue(&quot;国家体育总局及直属事业单位（协会）&quot; + fiscal + fundTypeName + &quot;预算执行计划表（含彩票公益金）&quot;); cell3.setCellStyle(cellStyle); HSSFCell cell4 = row5.createCell(30); cell4.setCellValue(&quot;单位：万元&quot;); cell4.setCellStyle(cellStyleRight); sheet.setColumnWidth(0,10*256); sheet.setColumnWidth(1,30*256); sheet.setColumnWidth(2,22*256); sheet.setColumnWidth(3,20*256); sheet.setColumnWidth(4,8*256); sheet.setColumnWidth(5,20*256); sheet.setColumnWidth(6,20*256); HSSFRow rows = sheet.createRow(5); HSSFCellStyle canEditStyle = wb.createCellStyle(); canEditStyle.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 canEditStyle.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 canEditStyle.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 canEditStyle.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 canEditStyle.setLocked(true); //设置列的锁定状态为锁定 HSSFCellStyle noCanEdit = wb.createCellStyle(); noCanEdit.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 noCanEdit.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 noCanEdit.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 noCanEdit.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 noCanEdit.setLocked(false); //设置列的锁定状态为锁定 //得到前端数据值集 List&lt;Map&lt;String, Object&gt;&gt; list = value; //得到单位预算码列 List&lt;Map&gt; map =budSchePlanDao.selectMadAgys(); //循环遍历两个结果集，进行匹配替换预算码 if (list.size() &gt; map.size()) &#123; for (int i = 1; i &lt; list.size(); i++) &#123; for(int y = 0; y &lt; map.size(); y++)&#123; if(list.get(i).get(&quot;agyCode&quot;).equals(map.get(y).get(&quot;agyName&quot;)))&#123; list.get(i).remove(&quot;agyCode&quot;); list.get(i).put(&quot;agyCode&quot;,map.get(y).get(&quot;agyCode&quot;)); &#125; &#125; &#125; &#125; else&#123; for (int i = 0; i &lt; map.size(); i++) &#123; for(int y = 1; y &lt; list.size(); y++)&#123; if(list.get(y).get(&quot;agyCode&quot;).equals(map.get(i).get(&quot;agyName&quot;)))&#123; list.get(y).remove(&quot;agyCode&quot;); list.get(y).put(&quot;agyCode&quot;,map.get(i).get(&quot;agyCode&quot;)); &#125; &#125; &#125; &#125; //条件匹配完毕进入过滤条件项 List&lt;Map&lt;String, Object&gt;&gt; collect =list; collect.stream().forEach(col-&gt;&#123; if(&quot;人员经费&quot;.equals(col.get(&quot;projectName&quot;)) || &quot;公用经费&quot;.equals(col.get(&quot;projectName&quot;)) )&#123; col.remove(&quot;projectName&quot;); col.put(&quot;projectName&quot;,&quot;&quot;); &#125; if(&quot;99901&quot;.equals(col.get(&quot;projectCode&quot;)) || &quot;99902&quot;.equals(col.get(&quot;projectCode&quot;)) )&#123; col.remove(&quot;projectCode&quot;); col.put(&quot;projectCode&quot;,&quot;&quot;); &#125; &#125;); int num = 6; for (int i = 0; i &lt; collect.size(); i++) &#123; HSSFRow row4 = sheet.createRow(num++); for (int a = 0; a &lt; title.size(); a++) &#123; HSSFCell rowsCell = rows.createCell(a); rowsCell.setCellStyle(setBorder); rowsCell.setCellValue(((LinkedHashMap) title.get(a)).get(&quot;desc&quot;).toString()); LinkedHashMap object = (LinkedHashMap) title.get(a); String object2 = object.get(&quot;value&quot;).toString(); HSSFCell createCell = row4.createCell(a); if (a &lt; 8) &#123; createCell.setCellStyle(canEditStyle); &#125; if (a &gt;= 8 &amp;&amp; a &lt; 33) &#123; createCell.setCellStyle(noCanEdit); &#125; if(a==9 || a==11 || a==13 || a==15 || a==17 || a==19|| a==21 || a==23 || a==25 || a==27 || a==29 || a==31)&#123; createCell.setCellValue((collect.get(i)).get(object2) == null ? &quot;&quot; : (collect.get(i)).get(object2).toString().concat(&quot;%&quot;)); &#125; else&#123; createCell.setCellValue((collect.get(i)).get(object2) == null ? &quot;&quot; : (collect.get(i)).get(object2).toString()); &#125; &#125; &#125; // 必须在单元格设值以后进行 // 设置为根据内容自动调整列宽/* for (int k = 0; k &lt; 5; k++) &#123; sheet.autoSizeColumn(k); &#125;*/ sheet.protectSheet(&quot;123&quot;); String saveFileName = &quot;&quot;; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyyMMdd&quot;); saveFileName += format.format(Calendar.getInstance().getTime())+fundTypeName+ &quot;预算执行计划表.xls&quot;; response.reset(); response.setContentType(&quot;application/octet-stream;charset=UTF-8&quot;); String userAgent = request.getHeader(&quot;user-agent&quot;); Boolean b = userAgent.indexOf(&quot;Edge&quot;) == -1 &amp;&amp; (userAgent.indexOf(&quot;Firefox&quot;) &gt;= 0 || userAgent.indexOf(&quot;Chrome&quot;) &gt;= 0 || userAgent.indexOf(&quot;Safari&quot;) &gt;= 0); if (b) &#123; saveFileName = new String((saveFileName).getBytes(), &quot;ISO8859-1&quot;); &#125; else &#123; //其他浏览器 saveFileName = URLEncoder.encode(saveFileName, &quot;UTF8&quot;); &#125; response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;filename=&quot; + saveFileName); OutputStream os = response.getOutputStream(); wb.write(os); os.flush(); os.close(); &#125; catch (Exception e) &#123; &#125; &#125; 3.导出zip123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427 @Override public void collectExcelExport(List title,String isAllAgy, BipSchePlan bip, Integer fiscal, HttpServletResponse response, HttpServletRequest request) &#123; try &#123; // 将excel导出的文件位置 String filePath = &quot;C:&quot;+File.separator+&quot;Users&quot;+File.separator+&quot;Public&quot; + File.separator+&quot;Downloads&quot; + File.separator + &quot;tyzj&quot;; //创建临时文件夹 createFile(filePath); //压缩导出 excelExport(title,filePath,isAllAgy,bip,fiscal,response,request); try &#123;/* delAllFile(filePath); // 删除完里面所有内容 filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); myFilePath.delete(); // 删除空文件夹 System.out.println(&quot;缓存文件删除完毕&quot;);*/ delFolder(filePath); System.out.println(&quot;缓存文件删除完毕&quot;); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; catch (Exception e) &#123; &#125; &#125; /** * 导出 */ private void excelExport(List title,String filePath,String isAllAgy, BipSchePlan bip, Integer fiscal, HttpServletResponse response, HttpServletRequest request) throws IOException &#123; //年度 String finalFundTypeName = &quot;&quot;; if(&quot;1&quot;.equals(bip.getFundType()))&#123; finalFundTypeName=&quot;当年&quot;; &#125; if(&quot;0&quot;.equals(bip.getFundType()))&#123; finalFundTypeName=&quot;上年&quot;; &#125; //生成excel List&lt;String&gt; fileNames =createExcel(title,isAllAgy,fiscal,bip); //导出压缩文件的全路径 List&lt;BipSchePlan&gt; exportAgyName = new ArrayList&lt;&gt;(); if(!StringUtils.isEmpty(bip.getFiscal()) &amp;&amp; !StringUtils.isEmpty(bip.getAgyCode()))&#123; exportAgyName=budSchePlanDao.selExportAgy(bip); &#125; //zip处理 String saveFileZipName = &quot;&quot;; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyyMMdd&quot;); saveFileZipName += format.format(Calendar.getInstance().getTime()) +exportAgyName.get(0).getAgyName()+finalFundTypeName+&quot;预算执行计划表&quot;+ &quot;.zip&quot;; String zipFilePath = filePath+File.separator+saveFileZipName; //导出zip File zip = new File(zipFilePath); //将excel文件生成压缩文件 File srcfile[] = new File[fileNames.size()]; for (int j = 0, n1 = fileNames.size(); j &lt; n1; j++) &#123; srcfile[j] = new File(fileNames.get(j)); &#125; ZipFiles(srcfile, zip); System.out.println(&quot;压缩文件生成目录：&quot;+zipFilePath); System.out.println(&quot;压缩文件生成完毕&quot;); String url = &quot;&quot;; url = URLEncoder.encode(zip.getName(), &quot;UTF8&quot;); response.setContentType(&quot;application/zip&quot;); response.setHeader(&quot;Location&quot;, url); response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment; filename=&quot; + url); OutputStream outputStream = response.getOutputStream(); InputStream inputStream = new FileInputStream(zipFilePath); byte[] buffer = new byte[1024]; int i = -1; while ((i = inputStream.read(buffer)) != -1) &#123; outputStream.write(buffer, 0, i); &#125; outputStream.flush(); outputStream.close(); inputStream.close(); System.out.println(&quot;导出完毕&quot;); &#125;/** * 生成excel */ private List&lt;String&gt; createExcel(List title,String isAllAgy,Integer fiscal,BipSchePlan bip)&#123; // 用于存放生成的excel文件名称 List&lt;String&gt; fileNames = new ArrayList&lt;String&gt;(); if(StringUtils.isEmpty(bip.getFundType()) || bip.getFundType()==&quot;&quot;)&#123; bip.setFundType(&quot;1&quot;); List&lt;String&gt; lastExcel = createExcelByFiscal(title,isAllAgy,fiscal,bip); bip.setFundType(&quot;0&quot;); List&lt;String&gt; excel = createExcelByFiscal(title,isAllAgy,fiscal,bip); fileNames.addAll(lastExcel); fileNames.addAll(excel); return fileNames; &#125; else&#123; List&lt;String&gt; excel = createExcelByFiscal(title,isAllAgy,fiscal,bip); fileNames.addAll(excel); return fileNames; &#125; &#125; /** * 分年度createExcel */ private List&lt;String&gt; createExcelByFiscal(List title,String isAllAgy,Integer fiscal,BipSchePlan bip)&#123; //输入流 InputStream in = null; //输出流 FileOutputStream o = null; // 用于存放生成的excel文件名称 List&lt;String&gt; fileNames = new ArrayList&lt;String&gt;(); // 导出Excel文件路径 String fullFilePath = &quot;&quot;; //年度 String fundTypeName = &quot;&quot;; if(&quot;1&quot;.equals(bip.getFundType()))&#123; fundTypeName=&quot;当年&quot;; &#125; if(&quot;0&quot;.equals(bip.getFundType()))&#123; fundTypeName=&quot;上年&quot;; &#125; //如果是单位的就导出单位的数据 List&lt;BipSchePlan&gt; bips =budSchePlanDao.selectExcel(bip); if(bips.size()&gt;0)&#123; bips.stream().forEach(b-&gt;&#123; if(&quot;人员经费&quot;.equals(b.getProjectName()) || &quot;公用经费&quot;.equals(b.getProjectName()))&#123; b.setProjectName(&quot;&quot;); &#125; if(&quot;99901&quot;.equals(b.getProjectCode()) || &quot;99902&quot;.equals(b.getProjectCode()))&#123; b.setProjectCode(&quot;&quot;); &#125; &#125;); JSONArray json = JSONArray.fromObject(bips); List&lt;Map&lt;String, Object&gt;&gt; list = json; //单位的 List&lt;Map&lt;String, Object&gt;&gt; collectDanWei = list.stream().filter(ee -&gt; StringUtils.isEmpty(ee.get(&quot;departmentCode&quot;))).collect(Collectors.toList()); //协会 Map&lt;String, List&lt;Map&lt;String, Object&gt;&gt;&gt; listValue = list.stream().filter(ee -&gt; !StringUtils.isEmpty(ee.get(&quot;departmentCode&quot;))) .collect(Collectors.groupingBy(e -&gt; e.get(&quot;departmentCode&quot;).toString())); //总体 listValue.put(&quot;agy&quot;, collectDanWei); //年度判断 String finalFundTypeName = fundTypeName; listValue.forEach((agy, col) -&gt; &#123; FileOutputStream os = null; try &#123; HSSFWorkbook wb = new HSSFWorkbook(); HSSFSheet sheet = wb.createSheet(&quot;导出excel&quot;); // 第一行 HSSFRow row = sheet.createRow(0); HSSFRow row1 = sheet.createRow(1); HSSFRow row2 = sheet.createRow(2); CellStyle style = CatalogExcelUtil.getHeadStyle(wb); HSSFFont font = wb.createFont(); font.setFontHeightInPoints((short) 12); font.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD);//粗体显示 font.setFontName(&quot;新宋体&quot;); font.setColor(HSSFColor.RED.index); font.setBoldweight((short) 10); //1.生成字体对象 HSSFCellStyle cellFontStyle = wb.createCellStyle(); cellFontStyle.setFont(font); HSSFCellStyle setFont2 = wb.createCellStyle(); HSSFFont font2 = wb.createFont(); font2.setFontName(&quot;仿宋_GB2312&quot;); font2.setBoldweight(HSSFFont.BOLDWEIGHT_BOLD);//粗体显示 font2.setFontHeightInPoints((short) 18); HSSFFont font3 = wb.createFont(); font3.setFontName(&quot;仿宋_GB2312&quot;); font3.setFontHeightInPoints((short) 18); HSSFCellStyle cellStyleRight = wb.createCellStyle(); cellStyleRight.setAlignment(HSSFCellStyle.ALIGN_RIGHT);//right cellStyleRight.setFont(font2); HSSFCellStyle cellStyleRight_wy = wb.createCellStyle(); cellStyleRight_wy.setAlignment(HSSFCellStyle.ALIGN_RIGHT);//right HSSFCellStyle cellStyleLeft = wb.createCellStyle(); cellStyleLeft.setAlignment(HSSFCellStyle.ALIGN_LEFT);//left cellStyleLeft.setFont(font2); HSSFCellStyle cellStyleLeft_fj = wb.createCellStyle(); cellStyleLeft_fj.setAlignment(HSSFCellStyle.ALIGN_LEFT);//left cellStyleLeft_fj.setFont(font3); HSSFCellStyle cellStyleLeft_hj = wb.createCellStyle(); cellStyleLeft_hj.setAlignment(HSSFCellStyle.ALIGN_LEFT);//left HSSFCellStyle cellStyleLeft_hj_align = wb.createCellStyle(); cellStyleLeft_hj_align.setAlignment(HSSFCellStyle.ALIGN_LEFT);//left cellStyleLeft_hj_align.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 cellStyleLeft_hj_align.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 cellStyleLeft_hj_align.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 cellStyleLeft_hj_align.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 HSSFCellStyle cellStyle = wb.createCellStyle(); cellStyle.setAlignment(HSSFCellStyle.ALIGN_CENTER); // 居中 cellStyle.setFont(font2); HSSFCellStyle setBorder = wb.createCellStyle(); setBorder.setWrapText(true);//设置自动换行 setBorder.setVerticalAlignment(HSSFCellStyle.VERTICAL_CENTER);//垂直居中 setBorder.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 setBorder.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 setBorder.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 setBorder.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 sheet.addMergedRegion(new CellRangeAddress(0, 0, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(1, 1, 0, title.size() - 1)); sheet.addMergedRegion(new CellRangeAddress(2, 2, 0, 5)); sheet.addMergedRegion(new CellRangeAddress(2, 2, 30, 31)); HSSFCell cell = row.createCell(0); cell.setCellValue(&quot;附件&quot;); cell.setCellStyle(cellStyleLeft_fj); HSSFCell cell3 = row1.createCell(0); cell3.setCellValue(&quot;国家体育总局及直属事业单位（协会）&quot; + fiscal + finalFundTypeName + &quot;预算执行计划表（含彩票公益金）&quot;); cell3.setCellStyle(cellStyle); String cell4Name = &quot;&quot;; if (StringUtils.isEmpty(col.get(0).get(&quot;departmentCode&quot;))) &#123; cell4Name = col.get(0).get(&quot;agyName&quot;).toString(); &#125; else &#123; cell4Name = col.get(0).get(&quot;departmentName&quot;).toString(); &#125; HSSFCell cell4 = row2.createCell(0); cell4.setCellValue(&quot;单位：&quot; + cell4Name); cell4.setCellStyle(cellStyleLeft); HSSFCell cell4_last = row2.createCell(30); cell4_last.setCellValue(&quot;单位：万元&quot;); cell4_last.setCellStyle(cellStyleRight_wy); sheet.setColumnWidth(0,10*256); sheet.setColumnWidth(1,30*256); sheet.setColumnWidth(2,22*256); sheet.setColumnWidth(3,20*256); sheet.setColumnWidth(4,8*256); sheet.setColumnWidth(5,20*256); sheet.setColumnWidth(6,20*256); HSSFRow rows = sheet.createRow(3); HSSFCellStyle canEditStyle = wb.createCellStyle(); canEditStyle.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 canEditStyle.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 canEditStyle.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 canEditStyle.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 canEditStyle.setLocked(true); //设置列的锁定状态为锁定 HSSFCellStyle sumCellStyle = wb.createCellStyle(); sumCellStyle.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 sumCellStyle.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 sumCellStyle.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 sumCellStyle.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 //创建行4 HSSFRow sumAmtRow = sheet.createRow(4); sumAmtRow.setRowStyle(cellStyleLeft_hj); HSSFCell sumAmtCell5 = sumAmtRow.createCell(6); sumAmtCell5.setCellValue(&quot;合计&quot;); sumAmtCell5.setCellStyle(cellStyleLeft_hj_align); //新建集合用来map转bean放入List计算合计 List&lt;BipSchePlan&gt; lsToBean = new ArrayList&lt;&gt;(); col.forEach(k-&gt;&#123; BipSchePlan b=new BipSchePlan(); transMap2Bean2(k,b); lsToBean.add(b); &#125; ); //合计方法 BipSchePlan sumBip = sumMonthSchedule(lsToBean); //设定 sumPlanAmt(sumBip,sumAmtRow,sumCellStyle); HSSFCellStyle noCanEdit = wb.createCellStyle(); noCanEdit.setBorderBottom(HSSFCellStyle.BORDER_THIN); //下边框 noCanEdit.setBorderLeft(HSSFCellStyle.BORDER_THIN);//左边框 noCanEdit.setBorderTop(HSSFCellStyle.BORDER_THIN);//上边框 noCanEdit.setBorderRight(HSSFCellStyle.BORDER_THIN);//右边框 noCanEdit.setLocked(false); //设置列的锁定状态为锁定 int num = 5; for (int i = 0; i &lt; col.size(); i++) &#123; HSSFRow row4 = sheet.createRow(num++); for (int a = 0; a &lt; title.size(); a++) &#123; HSSFCell rowsCell = rows.createCell(a); rowsCell.setCellStyle(setBorder); rowsCell.setCellValue(((LinkedHashMap) title.get(a)).get(&quot;desc&quot;).toString()); LinkedHashMap object = (LinkedHashMap) title.get(a); String object2 = object.get(&quot;value&quot;).toString(); HSSFCell createCell = row4.createCell(a); if (a &lt; 8) &#123; createCell.setCellStyle(canEditStyle); &#125; if (a &gt;= 8 &amp;&amp; a &lt; 32) &#123; createCell.setCellStyle(noCanEdit); &#125; //合计添加百分号 if(a==9 || a==11 || a==13 || a==15 || a==17 || a==19|| a==21 || a==23 || a==25 || a==27 || a==29 || a==31)&#123; createCell.setCellValue((col.get(i)).get(object2) == null ? &quot;0%&quot; : (col.get(i)).get(object2).toString().concat(&quot;%&quot;)); &#125;else&#123; createCell.setCellValue((col.get(i)).get(object2) == null ? &quot;&quot; : (col.get(i)).get(object2).toString()); &#125; &#125; &#125; //设置边框 for (int i = 0; i &lt;= 5; i++) &#123; sumAmtRow.createCell(i).setCellStyle(sumCellStyle); &#125; // 必须在单元格设值以后进行 // 设置为根据内容自动调整列宽/* for (int k = 0; k &lt; 5; k++) &#123; sheet.autoSizeColumn(k); &#125;*/ sheet.protectSheet(&quot;123&quot;); String saveFileName = &quot;&quot;; SimpleDateFormat format = new SimpleDateFormat(&quot;yyyyMMdd&quot;); saveFileName += format.format(Calendar.getInstance().getTime()) + &quot;预算执行批复表.xls&quot;; // 导出excel的全路径 String excName = &quot;&quot;; if (StringUtils.isEmpty(col.get(0).get(&quot;departmentCode&quot;))) &#123; excName = col.get(0).get(&quot;agyName&quot;).toString(); &#125; else &#123; excName = col.get(0).get(&quot;departmentName&quot;).toString(); &#125; String fullFilePaths =&quot;&quot;; if(&quot;all&quot;.equals(isAllAgy))&#123; fullFilePaths=&quot;C:&quot;+File.separator+&quot;Users&quot;+File.separator+&quot;Public&quot; + File.separator+&quot;Downloads&quot; +File.separator +&quot;预算执行计划表(所有单位)&quot;+File.separator+ bip.getAgyName() + File.separator + excName +finalFundTypeName+ saveFileName; &#125;else &#123; fullFilePaths=&quot;C:&quot;+File.separator+&quot;Users&quot;+File.separator+&quot;Public&quot; + File.separator+&quot;Downloads&quot; +File.separator +&quot;tyzj&quot;+File.separator+ excName +finalFundTypeName+ saveFileName; &#125; fileNames.add(fullFilePaths); os = new FileOutputStream(fullFilePaths); // 写文件 wb.write(os); //清空流缓冲区数据 os.flush(); //关闭流 os.close(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;); return fileNames; &#125; else &#123; return fileNames; &#125; &#125; /** * 创建文件夹 */ private void createFile(String path)&#123; File fileDir = new File(path); System.out.println(path); //创建文件夹 if (!fileDir.exists() &amp;&amp; !fileDir.isDirectory()) &#123; fileDir.mkdirs(); &#125; &#125; //压缩文件 public void ZipFiles(File[] srcfile, File zipfile) &#123; byte[] buf = new byte[1024]; try &#123; ZipOutputStream out = new ZipOutputStream(new FileOutputStream( zipfile)); for (int i = 0; i &lt; srcfile.length; i++) &#123; FileInputStream in = new FileInputStream(srcfile[i]); out.putNextEntry(new ZipEntry(srcfile[i].getName())); int len; while ((len = in.read(buf)) &gt; 0) &#123; out.write(buf, 0, len); &#125; out.closeEntry(); in.close(); &#125; out.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; /*** * 删除指定文件夹下所有文件 * * @param path 文件夹完整绝对路径 * @return */ public static boolean delAllFile(String path) &#123; boolean flag = false; File file = new File(path); if (!file.exists()) &#123; return flag; &#125; if (!file.isDirectory()) &#123; return flag; &#125; String[] tempList = file.list(); File temp = null; for (int i = 0; i &lt; tempList.length; i++) &#123; if (path.endsWith(File.separator)) &#123; temp = new File(path + tempList[i]); &#125; else &#123; temp = new File(path + File.separator + tempList[i]); &#125; if (temp.isFile()) &#123; temp.delete(); &#125; if (temp.isDirectory()) &#123; delAllFile(path + &quot;/&quot; + tempList[i]);// 先删除文件夹里面的文件 delFolder(path + &quot;/&quot; + tempList[i]);// 再删除空文件夹 flag = true; &#125; &#125; return flag; &#125; /*** * 删除文件夹 * * @param folderPath 文件夹完整绝对路径 */ public static void delFolder(String folderPath) &#123; try &#123; delAllFile(folderPath); // 删除完里面所有内容 String filePath = folderPath; filePath = filePath.toString(); java.io.File myFilePath = new java.io.File(filePath); myFilePath.delete(); // 删除空文件夹 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>Java编码实践</tag>
        <tag>SpringBoot项目</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java 多层压缩包解压后放到指定文件夹]]></title>
    <url>%2F2023%2F10%2F02%2Fjava%20%E5%A4%9A%E5%B1%82%E5%8E%8B%E7%BC%A9%E5%8C%85%E8%A7%A3%E5%8E%8B%E5%90%8E%E6%94%BE%E5%88%B0%E6%8C%87%E5%AE%9A%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[思路 实现代码 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.51cto.com/u_12192/6442520 思路批量下载文件时，需要将多个文件打包为zip，然后再下载。实现思路有两种：一是将所有文件先打包压缩为一个文件，然后下载这个压缩包，二是一边压缩一边下载，将多个文件逐一写入到压缩文件中。 实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131@ResponseBody public void downloadFiles(HttpServletRequest request, HttpServletResponse response, 其他为获取下载文件信息的必须参数)&#123; //响应头的设置 response.reset(); response.setCharacterEncoding(&quot;utf-8&quot;); response.setContentType(&quot;multipart/form-data&quot;); //设置压缩包的名字 //解决不同浏览器压缩包名字含有中文时乱码的问题 String downloadName = &quot;我是压缩包的名字.zip&quot;; String agent = request.getHeader(&quot;USER-AGENT&quot;); try &#123; if (agent.contains(&quot;MSIE&quot;)||agent.contains(&quot;Trident&quot;)) &#123; downloadName = java.net.URLEncoder.encode(downloadName, &quot;UTF-8&quot;); &#125; else &#123; downloadName = new String(downloadName.getBytes(&quot;UTF-8&quot;),&quot;ISO-8859-1&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;fileName=\&quot;&quot; + downloadName + &quot;\&quot;&quot;); //设置压缩流：直接写入response，实现边压缩边下载 ZipOutputStream zipos = null; try &#123; zipos = new ZipOutputStream(new BufferedOutputStream(response.getOutputStream())); zipos.setMethod(ZipOutputStream.DEFLATED); //设置压缩方法 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //循环将文件写入压缩流 DataOutputStream os = null; for(int i = 0; i &lt; 要下载的文件个数; i++ )&#123; File file = new File(要下载的某个文件的路径); try &#123; //添加ZipEntry，并ZipEntry中写入文件流 //这里，加上i是防止要下载的文件有重名的导致下载失败 zipos.putNextEntry(new ZipEntry(i + 文件名字)); os = new DataOutputStream(zipos); InputStream is = new FileInputStream(file); byte[] b = new byte[100]; int length = 0; while((length = is.read(b))!= -1)&#123; os.write(b, 0, length); &#125; is.close(); zipos.closeEntry(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //关闭流 try &#123; os.flush(); os.close(); zipos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @ResponseBody public void downloadFiles(HttpServletRequest request, HttpServletResponse response, 其他为获取下载文件信息的必须参数)&#123; //响应头的设置 response.reset(); response.setCharacterEncoding(&quot;utf-8&quot;); response.setContentType(&quot;multipart/form-data&quot;); //设置压缩包的名字 //解决不同浏览器压缩包名字含有中文时乱码的问题 String downloadName = &quot;我是压缩包的名字.zip&quot;; String agent = request.getHeader(&quot;USER-AGENT&quot;); try &#123; if (agent.contains(&quot;MSIE&quot;)||agent.contains(&quot;Trident&quot;)) &#123; downloadName = java.net.URLEncoder.encode(downloadName, &quot;UTF-8&quot;); &#125; else &#123; downloadName = new String(downloadName.getBytes(&quot;UTF-8&quot;),&quot;ISO-8859-1&quot;); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; response.setHeader(&quot;Content-Disposition&quot;, &quot;attachment;fileName=\&quot;&quot; + downloadName + &quot;\&quot;&quot;); //设置压缩流：直接写入response，实现边压缩边下载 ZipOutputStream zipos = null; try &#123; zipos = new ZipOutputStream(new BufferedOutputStream(response.getOutputStream())); zipos.setMethod(ZipOutputStream.DEFLATED); //设置压缩方法 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; //循环将文件写入压缩流 DataOutputStream os = null; for(int i = 0; i &lt; 要下载的文件个数; i++ )&#123; File file = new File(要下载的某个文件的路径); try &#123; //添加ZipEntry，并ZipEntry中写入文件流 //这里，加上i是防止要下载的文件有重名的导致下载失败 zipos.putNextEntry(new ZipEntry(i + 文件名字)); os = new DataOutputStream(zipos); InputStream is = new FileInputStream(file); byte[] b = new byte[100]; int length = 0; while((length = is.read(b))!= -1)&#123; os.write(b, 0, length); &#125; is.close(); zipos.closeEntry(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; //关闭流 try &#123; os.flush(); os.close(); zipos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; 以上代码，在chrome/firefox/ie下都可以正常下载。 本文转自 https://blog.51cto.com/u_12192/6442520，如有侵权，请联系删除。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>Java编码实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用BeautifulSoup进行解析数据]]></title>
    <url>%2F2023%2F10%2F02%2F%E4%BD%BF%E7%94%A8BeautifulSoup%E8%BF%9B%E8%A1%8C%E8%A7%A3%E6%9E%90%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[1.bs4数据分析 一、基础介绍 二、实例操作 1.获取北京新发地网页中每日菜价的所有数据 （1）.第一步分析网页 （2）.第二步拿到数据 （3）.第三步解析数据 2.下载优美图库中的图片，并保存在本地文件中 （1）.第一步分析网页 （2）.第二步拿到数据 （3）.第三步解析数据 补充：正则表达式进行图片链接提取 （4）.第四步保存数据 3.爬取《三国演义》小说 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1.bs4数据分析bs4数据分析 一、基础介绍bs4 全名 BeautifulSoup，是编写 python 爬虫常用库之一，BeautifulSoup4也是一个html/xml的解析器，主要用来解析 html 标签。 -数据解析的原理： 1.标签定位 2.提取标签、标签属性中存储的数据值 - bs4数据解析的原理： 1.实例化一个BeautifulSoup对象，并且将页面源码数据加载到该对象中 2.通过调用BeautifulSoup对象中相关的属性或者方法进行标签定位和数据提取 我们一般在使用bs4库进行数据分析时，最主要使用的都是beautifulsoup。所以我们在使用时一般都是引入这个库 1from bs4 import BeautifulSoup bs4提供用于数据解析的方法和属性有： soup.find().text 获取标签内文本内容 soup.get_text() 获取标签内的文本内容 soup.get() 获取标签属性的值 soup.tagName:返回的是文档中第一次出现的tagName对应的标签 soup.find(): -soup.find(‘div’,class_/id/attr=‘song’) soup.find_all(‘tagName’):返回符合要求的所有标签（列表） find(‘tagName’):等同于soup.div 有了这些基本介绍下，我们就能够进行基本的bs4数据解析了 接下来将通过几个实例进行巩固。 二、实例操作1.获取北京新发地网页中每日菜价的所有数据流程： 分析网页：打开开发者工具，观察我们所需要的内容特点，并且看看网站的源代码中是否由我们所需要的内容，如果有便可以直接进行爬取，如果没有的话可能还需要进行更深入的查找 拿到数据：通过urllib进行request请求，拿到网页数据 数据分析：使用bs4进行解析，拿到我们想要的数据 首先我们需要导入两个库 12import requestsfrom bs4 import BeautifulSoup （1）.第一步分析网页 我们所需要的东西都在这个表格里，同时我们也发现它还有好多页数据，如果我们想要所有页的数据该怎么办。 我们发现这个网址有一个规律 http://www.xinfadi.com.cn/marketanalysis/0/list/1.shtml 当第一页时，list为1，第二页时list为2.依次列推，这样之后我们可以利用这个规律，将所有网页的信息都获取到 右键打开网页源代码，Ctrl+f 查找大白菜 发现我们所需要的数据在源代码中存在。 所以我们直接访问此网址进行数据提取即可 然后打开开发者工具，点击我们要的数据进行观察 由图也能看到，我们所需要的数据都存在table表中 我们只需要能够定位到table表中，便能进一步得到数据 点开其中的tr我们可以看到，我们所需要的内容都在tr标签的td中，所以我们只需要获取td标签中的文本信息，便完成了整个数据爬取。接下来我们将进入下一步：拿到数据 （2）.第二步拿到数据首先我们定义一个变量，存放网址 123url =&quot;http://www.xinfadi.com.cn/marketanalysis/0/list/1.shtml&quot;requ = requests.get(url)requ.encoding=&quot;utf-8&quot; 当然还需要定义一个变量，存放request请求到的网页信息 同时为了防止可能出现乱码，所以使用encoding转化为”utf-8” 这样其实就已经拿到了我们这个网址的源代码了，我们可以输出看一下 下一步便是解析数据了 （3）.第三步解析数据我们使用的是bs4库进行解析 首先 要实例化一个BeautifulSoup对象 1page = BeautifulSoup(requ.text,&quot;html.parser&quot;) 设置一个变量存储bs4处理后的源代码数据 beautifulsoup括号中的第一个参数时要解析的HTML文本，第二个参数是使用的解析器，解析HTML使用的是自带的html.parser 根据之前分析网页的过程，我们知道我们需要的内容都存在于一个table表中，所以我们使用bs4中的方法进行数据解析 1table = page.find(&quot;table&quot;, class_=&quot;hq_table&quot;) 通过find方法，找到源代码中class=”hq_table”的table内容 我们可以输出看一下得到了什么 然后下一步我们继续往下找，找到所有的tr标签的内容 1trs = table.find_all(&quot;tr&quot;)[1:] 找寻所有符合条件的使用find_all方法 因为我们第一行是我们不需要的数据，所以我们从第二行情开始。 同样我们也可以输出结果看看 得到了所有的tr标签后，我们所需要的内容都在其中的td标签中 因为数据是比较多的，所以我们利用一个循环来获取所有的td标签 12for tr in trs: tds = tr.find_all(&quot;td&quot;) 这样我们就得到了所有的td标签了 也可以输出看一下 但是我们需要的是td标签中的文本信息 1234567name = tds[0].text #.text 表示拿到被标签标记的内容low = tds[1].textavg = tds[2].texthigh = tds[3].textgui = tds[4].textkind = tds[5].textdata = tds[6].text 根据观察我们所获取的内容可以看到，我们的菜品名称是第一个td的文本内容，所以我们输入tds[0],定位到这个标签后加上**.text**,便可以获取被标签标记的文本内容。输出后便能得到我们最终需要的内容了 嘿嘿，这样便完成了 当然我们还可以扩展很多操作，可以将数据进行保存，也可以进行翻页爬取。 2.下载优美图库中的图片，并保存在本地文件中步骤和上一个例子是一样的，同样还是打开网页，分析网页的内容 （1）.第一步分析网页我们想要下载图片，所以需要拿到图片的下载链接。 首先打开网址，右键查看源代码，看源代码中是否有我们想要的数据 我们看到源代码，发现其实里边存在我们想要的链接。 那便尝试下使用bs4进行提取内容 （2）.第二步拿到数据一样的步骤 导入库： 1import requestsfrom bs4 import BeautifulSoup 然后请求网址，获取网页源代码： 123url = &quot;https://www.umei.net/bizhitupian/weimeibizhi/&quot;requ = requests.get(url)requ.encoding=&quot;utf-8&quot; （3）.第三步解析数据实例化bs4对象，并生成page对象 根据网页分析，获得class = “TypeList”下的a标签 12page = BeautifulSoup(requ.text,&quot;html.parser&quot;)div = page.find(&quot;div&quot;,class_=&quot;TypeList&quot;).find_all(&quot;a&quot;) 得到后，因为我们有很多张图片信息需要获取，所以也用一个循环来进行操作 123for a in div: chref = a.get(&apos;img&apos;) #直接通过get就可以拿到属性的值 print(chref) 然后输出我们需要的图片链接 结果为： 我们所爬取到的却是空值 搞了很久才知道问题所在，因为我们的bs4解析，是根据标签中属性去进行提取其中的值，而img是在a标签里边的内容，我们可以定义href得到网址内容，也可以定义class得到内容，但是无法对标签里的内容进行提取，所以我们使用bs4提取的话，是需要先进入到网站的子网站中去，才能获取到图片的链接。 但是既然在源代码中已经存在了，那我们一样就可以直接提取。我们可以使用正则表达式进行数据提取。 当然这里还是讲解我们的bs4提取方式 因为我们无法直接在源代码中提取到信息，所以我们需要访问到图片的子网页中，下一步便是获得每个子网页的网址，同样因为网址很多，所以我们利用寻循环进行提取 123for a in div: chref = a.get(&apos;href&apos;) #直接通过get就可以拿到属性的值 print(chref) 输出结果便是子网页的网址 但是我们经过观察发现，并不是完整的网址，不能点击进入 我们得到的是： /bizhitupian/weimeibizhi/225260.htm /bizhitupian/weimeibizhi/225259.htm 实际网址是：https://www.umei.net/bizhitupian/weimeibizhi/225260.htm 原网址：https://www.umei.net/bizhitupian/weimeibizhi/ 经过对比观察我们发现，我们得到的网址其实每个都是只有后边的数字在变化，所以我们可以将后边的数字分开存储。 然后和原网址进行拼接，便能得到所有能够进入的子网页网址 1href_name = chref.split(&quot;/&quot;)[-1]href = url + href_name split （） ：从分号为准，进行切割 我们可以输出一下看看 [外链图片转存失败,源站可能有防盗链机制,建议将图片保存下来直接上传(img-emXe8pdu-1626970354485)(C:\Users\苏柒\AppData\Roaming\Typora\typora-user-images\image-20210713201942623.png)] 这就是我们得到的内容 当然还没有结束，接下来，我们需要请求子网页的地址，获取子网页的内容，其实和我们获取原网页的内容操作是一样的 123child_page_requ = requests.get(href)child_page_requ.encoding=&quot;utf-8&quot;child_page_text = child_page_requ.text 然后也是一样实例化bs4对象，进行数据提取。 根据网页格式，我们先进入到p标签下，然后在进入到img标签中，最后找到图片链接的属性src，提取到我们需要的图片下载链接。 1234child_page = BeautifulSoup(child_page_text,&quot;html.parser&quot;)p = child_page.find(&quot;p&quot;, align=&quot;center&quot;)img = p.find(&quot;img&quot;)src = img.get(&quot;src&quot;) 这样我们就得到了所有的下载链接 当然这个也可以进行翻页爬取，之后可以作为拓展练习操作 补充：正则表达式进行图片链接提取首先我们也需要引入一个库 1import re 然后定义一个正则表达式规则进行数据提取 1obj2 = re.compile(r&apos;img src=&quot;(.*?)&quot;&apos;,re.S) re.compile 编译成 Pattern 对象 然后便可以通过re常用的方法进行匹配查找 1234for a in div: a=str(a) res=obj2.findall(a)[0] print(res) 这里我们用了findall进行查找，当然如果我们直接进行查找的话是会报错的，因为我们的正则是在字符串中进行提取数据，但是当时的a是一个bs4对象，所有我们需要先进行转化，才能得到最后的结果 当然，我们还是回到bs4方法中来，虽然这个网站里存在我们子网页中的信息，但是很多网页中，我们想要的内容都不会在当前网页的源代码中，所以就需要我们去深入查找，我们的bs4也就能够运用进来。 其实我们爬虫的方式有很多种，每个网站的信息也不同，我们可以根据不同的网页信息，去使用不同的爬取方法，只要最终能够得到我们所需要的内容。 注意：我们通过观察源代码中图片和子网页中图片链接对比能发现在源代码中得到的图片只是缩略图，所以如果我们需要对图片清晰度有一定的要求的话，还是得进入到子网页中进行图片下载 （4）.第四步保存数据123456img_requ = requests.get(src) #请求src链接 #img_requ.content #这里拿到的是字节img_name = src.split(&quot;/&quot;)[-1] #拿到url最后一个/以后的内容with open(&quot;优美图库/&quot;+img_name,mode=&quot;wb&quot;) as f: f.write(img_requ.content) #图片内容写入文件 print(&quot;over!!!&quot;,img_name)time.sleep(1) 我们可以执行with open（）命令，打开或者新建一个文件夹，并对参数进行设置，建立一个“优美图库”的文件，执行二进制写入的操作 然后将图片写入文件中： f.write（img_requ.content） 便可以将图片下载到本地文件中了 因为我们的图库中都是图片，为了不让它在pycharm中占用索引搜索，我们把它标记为已排除文件 因为我们的软件每一次都需要对所有文件进行索引，把文件进行标记后，可以跳过此文件，减少索引时间。 这样，我们这个下载图片的过程就已经完成了 3.爬取《三国演义》小说12345678910111213141516171819202122232425262728293031323334353637383940414243444546#打开网页源代码检查我们需要的数据#数据在子页面中#流程：1.获取子网页网址#2.提取文本内容#3.下载文本内容import requestsfrom bs4 import BeautifulSoupimport refrom lxml import etreeurl = &quot;https://www.shicimingju.com/book/sanguoyanyi.html&quot;requ = requests.get(url)requ.encoding=(&quot;utf-8&quot;)#提取子网页网址page = BeautifulSoup(requ.text,&quot;html.parser&quot;)div = page.find(&apos;div&apos;,class_=&quot;book-mulu&quot;).find_all(&apos;a&apos;)obj = re.compile(r&apos;&lt;div class=&quot;chapter_content&quot;&gt;(.*?)&lt;/div&gt;&apos;,re.S)i = 0for a in div: # html = etree.HTML(requ.text) # text = html.xpath(&apos;/html/body/div[3]/div[1]/div/div[4]/ul/li/a/text()&apos;)[i] # i = i+1 # print(text) text = a.get_text() #print(text) href = a.get(&apos;href&apos;) text_name = url.split(&quot;/book&quot;)[0]+href childrequ = requests.get(text_name) childrequ.encoding=(&quot;utf-8&quot;) #print(text) # childrequ =str(childrequ.text) # # print(childrequ) # res = obj.findall(childrequ)[0].replace(&apos;&lt;p&gt;&apos;,&apos;&apos;).replace(&apos;&amp;nbsp;&apos;,&apos;&apos;).replace(&apos; &apos;,&apos;&apos;).replace(&apos;\\n&apos;,&apos;&apos;).replace(&apos;\\t&apos;,&apos;&apos;).replace(&apos;\\r&apos;,&apos;&apos;).replace(&apos;&lt;BR&gt;&apos;,&apos;&apos;).replace(&apos;/p&apos;,&apos;&apos;).replace(&apos;br/&apos;,&apos;&apos;).replace(&apos;&lt;br&gt;&apos;,&apos;&apos;) # print(res) childrequ_page = BeautifulSoup(childrequ.text,&quot;html.parser&quot;) div1 = childrequ_page.find(&apos;div&apos;,class_ =&quot;chapter_content&quot;) div1 = str(div1.text).strip() #print(div1) with open(r&apos;D:\python练习\python爬虫\自主爬虫训练&apos;+&apos;\三国演义\\&apos;+text+&apos;.txt&apos;,&apos;w&apos;,encoding=&apos;utf-8&apos;) as f: f.write(&apos;\r\n&apos;+div1) print(&quot;导入成功！&quot;,text)print(&quot;over!!!&quot;) 简单讲述下爬取过程 首先是打开了网页进行分析，发现当前网页没有我们想要的文本内容，所以我进入到了子网页中查看源代码，找到了我们所需要的内容。所有我们便有了大致的流程，先要从原网址中找到子网址，然后在从子网址中得到数据，进行下载。 所以我们直接请求原网址内容，然后用bs4提取子网页网址。 提取后发现不能直接打开，需要做一些修整，与原网页网址对比后，发现了关系，调整后便可以获取了。 进入子网页后也是一样的请求子网页原代码，然后利用bs4提取文本内容，但是在提取后得到的不仅仅是文本内容，还会得到什么div标签得内容。 但是后面重新提取就没问题了 在发现有问题后我就使用了正则提取，先导入库后，定义了一个正则表达式，然后进行提取，提取内容会发现很多其他符号，利用replace去除后，也能得到想要的内容 文本内容获取到了，但是我还想得到标题，每一个标题对应每一章内容 经过网页分析发现标题并不在子网页中，而是在原网页中，所以我们只需要获取原网页中，a标签中的文本内容便可以了。但是并不知道bs4可以提取文本内容，所以我使用了xpath进行提取。首先导入库from lxml import etree ，并解析HTML文档内容 html = etree.HTML(requ.text) 然后便可以进行xpath提取了，得到a标签的文本内容 后边自己查了一下，原来bs4中可以使用get_text（）提取标签中内容。 最后就是将文本存入本地文件中，但是存入后不能自动换行，这是最后一直都没有解决的问题，以及排序的问题，乱序。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORA-00257: 归档程序错误。只有在解析完成后才以 AS SYSDBA 方式连接]]></title>
    <url>%2F2023%2F04%2F07%2FORA-00257-%E5%BD%92%E6%A1%A3%E7%A8%8B%E5%BA%8F%E9%94%99%E8%AF%AF%E3%80%82%E5%8F%AA%E6%9C%89%E5%9C%A8%E8%A7%A3%E6%9E%90%E5%AE%8C%E6%88%90%E5%90%8E%E6%89%8D%E4%BB%A5-AS-SYSDBA-%E6%96%B9%E5%BC%8F%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[1. 问题分析 一、怀疑空间不足 二、检查空间归档相关 1、检查空间redo log\recovery file\flash_recovery_area_usage使用情况 2、手工切换日志 3、排查DB_RECOVERY_FILE_DEST_SIZE大小 4、执行完成后检查 5、验证登录是否正常 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/Darren_tan/article/details/108421033 1. 问题分析今天开发人员报公司测试环境昨天能正常连接数据库，现在不能连接报“ORA-00257: 归档程序错误。只有在解析完成后才以 AS SYSDBA方式连接”错误提示。我接到问题后，排查分析如下： 一、怀疑空间不足1、检查数据库服务器磁盘空间存储情况 通过查看判断，空间存储虽然不多，但在测试场景下是足够用的。此点可以排除在外，继续往下排查。 二、检查空间归档相关1、检查空间redo log\recovery file\flash_recovery_area_usage使用情况select from v$log;select from v$recovery_file_dest;select * from v$flash_recovery_area_usage; 从中发现ARCHIVED LOG、/u01/app/oracle/fast_recovery_area分别使用率达到90% 2、手工切换日志alter system switch logfile; 运行手工切换命令，发现很长时间未有反馈。后来想到DB_RECOVERY_FILE_DEST_SIZE太少会导致日志文件不匹配。 3、排查DB_RECOVERY_FILE_DEST_SIZE大小检查发现此参数当时只配了3G，文件存储空间还有35GB。 上述归档日志、恢复空间使用率过高，因此需要调整扩容该参数由原来3GB-&gt;15GB。 执行： alter system set DB_RECOVERY_FILE_DEST_SIZE=15g; 4、执行完成后检查检查第1点操作，发现 归档日志使用率降低到22.43以下。 使用率和分配的空间存储大小恢复合理了。 5、验证登录是否正常 从登录显示已恢复正常了，归档日志解析恢复正常流转了。 小结：恢复区大小设置与业务高峰期产生的归档日志信息需要相匹配，设置过小容易导致空间不够成为瓶颈。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>SQL</tag>
        <tag>Oracle问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL 8.0 安装及配置]]></title>
    <url>%2F2023%2F04%2F07%2FMySQL-8-0-%E5%AE%89%E8%A3%85%E5%8F%8A%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[0.卸载MySQL(如果有) 1.官网下载MySQL 2.前期准备工作 3.开始安装 4.配置MySQL Server 5.环境变量配置 6.更改时区和 禁用MySQL 自动更新 更改时区 (学习JAVA用到JDBC会有时区问题, 要改成东八区) 禁用MySQL 自动检查更新 7.验证安装 8.MySQL更新教程示例(可以收藏后续用得到) 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 0.卸载MySQL(如果有)在安装之前, 先 确定一下, 电脑上之前有没有安装MySQL ? ！！！整篇文章最需要注意的一步！！！ 安装有问题80%是因为这个原因 推荐两篇博客 我这里就不写了 安装MySQL时出现starting the server失败 MySQL安装 starting the server失败的解决办法 或者看看有没有这个路径 如果有, 请搜索网上的教程 1,停止服务 2,删除注册表 3,删除安装目录和data目录(如果有data目录的话) 弄完最好再重启系统 如果 有删除残留可能导致后面安装出现问题 再开始阅读本教程 1.官网下载MySQLMySQL :: Download MySQL Installer 这只是一个安装器, 安装包里有64位的MySQL Server 这里让我们登账号, 我们可以忽略直接下载 这时候如果直接安装你会发现: 默认装到 C:\Program Files\MySQL , 而且不给你路径选择 MySQL如果是 msi安装包安装, 会安装到C盘且没有路径选择.(当然你要是只分了一个盘请忽略) 如果是压缩包安装, 可以配置 配置文件, 可以解压安装到指定的路径. CSDN的绝大多数教程都是 解压安装MySQL. 还要配置文件什么的很麻烦 安装包安装的 图形化界面 可以帮助更新MySQL和其他数据库驱动到最新版本(解压安装 没有) ! 本教程原理: 空文件夹占用原本mysql的安装路径, 软件被迫给你选择路径 ! 2.前期准备工作在C盘下准备如下的目录 (别的目录 你以后也可能会用到, 所以最好全留着): 如果装在C盘无所谓, 可直接开始安装 —&gt; 3.开始安装 C:\Program Files\MySQL C:\Program Files (x86)\MySQL PS:两个 Program Files 文件夹都最好放, 经过我研究发现, 两个文件夹都会有 . 准备占用目录 高阶教程: 复制下面这行代码放到新建的txt里面 md &quot;Connector C++ 8.0&quot; &quot;Connector J 8.0&quot; &quot;Connector NET 8.0&quot; &quot;Connector ODBC 8.0&quot; &quot;Connector Python 8.0&quot; &quot;MySQL Documentation 8.0&quot; &quot;MysQL for Visual Studio 1.2&quot; &quot;MySQL Installer for Windows&quot; &quot;MySQL Router 8.0&quot; &quot;MySQL Server 8.0&quot; &quot;MySQL Shell 8.0&quot; &quot;MySQL Workbench 8.0&quot; &quot;Samples and Examples 8.0&quot; 把.txt 改为 .bat , 然后执行, 系统会帮你创建上面写出的目录 注意, 由于C盘的权限问题, 可能用管理员权限执行.bat也没用. 我们在D盘创建文件夹再复制过去即可 在D盘生成的目录 复制过去 检查下C盘的路径 3.开始安装 我们选择自定义安装, 因为有些应用我们可能用不到 选择要安装的服务, 并点击箭头 将其添加到右边 (比如说你不装python, 然后这里想装python的驱动, 就会报错) (后续想要安装别的, 参考文末的更新, 选择ADD 即可) 2022/2/23 更新 （如果没这个问题直接跳过！） 如果到这里安装出现这个 Check Requirements 说明你的 系统缺少 MySQL需要的C++库 , 安装即可 点击 execute 同意, 继续安装 后面就OK了 选择好了之后点击 NEXT 我们的路径占用已经生效了😏😏😏, 全部 修改到想要安装的路径即可. (注意, 是每个选项都单独可以更改路径) (PS: 占用改路径了以后, 是不是它就不会往里面放东西了呢? 不完全是的, 最大的 MySQL服务, 确实是放到了D盘, 但是 编程语言的数据库驱动, 还是会在C盘 , 后面记得在这找, 不过Java的JDBC只有2.72 MB, 无伤大雅 ) execute安装等待它安装完毕 点击 NEXT 4.配置MySQL Server 这个界面 默认即可, 不要动它 , 点击下一步 官方推荐第一种, 我们就用第一种 千万注意 ! ! ! 如果后面我们要用到 数据库图形化工具 的话(navicat举例) 如果navicat版本太老, 比如11, 会产生数据库连接错误 就建议 选择第二个密码选项 或者升级软件 图形化工具 的版本 学习MySQL的话, 就随便取个好记的密码(忘密码比较麻烦) 这里可以改成MySQL, 在启动服务的时候方便些 接着继续安装 安装完成 回到外面 不要启动workbench 5.环境变量配置这个时候大家打开命令行, 直接输入 mysql 应该是会报错的, 因为我们还没有配置环境变量, 没办法直接使用 mysql命令 打开我们的安装目录, 来到 MySQL Server 8.0\bin 目录下, 复制这一整行地址 1. 此电脑右键属性 2. 打开高级系统设置(我是win11, win10 应该在左边或右边) 3.环境变量 4.找到系统变量的PATH, 双击进入编辑 5.新建, 把你刚刚复制的那个路径粘贴即可 6. 注意, 一定要一层层点确定退出去 ! 一直点到这个页面为止 6.更改时区和 禁用MySQL 自动更新更改时区 (学习JAVA用到JDBC会有时区问题, 要改成东八区)win10下先 勾选这个以便找到 ProgramData 文件夹 来到 ProgramData\MySQL\MySQL Server 8.0 (不一定和我一样在D盘, 如果找不到这个文件, 建议用everything全局搜索 ) 往下找到 [mysqld] 在下面加上这么一句话 default-time_zone=&#39;+8:00&#39; 并保存 关闭以后 重启mysql即可生效 如果还没有启动, 那就是开启后生效, 先不急 继续往下 禁用MySQL 自动检查更新1. 打开管理 2. 按照箭头逐层来到这个界面 右键禁用 7.验证安装win + s 搜索cmd 或者powershell, 右键用管理员启动 验证刚刚配置的命令行 ( 第4个标题 ) 输入 mysql -uroot -p 再输入密码 在开始菜单界面 可以看到多出来这些东西 如果上面没选择workbench就没有 点击MySQL自带的命令行(MySQL command line client) 验证一下, 成功了 看看GUI界面 GUI界面可以帮助你更新MySQL和其他数据库接口驱动到最新版本 8.MySQL更新教程示例(可以收藏后续用得到) 2022年1月21日更新: 如图, 可以升级server版本 点击升级 选中要升级的选项 等待下载完毕 如图, 全都是最新的, 与时俱进(不用担心这个教程会过时, 因为能升级到最新版本)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORA-12516 TNS监听程序找不到符合协议堆栈要求的可用处理程序的解决方案]]></title>
    <url>%2F2023%2F04%2F07%2FORA-12516-TNS%E7%9B%91%E5%90%AC%E7%A8%8B%E5%BA%8F%E6%89%BE%E4%B8%8D%E5%88%B0%E7%AC%A6%E5%90%88%E5%8D%8F%E8%AE%AE%E5%A0%86%E6%A0%88%E8%A6%81%E6%B1%82%E7%9A%84%E5%8F%AF%E7%94%A8%E5%A4%84%E7%90%86%E7%A8%8B%E5%BA%8F%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[1. 问题出现的原因 2. 具体方法 2.1 登录sql控制台 2.2 连接为管理员 2.3 查看processes和session参数 2.3.1 查看processes参数 2.3.2 查看session参数 2.4 查看当前使用的情况 2.4.1 查看当前会话数 2.4.2 查看当前会话数 2.5 调整process和session 2.6 重启oracle 使配置生效 2.6.1 关闭 2.6.2 启动 2.7 查看procress\&amp;session的参数值 查看配置是否生效 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 问题出现的原因 起因是需要将数据库中的条目信息和磁盘上存储的文件信息进行比对，通过Java编程，连接数据库。由于需要精准比对，本人目前能力有限，只好采取单次查询，然后返回结果进行匹配，中间观察到控制台出现“ORA-12516 TNS监听程序找不到符合协议堆栈要求的可用处理程序”的报错，网上解决方案是调整session和processes。 2. 具体方法2.1 登录sql控制台 sqlplus /nolog 2.2 连接为管理员 conn / as sysdba 2.3 查看processes和session参数2.3.1 查看processes参数 show parameter processes; 12345678910111213SQL&gt; show parameter processNAME TYPE VALUE------------------------------------ ----------- ------------------------------aq_tm_processes integer 1cell_offload_processing boolean TRUEdb_writer_processes integer 1gcs_server_processes integer 0global_txn_processes integer 1job_queue_processes integer 1000log_archive_max_processes integer 4processes integer 1000processor_group_name string 等价于12345SQL&gt; select value from v$parameter where name = 'processes';VALUE---------------------------1000 2.3.2 查看session参数 show parameter session;123456789101112SQL&gt; show parameter sessionNAME TYPE VALUE------------------------------------ ----------- ------------------------------java_max_sessionspace_size integer 0java_soft_sessionspace_limit integer 0license_max_sessions integer 0license_sessions_warning integer 0session_cached_cursors integer 50session_max_open_files integer 10sessions integer 1524shared_server_sessions integer 等价于12345SQL&gt; select value from v$parameter where name = 'sessions';VALUE----------------------------1524 2.4 查看当前使用的情况2.4.1 查看当前会话数 select count(*) from v$process;12345SQL&gt; select count(*) from v$process; COUNT(*)---------- 998 2.4.2 查看当前会话数 select count(*) from v$session;12345SQL&gt; select count(*) from v$session; COUNT(*)---------- 995 2.5 调整process和session alter system set processes=1000 scope=spfile; alter system set sessions=1105 scope=spfile; 2.6 重启oracle 使配置生效2.6.1 关闭 shutdown immediate 1234SQL&gt; shutdown immediateDatabase closed.Database dismounted.ORACLE instance shut down. 2.6.2 启动 startup123456789SQL&gt; startupORACLE instance started.Total System Global Area 6680915968 bytesFixed Size 2213936 bytesVariable Size 5301602256 bytesDatabse Buffers 1342177280 bytesRedo Buffers 34922496 bytesDatabase mounted.Database opened. 2.7 查看procress&amp;session的参数值 查看配置是否生效1).查看procress参数值 show parameter processes 2).查看session参数值 show parameter sessions 修改成功]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>SQL</tag>
        <tag>Oracle问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORA报错汇总]]></title>
    <url>%2F2023%2F04%2F07%2FORA%E6%8A%A5%E9%94%99%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1. ORA-12516 TNS监听程序找不到符合协议堆栈要求的可用处理程序 2. ORA-12560: TNS: 协议适配器错误 3. ORA-12541：TNS：没有监听器 4. ORA-12500：TNS：监听程序无法启动专用服务器进程 或 ORA-12560：TNS：协议适配器错误 5. ORA-12154：TNS：能解析服务名 6. ORA-1034 ：TNS：ORACLE不可用 7. ORA-12560：TNS：协议适配器错误(顽固性的) 8. ORA-00257: 归档程序错误。 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章：参考本人发布的文章 错误代码 解决 12516 √ 12560 √ 12541 √ 12500 √ 12154 √ 1034 √ 00257 √ 1. ORA-12516 TNS监听程序找不到符合协议堆栈要求的可用处理程序简单来说，就是你把数据库可用的连接全用完了，没法增加新的连接 2. ORA-12560: TNS: 协议适配器错误检查各种Oracle服务 3. ORA-12541：TNS：没有监听器原因：没有启动监听器或者监听器损坏。如果是前者，使用命令net start OracleOraHome81TNSListener(名字可能有出入)即可;如果是后者，则使用“Net8 Configuration Assistant”工具向导之“监听程序配置”增加一个监听器即可(基本不用写任何信息，一路OK。在添加之前可能需要把所有的监听器先删除!) 4. ORA-12500：TNS：监听程序无法启动专用服务器进程 或 ORA-12560：TNS：协议适配器错误原因：ORACLE的数据库服务没有启动。使用命令net start ORACLESERVICEORADB(ORADB为数据库名字)即可。如果仍没有解决，请继续向下看。 如果数据库服务启动失败，则很有可能是其注册表项值损坏，最好的做法是以下两步： 1)ORADIM -DELETE -SID oradb 删除数据库服务项 2)ORADIM -NEW -SID oradb 新增数据库服务项 注：这个过程中如果出错，就重启计算机! 5. ORA-12154：TNS：能解析服务名原因：ORACLE的网络服务名没有正确配置。请使用“Net8 Configuration Assistant”工具向导之“本地网络服务名配置”配置TNS即可。如果仍没有解决，请继续向下看。 6. ORA-1034 ：TNS：ORACLE不可用原因：ORACLE的数据库服务正确启动，但是数据库没有打开! 使用命令： 1)svrmgrl 启动服务管理器 2)connect internal 以internal身份登陆 3)startup 打开数据库 7. ORA-12560：TNS：协议适配器错误(顽固性的)原因：未知。 解决：必杀技–打开“Windows任务管理器”，杀死ORACLE.exe及ORADIM.exe进程，书写自己的 ora_startup.bat，执行之! PS： 1、我的ora_startup.bat：12345net start OracleOraHome81TNSListenernet start ORACLESERVICEORADBsvrmgrl 一般情况下不用，不过有时少不了它的，具体步骤见第5步。 2、我的ora_shutdown.bat：123456789101112131415161718192021222324252627282930313233net stop OracleOraHome81TNSListenernet stop ORACLESERVICEORADBORACLE_HOME=/u01/app/oracle/product/8.1.6export ORACLE_HOME/ 包括Oracle软件的目录 /LD_LIBRARY_PATH=/u01/app/oracle/product/8.1.6/lib;export LD_LIBRARY_PATHORACLE_BASE=/u01/app/oracleexport ORACLE_BASE/ 包括Oracle软件的目录和管理软件的目录 /ORACLE_SID=ORCLexport ORACLE_SID/ 缺省数据库的标识 /ORACLE_TERM=vt100export ORACLE_TERMORA_NLS33=/u01/app/oracle/product/8.1.6/ocommon/nls/admin/dataexport ORA_NLS33 / 语言支持 /PATH=$PATH: /u01/app/oracle/product/8.1.6/binexport PATH 8. ORA-00257: 归档程序错误。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>SQL</tag>
        <tag>Oracle问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ORA-12560:TNS:协议适配器错误的解决方案]]></title>
    <url>%2F2023%2F04%2F07%2FORA-12560-TNS-%E5%8D%8F%E8%AE%AE%E9%80%82%E9%85%8D%E5%99%A8%E9%94%99%E8%AF%AF%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[1. 问题出现的原因 2. 网上分析 3. 问题解决了，开心不？ 4. 不开心，新的风暴已经出现，千万不要停滞不前 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 问题出现的原因 起因是需要将数据库中的条目信息和磁盘上存储的文件信息进行比对，通过Java编程，连接数据库。由于需要精准比对，本人目前能力有限，只好采取单次查询，然后返回结果进行匹配，中间观察到控制台出现“ORA-12516 TNS监听程序找不到符合协议堆栈要求的可用处理程序”的报错，网上解决方案是调整session和processes。 按照网上的说法，需要通过SQL plus先登录控制台 sqlplus /nolog conn / as sysdba 然后华丽丽的报错了 2. 网上分析造成ORA-12560: TNS: 协议适配器错误的问题的原因有三个： 1.监听服务没有起起来。 windows平台个一如下操作：开始—程序—管理工具—服务，打开服务面板，启动oraclehome92TNSlistener服务。 2.database instance没有起起来。 windows平台如下操作：开始—程序—管理工具—服务，打开服务面板，启动oracleserviceXXXX,XXXX就是你的database SID. 3.注册表问题。 regedit，然后进入HKEY_LOCAL_MACHINE\SOFTWARE\ORACLE\HOME0将该环境变量ORACLE_SID设置为XXXX,XXXX就是你的database SID.或者右键我的电脑，属性–高级–环境变量—系统变量–新建，变量名=oracle_sid,变量值=XXXX,XXXX就是你的database SID.或者进入sqlplus前，在command line下输set oracle_sid=XXXX,XXXX就是你的database SID. 3. 问题解决了，开心不？4. 不开心，新的风暴已经出现，千万不要停滞不前]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>SQL</tag>
        <tag>Oracle问题解决</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VB.Net学习]]></title>
    <url>%2F2021%2F08%2F01%2FVB.Net%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[1. VB.Net 环境配置 .NET框架 VB.Net的集成开发环境（IDE） 2. VB.Net - 程序结构 VB.Net Hello World示例 写在前面： 学习过程中乱七八糟的笔记和截取如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://dotnetfoundation.org/ https://docs.microsoft.com/zh-cn/dotnet/core/introduction https://www.w3cschool.cn/vb_net/vb_net_environment_setup.html 1. VB.Net 环境配置在本章中，我们将讨论可用于创建VB.Net应用程序的工具。 我们已经提到VB.Net是.Net框架的一部分，用于编写.Net应用程序。 因此，在讨论用于运行VB.Net程序的可用工具之前，让我们先了解VB.Net如何与.Net框架相关。 .NET框架（1）.NET Framework是一个革命性的平台，可以帮助你编写以下类型的应用： Windows应用程序 Web应用程序 网页服务 （2）.Net框架应用程序是多平台应用程序。该框架的设计方式使其可以从以下任何语言使用：Visual Basic，C＃，C ++，Jscript和COBOL等。 （3）.Net框架包含一个巨大的代码库，用于客户端语言（如 VB.Net）。 这些语言使用面向对象的方法。所有这些语言可以访问框架以及彼此通信。 （4）.Net框架的一些组件： 公共语言运行时（CLR） Common Language Runtime (CLR) .NET框架类库 The .Net Framework Class Library 公共语言规范 Common Language Specification 通用类型系统 Common Type System 元数据和组件 Metadata and Assemblies Windows窗体 Windows Forms ASP.Net 和 ASP.Net AJAX ADO.Net Windows工作流基础（WF） Windows Workflow Foundation (WF) Windows演示基础 Windows Presentation Foundation Windows通讯基础（WCF） Windows Communication Foundation (WCF) LINQ VB.Net的集成开发环境（IDE）Microsoft为VB.Net编程提供以下开发工具： 1、Visual Studio 2010（VS） 2、Visual Basic 2010 Express（VBE） 3、可视化Web开发 后两个是免费的。 Visual Basic Express 和 Visual Web Developer Express版是Visual Studio的精简版本，具有相同的外观和感觉。 它们保留了Visual Studio的大多数功能。 2. VB.Net - 程序结构在我们学习VB.Net编程语言的基本构建块之前，让我们看看一个最小的VB.Net程序结构，以便我们可以将它作为未来的章节的参考。 VB.Net Hello World示例一个VB.Net程序主要由以下几部分组成： 命名空间声明 Namespace declaration 一个类或模块 A class or module 一个或多个程序 One or more procedures 变量 Variables 主过程 The Main procedure 语句和表达式 Statements &amp; Expressions 注释 Comments 让我们看一个简单的代码，打印单词“Hello World”： 12345678Imports SystemModule Module1 &apos;This program will display Hello World Sub Main() Console.WriteLine(&quot;Hello World&quot;) Console.ReadKey() End SubEnd Module 当上述代码被编译和执行时，它产生了以下结果：1Hello, World! 让我们来看看上面的程序中的各个部分： 程序Imports System的第一行用于在程序中包括系统命名空间。(The first line of the program Imports System is used to include the System namespace in the program.) 下一行有一个Module声明，模块Module1。 VB.Net是完全面向对象的，所以每个程序必须包含一个类的模块，该类包含您的程序使用的数据和过程。(The next line has a Module declaration, the module Module1. VB.Net is completely object oriented, so every program must contain a module of a class that contains the data and procedures that your program uses.) 类或模块通常将包含多个过程。 过程包含可执行代码，或者换句话说，它们定义了类的行为。 过程可以是以下任何一种： 功能 Function 子 Sub 运算符 Operator 获取 Get 组 Set AddHandler RemoveHandler RaiseEvent 下一行（’这个程序）将被编译器忽略，并且已经在程序中添加了额外的注释。 下一行定义了Main过程，它是所有VB.Net程序的入口点。 Main过程说明了模块或类在执行时将做什么。 Main过程使用语句指定其行为 Console.WriteLine（“Hello World”的） WriteLine是在System命名空间中定义的Console类的一个方法。 此语句会导致消息”Hello，World ！”在屏幕上显示。最后一行Console.ReadKey（）是用于VS.NET用户的。 这将阻止屏幕从Visual Studio .NET启动时快速运行和关闭。 编译和执行VB.Net程序：如果您使用Visual Studio.Net IDE，请执行以下步骤： 启动Visual Studio。 Start Visual Studio. 在菜单栏，选择文件，新建，项目。 On the menu bar, choose File, New, Project. 从模板中选择Visual Basic。Choose Visual Basic from templates 选择控制台应用程序。Choose Console Application. 使用浏览按钮指定项目的名称和位置，然后选择确定按钮。 Specify a name and location for your project using the Browse button, and then choose the OK button. 新项目显示在解决方案资源管理器中。 The new project appears in Solution Explorer. 在代码编辑器中编写代码。 Write code in the Code Editor. 单击运行按钮或F5键运行项目。 将出现一个包含行Hello World的命令提示符窗口。 Click the Run button or the F5 key to run the project. A Command Prompt window appears that contains the line Hello World. 您可以使用命令行而不是Visual Studio IDE编译VB.Net程序： 打开文本编辑器，并添加上述代码。 Open a text editor and add the above mentioned code. 将文件另存为helloworld.vb。 Save the file as helloworld.vb 打开命令提示符工具并转到保存文件的目录。 Open the command prompt tool and go to the directory where you saved the file. 类型VBC helloworld.vb，然后按回车编译代码。 Type vbc helloworld.vb and press enter to compile your code. 如果在你的代码中没有错误命令提示符下会带你到下一行，并会产生HelloWorld.exe的可执行文件。 If there are no errors in your code the command prompt will take you to the next line and would generate helloworld.exe executable file. 接下来，输入的HelloWorld来执行你的程序。 Next, type helloworld to execute your program. 您将可以看到“Hello World”字样在屏幕上。 You will be able to see “Hello World” printed on the screen.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>vb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识管理的方法]]></title>
    <url>%2F2021%2F07%2F23%2F%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 搭建个人知识管理体系 2. 搭建知识管理系统 3. 写在前面： 仅代表本人当前时间段的认识如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 搭建个人知识管理体系2. 搭建知识管理系统3.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>知识管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识管理汇总]]></title>
    <url>%2F2021%2F07%2F23%2F%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1. 知识管理的内涵和意义 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 知识管理的内涵和意义知识管理—-搭建个人知识体系，提升工作效率]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>知识管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[音乐格式转换]]></title>
    <url>%2F2021%2F07%2F20%2F%E9%9F%B3%E4%B9%90%E6%A0%BC%E5%BC%8F%E8%BD%AC%E6%8D%A2%2F</url>
    <content type="text"><![CDATA[1. .mov转换为.mp4 2. .mp4转换为.gif 3. .m4v、.m4b、.flac转换为.mp3 4. 特殊格式 写在前面： 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://blog.csdn.net/weixin_39986169/article/details/111271786 https://blog.csdn.net/weixin_31315007/article/details/114324887 1. .mov转换为.mp4.mov是QuickTime影片格式，是Apple公司开发的一种音频、视频文件格式。我们只需要iMovie打开相关文件，然后重新导出即可，iMovie默认导出的视频格式就是.mp4 2. .mp4转换为.gifconvertio：https://convertio.co/zh/mp4-gif/ 上传非常慢，有时页面点击后无反应 aconvert：https://www.aconvert.com/cn/video/mp4-to-gif/# 上传很快，但下载很慢，并且保持期限只有1小时，过期不下载自动被清除 3. .m4v、.m4b、.flac转换为.mp3cloudconvert：https://cloudconvert.com/flac-to-mp3 上传下载都很快，但在未注册的情况下限制10分钟以内只能操作一次 FLAC To MP3 Converter Online：https://www.flacmp3.net/online/ 第一次页面加载特别慢，而且部分浏览器没有显示上传文件按钮，我用的Chrome和QQ浏览器显示正常 XAudioPro：https://www.xaudiopro.com/fmtcvt 强烈推荐，上传、解析、下载速度快 4. 特殊格式QQ音乐或网易云音乐在会员期间下载的仅限会员可收听的音乐，其格式都已经加密，我们需要先解密才能再做转换 音乐解锁：http://moresound.tk/music/tool/ 目前支持网易云音乐(ncm), QQ音乐(qmc, mflac, mgg), 虾米音乐(xm), 酷我音乐(.kwm) 解密]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NFC功能实现一碰传、WiFi自动连入]]></title>
    <url>%2F2021%2F07%2F18%2FNFC%E5%8A%9F%E8%83%BD%E5%AE%9E%E7%8E%B0%E4%B8%80%E7%A2%B0%E4%BC%A0%E3%80%81WiFi%E8%87%AA%E5%8A%A8%E8%BF%9E%E5%85%A5%2F</url>
    <content type="text"><![CDATA[1. 非华为电脑（华硕）和华为手机实现一碰传 1. 下载华为电脑管家 2. 在下载好的文件里打开“安装激活软件” 3. 标签激活 4. 电脑打开安装激活软件，检查数据是否正常 5. 数据正常，手机打开一碰传助手 2. 手机NFC连接WiFi 1. 酷安下载 NFC Tools 2. 打开app，点击写 3. 写入NFC贴纸 写在前面： 目标是实现一碰传功能，然后就解锁了各种新奇的使用方法如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 1. 非华为电脑（华硕）和华为手机实现一碰传1. 下载华为电脑管家百度网盘 提取码：1234 ps: 如果电脑之前已经在使用旧版本的华为电脑管家，必须要先卸载干净，==方法：==&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;先进入安全模式，然后进入C盘，再进入路径 C:\Program Files\Huawei选中 Huawei 这个文件夹，整个删除。 2. 在下载好的文件里打开“安装激活软件”（1）将电脑时间修改为 2020年7月18日==原因== 版本对应时间，否则无法解锁 （2）界面中填入口令 19221A （3）点击安装 ps:这里安装好了之后电脑管家并不能正常使用 ==解决方法== 把下载的文件 “version.dll” 复制到 &nbsp;&nbsp;C:\Program Files\Huawei\PCManager 3. 标签激活在下载的文件找到一碰传助手，用QQ传到手机的QQ上进行安装ps:必须是QQ传 微信之类的会无法安装的 4. 电脑打开安装激活软件，检查数据是否正常SN码是否是==16==位，无特殊符号，蓝牙==12==位 5. 数据正常，手机打开一碰传助手点扫一扫，对着安装激活软件上的二维码进行扫码 然后跳转到一个页面，再把手机的NFC感应区对着NFC标签进行激活，直到出现激活成功，这个标签就完成数据写入了。 此时碰标签就可以正常连接电脑了 2. 手机NFC连接WiFi当朋友来家里的时候，直接告诉WiFi密码和给他输入WiFi密码都有些奇奇怪怪的，实现一碰连接就很舒适了。 1. 酷安下载 NFC Tools2. 打开app，点击写选择添加记录中的WiFi网络，按照自家WiFi的情况进行填写即可。不清楚的可以点进WiFi看详情。 仅供参考： 身份验证：WP2-Personal加密： AESSSID(这是你家WiFi的名字)：666密码(字面意思)：hahaha 填完之后点击OK,就会在写中看到一条编辑好的信息 3. 写入NFC贴纸把你的NFC贴纸靠近手机，等待一两秒写入完成即可。]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[电动升降桌选择调查]]></title>
    <url>%2F2021%2F07%2F15%2F%E7%94%B5%E5%8A%A8%E5%8D%87%E9%99%8D%E6%A1%8C%E9%80%89%E6%8B%A9%E8%B0%83%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[知乎阿念 一、电动升降桌和普通办公桌的区别 二、电动升降桌工作原理浅析 三、购买电动升降桌注意点 1、电机配置 2、产品材质 3、升降范围 4、桌腿安装方式 5、稳定性能 + 承重性能 6、其它辅助功能 四、电动升降桌牌子 五、不同价位、高性价比电动升降桌 （1）1500元内 （2）1500-2000元 （3）2000元以上 油管少华有态度 Elaine测评 SchelleyYuki 写在前面： 本文是信息的采集，不代表个人意见如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://zhuanlan.zhihu.com/p/270023472 https://www.youtube.com/watch?v=f2kSxwKeqBM https://www.youtube.com/watch?v=T34A8NDwaS0 https://www.youtube.com/watch?v=yLJowy8pa1s 知乎阿念一、电动升降桌和普通办公桌的区别（1）解决办公久坐问题 （2）而且电动升降桌还能满足多场景、多人群的使用调节 二、电动升降桌工作原理浅析 原理 &nbsp;利用电力进行驱动，通过电机对机械装置进行控制，从而到达调节升降桌高低的效果。 简单来说，就是通过桌腿中的电机对桌子进行升降，类似电梯。 三、购买电动升降桌注意点1、电机配置电机是电动升降桌的核心零件，而电动升降桌的电机配置又分为单电机、双电机和四电机三种类型。 电机分类 单电机 双电机 升降原理 桌腿一侧安装电机，通过连杆驱动带动另一侧桌腿进行升降。 桌腿两侧都安装电机，通过中间控制器来对两侧实现同时升降。 承重性能 70kg 100kg 升降速度 25mm/s 35mm/s 使用寿命 长 短 稳定效果 桌架较重，28KG 桌架较轻，20KG 2、产品材质除了核心部件之外，电动升降桌的桌腿材质和桌板材质也是不容忽视的问题。 桌板材质： 市面上主流电动升降桌的桌板材质主要有实木板、钢化玻璃材质和环保面板（颗粒板/密度板）三种。质量最好的是实木板，其次是钢化玻璃材质，最后是环保面板，选择时也可以按这个顺序进行挑选。 桌腿材质（升降柱）： 桌腿材质的优先级顺序是：冷轧钢材质&gt;铝合金材质&gt;普通钢材质。质量最好的是冷轧碳素钢板，如果考虑轻便性，也可以选择铝合金材质。 3、升降范围升降范围是指升降桌升起时的最高位置和降下时最低位置。目前主流电动升降桌的升降范围值多在60-120cm左右。 升降范围的选择最好是根据自身身高以及使用习惯来选，另外有一点需要注意的是升降间隙问题，间隙小的升降距离也相对较短。 4、桌腿安装方式升降桌的桌腿出了支撑整个桌子之外，最主要的作用是调节升降桌的高低。桌腿主要分为二节和三节两种形式，其中三节桌腿在稳定性上要比两节桌腿好很多。安装上桌腿又分为正装和倒装两种，正装是顶部升降，倒装则是底部升降，正装效果要比倒装好，大家在安装时可以注意一下。 5、稳定性能 + 承重性能电动升降桌的稳定性能直接决定了在使用过程中桌子是否会晃动，而承重性能则是考验桌板所承受物品的重量。从参数数值方面来讲，稳定性能主要和电机数量有关，承重性能越大越好。 6、其它辅助功能丰富的辅助功能是购买电动升降桌时的加分项，比如高度记忆功能，可以预设几个不同高度，方便下一次使用时能调节到合适高度。另外还有久坐提醒、蓝牙/APP控制、有线快充/无线快充功能等等，大家在购买时可以看自己需求来决定。 四、电动升降桌牌子目前国内电动升降桌的主流品牌主要以乐歌、Brateck、赛途为主，另外还有京东京造、趣东乐等小众品牌。其中赛途主打电竞升降桌领域，在这里对三个主流品牌进行一个品牌介绍： （1）乐歌国内人体工学线性驱动应用和健康办公整体解决方案的领军企业，成立于2002年3月，专注于人体工学研究。乐歌电动升降桌在国内的销量非常高，隐隐有种一哥的感觉。而且产品线也非常丰富，从低端到高端都有涉及。 （2）Brateck：2005年成立于浙江宁波，之前主要是做出口，研发产品的出口国家就多达100多个。近几年进入国内市场后，线上线下同步发展，也赢得了不少好评，同时产品质量也非常的好。 （3）赛途：专业的电竞设备品牌，旗下产品线十分丰富，有满足广泛玩家需求的的觉醒系列，更有骨灰级玩家的专业电竞设备—荣耀系列。 五、不同价位、高性价比电动升降桌（1）1500元内在1500元以内这个价格，通过关键指标横向对比得出四款性价比不错的产品： 迈德斯特M2-D Brateck K21 Brateck K22 乐歌 E2标准 结合品牌与用户好评之后，性价比最高的是Brateck的两款和乐歌E2 标准款。 型号：乐歌E2电动升降桌 标准版 电机类型：单电机升降高度：71-121cm桌架收缩：85-129cm升降速度：25mm/s桌腿形式：2节倒装承重范围：70kg 推荐理由：E2这款升降桌属于乐歌E系列入门款，在同价位产品中性价比非常高。虽然是单电机配置，但升降速度却可达25mm/秒。桌架采用了冷轧钢板，搭配120x60的复合环保面板，操作空间大，同时可以承受70kg的物品重量。值得肯定的是支持免费安装。 不过这款升降桌不支持一键记忆功能，而且升降过程中产生的噪音控制在50分贝左右，只能算是合格水平。 型号：Brateck电动升降桌 K22 电机类型：单电机升降高度：73-123cm桌架收缩：84-130cmm升降速度：38mm/s桌腿形式：2节正装承重范围：70kg 推荐理由：Brateck主要是做出口，在全球的口碑都很不错。而K22这款升降桌最大的优势在于采用的是大功率直流电机，性能非常强悍，升降速度到达38mm/s，同时还能保证较好的稳定性。在性能上可以媲美双电机，除此之外还能承受70kg的重量。 不足之处在于桌子整体会比其它桌子高出不少，而且桌腿部位不是碳素钢材质，但胜在价格优势，性价比还是很高的。 不过如果你预算实在有限或是为了体验升降桌，也可以看看k21这一款，除了电机区别，其它参数基本相同，性价比同样很高。 （2）1500-2000元在1500-2000元预算区间，通过关键指标横向对比得出Brateck K32 高配和乐歌 E1D白色两款高性价比产品。除了这两款产品外，我还比较推荐乐歌E5和京东京造，E5是我自用款，京东京造之前有推荐朋友买过，性价比远比参数所体现的要高。 商品：Brateck电动升降桌 K32 电机类型：单电机升降高度：73-123cm桌架收缩：84-130cmm升降速度：38mm/s桌腿形式：2节正装承重范围：80kg 推荐理由：K32这一款升降桌操作方式和K22比较相似，属于K22的升级版本。都采用了智能触控的操作模式，同时还增加了定时提醒。电机是采用的全封闭式的，具有更好的稳定性。 安全性方面也十分完善，有过载保护、过热保护，还有实用的遇阻退回功能。另外可承载物品的最大重量是80kg。 商品：乐歌E5电动升降桌 雅白 电机类型：单电机升降高度：72-121cm桌架收缩：不支持升降速度：25mm/s桌腿形式：2节倒装承重范围：50kg 推荐理由：我自己使用的就是E5这款，抛开参数不谈，颜值是真的非常高。购买这一款的也有很多多，口碑各方面都很不错。除了雅白外还有黑色可以选，能够根据装修风格选择搭配。 面板采用的是钢化玻璃材质，桌面长度1.2米，可以满足日常放置的需求；同时还有一个隐藏式的抽屉，这一点设计的比较好，可以用来放置各种小物品。 商品：京东京造 电动升降桌 电机类型：单电机升降高度：72-120cm桌架收缩：不支持升降速度：不详桌腿形式：2节正装承重范围：80kg 推荐理由：京东京造这款升降桌的特点在于采用了实木弧形面板，能更好的贴合身体。同时还有四档高度记忆键，这一点比较少见。除此以外多功能集成插座（包含双USB接口）、蓝牙与APP双重操作，都可谓是充满科技感。 商品：乐歌E1D 电动升降桌 电机类型：双电机升降高度：71-121cm桌架收缩：85-129cm升降速度：25mm/s桌腿形式：2节倒装承重范围：70kg 推荐理由：E1D升降桌采用的是双电机配置，不过只是入门级别，但是在京东的销量确非常好，整体性价比很高，毕竟价格不到两千元。 桌板提供了白/黑/胡桃木/原木四种颜色可选，桌腿也提供了白/黑/灰三种，可以自行搭配。升降速度最高可达32mm/秒，全程15秒；噪音50分贝，承重100kg，同时配备了三档高度记忆、久坐提醒功能。 （3）2000元以上 基本都采用双电机配置，稳定性、升降速度及使用寿命上都有所提升，整体体验感也更好。 在这个价格区间经过指标比对，结合用户口碑我筛选出了四款不错的产品： 猫神维斯网红款 乐歌E4 趣动乐 Joy25 乐歌E3四款产品的价格从低到高，在功能配置上有非常不错的表现。特别是乐歌E4，与E3相比除了升降高度上一点细微的差距外，可以说性价比无敌。 商品：MOTIONWISE 电动升降桌 网红热推款 电机类型：双电机升降高度：72-122cm桌架收缩：110cm升降速度：30mm/s桌腿形式：2节正装承重范围：120kg 推荐理由：猫神维斯是美国品牌，与国产升降桌相比，这款桌子的整体性价比都要高不少。最大的特色在于有配抽屉设计，便于生活中的收纳。同时采用双电机配置，升降速度在30mm/秒情况下还能让噪音控制在40分贝，相当难得。 其它功能方面也都比较OK，支持四档记忆高度调节，同时还配有USB接口，可以用来给移动设备供电。除此之外，还有七档位灵敏度防撞夹，具有可靠的安全性。 商品：乐歌LIFT1 电动升降桌 (原型号：E3) 电机类型：双电机升降高度：60-123cm桌架收缩：118-180cm升降速度：38mm/s桌腿形式：3节正装承重范围：125kg 推荐理由：E3是乐歌唯一采用了三段正装桌腿的产品，而且还搭配了人体工学键盘托，能够保护手肘。升降速度38mm/秒，标配三档高度记忆和久坐提醒功能。唯一不足就是价格比较高，和E4相比，我会更推荐E4，性价比更高；如果不差钱，选择这一款也无可厚非。 商品：乐歌E4 电动升降桌 电机类型：双电机升降高度：60-125cm桌架收缩：84-100cm升降速度：38mm/s桌腿形式：3节倒装承重范围：125kg 推荐理由：乐歌E4同样采用了双电机配置，能保证升降速度在38mm/秒的情况下依旧保持平稳；还有一个比较大的特点，能满足可调节范围内任意高度的0.1cm升降变量。在其它功能方面配备有三档高度记忆、久坐提醒功能。 除此之外，承重性能100kg，噪音控制50分贝，只能说处于合格水平；而且面板材质依旧不是实木面板。 商品：趣动乐Joy25 电动升降桌 电机类型：双电机升降高度：62-127cm桌架收缩：不支持升降速度：38mm/s桌腿形式：3节正装承重范围：100kg 推荐理由：趣动乐Joy25 最大特色在于它的控制器，不需要寻找升降器，可以凭直觉控制， 曾获得过红点设计奖；除此之外，还能通过手机APP进行一键升降控制。桌架可以承重100kg，具有很好的稳定性，也能满足日常使用。更值得肯定的是 厂家提供5年质保。 商品：读立四驱系列 电动升降桌 产品尺寸：18080120cm电机类型：四电机升降高度： 71-120cm桌腿形式：两节倒装承重范围：200kg产品材料：高强度铝合金及钢材+实木颗粒板 推荐理由：读立四驱系列的这款桌子稳定性非常好，因为它是是个桌腿的设计，而且采用了四电机配置，这一点是比较少见的。同时还能承受200kg的重量，属于升降桌中的高端产品，主要用于办公室。 另外这款升降桌支持个人定制，有很多配件可以自己加装。比如包挂、抽屉、键盘托架、背景灯等等。另外还有一个非常棒的设计，加装配件的时候桌面不需要打孔。而且拆卸安装也非常的方便。售后方面也是比较有保障的那种，官方承诺五年质保。 油管少华有态度对乐歌E5进行了测评，升降速度还可，平稳度良好，分贝控制40左右 Elaine测评Autonomous SmartDesk 2 Premium Standing Desk 美国桌子，稳定性不错，价格2K8左右 SchelleyYuki]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[知识管理---搭建个人知识体系，提升工作效率]]></title>
    <url>%2F2021%2F07%2F14%2F%E7%9F%A5%E8%AF%86%E7%AE%A1%E7%90%86---%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB%EF%BC%8C%E6%8F%90%E5%8D%87%E5%B7%A5%E4%BD%9C%E6%95%88%E7%8E%87%2F</url>
    <content type="text"><![CDATA[0. 什么是知识管理呢？ 1.提高效率——知识的复用！ 2.提升认知水平 写在前面： 新的名词，新的学习 本文是在阅读并转载参考文章1的基础上进行的修饰 通过参考文章1的解读，知识管理更像是自己构建一个模型对输入的各种信息进行分类处理，存储，再加工。知识管理的核心应该在于选用合适的方式（架构，算法，连接模式等）对知识进行最大程度的运用 如本文描述有错误，希望读到这篇文章的您能够提出批评指正。 联系方式：172310978@qq.com 参考文章： https://zhuanlan.zhihu.com/p/148299598 0. 什么是知识管理呢？我认为，知识管理是一个包括对外部信息的加工，核心知识的提炼以及思维模型的搭建过程，而这个过程一切都是围绕着提升我们认知水平和行动速度进行的。 如果从这个概念去理解知识管理的话，知识管理殿堂主要有3层，最底下也是最基础的一层是工具的使用，中间层为方法论的形成，而最高一层为核心思维模型（比如我们人类几千年历史所总结出来的知识瑰宝，如物理学定理、心理学法则等）。 “世界上，很多看似复杂的知识和道理，其实都可以通过一些基本的模型和框架去解释”。在我们日常生活和工作中，总会遇到各种各样的问题，有的人会基于过往的经验和知识，去解决这个问题；还有的人会探寻问题表象下的根源，为什么会产生这个问题？以前有没有产生过类似的问题？如何解释这个问题？是否有一个共通的方法可以解决类似的问题？ 前者，或许解决问题能力会不断提高，但问题总是会一个接着一个出现的，他们会不断忙于解决后来出现的问题，但随着年龄的增大，体力和精力的下降，会感觉越来越力不从心。而后者，由于善于探寻问题的本质，并思考提炼出解决这类问题的思维模型，往后遇到类似的问题时他们可以直接套用此前总结出来的方法去解决，这类人往往也被我们称之为”专家”。 后者，更倾向于真正的知识管理。个人的知识管理，核心是从信息的收集，到方法论的形成，再到模型和思维框架的形成过程，也是一个从隐形知识到显性知识的过程。而这最明显的好处体现在它可以提升我们的认知水平和提高效率。 1.提高效率——知识的复用！比如，写一篇文章，需要经过选题、素材收集、素材梳理和筛选、动笔写这4个基本的步骤。正常来说，每个步骤都需要占去你一定的时间，如果说写一篇文章需要花费2个小时，素材收集和整理通常会占1个小时，当收集的素材足够丰富，而且写的选题是作者熟悉的领域，真正的动笔写是不需要花费很多时间的。 这个过程中，素材的收集和整理是决定文章是否具备深度和广度的重要步骤之一。但这个步骤也是最能够帮助我们节省时间的步骤。 假如，我们写文章所需的素材已经存在于我们搭建的个人知识库中呢，我们只需要调用出来就可以了，那么我们的效率将会得到极大的提升。 而这本质是知识的复用。 在日常的生活中和工作中，刻意收集一些对我们有价值的知识，并且存储在个人知识库中（这里我选择用”印象笔记”作为我的个人知识库的主要承载工具），往后当我们需要用到相关的知识时，检索调用出来，快速帮助我们解释问题或解决问题。 2.提升认知水平从宏观的角度来理解知识管理，知识管理的确可以帮助我们提升认知水平。 在《穷查理宝典》这本书中，查理·芒格讲到：“如果你只是孤立地记住一些事物，试图把它们硬凑起来，那你无法真正理解任何事情……你必须依靠模型组成的框架来安排你的经验。” 知识管理，就是将我们日常经验、每日学习到的零散知识汇总在一起，并整理归档。类似于图书馆，知识以分类的形式存储在相应的地方，每本书作为一个小知识块存储在相应的地方，同类的书组成某一领域的知识，而多个领域的图书则构成一个大的图书馆。但与之相区别的是，知识管理更高级，组成知识体系中的每一小块知识是可以相互联结在一起的，并非只有点与点之间的线性关系，而是网状关系。 在个人知识体系搭建起来后，我们可以像吸铁石一样，将所有对我们当下或不远的未来有用的信息吸进来，并经过思考整理成知识后，将这些知识存储起来，随着我们不断的积累，我们所搭建的知识体系框架会越来越有内容，越来越丰满。 从另一方面来说，其实通过外部的工具搭建个人知识体系，本质是减少我们的记忆信息量，而将时间用在思考和创造上。 很多时候，在我们的身边，包括我自己，我们会将学过的东西遗忘了或者前不久父母或女友/男友交代的事情忘记了归因于记忆力下降或者最近事情忙等等。或者羡慕别人的好记性…… 但其实，相比记忆，我们的大脑更善于思考。只不过，我们很多时候，都有意或无意地对大脑的要求重在记忆而已。但我们能接触到的、以及能记住的知识其实不过是人类知识海洋中的沧海一粟。特别是现代社会中，每天都有大量的新信息、新知识的出现，我们不断要求自己的大脑学习、记忆、学习、记忆，而这个过程的速度远远跟不上信息产生的速度，所以自然而然就产生了知识焦虑。 如果，我们将记忆的绝大部分工作交给外部的工具，比如云笔记（目前比较流行的工具有印象笔记、有道云笔记、幕布、石墨文档等），以这类的工具作为我们外接的”网络云盘”（或我称之为”第二大脑”，该”大脑”重在知识的存储），将自己的大脑用在更有价值的地方，比如思考和创造，生命会不会更有意义呢？ 所以，放弃”我有一个好脑子，我一定要记住这些东西”的想法吧，当面对新知识或者想到的好想法时，拿出更多的精力去思考和创造，将记忆交给外部工具，当大脑进行思考和创造多了，自然而然，我们的认知水平也就上升到了一个更高的水平，我们看待事物的角度也将远远不同。 正如《教父》这部电影中有这么一句话”花半秒钟就看透事物本质的人，和花一辈子都看不清的人，注定是截然不同的命运。”]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>知识管理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[彻底消除 Flash 助手推荐的弹窗广告]]></title>
    <url>%2F2021%2F07%2F07%2F%E5%BD%BB%E5%BA%95%E6%B6%88%E9%99%A4%20Flash%20%E5%8A%A9%E6%89%8B%E6%8E%A8%E8%8D%90%E7%9A%84%E5%BC%B9%E7%AA%97%E5%B9%BF%E5%91%8A%2F</url>
    <content type="text"><![CDATA[1. 关闭“Flash Helper Service”后台进程。 2、禁止“Flash Helper Service”自动运行。 3、删除“Flash Helper Service”应用程序。 4、清理注册表痕迹。 写在前面： 全新的 Windows 10 操作系统，安装好没多久就弹出个“ FF 新推荐”的大幅广告窗口，点击“近期不弹”选项，不再弹出。今天又发现在屏幕右下角弹出了个“Flash 助手推荐”的广告。虽然在那个下拉菜单中，也可以选择“近期不再弹出”的选项，但看着总是心烦。一开始还以为中恶意木马，看到许多网友也中招，才知道这是官方流氓行为。这是 Adobe 公司携手重庆重橙网络科技有限公司，为中国网民保留的特色流氓服务，是我们安装了 Adobe Flash Player 插件后的“正常”情况。 理论上说，Adobe 于 2020 年 12 月 31 日终止支持 Flash，各主流浏览器从几年前就陆续禁止 Flash 插件开启。也就是说 Flash 插件已经被淘汰了，没必要安装了。把 Adobe Flash Player 插件卸载就可以彻底清除 Flash 助手弹窗广告了。 但还有个别小视频网站，出于获取用户信息、降低运营成本等考虑，还在坚持使用 Flash 插件播放视频，所以我们可能还要保留 Adobe Flash Player 插件，那么我们就来删除 Flash 助手推荐。 1. 关闭“Flash Helper Service”后台进程。右键任务栏，或 Ctrl+Shift+ESC 打开任务管理，在“后台进程”中找到“Flash Helper Service.exe”（居然有3个），结束任务。 2、禁止“Flash Helper Service”自动运行。右键点击“此电脑”，点击“管理”，在计算机管理点击左侧的“服务”，在右栏找到“Flash Helper Service”，右键选择“属性”。在“Flash Helper Service 的属性”界面，先停止服务，再在启动类型内，选择“禁用”，最后点击“确定”即可。 我们可在描述中发现端倪：Flash Player更新辅助服务,确保使用最新版的 Flash Player 软件。会向重庆重橙网络科技有限公司发送匿名使用Flash相关数据以帮助改进 Flash Player。 3、删除“Flash Helper Service”应用程序。在任务管理器中，点击进程名称，右键“打开文件所在的位置”，就可以找到它的息身之所了。或者在服务属性中，我们可看到可执行文件的路径。一般情况下，他在这里：C:\Windows\SysWOW64\Macromed\Flash\ 。直接删除FlashHelperService.exe 即可。最好把flash文件夹直接删了 4、清理注册表痕迹。清理注册表中有关 Flash Helper Service 的所有东西 (1) 法一：按键盘Win键（有的键盘是一个像 Windows 窗口的图标）+R键，打开运行，输入 regedit 点确定，打开注册表管理器，搜索 FlashHelperService.exe，找到后右键删除，然后按F3搜索下一个，直到搜索完毕。 (2) 法二：注册表清理软件]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有趣的注释]]></title>
    <url>%2F2021%2F07%2F05%2F%E6%9C%89%E8%B6%A3%E7%9A%84%E6%B3%A8%E9%87%8A%2F</url>
    <content type="text"><![CDATA[1. 佛祖保佑，永无BUG 2. 神兽护体，永无BUG 3. 来首程序员打油诗，笑 5. 单身狗专用 6. 骷髅头 7. 标准键盘 8. 顶 9. 其他 写在前面： 程序员们可真是神奇的动物，如果你看源码，会发现他们将自己的情绪详细的记录http://www.asciiworld.com/ 1. 佛祖保佑，永无BUG123456789101112131415161718192021// _ooOoo_ // o8888888o // 88&quot; . &quot;88 // (| -_- |) // O\ = /O // ____/`---&apos;\____ // . &apos; \\| |// `. // / \\||| : |||// \ // / _||||| -:- |||||- \ // | | \\\ - /// | | // | \_| &apos;&apos;\---/&apos;&apos; | | // \ .-\__ `-` ___/-. / // ___`. .&apos; /--.--\ `. . __ // .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. // | | : `- \`.;`\ _ /`;.`/ - ` : | | // \ \ `-. \_ __\ /__ _/ .-` / / // ======`-.____`-.___\_____/___.-`____.-&apos;====== // `=---=&apos; // // ............................................. // 佛祖保佑 永无BUG 2. 神兽护体，永无BUG1234567891011121314151617// ┏┓ ┏┓// ┏┛┻━━━┛┻┓// ┃ ┃ // ┃ ━ ┃// ┃ ┳┛ ┗┳ ┃// ┃ ┃// ┃ ┻ ┃// ┃ ┃// ┗━┓ ┏━┛// ┃ ┃ Code is far away from bug with the animal protecting // ┃ ┃ 神兽保护，永无BUG！// ┃ ┗━━━┓// ┃ ┣┓// ┃ ┏┛// ┗┓┓┏━┳┓┏┛// ┃┫┫ ┃┫┫// ┗┻┛ ┗┻┛ 1234567891011121314151617181920212223/** * ┏┓ ┏┓+ + * ┏┛┻━━━┛┻┓ + + * ┃ ┃ * ┃ ━ ┃ ++ + + + * ████━████ ┃+ * ┃ ┃ + * ┃ ┻ ┃ * ┃ ┃ + + * ┗━┓ ┏━┛ * ┃ ┃ * ┃ ┃ + + + + * ┃ ┃ Code is far away from bug with the animal protecting * ┃ ┃ + 神兽保佑,永无bug * ┃ ┃ * ┃ ┃ + * ┃ ┗━━━┓ + + * ┃ ┣┓ * ┃ ┏┛ * ┗┓┓┏━┳┓┏┛ + + + + * ┃┫┫ ┃┫┫ * ┗┻┛ ┗┻┛+ + + + */ 3. 来首程序员打油诗，笑1234567891011/** * 江城子 . 程序员之歌 * * 十年生死两茫茫，写程序，到天亮。 * 千行代码，Bug何处藏。 * 纵使上线又怎样，朝令改，夕断肠。 * * 领导每天新想法，天天改，日日忙。 * 相顾无言，惟有泪千行。 * 每晚灯火阑珊处，夜难寐，加班狂。*/ 12345678910/** * 写字楼里写字间，写字间里程序员； * 程序人员写程序，又拿程序换酒钱。 * 酒醒只在网上坐，酒醉还来网下眠； * 酒醉酒醒日复日，网上网下年复年。 * 但愿老死电脑间，不愿鞠躬老板前； * 奔驰宝马贵者趣，公交自行程序员。 * 别人笑我忒疯癫，我笑自己命太贱； * 不见满街漂亮妹，哪个归得程序员？ */ 5. 单身狗专用123456789101112131415161718192021222324252627282930313233343536&lt;!-- :: :;J7, :, ::;7: ,ivYi, , ;LLLFS: :iv7Yi :7ri;j5PL ,:ivYLvr ,ivrrirrY2X, :;r@Wwz.7r: :ivu@kexianli. :iL7::,:::iiirii:ii;::::,,irvF7rvvLujL7ur ri::,:,::i:iiiiiii:i:irrv177JX7rYXqZEkvv17 ;i:, , ::::iirrririi:i:::iiir2XXvii;L8OGJr71i :,, ,,: ,::ir@mingyi.irii:i:::j1jri7ZBOS7ivv, ,::, ::rv77iiiriii:iii:i::,rvLq@huhao.Li ,, ,, ,:ir7ir::,:::i;ir:::i:i::rSGGYri712: ::: ,v7r:: ::rrv77:, ,, ,:i7rrii:::::, ir7ri7Lri , 2OBBOi,iiir;r:: ,irriiii::,, ,iv7Luur: ,, i78MBBi,:,:::,:, :7FSL: ,iriii:::i::,,:rLqXv:: : iuMMP: :,:::,:ii;2GY7OBB0viiii:i:iii:i:::iJqL;:: , ::::i ,,,,, ::LuBBu BBBBBErii:i:i:i:i:i:i:r77ii , : , ,,:::rruBZ1MBBqi, :,,,:::,::::::iiriri: , ,,,,::::i: @arqiao. ,:,, ,:::ii;i7: :, rjujLYLi ,,:::::,:::::::::,, ,:i,:,,,,,::i:iii :: BBBBBBBBB0, ,,::: , ,:::::: , ,,,, ,,::::::: i, , ,8BMMBBBBBBi ,,:,, ,,, , , , , , :,::ii::i:: : iZMOMOMBBM2::::::::::,,,, ,,,,,,:,,,::::i:irr:i:::, i ,,:;u0MBMOG1L:::i:::::: ,,,::, ,,, ::::::i:i:iirii:i:i: : ,iuUuuXUkFu7i:iii:i:::, :,:,: ::::::::i:i:::::iirr7iiri:: : :rk@Yizero.i:::::, ,:ii:::::::i:::::i::,::::iirrriiiri::, : 5BMBBBBBBSr:,::rv2kuii:::iii::,:i:,, , ,,:,:i@petermu., , :r50EZ8MBBBBGOBBBZP7::::i::,:::::,: :,:,::i;rrririiii:: :jujYY7LS0ujJL7r::,::i::,::::::::::::::iirirrrrrrr:ii: ,: :@kevensun.:,:,,,::::i:i:::::,,::::::iir;ii;7v77;ii;i, ,,, ,,:,::::::i:iiiii:i::::,, ::::iiiir@xingjief.r;7:i, , , ,,,:,,::::::::iiiiiiiiii:,:,:::::::::iiir;ri7vL77rrirri:: :,, , ::::::::i:::i:::i:i::,,,,,:,::i:i:::iir;@Secbone.ii:::--&gt; 6. 骷髅头123456789101112131415161718192021222324/** ************************************************************** * * * .=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-. * * | ______ | * * | .-&quot; &quot;-. | * * | / \ | * * | _ | | _ | * * | ( \ |, .-. .-. ,| / ) | * * | &gt; &quot;=._ | )(__/ \__)( | _.=&quot; &lt; | * * | (_/&quot;=._&quot;=._ |/ /\ \| _.=&quot;_.=&quot;\_) | * * | &quot;=._&quot;(_ ^^ _)&quot;_.=&quot; | * * | &quot;=\__|IIIIII|__/=&quot; | * * | _.=&quot;| \IIIIII/ |&quot;=._ | * * | _ _.=&quot;_.=&quot;\ /&quot;=._&quot;=._ _ | * * | ( \_.=&quot;_.=&quot; `--------` &quot;=._&quot;=._/ ) | * * | &gt; _.=&quot; &quot;=._ &lt; | * * | (_/ \_) | * * | | * * &apos;-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=-=&apos; * * * * LASCIATE OGNI SPERANZA, VOI CH&apos;ENTRATE * ************************************************************** */ 7. 标准键盘12345678910111213141516/** * ┌───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┬───┐ ┌───┬───┬───┐ * │Esc│ │ F1│ F2│ F3│ F4│ │ F5│ F6│ F7│ F8│ │ F9│F10│F11│F12│ │P/S│S L│P/B│ ┌┐ ┌┐ ┌┐ * └───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┴───┘ └───┴───┴───┘ └┘ └┘ └┘ * ┌───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───┬───────┐ ┌───┬───┬───┐ ┌───┬───┬───┬───┐ * │~ `│! 1│@ 2│# 3│$ 4│% 5│^ 6│&amp; 7│* 8│( 9│) 0│_ -│+ =│ BacSp │ │Ins│Hom│PUp│ │N L│ / │ * │ - │ * ├───┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─────┤ ├───┼───┼───┤ ├───┼───┼───┼───┤ * │ Tab │ Q │ W │ E │ R │ T │ Y │ U │ I │ O │ P │&#123; [│&#125; ]│ | \ │ │Del│End│PDn│ │ 7 │ 8 │ 9 │ │ * ├─────┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴┬──┴─────┤ └───┴───┴───┘ ├───┼───┼───┤ + │ * │ Caps │ A │ S │ D │ F │ G │ H │ J │ K │ L │: ;│&quot; &apos;│ Enter │ │ 4 │ 5 │ 6 │ │ * ├──────┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴─┬─┴────────┤ ┌───┐ ├───┼───┼───┼───┤ * │ Shift │ Z │ X │ C │ V │ B │ N │ M │&lt; ,│&gt; .│? /│ Shift │ │ ↑ │ │ 1 │ 2 │ 3 │ │ * ├─────┬──┴─┬─┴──┬┴───┴───┴───┴───┴───┴──┬┴───┼───┴┬────┬────┤ ┌───┼───┼───┐ ├───┴───┼───┤ E││ * │ Ctrl│ │Alt │ Space │ Alt│ │ │Ctrl│ │ ← │ ↓ │ → │ │ 0 │ . │←─┘│ * └─────┴────┴────┴───────────────────────┴────┴────┴────┴────┘ └───┴───┴───┘ └───────┴───┴───┘ */ 8. 顶123456789101112131415/** * 頂頂頂頂頂頂頂頂頂 頂頂頂頂頂頂頂頂頂 * 頂頂頂頂頂頂頂 頂頂 * 頂頂 頂頂頂頂頂頂頂頂頂頂頂 * 頂頂 頂頂頂頂頂頂頂頂頂頂頂 * 頂頂 頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂 頂頂頂 頂頂 * 頂頂 頂頂頂 * 頂頂 頂頂 頂頂 頂頂 * 頂頂頂頂 頂頂頂頂頂 頂頂頂頂頂 * 頂頂頂頂 頂頂頂頂 頂頂頂頂 */ 9. 其他12345678910111213141516171819202122/** * _ooOoo_ * o8888888o * 88&quot; . &quot;88 * (| -_- |) * O\ = /O * ___/`---&apos;\____ * . &apos; \\| |// `. * / \\||| : |||// \ * / _||||| -:- |||||- \ * | | \\\ - /// | | * | \_| &apos;&apos;\---/&apos;&apos; | | * \ .-\__ `-` ___/-. / * ___`. .&apos; /--.--\ `. . __ * .&quot;&quot; &apos;&lt; `.___\_&lt;|&gt;_/___.&apos; &gt;&apos;&quot;&quot;. * | | : `- \`.;`\ _ /`;.`/ - ` : | | * \ \ `-. \_ __\ /__ _/ .-` / / * ======`-.____`-.___\_____/___.-`____.-&apos;====== * `=---=&apos; * ............................................. * 佛曰：bug泛滥，我已瘫痪！ */ 123456789101112131415161718192021222324252627282930313233/** * ,s555SB@@&amp; * :9H####@@@@@Xi * 1@@@@@@@@@@@@@@8 * ,8@@@@@@@@@B@@@@@@8 * :B@@@@X3hi8Bs;B@@@@@Ah, * ,8i r@@@B: 1S ,M@@@@@@#8; * 1AB35.i: X@@8 . SGhr ,A@@@@@@@@S * 1@h31MX8 18Hhh3i .i3r ,A@@@@@@@@@5 * ;@&amp;i,58r5 rGSS: :B@@@@@@@@@@A * 1#i . 9i hX. .: .5@@@@@@@@@@@1 * sG1, ,G53s. 9#Xi;hS5 3B@@@@@@@B1 * .h8h.,A@@@MXSs, #@H1: 3ssSSX@1 * s ,@@@@@@@@@@@@Xhi, r#@@X1s9M8 .GA981 * ,. rS8H#@@@@@@@@@@#HG51;. .h31i;9@r .8@@@@BS;i; * .19AXXXAB@@@@@@@@@@@@@@#MHXG893hrX#XGGXM@@@@@@@@@@MS * s@@MM@@@hsX#@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@&amp;, * :GB@#3G@@Brs ,1GM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@B, * .hM@@@#@@#MX 51 r;iSGAM@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@8 * :3B@@@@@@@@@@@&amp;9@h :Gs .;sSXH@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@: * s&amp;HA#@@@@@@@@@@@@@@M89A;.8S. ,r3@@@@@@@@@@@@@@@@@@@@@@@@@@@r * ,13B@@@@@@@@@@@@@@@@@@@5 5B3 ;. ;@@@@@@@@@@@@@@@@@@@@@@@@@@@i * 5#@@#&amp;@@@@@@@@@@@@@@@@@@9 .39: ;@@@@@@@@@@@@@@@@@@@@@@@@@@@; * 9@@@X:MM@@@@@@@@@@@@@@@#; ;31. H@@@@@@@@@@@@@@@@@@@@@@@@@@: * SH#@B9.rM@@@@@@@@@@@@@B :. 3@@@@@@@@@@@@@@@@@@@@@@@@@@5 * ,:. 9@@@@@@@@@@@#HB5 .M@@@@@@@@@@@@@@@@@@@@@@@@@B * ,ssirhSM@&amp;1;i19911i,. s@@@@@@@@@@@@@@@@@@@@@@@@@@S * ,,,rHAri1h1rh&amp;@#353Sh: 8@@@@@@@@@@@@@@@@@@@@@@@@@#: * .A3hH@#5S553&amp;@@#h i:i9S #@@@@@@@@@@@@@@@@@@@@@@@@@A. * * * */]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[显示器选择调查]]></title>
    <url>%2F2021%2F07%2F04%2F%E6%98%BE%E7%A4%BA%E5%99%A8%E9%80%89%E6%8B%A9%E8%B0%83%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[1. 品牌倾向 2. 价格区间 3. 参数选择 写在前面： 1. 品牌倾向护眼：明基2. 价格区间3. 参数选择 （1）是否高刷 （2）是否4k （3）]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BP神经网络学习]]></title>
    <url>%2F2021%2F06%2F11%2Fbp%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[1. BP网络是什么？ 2. 神经网络的基础架构 写在前面： 参考文章： https://zhuanlan.zhihu.com/p/40601434 1. BP网络是什么？BP(Back-propagation)，即反向传播。 反向传播的东西是：误差 就是在模拟过程中（这是一个循环，我们在训练神经网络的时候是要不断的去重复这个过程的）收集系统所产生的误差，并且返回这些误差到输出值，之后用这些误差来调整神经元的权重，这样生成一个可以模拟出原始问题的人工神经网络系统。 2. 神经网络的基础架构神经网络其实就是几层神经元，每层神经元里有几个神经元点。不同layer之间的神经元相互连接。其实就是如此：]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[错误Non-UTF-8 code starting with ‘\xe7‘解决办法]]></title>
    <url>%2F2021%2F05%2F19%2F%E9%94%99%E8%AF%AFNon-UTF-8%20code%20starting%20with%20%E2%80%98xe7%E2%80%98%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这个地方我们需要在首行添加# -- coding:utf-8 --一般我们没有添加这个的时候，书写中文就会跳出错误，只要写上就没有了]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之输出整个tensor的方法]]></title>
    <url>%2F2021%2F05%2F19%2FPytorch%E4%B9%8B%E8%BE%93%E5%87%BA%E6%95%B4%E4%B8%AAtensor%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. Pytorch：输出整个tensor的方法 参考文章： https://blog.csdn.net/qq_39355160/article/details/106208467 1. Pytorch：输出整个tensor的方法1234torch.set_printoptions(profile="full")print(x)torch.set_printoptions(profile="default")print(x) 1将这个代码放在import torch之后就可以了，full代表输出所有，deflaut是默认输出部分]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习中的范数规则化之（一）L0、L1与L2范数]]></title>
    <url>%2F2021%2F05%2F18%2F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%8C%83%E6%95%B0%E8%A7%84%E5%88%99%E5%8C%96%E4%B9%8B%EF%BC%88%E4%B8%80%EF%BC%89L0%E3%80%81L1%E4%B8%8EL2%E8%8C%83%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1.监督学习的基本模型 2.L0范数与L1范数 3.L2范数 参考文章： https://blog.csdn.net/bitcarmanlee/article/details/51932055 项目github地址：bitcarmanlee easy-algorithm-interview-and-practice欢迎大家star，留言，一起学习进步 1.监督学习的基本模型监督机器学习问题无非就是”minimizeyour error while regularizing your parameters”，也就是在规则化参数的同时最小化误差。最小化误差是为了让我们的模型拟合我们的训练数据，而规则化参数是防止我们的模型过分拟合我们的训练数据。多么简约的哲学啊！因为参数太多，会导致我们的模型复杂度上升，容易过拟合，也就是我们的训练误差会很小。但训练误差小并不是我们的最终目标，我们的目标是希望模型的测试误差小，也就是能准确的预测新的样本。所以，我们需要保证模型”简单”的基础上最小化训练误差，这样得到的参数才具有好的泛化性能（也就是测试误差也小），而模型”简单”就是通过规则函数来实现的。另外，规则项的使用还可以约束我们的模型的特性。这样就可以将人对这个模型的先验知识融入到模型的学习当中，强行地让学习到的模型具有人想要的特性，例如稀疏、低秩、平滑等等。要知道，有时候人的先验是非常重要的。前人的经验会让你少走很多弯路，这就是为什么我们平时学习最好找个大牛带带的原因。一句点拨可以为我们拨开眼前乌云，还我们一片晴空万里，醍醐灌顶。对机器学习也是一样，如果被我们人稍微点拨一下，它肯定能更快的学习相应的任务。只是由于人和机器的交流目前还没有那么直接的方法，目前这个媒介只能由规则项来担当了。 还有几种角度来看待规则化的。规则化符合奥卡姆剃刀(Occam’s razor)原理。这名字好霸气，razor！不过它的思想很平易近人：在所有可能选择的模型中，我们应该选择能够很好地解释已知数据并且十分简单的模型。从贝叶斯估计的角度来看，规则化项对应于模型的先验概率。民间还有个说法就是，规则化是结构风险最小化策略的实现，是在经验风险上加一个正则化项(regularizer)或惩罚项(penalty term)。 一般来说，监督学习可以看做最小化下面的目标函数： 其中，第一项L(yi,f(xi;w)) 衡量我们的模型（分类或者回归）对第i个样本的预测值f(xi;w)和真实的标签yi之前的误差。因为我们的模型是要拟合我们的训练样本的嘛，所以我们要求这一项最小，也就是要求我们的模型尽量的拟合我们的训练数据。但正如上面说言，我们不仅要保证训练误差最小，我们更希望我们的模型测试误差小，所以我们需要加上第二项，也就是对参数w的规则化函数Ω(w)去约束我们的模型尽量的简单。 OK，到这里，如果你在机器学习浴血奋战多年，你会发现，哎哟哟，机器学习的大部分带参模型都和这个不但形似，而且神似。是的，其实大部分无非就是变换这两项而已。对于第一项Loss函数，如果是Square loss，那就是最小二乘了；如果是Hinge Loss，那就是著名的SVM了；如果是exp-Loss，那就是牛逼的 Boosting了；如果是log-Loss，那就是Logistic Regression了；还有等等。不同的loss函数，具有不同的拟合特性，这个也得就具体问题具体分析的。但这里，我们先不究loss函数的问题，我们把目光转向”规则项Ω(w)”。 规则化函数Ω(w)也有很多种选择，一般是模型复杂度的单调递增函数，模型越复杂，规则化值就越大。比如，规则化项可以是模型参数向量的范数。然而，不同的选择对参数w的约束不同，取得的效果也不同，但我们在论文中常见的都聚集在：零范数、一范数、二范数、迹范数、Frobenius范数和核范数等等。这么多范数，到底它们表达啥意思？具有啥能力？什么时候才能用？什么时候需要用呢？不急不急，下面我们挑几个常见的娓娓道来。 2.L0范数与L1范数L0范数是指向量中非0的元素的个数。如果我们用L0范数来规则化一个参数矩阵W的话，就是希望W的大部分元素都是0。这太直观了，太露骨了吧，换句话说，让参数W是稀疏的。OK，看到了”稀疏”二字，大家都应该从当下风风火火的”压缩感知”和”稀疏编码”中醒悟过来，原来用的漫山遍野的”稀疏”就是通过这玩意来实现的。但你又开始怀疑了，是这样吗？看到的papers世界中，稀疏不是都通过L1范数来实现吗？脑海里是不是到处都是||W||1影子呀！几乎是抬头不见低头见。没错，这就是这节的题目把L0和L1放在一起的原因，因为他们有着某种不寻常的关系。那我们再来看看L1范数是什么？它为什么可以实现稀疏？为什么大家都用L1范数去实现稀疏，而不是L0范数呢？ L1范数是指向量中各个元素绝对值之和，也有个美称叫”稀疏规则算子”（Lasso regularization）。现在我们来分析下这个价值一个亿的问题：为什么L1范数会使权值稀疏？有人可能会这样给你回答”它是L0范数的最优凸近似”。实际上，还存在一个更美的回答：任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个”求和”的形式，那么这个规则化算子就可以实现稀疏。这说是这么说，W的L1范数是绝对值，|w|在w=0处是不可微，但这还是不够直观。这里因为我们需要和L2范数进行对比分析。所以关于L1范数的直观理解，请待会看看第二节。 对了，上面还有一个问题：既然L0可以实现稀疏，为什么不用L0，而要用L1呢？个人理解一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解。所以大家才把目光和万千宠爱转于L1范数。 OK，来个一句话总结：L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。 好，到这里，我们大概知道了L1可以实现稀疏，但我们会想呀，为什么要稀疏？让我们的参数稀疏有什么好处呢？这里扯两点： 1）特征选择(Feature Selection)：大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，xi的大部分元素（也就是特征）都是和最终的输出yi没有关系或者不提供任何信息的，在最小化目标函数的时候考虑xi这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确yi的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为0。 2）可解释性(Interpretability)：另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型：y=w1 x1+w2_x2+…+w1000 _x1000+b（当然了，为了让y限定在[0,1]的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的w就只有很少的非零元素，例如只有5个非零的wi，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果1000个wi都非0，医生面对这1000种因素，累觉不爱。 3.L2范数除了L1范数，还有一种更受宠幸的规则化范数是L2范数: ||W||2。它也不逊于L1范数，它有两个美称，在回归里面，有人把有它的回归叫”岭回归”（Ridge Regression），有人也叫它”权值衰减weight decay”。这用的很多吧，因为它的强大功效是改善机器学习里面一个非常重要的问题：过拟合。至于过拟合是什么，上面也解释了，就是模型训练时候的误差很小，但在测试的时候误差很大，也就是我们的模型复杂到可以拟合到我们的所有训练样本了，但在实际预测新的样本的时候，糟糕的一塌糊涂。通俗的讲就是应试能力很强，实际应用能力很差。擅长背诵知识，却不懂得灵活利用知识。例如下图所示（来自Ng的course）： 上面的图是线性回归，下面的图是Logistic回归，也可以说是分类的情况。从左到右分别是欠拟合（underfitting，也称High-bias）、合适的拟合和过拟合（overfitting，也称High variance）三种情况。可以看到，如果模型复杂（可以拟合任意的复杂函数），它可以让我们的模型拟合所有的数据点，也就是基本上没有误差。对于回归来说，就是我们的函数曲线通过了所有的数据点，如上图右。对分类来说，就是我们的函数曲线要把所有的数据点都分类正确，如下图右。这两种情况很明显过拟合了。 OK，那现在到我们非常关键的问题了，为什么L2范数可以防止过拟合？回答这个问题之前，我们得先看看L2范数是个什么东西。 L2范数是指向量各元素的平方和然后求平方根。我们让L2范数的规则项||W||2最小，可以使得W的每个元素都很小，都接近于0，但与L1范数不同，它不会让它等于0，而是接近于0，这里是有很大的区别的哦。而越小的参数说明模型越简单，越简单的模型则越不容易产生过拟合现象。为什么越小的参数说明模型越简单？我也不懂，我的理解是：限制了参数很小，实际上就限制了多项式某些分量的影响很小（看上面线性回归的模型的那个拟合的图），这样就相当于减少参数个数。其实我也不太懂，希望大家可以指点下。 这里也一句话总结下：通过L2范数，我们可以实现了对模型空间的限制，从而在一定程度上避免了过拟合。 L2范数的好处是什么呢？这里也扯上两点：1）学习理论的角度：从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力。2）优化计算的角度：从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。哎，等等，这condition number是啥？我先google一下哈。 这里我们也故作高雅的来聊聊优化问题。优化有两大难题，一是：局部最小值，二是：ill-condition病态问题。前者俺就不说了，大家都懂吧，我们要找的是全局最小值，如果局部最小值太多，那我们的优化算法就很容易陷入局部最小而不能自拔，这很明显不是观众愿意看到的剧情。那下面我们来聊聊ill-condition。ill-condition对应的是well-condition。那他们分别代表什么？假设我们有个方程组AX=b，我们需要求解X。如果A或者b稍微的改变，会使得X的解发生很大的改变，那么这个方程组系统就是ill-condition的，反之就是well-condition的。我们具体举个例子吧： 咱们先看左边的那个。第一行假设是我们的AX=b，第二行我们稍微改变下b，得到的x和没改变前的差别很大，看到吧。第三行我们稍微改变下系数矩阵A，可以看到结果的变化也很大。换句话来说，这个系统的解对系数矩阵A或者b太敏感了。又因为一般我们的系数矩阵A和b是从实验数据里面估计得到的，所以它是存在误差的，如果我们的系统对这个误差是可以容忍的就还好，但系统对这个误差太敏感了，以至于我们的解的误差更大，那这个解就太不靠谱了。所以这个方程组系统就是ill-conditioned病态的，不正常的，不稳定的，有问题的，哈哈。这清楚了吧。右边那个就叫well-condition的系统了。 还是再啰嗦一下吧，对于一个ill-condition的系统，我的输入稍微改变下，输出就发生很大的改变，这不好啊，这表明我们的系统不能实用啊。你想想看，例如对于一个回归问题y=f(x)，我们是用训练样本x去训练模型f，使得y尽量输出我们期待的值，例如0。那假如我们遇到一个样本x’，这个样本和训练样本x差别很小，面对他，系统本应该输出和上面的y差不多的值的，例如0.00001，最后却给我输出了一个0.9999，这很明显不对呀。就好像，你很熟悉的一个人脸上长了个青春痘，你就不认识他了，那你大脑就太差劲了，哈哈。所以如果一个系统是ill-conditioned病态的，我们就会对它的结果产生怀疑。那到底要相信它多少呢？我们得找个标准来衡量吧，因为有些系统的病没那么重，它的结果还是可以相信的，不能一刀切吧。终于回来了，上面的condition number就是拿来衡量ill-condition系统的可信度的。condition number衡量的是输入发生微小变化的时候，输出会发生多大的变化。也就是系统对微小变化的敏感度。condition number值小的就是well-conditioned的，大的就是ill-conditioned的。 如果方阵A是非奇异的，那么A的conditionnumber定义为： 也就是矩阵A的norm乘以它的逆的norm。所以具体的值是多少，就要看你选择的norm是什么了。如果方阵A是奇异的，那么A的condition number就是正无穷大了。实际上，每一个可逆方阵都存在一个condition number。但如果要计算它，我们需要先知道这个方阵的norm（范数）和Machine Epsilon（机器的精度）。为什么要范数？范数就相当于衡量一个矩阵的大小，我们知道矩阵是没有大小的，当上面不是要衡量一个矩阵A或者向量b变化的时候，我们的解x变化的大小吗？所以肯定得要有一个东西来度量矩阵和向量的大小吧？对了，他就是范数，表示矩阵大小或者向量长度。OK，经过比较简单的证明，对于AX=b，我们可以得到以下的结论： 也就是我们的解x的相对变化和A或者b的相对变化是有像上面那样的关系的，其中k(A)的值就相当于倍率，看到了吗？相当于x变化的界。 对condition number来个一句话总结：conditionnumber是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，如果一个矩阵的condition number在1附近，那么它就是well-conditioned的，如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的，它的输出结果就不要太相信了。 好了，对这么一个东西，已经说了好多了。对了，我们为什么聊到这个的了？回到第一句话：从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题。因为目标函数如果是二次的，对于线性回归来说，那实际上是有解析解的，求导并令导数等于零即可得到最优解为： 然而，如果当我们的样本X的数目比每个样本的维度还要小的时候，矩阵XTX将会不是满秩的，也就是XTX会变得不可逆，所以w*就没办法直接计算出来了。或者更确切地说，将会有无穷多个解（因为我们方程组的个数小于未知数的个数）。也就是说，我们的数据不足以确定一个解，如果我们从所有可行解里随机选一个的话，很可能并不是真正好的解，总而言之，我们过拟合了。 但如果加上L2规则项，就变成了下面这种情况，就可以直接求逆了： 这里面，专业点的描述是：要得到这个解，我们通常并不直接求矩阵的逆，而是通过解线性方程组的方式（例如高斯消元法）来计算。考虑没有规则项的时候，也就是λ=0的情况，如果矩阵XTX的 condition number 很大的话，解线性方程组就会在数值上相当不稳定，而这个规则项的引入则可以改善condition number。 另外，如果使用迭代优化的算法，condition number 太大仍然会导致问题：它会拖慢迭代的收敛速度，而规则项从优化的角度来看，实际上是将目标函数变成λ-strongly convex（λ强凸）的了。哎哟哟，这里又出现个λ强凸，啥叫λ强凸呢？ 当f满足： 时，我们称f为λ-stronglyconvex函数，其中参数λ&gt;0。当λ=0时退回到普通convex 函数的定义。 在直观的说明强凸之前，我们先看看普通的凸是怎样的。假设我们让f在x的地方做一阶泰勒近似（一阶泰勒展开忘了吗？f(x)=f(a)+f’(a)(x-a)+o(||x-a||).）： 直观来讲，convex 性质是指函数曲线位于该点处的切线，也就是线性近似之上，而 strongly convex 则进一步要求位于该处的一个二次函数上方，也就是说要求函数不要太”平坦”而是可以保证有一定的”向上弯曲”的趋势。专业点说，就是convex 可以保证函数在任意一点都处于它的一阶泰勒函数之上，而strongly convex可以保证函数在任意一点都存在一个非常漂亮的二次下界quadratic lower bound。当然这是一个很强的假设，但是同时也是非常重要的假设。可能还不好理解，那我们画个图来形象的理解下 大家一看到上面这个图就全明白了吧。不用我啰嗦了吧。还是啰嗦一下吧。我们取我们的最优解w 的地方。如果我们的函数f(w)，见左图，也就是红色那个函数，都会位于蓝色虚线的那根二次函数之上，这样就算wt和w离的比较近的时候，f(wt)和f(w)的值差别还是挺大的，也就是会保证在我们的最优解w 附近的时候，还存在较大的梯度值，这样我们才可以在比较少的迭代次数内达到w。但对于右图，红色的函数f(w)只约束在一个线性的蓝色虚线之上，假设是如右图的很不幸的情况（非常平坦），那在wt还离我们的最优点w 很远的时候，我们的近似梯度(f(wt)-f(w))/(wt-w)就已经非常小了，在wt处的近似梯度∂f/∂w就更小了，这样通过梯度下降wt+1=wt-α(∂f/∂w)，我们得到的结果就是w的变化非常缓慢，像蜗牛一样，非常缓慢的向我们的最优点w爬动，那在有限的迭代时间内，它离我们的最优点还是很远。 所以仅仅靠convex 性质并不能保证在梯度下降和有限的迭代次数的情况下得到的点w会是一个比较好的全局最小点w 的近似点（插个话，有地方说，实际上让迭代在接近最优的地方停止，也是一种规则化或者提高泛化性能的方法）。正如上面分析的那样，如果f(w)在全局最小点w周围是非常平坦的情况的话，我们有可能会找到一个很远的点。但如果我们有”强凸”的话，就能对情况做一些控制，我们就可以得到一个更好的近似解。至于有多好嘛，这里面有一个bound，这个 bound 的好坏也要取决于strongly convex性质中的常数α的大小。看到这里，不知道大家学聪明了没有。如果要获得strongly convex怎么做？最简单的就是往里面加入一项(α/2)*||w||2。 呃，讲个strongly convex花了那么多的篇幅。实际上，在梯度下降中，目标函数收敛速率的上界实际上是和矩阵XTX的 condition number有关，XTX的 condition number 越小，上界就越小，也就是收敛速度会越快。 这一个优化说了那么多的东西。还是来个一句话总结吧：L2范数不但可以防止过拟合，还可以让我们的优化求解变得稳定和快速。 好了，这里兑现上面的承诺，来直观的聊聊L1和L2的差别，为什么一个让绝对值最小，一个让平方最小，会有那么大的差别呢？我看到的有两种几何上直观的解析： 1）下降速度： 我们知道，L1和L2都是规则化的方式，我们将权值参数以L1或者L2的方式放到代价函数里面去。然后模型就会尝试去最小化这些权值参数。而这个最小化就像一个下坡的过程，L1和L2的差别就在于这个”坡”不同，如下图：L1就是按绝对值函数的”坡”下降的，而L2是按二次函数的”坡”下降。所以实际上在0附近，L1的下降速度比L2的下降速度要快。所以会非常快得降到0。不过我觉得这里解释的不太中肯，当然了也不知道是不是自己理解的问题。 L1在江湖上人称Lasso，L2人称Ridge。不过这两个名字还挺让人迷糊的，看上面的图片，Lasso的图看起来就像ridge，而ridge的图看起来就像lasso。 2）模型空间的限制： 实际上，对于L1和L2规则化的代价函数来说，我们可以写成以下形式： 也就是说，我们将模型空间限制在w的一个L1-ball 中。为了便于可视化，我们考虑两维的情况，在(w1, w2)平面上可以画出目标函数的等高线，而约束条件则成为平面上半径为C的一个 norm ball 。等高线与 norm ball 首次相交的地方就是最优解： 可以看到，L1-ball 与L2-ball 的不同就在于L1在和每个坐标轴相交的地方都有”角”出现，而目标函数的测地线除非位置摆得非常好，大部分时候都会在角的地方相交。注意到在角的位置就会产生稀疏性，例如图中的相交点就有w1=0，而更高维的时候（想象一下三维的L1-ball 是什么样的？）除了角点以外，还有很多边的轮廓也是既有很大的概率成为第一次相交的地方，又会产生稀疏性。 相比之下，L2-ball 就没有这样的性质，因为没有角，所以第一次相交的地方出现在具有稀疏性的位置的概率就变得非常小了。这就从直观上来解释了为什么L1-regularization 能产生稀疏性，而L2-regularization 不行的原因了。 因此，一句话总结就是：L1会趋向于产生少量的特征，而其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。Lasso在特征选择时候非常有用，而Ridge就只是一种规则化而已。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[黑箱方法文本对抗样本生成]]></title>
    <url>%2F2021%2F05%2F17%2F%E9%BB%91%E7%AE%B1%E6%96%B9%E6%B3%95%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%2F</url>
    <content type="text"><![CDATA[1. 介绍 2. DeepWordBug算法 参考文章： https://zhuanlan.zhihu.com/p/113930556 摘要：论文旨在进行黑箱场景下的文本对抗样本生成。制定了一个新的打分策略以评估句子中的各个单词的重要性，再将最重要的单词进行字母级别的改变，进而在改变最小的情况下生成对抗样本。在垃圾邮件分类和IMDB影评分类的任务上使用了此方法，准确率分别从99%和87%降到了40%和26%。 1. 介绍对这一问题进行形式化定义，即在添加较小扰动的条件下让分类器分类错误。 在这一大问题下，还有一些细分的问题。比如扰动的大小、是否让分类器犯特定类型的错误、黑箱或白箱的选择。 文本与图像不同，不能使用范数衡量改变大小，文本中句子也不等长，对于扰动的大小难以衡量。 贡献：提出了DeepWordBug算法，可在黑箱条件下生成简单高效的轻微扰动。 2. DeepWordBug算法A. 循环神经网络 通过迭代结构处理序列数据，LSTM解决了梯度消失的问题。 B. 基于单词修改的对抗序列 一个单词序列可供更改的备选太多了，所以需要一个评分函数，找出序列中最为重要的单词。总共分为两步：第一步是使用评分函数确认序列中单词的重要程度，第二步是使用修改算法改变被选中的词。 C. 第一步：单词评分函数和排序 方法优点：黑箱状态下可迅速计算出各个单词对于序列预测结果的影响程度。 1) 时序评分 白箱状态下，可以根据模型的参数进行求导，即可对单词重要性评分了。黑箱状态下，只能根据去掉一个单词后分类器结果的差异来确定一个单词的重要性，公式如下。 2) 时序尾部分 时序评分的问题在于忽略了所删除单词的后续词的影响，所以增加了一个尾部时序评分，公式如下。 3) 综合得分 可以综合两种得分，使用一个超参数平衡两者，得到一个综合分数。得到了综合分数，就能筛选出句子中最重要的前m个单词，来生成对抗样本。 D. 第二步：单词修改器 从前的工作有梯度方向的指示，而在黑箱环境中，论文选择使用制造拼写错误的单词来进行攻击。 文本分类器都是存在着”词典”的，”词典”是一个有限的集合，其大小远小于字母的排列组合情况。如果我们将序列中的重要单词进行错误拼写的话，模型会将这些词视为”unknown”。模型对于缺失了重要单词的序列是很容易判断失误的。 四种改变单词的方式：(1)使用随机字母进行替换。(2)随机删除一个字母。(3)在单词中插入一个随机字母。(4)交换两个临近字母。替换、删除、插入操作的编辑距离为1，交换操作的编辑距离为2。 当然，这样的方法不可能完全避免一个单词被改变成为另一个单词，但因为词典的稀疏性，这样的碰撞概率不大。 整体算法如下图所示。 对抗序列有效性实验 在两个NLP数据集上实验提出的算法，主要研究两个问题：使用了对抗样本后深度学习准确率是否下降？模型生成的对抗样本能够在不同分类器间通用吗？ A. 实验设置 数据集：影评数据集IMDB和安然垃圾邮件分类数据集。 目标深度模型：在单向和双向长短期记忆网络上都做了实验， 基线：实现下列攻击算法来生成对抗样本。 Projected FGSM——快速梯度符号法，属于白盒攻击。 Random + DeepWordBug Transformer——随机寻找单词，并攻击该单词。 论文方法：使用评分函数对句子中的每个单词进行评分，对分数较高的单词进行攻击。 平台：使用Keras框架和Titan显卡。 表现：攻击方法是由模型的准确率变化来决定的，可修改的单词数上限是个超参数。 B. 分类的实验结果 使用了综合两种评分方式和进行单词修改的方法取得了最好的效果，可见对于重点词的寻找和对重点词的攻击都很重要。 C. 对抗序列的可传递性 论文方法所创造出的的对抗样本在各个文本分类器中的泛化情况。 从表中可以看出，同样的对抗样本在不同的分类器中，都取得了一定效果，即使不同的分类器有不同的嵌入层。 与过去研究的联系曾经的种种研究： (1) 随机选择句子中的一个单词，然后使用梯度方法对该单词向量加以扰动，再寻找到嵌入层与该单词最接近的单词进行替换。 (2) 根据梯度计算出序列中的重要单词，使用同义词、错拼词为单词建立备选词库，使用备选词库替换重要词。 (3) 根据单词在某一类别中的比例来确定单词的重要性，再使用启发式方法对重要单词来进行增删改的操作。 总的来说，曾经的方法未处于黑箱场景，且主要使用启发式方法。论文在黑箱环境下使用了较为简单的解决方法。 结论 论文在黑箱环境下提出了优于从前方法性能的方法，对抗样本与原样本的编辑距离小，且具备传递性。 参考文献 Gao J, Lanchantin J, Soffa M L, et al. Black-Box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers[C]. ieee symposium on security and privacy, 2018: 50-56.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FGPM：文本对抗样本生成新方法]]></title>
    <url>%2F2021%2F05%2F17%2FFGPM%EF%BC%9A%E6%96%87%E6%9C%AC%E5%AF%B9%E6%8A%97%E6%A0%B7%E6%9C%AC%E7%94%9F%E6%88%90%E6%96%B0%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 引言 2. 当前文本对抗样本的研究 3. 核心思想 4. 模型介绍 4.1 文本对抗样本 4.2 对抗样本的生成 5. FGPM的对抗训练 6. 实验结果 6.1 数据集 6.2 对抗攻击有效性评估 参考文章： https://blog.csdn.net/c9Yv2cf9I06K2A9E/article/details/108806253 论文标题： Fast Gradient Projection Method for Text Adversary Generation and Adversarial Training 论文链接： https://arxiv.org/abs/2008.03709 1. 引言本文是关于文本类对抗样本的生成的文章。要清楚的是 由于图片和文本数据内在的不同，用于图像的对抗攻击方法无法直接应用于文本数据上。 首先图像数据是连续的（准确地说是近似连续，因为图像像素值是 0 到 255 的整数值，但是如果输出的像素值是浮点数可以进行取整操作）， 但文本数据是离散的（比如有一个 one-hot 编码为 000001 表示的”道”字，那么编码 000010 表示的字与道字不存在连续性）。 这也就是为什么当前文本生成图像整体的生成质量普遍不高的原因，因为不能很好地将图像的连续空间与文本的离散空间统一起来。 其次， 仅仅对像素值进行微小的改变就可以造成图像数据的扰动，而且这种扰动是很难被人眼察觉的。但是对于文本的对抗攻击中，小的扰动很容易被察觉，但人类同样能猜出本来表达的意义。 因此 NLP 模型需要对可辨识的特征鲁棒，而不像视觉只需要对不太重要的特征鲁棒。现有的文本攻击方法虽然有效，但还不足以应用于实际的文本对抗训练中，本文提出了一种 基于同义词替换的快速梯度投影方法（FGPM），我对 FGPM 方法进行详细解读。 2. 当前文本对抗样本的研究引言中已经提及到在文本域中，词法、语法和语义的约束以及离散的输入空间使得文本对抗样本的生成变得更加困难。目前的攻击方法包括字符级攻击，单词级攻击还有句子级攻击。为了方便查阅我对这些文章进行了汇总具体如下所示：字符级的攻击论文有： 论文标题： Deep Text Classification Can be Fooled 论文链接： https://www.ijcai.org/Proceedings/2018/0585.pdf 论文标题： TextBugger: Generating Adversarial Text Against Real-world Applications 论文链接： https://arxiv.org/abs/1812.05271 论文标题： HotFlip: White-Box Adversarial Examples for Text Classification 论文链接： https://www.aclweb.org/anthology/P18-2006.pdf 单词级的攻击论文有： 论文标题： Crafting Adversarial Input Sequences for Recurrent Neural Networks 论文链接： https://arxiv.org/abs/1604.08275 论文标题： Towards Crafting Text Adversarial Samples 论文链接： https://arxiv.org/abs/1707.02812 论文标题： Adversarial Texts with Gradient Methods 论文链接： https://arxiv.org/abs/1801.07175 论文标题： Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples 论文链接： https://arxiv.org/abs/1803.01128 句子级别的攻击论文有： 论文标题： Adversarial Example Generation with Syntactically Controlled Paraphrase Networks 论文链接： https://www.aclweb.org/anthology/N18-1170/ 论文标题： Semantically Equivalent Adversarial Rules for Debugging NLP models 论文链接： https://www.aclweb.org/anthology/P18-1079/ 最近的研究表明，对于字符级的攻击，拼写检查器可以很容易地修复干扰。对于单词级别的攻击，HotFlip 虽然可以进行攻击，但是由于句法和语义的限制，无法生成大量的对抗样本。 对于句子级别的攻击，通常是基于转述这样会使得对手生成需要更长的时间。综上所述，文本类的攻击要么面临基于梯度的扰动的语义保持质量的挑战，要么是基于查询的同义词替换的高计算量的成本。 3. 核心思想该论文中作者提出了一种基于同义词替换的快速梯度投影方法（FGPM），该方法根据梯度大小和原单词与候选单词在梯度方向上的投影距离的乘积来计算每个替换的得分。 FGPM 具有一定的攻击性能和可转移性，同时比目前最快的文本攻击方法快 20 倍左右（时间上的统计）。作者还将通过 FGPM 生成的对抗样本与对抗训练结合起来作为一种模型防御的手段，并扩展到大型神经网络和数据集。 4. 模型介绍论文作者形式化地定义了用于文本分类的对抗样本，并详细描述了所提出的对抗性攻击方法快速梯度投影法（FGPM）。 4.1 文本对抗样本设 表示包含所有可能输入文本的空间， 表示输出空间。设 表示由 个单词组成的输入样本， 是包含输入文本中所有可能单词的字典。分类器 学习一个映射 ，使得对于任何一个样本 ，预测的标签为 。 设 表示类别 上分类器 的 logit 输出。攻击方在 上添加一个不可察觉的扰动 ，目的是生成误导分类器 的对抗样本 ，具体的优化形式如下所示： 其中， 是表示扰动上界的超参数。 是 范数距离度量，其通常表示单词替换率 ，作为同义词替换引起的扰动的度量如下所示： 其中， 是一个指示函数， ， 。 4.2 对抗样本的生成现已有研究表明反拟合可以帮助去除原 glove 词向量空间中也被视为”相似词”的反义词，提高向量表示语义相似性的能力。在该论文中作者通过反拟合对 glove 词向量进行处理，并在嵌入空间中为每个单词 定义一个同义词集，如下所示： 其中 是一个超参数，它限制了嵌入空间中同义词的最大欧式距离。作者得到了每个单词 的同义词集 ，本文中需要解决的最重要的问题就是同义词的选择和替换顺序的确定。 如下图所示，对于每个单词 ，选择一个单词 ，它对整个替换过程最为有利，论文中称其为最优同义词。由于寻找最佳同义词的很费劲，以往的研究是通过贪婪地选取一个同义词 ，使分类置信度最小化： 其中 。选择过程是非常耗时的，为了降低基于深度模型的计算复杂度，本文作者利用梯度的大小与词嵌入空间中两个同义词在梯度方向上的投影距离的乘积来估计变化量，从而得到分类置信度。 具体如下图所示，首先计算每个单词 的梯度 ，然后通过计算 来估计变化量，并确定最优同义词 ，具体的公式如下所示： 对于在文本 每个单词 ，作者使用上面的词替换策略选择其最优替代同义词，并获得一组候选集 。 之后需要确定应该替换文本 中的哪个单词。类似于这个词替换策略，最大的扰动值投影梯度的公式为： 为了方便理解，我将原论文的算法框架图重新进行了整理如下图所示，为了生成一个文本对抗样本，作者采用了同义词替换和替换顺序策略迭代地进行单词替换，直到分类器做出错误的预测。 为了避免在同一文本位置多次替换所造成的语义偏移，作者为原句子构造了一个候选同义词集，并将所有的替换词 约束到该集合中，算法中还设置了单词替换率的上限，在每次迭代中，FGPM 只通过反向传播计算一次梯度。 5. FGPM的对抗训练以前的研究已经表明将对抗样本纳入对抗训练可以提高模型的鲁棒性。但是这种改进是有限的。对抗性训练需要大量基于当前模型参数生成的对抗性样本才能更好地增强鲁棒性。 由于文本对抗样本生成效率低下，现有的基于同义词替换的文本攻击方法无法为对抗性训练提供足够的样本。鉴于 FGPM 的高效性，作者采用 FGPM 的对抗性训练来有效地提高文本分类的模型鲁棒性。具体的对抗训练的目标函数如下： 其中 是 FGPM 基于当前模型参数 生成的对抗样本。 6. 实验结果作者用四种对抗性攻击方法，在三个涉及三个不同神经网络的基准数据集上对所提出的 FGPM 进行了实证评估。实验中由于攻击基线的效率较低，在每个数据集中随机抽取 200 个实例，并根据这些攻击方法针对不同的模型生成对抗样本。 6.1 数据集本文的数据集为三个广泛使用的基准数据集分别是 AG’s News、DBPediaontology 和 Yahoo Answers。AG’s News 数据集由世界、体育、商业和科技四个类别的新闻文章组成，每个类别包括 30000 个训练样本和 1900 个测试示样本。 DBPedia 数据集是通过从 dbpedia2014 中挑选 14 个不重叠的类来构建的，DBPedia 是一个众包社区努力从 Wikipedia 中提取结构化信息。Yahoo Answers 是一个包含 10 个类的主题分类数据集，每个类包含 14 万个训练样本和 5000 个测试样本。 6.2 对抗攻击有效性评估为了评估攻击的有效性，作者从攻击下的模型分类精度和可转移性两个方面与基线算法进行比较。如下表所示，作者给出了 FGPM 下的分类精度和三个标准数据集的基线攻击。 攻击方法越有效，目标模型的分类精度越低。可以观察到 FGPM 比其他基于 DBPedia 数据集的 CNN 分类方法降低了更多的分类准确率，说明所提出的梯度投影技术显著提高了白盒攻击的有效性。 对抗样本的可迁移性是指通过在特定模型上生成对抗样本来降低不同模型的分类精度的能力，这是现实世界应用中的另一个严重威胁。为了说明 FGPM 的可转移性，作者在每种模型上通过不同的攻击方法和在这些对抗样本上评估其他模型的分类精度。如下表所示，FGPM 生成的对抗样本通常产生次优的可迁移性性。 文本对抗样本中攻击效率对于评估攻击方法也很重要，尤其是当将攻击作为一种防御方法纳入对抗训练时。对抗训练需要高效训练才能有效地提高模型的鲁棒性。 如下表所示，FGPM 生成 200 个对抗样本的平均时间是 GSA 的近 20 倍，是基于同义词替换的第二快攻击，但 GSA 攻击性能比 FGPM 差，可传迁移也较低。FGPM 平均比 IGA 快 970 倍，IGA 对分类精度的影响最大，综合来说，FGPM 在攻击效果和时间消耗都是可观的。 如下表所示。对于常规训练，在不同的对抗性攻击下，模型在所有数据集上的分类精度都会急剧下降。相比之下，SEM 和 TF 都能稳定有效地提高模型在所有模型和数据集中的鲁棒性。 一个好的防御方法不仅要防御对抗性攻击，还要抵抗对抗性可迁移性。为了评估各模型对敌方示例可转移性的阻断能力，作者在 DBPedia 上正常训练的情况下，对不同攻击方法生成的对抗样本进行分类精度评估。如下表所示，TF 比常规训练和防御基准算法更成功地阻止了对抗样本的可迁移性。 更多阅读]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BiLSTM-Attention-Based]]></title>
    <url>%2F2021%2F05%2F17%2FBiLSTM-Attention-Based%2F</url>
    <content type="text"><![CDATA[1. 概述 2. 算法思想 2.1 算法的组成部分 2.2. BiLSTM层的输出 2.3. Attention机制 2.4. 分类 参考文献 参考文章： https://blog.csdn.net/google19890102/article/details/94412928 1. 概述随着神经网络，尤其是深度学习算法的发展，神经网络在文本分类任务中取得了很大的发展，提出了各种解决方案，如CNN在文本分类中的应用，RNN，LSTM等等，相比较于CNN以及RNN方法，LSTM可以学习长距离的语义信息。Attention-Based BiLSTM结合双向的LSTM（Bidirectional LSTM）以及Attention机制处理文本分类的相关问题，通过attention机制，该方法可以聚焦到最重要的词，从而捕获到句子中最重要的语义信息。 2. 算法思想2.1 算法的组成部分Attention-Based BiLSTM算法的网络结构如下所示：在Attention-Based BiLSTM网络中，主要由5个部分组成： 输入层（Input layer）：指的是输入的句子，对于中文，指的是对句子分好的词； Embedding层：将句子中的每一个词映射成固定长度的向量； LSTM层：利用双向的LSTM对embedding向量计算，实际上是双向LSTM通过对词向量的计算，从而得到更高级别的句子的向量； Attention层：对双向LSTM的结果使用Attention加权； 输出层（Output layer）：输出层，输出具体的结果。 注意点： Embedding通常有两种处理方法，一个是静态embedding，即通过事先训练好的词向量，另一种是动态embedding，即伴随着网络一起训练； 双向LSTM的网络结构会在其他的文章中做进一步的介绍，这里就不详细展开。 2.2. BiLSTM层的输出假设句子通过分词算法后，得到的 T 个词为：{ $x_1, x_2 , ⋯ , x_T$}，每一个词 $x_i$ ​经过词向量的映射得到对应的词向量 $e_i$ ​，假设经过LSTM后正向的输出为 $\overrightarrow{h_i}$，逆向的输出为 $\overleftarrow{h_i}$，则第 i 个词经过BiLSTM后得到的向量为： $h{i}=\left[\overrightarrow{h{i}} \bigoplus \overleftarrow{h_{i}}\right]$ 式中 $\bigoplus$ 表示对应元素相加。 2.3. Attention机制假设 H 是所有 $T_w$个词经过BiLSTM后得到的向量的集合：[$h_1, h_2 , \cdot\cdot\cdot , h_T$]，那么Attention的的结果由公式求得： $M = tanh(H) \text{，} H \in R^{d^w \times T}$$\alpha = softmax(w^T M)$$r = H\alpha^T$$h^{\ast}=tanh(r)$ 式中 $d^w$ 表示向量的维度；$w^T$ 表示需要学习的参数。 2.4. 分类针对句子 S，通过上述的BiLSTM以及Attention机制，得到了对应的表示矩阵：$h^{\ast}$，其维度为$d^w\times 1$。分类器以$h^{\ast}$为输入： $\hat{p}(y \mid S)=\operatorname{softmax}\left(W^{(S)} h^{*}+b^{(S)}\right)$ 参考文献 Attention-Based Bidirectional Long Short-Term Memory Networks for Relation Classification Understanding LSTM Networks]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>文本分类模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TextCNN原理详解]]></title>
    <url>%2F2021%2F05%2F17%2FTextCNN%E5%8E%9F%E7%90%86%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[1. TextCNN 是什么 2. TextCNN 的优势 3. TextCNN 的流程 4. TextCNN 的总结 参考文章： https://www.cnblogs.com/ModifyRong/p/11319301.html 今天主要讲TextCNN的基本原理和优劣势，包括网络结构、如何更新参数以及应用场景等。 1. TextCNN 是什么我们之前提前CNN时，通常会认为是属于CV领域，用于计算机视觉方向的工作，但是在2014年，Yoon Kim针对CNN的输入层做了一些变形，提出了文本分类模型textCNN。与传统图像的CNN网络相比, textCNN 在网络结构上没有任何变化(甚至更加简单了), 从图一可以看出textCNN 其实只有一层卷积,一层max-pooling, 最后将输出外接softmax 来n分类。 与图像当中CNN的网络相比，textCNN 最大的不同便是在输入数据的不同： 图像是二维数据, 图像的卷积核是从左到右, 从上到下进行滑动来进行特征抽取。 自然语言是一维数据, 虽然经过word-embedding 生成了二维向量，但是对词向量做从左到右滑动来进行卷积没有意义. 比如 “今天” 对应的向量[0, 0, 0, 0, 1], 按窗口大小为 1* 2 从左到右滑动得到[0,0], [0,0], [0,0], [0, 1]这四个向量, 对应的都是”今天”这个词汇, 这种滑动没有帮助. TextCNN的成功, 不是网络结构的成功, 而是通过引入已经训练好的词向量来在多个数据集上达到了超越benchmark 的表现，进一步证明了构造更好的embedding, 是提升nlp 各项任务的关键能力。 2. TextCNN 的优势 TextCNN最大优势 网络结构简单 ,在模型网络结构如此简单的情况下，通过引入已经训练好的词向量依旧有很不错的效果，在多项数据数据集上超越benchmark。 网络结构简单导致 参数数目少, 计算量少, 训练速度快，在单机单卡的v100机器上，训练165万数据, 迭代26万步，半个小时左右可以收敛。 3. TextCNN 的流程1.Word Embedding 分词构建词向量 如图二所示, textCNN 首先将 “今天天气很好,出来玩” 分词成”今天/天气/很好/，/出来/玩, 通过word2vec或者GLOV 等embedding 方式将每个词成映射成一个5维(维数可以自己指定)词向量, 如 “今天” -&gt; [0,0,0,0,1], “天气” -&gt;[0,0,0,1,0], “很好” -&gt;[0,0,1,0,0]等等。 这样做的好处主要是将自然语言数值化，方便后续的处理。从这里也可以看出不同的映射方式对最后的结果是会产生巨大的影响, nlp 当中目前最火热的研究方向便是如何将自然语言映射成更好的词向量。我们构建完词向量后，将所有的词向量拼接起来构成一个6*5的二维矩阵，作为最初的输入 2. Convolution 卷积 卷积是一种数学算子。我们用一个简单的例子来说明一下 step.1将 “今天”/“天气”/“很好”/“,” 对应的4*5 矩阵 与卷积核做一个point wise 的乘法然后求和, 便是卷积操作： feature_map[0] =01 + 00 + 01 + 00 + 1*0 + //(第一行) 00 + 00 + 00 + 10 + 0*0 + //(第二行) 01 + 00 + 11 + 00 + 0*0 + //(第三行) 01 + 10 + 01 + 00 + 0*0 //(第四行) = 1 step.2将窗口向下滑动一格(滑动的距离可以自己设置),”天气”/“很好”/“,”/“出来” 对应的4*5 矩阵 与卷积核(权值不变) 继续做point wise 乘法后求和 feature_map[1] = 01 + 00 + 01 + 10 + 0*0 + //(第一行) 00 + 00 + 10 + 00 + 0*0 + //(第二行) 01 + 10 + 01 + 00 + 0*0 + //(第三行) 11 + 00 + 01 + 00 + 0*0 //(第四行) = 1 step.3将窗口向下滑动一格(滑动的距离可以自己设置) “很好”/“,”/“出来”/“玩” 对应的4*5 矩阵 与卷积核(权值不变) 继续做point wise 乘法后求和 feature_map[2] = 01 + 00 + 11 + 10 + 0*0 + //(第一行) 00 + 10 + 00 + 00 + 0*0 + //(第二行) 11 + 00 + 01 + 00 + 0*0 + //(第三行) 01 + 00 + 01 + 10 + 1*0 //(第四行) = 2 feature_map 便是卷积之后的输出, 通过卷积操作 将输入的65 矩阵映射成一个 31 的矩阵，这个映射过程和特征抽取的结果很像，于是便将最后的输出称作feature map。一般来说在卷积之后会跟一个激活函数，在这里为了简化说明需要，我们将激活函数设置为f(x) = x 关于channel 的说明 在CNN 中常常会提到一个词channel, 图三 中 深红矩阵与 浅红矩阵 便构成了两个channel 统称一个卷积核, 从这个图中也可以看出每个channel 不必严格一样, 每个4*5 矩阵与输入矩阵做一次卷积操作得到一个feature map. 在计算机视觉中，由于彩色图像存在 R, G, B 三种颜色, 每个颜色便代表一种channel。 根据原论文作者的描述, 一开始引入channel 是希望防止过拟合(通过保证学习到的vectors 不要偏离输入太多)来在小数据集合获得比单channel更好的表现，后来发现其实直接使用正则化效果更好。 不过使用多channel 相比与单channel, 每个channel 可以使用不同的word embedding, 比如可以在no-static(梯度可以反向传播) 的channel 来fine tune 词向量，让词向量更加适用于当前的训练。 对于channel在textCNN 是否有用, 从论文的实验结果来看多channels 并没有明显提升模型的分类能力, 七个数据集上的五个数据集 单channel 的textCNN 表现都要优于 多channels的textCNN。我们在这里也介绍一下论文中四个model 的不同 CNN-rand (单channel), 设计好 embedding_size 这个 Hyperparameter 后, 对不同单词的向量作随机初始化, 后续BP的时候作调整. CNN-static(单channel), 拿 pre-trained vectors from word2vec, FastText or GloVe 直接用, 训练过程中不再调整词向量. CNN-non-static(单channel), pre-trained vectors + fine tuning , 即拿word2vec训练好的词向量初始化, 训练过程中再对它们微调. CNN-multiple channel(多channels), 类比于图像中的RGB通道, 这里也可以用 static 与 non-static 搭两个通道来做. 4.max-pooling 得到feamap = [1,1,2] 后, 从中选取一个最大值[2] 作为输出, 便是max-pooling。max-pooling 在保持主要特征的情况下, 大大降低了参数的数目, 从图五中可以看出 feature map 从 三维变成了一维, 好处有如下两点: 降低了过拟合的风险, feature map = [1, 1, 2] 或者[1, 0, 2] 最后的输出都是[2], 表明开始的输入即使有轻微变形, 也不影响最后的识别。 参数减少, 进一步加速计算。 pooling 本身无法带来平移不变性(图片有个字母A, 这个字母A 无论出现在图片的哪个位置, 在CNN的网络中都可以识别出来)，卷积核的权值共享才能. max-pooling的原理主要是从多个值中取一个最大值，做不到这一点。cnn 能够做到平移不变性，是因为在滑动卷积核的时候，使用的卷积核权值是保持固定的(权值共享), 假设这个卷积核被训练的就能识别字母A, 当这个卷积核在整张图片上滑动的时候，当然可以把整张图片的A都识别出来。 5.使用softmax k分类 如图六所示, 我们将 max-pooling的结果拼接起来, 送入到softmax当中, 得到各个类别比如 label 为1 的概率以及label 为-1的概率。如果是预测的话，到这里整个textCNN的流程遍结束了。 如果是训练的话，此时便会根据预测label以及实际label来计算损失函数, 计算出softmax 函数,max-pooling 函数, 激活函数以及卷积核函数 四个函数当中参数需要更新的梯度, 来依次更新这四个函数中的参数，完成一轮训练 。 4. TextCNN 的总结本次我们介绍的textCNN是一个应用了CNN网络的文本分类模型。 textCNN的流程：先将文本分词做embeeding得到词向量, 将词向量经过一层卷积,一层max-pooling, 最后将输出外接softmax 来做n分类。 textCNN 的优势：模型简单, 训练速度快，效果不错。 textCNN的缺点：模型可解释型不强，在调优模型的时候，很难根据训练的结果去针对性的调整具体的特征，因为在textCNN中没有类似gbdt模型中特征重要度(feature importance)的概念, 所以很难去评估每个特征的重要度。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习汇总]]></title>
    <url>%2F2021%2F05%2F12%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[1. 文本分类模型论文阅读 2. pytorch 3. 卷积神经网络 4. 对抗样本 写在前面： 自己写过或者转载的文章乱七八槽，整理一下 1. 文本分类模型论文阅读《Long Short-Term Memory》阅读BilstmBiGRU-Attention 模型Han 翻译论文阅读-label-wise-attention深度学习笔记——RNN（LSTM、GRU、双向RNN）学习总结HAN_pytorch版复现HAN_论文阅读HAN学习指导未完待续TextCNN原理详解BiLSTM-Attention-Based 2. pytorchPytorch之cat()函数%E5%87%BD%E6%95%B0/)Pytorch之tensor个人总结Pytorch之tensor的创建PyTorch之scatter()与scatter_()函数%E4%B8%8Escatter_()%E5%87%BD%E6%95%B0/)Pytorch错误集锦—那些年我们的血泪史Pytorch之tensor维度的扩展，挤压，扩张Pytorch之nn.init中实现的初始化函数Pytorch之matmul函数Pytorch之permute函数pytorch_torchtext学习笔记_2torch-nn学习-1python_torchtext学习笔记_1python_argparse学习Pytorch中Torch 工具包的数学操作汇总速查 3. 卷积神经网络卷积神经网络超详细介绍 4. 对抗样本FGPM：文本对抗样本生成新方法黑箱方法文本对抗样本生成]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习]]></title>
    <url>%2F2021%2F05%2F12%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[1. 文本分类模型论文阅读 2. pytorch 3. 卷积神经网络 写在前面： 自己写过或者转载的文章乱七八槽，整理一下 1. 文本分类模型论文阅读《Long Short-Term Memory》阅读BilstmBiGRU-Attention 模型Han 翻译论文阅读-label-wise-attention深度学习笔记——RNN（LSTM、GRU、双向RNN）学习总结HAN_pytorch版复现HAN_论文阅读HAN学习指导未完待续 2. pytorchPytorch之cat()函数%E5%87%BD%E6%95%B0/)Pytorch之tensor个人总结Pytorch之tensor的创建PyTorch之scatter()与scatter_()函数%E4%B8%8Escatter_()%E5%87%BD%E6%95%B0/)Pytorch错误集锦—那些年我们的血泪史Pytorch之tensor维度的扩展，挤压，扩张Pytorch之nn.init中实现的初始化函数Pytorch之matmul函数Pytorch之permute函数pytorch_torchtext学习笔记_2torch-nn学习-1python_torchtext学习笔记_1python_argparse学习Pytorch中Torch 工具包的数学操作汇总速查 3. 卷积神经网络卷积神经网络超详细介绍]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Long Short-Term Memory》阅读]]></title>
    <url>%2F2021%2F05%2F06%2F%E3%80%8ALong%20Short-Term%20Memory%E3%80%8B%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[论文原文 0. Abstract 1 INTRODUCTION 2 PREVIOUS WORK 3 CONSTANT ERROR BACKPROP 固定误差支持 3.1 EXPONENTIALLY DECAYING ERROR 指数衰减误差 3.2 CONSTANT ERROR FLOW: NAIVE APPROACH 常量错误流:简单的方法 4 LONG SHORT-TERM MEMORY 5 EXPERIMENTS 实验 - [Outline of experiments 试验大纲](#outline-of-experiments-试验大纲) 5.1 EXPERIMENT 1: EMBEDDED REBER GRAMMAR 论文原文https://arxiv.org/pdf/1506.04214.pdf 0. AbstractLearning to store information over extended time intervals via recurrent backpropagation takes a very long time, mostly due to insucient, decaying error back ow. We brie y review Hochreiter’s 1991 analysis of this problem, then address it by introducing a novel, ecient, gradient-based method called \Long Short-Term Memory” (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete time steps by enforcing constant error ow through \constant error carrousels” within special units. Multiplicative gate units learn to open and close access to the constant error ow. LSTM is local in space and time; its computational complexity per time step and weight is O(1). Our experiments with arti cial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with RTRL, BPTT, Recurrent Cascade-Correlation, Elman nets, and Neural Sequence Chunking, LSTM leads to many more successful runs, and learns much faster. LSTM also solves complex, arti cial long time lag tasks that have never been solved by previous recurrent network algorithms. 通过周期性的反向传播学习在扩展的时间间隔内存储信息需要很长的时间，这主要是由于不确定的、衰减的错误导致的。我们简要回顾了Hochreiter在1991年对这个问题的分析，然后介绍了一种新颖的、独特的、基于梯度的方法，称为LSTM (LSTM)。在不造成伤害的情况下截断梯度，LSTM可以学习在超过1000个离散时间步长的最小时间滞后上桥接，方法是通过在特殊单元内的"恒定误差轮盘"强制执行恒定误差。乘性门单元学习打开和关闭访问的恒定误差低。LSTM在空间和时间上都是局部的;其每时间步长的计算复杂度和权值为O(1)。我们对人工数据的实验包括局部的、分布式的、实值的和有噪声的模式表示。在与RTRL、BPTT、周期性级联相关、Elman网和神经序列分块的比较中，LSTM带来了更多的成功运行，并且学习速度更快。LSTM还解决了以前的递归网络算法所不能解决的复杂、人工的长时间滞后问题 1 INTRODUCTIONRecurrent networks can in principle use their feedback connections to store representations of recent input events in form of activations (\short-term memory”, as opposed to \long-term memory” embodied by slowly changing weights). This is potentially signicant for many applications, including speech processing, non-Markovian control, and music composition (e.g., Mozer 1992). The most widely used algorithms for learning what to put in short-term memory, however, take too much time or do not work well at all, especially when minimal time lags between inputs and corresponding teacher signals are long. Although theoretically fascinating, existing methods do not provide clear practical advantages over, say, backprop in feedforward nets with limited time windows. This paper will review an analysis of the problem and suggest a remedy. 递归网络原则上可以使用它们的反馈连接以激活的形式存储最近输入事件的表示(“短期记忆”，而不是”长期记忆”，后者由缓慢变化的权重表示)。这对许多应用程序都有潜在的重要性，包括语音处理、非马尔可夫控制和音乐作曲(例如，Mozer 1992)。然而，最广泛使用的学习短期记忆的算法要么花费了太多时间，要么根本就不能很好地工作，尤其是在输入和相应教师信号之间的最小时滞很长时。虽然理论上很吸引人，但现有的方法并没有提供明显的实际优势，例如，在有限时间窗口的前馈网络中，backprop。本文将对这一问题进行分析，并提出解决办法。 The problem. With conventional \Back-Propagation Through Time” (BPTT, e.g., Williams and Zipser 1992, Werbos 1988) or \Real-Time Recurrent Learning” (RTRL, e.g., Robinson and Fallside 1987), error signals \ owing backwards in time” tend to either (1) blow up or (2) vanish: the temporal evolution of the backpropagated error exponentially depends on the size of the weights (Hochreiter 1991). Case (1) may lead to oscillating weights, while in case (2) learning to bridge long time lags takes a prohibitive amount of time, or does not work at all (see section 3). 这个问题。与传统\反向传播通过时间”(BPTT,例如,1992年威廉姆斯和拉链,Werbos 1988)或\实时复发性学习”(RTRL,例如,罗宾逊和Fallside 1987),误差信号在时间上向后\由于”倾向于(1)炸毁或(2):消失的时间演化backpropagated误差指数的大小取决于重量(Hochreiter 1991)。情形(1)可能会导致权值的振荡，而情形(2)学习如何桥接长时间滞后的情况会花费大量的时间，或者根本不起作用(参见第3节)。 The remedy. This paper presents \Long Short-Term Memory” (LSTM), a novel recurrent network architecture in conjunction with an appropriate gradient-based learning algorithm. LSTM is designed to overcome these error back- ow problems. It can learn to bridge time intervals in excess of 1000 steps even in case of noisy, incompressible input sequences, without loss of short time lag capabilities. This is achieved by an ecient, gradient-based algorithm for an architecture enforcing constant (thus neither exploding nor vanishing) error ow through internal states of special units (provided the gradient computation is truncated at certain architecture-specic points this does not aect long-term error ow though). 补救措施。本文提出了一种新的递归网络结构——长短时记忆(LSTM)，并结合适当的梯度学习算法。LSTM的设计就是为了克服这些错误的反向问题。它可以学习桥接超过1000步的时间间隔，即使在有噪声、不可压缩的输入序列的情况下，也不会损失短时间延迟能力。这是通过一种特殊的、基于梯度的算法来实现的，它针对的是一种通过特殊单元的内部状态来执行常量(因此既不会爆炸也不会消失)的错误(假设梯度计算在某些特定的体系结构点被截断，但这并不影响长期的错误)。 Outline of paper. Section 2 will brie y review previous work. Section 3 begins with an outline of the detailed analysis of vanishing errors due to Hochreiter (1991). It will then introduce a naive approach to constant error backprop for didactic purposes, and highlight its problems concerning information storage and retrieval. These problems will lead to the LSTM architecture as described in Section 4. Section 5 will present numerous experiments and comparisons with competing methods. LSTM outperforms them, and also learns to solve complex, articial tasks no other recurrent net algorithm has solved. Section 6 will discuss LSTM’s limitations and advantages. The appendix contains a detailed description of the algorithm (A.1), and explicit error ow formulae (A.2). 第二部分将简要回顾以前的工作。第3节以详细分析Hochreiter(1991)所造成的消失误差的大纲开始。然后，它将介绍一种用于教学目的的幼稚的不断错误支持方法，并突出其在信息存储和检索方面的问题。这些问题将导致第4节中描述的LSTM体系结构。第5节将提供大量的实验和与竞争方法的比较。LSTM比它们做得更好，而且还学会了解决复杂的人工任务，这是其他递归网络算法所不能解决的。第6节将讨论LSTM的局限性和优点。附录中有算法的详细描述(a .1)，以及公式的显式误差(a .2)。 2 PREVIOUS WORKThis section will focus on recurrent nets with time-varying inputs (as opposed to nets with stationary inputs and xpoint-based gradient calculations, e.g., Almeida 1987, Pineda 1987). 本节将集中讨论具有时变输入的递归网络(而不是具有固定输入和基于x点的梯度计算的网络，例如Almeida 1987和Pineda 1987)。 Gradient-descent variants. The approaches of Elman (1988), Fahlman (1991), Williams (1989), Schmidhuber (1992a), Pearlmutter (1989), and many of the related algorithms in Pearlmutter’s comprehensive overview (1995) suer from the same problems as BPTT and RTRL (see Sections 1 and 3). 梯度下降法变体。Elman(1988)、Fahlman(1991)、Williams(1989)、Schmidhuber (1992a)、Pearlmutter(1989)的方法，以及Pearlmutter的综合综述(1995)中的许多相关算法，都是从与BPTT和RTRL相同的问题中提出的(见第1节和第3节) Time-delays. Other methods that seem practical for short time lags only are Time-Delay Neural Networks (Lang et al. 1990) and Plate’s method (Plate 1993), which updates unit activations based on a weighted sum of old activations (see also de Vries and Principe 1991). Lin et al. (1995) propose variants of time-delay networks called NARX networks. 时间延迟。其他似乎只适用于短时间滞后的方法有时滞神经网络(Lang et al. 1990)和Plate法(Plate 1993)，后者基于旧激活的加权和更新单位激活(参见de Vries和Principe 1991)。Lin等人(1995)提出了时延网络的变体NARX网络。 Time constants. To deal with long time lags, Mozer (1992) uses time constants in uencing changes of unit activations (deVries and Principe’s above-mentioned approach (1991) may in fact be viewed as a mixture of TDNN and time constants). For long time lags, however, the time constants need external ne tuning (Mozer 1992). Sun et al.’s alternative approach (1993) updates the activation of a recurrent unit by adding the old activation and the (scaled) current net input. The net input, however, tends to perturb the stored information, which makes long-term storage impractical. 时间常量。为了处理长时间滞后，Mozer(1992)使用时间常数来表示单位激活的变化(deVries and Principe’s上述方法(1991)实际上可以看作是TDNN和时间常数的混合物)。然而，对于长时间滞后，时间常数需要外部ne调谐(Mozer 1992)。Sun等人的替代方法(1993)通过添加旧的激活和(缩放的)当前净输入来更新一个经常性单元的激活。然而，净输入往往会干扰所存储的信息，这使得长期存储变得不切实际。 Ring’s approach. Ring (1993) also proposed a method for bridging long time lags. Whenever a unit in his network receives con icting error signals, he adds a higher order unit in uencing appropriate connections. Although his approach can sometimes be extremely fast, to bridge a time lag involving 100 steps may require the addition of 100 units. Also, Ring’s net does not generalize to unseen lag durations. 环的方法。Ring(1993)也提出了一种桥接长时间滞后的方法。当他的网络中的一个单元接收到通信错误信号时，他就增加一个更高阶的单元来建立适当的连接。虽然他的方法有时非常快，但要跨越100步的时间延迟可能需要增加100个单元。同样，环网也不能推广到看不见的滞后时间。 Bengio et al.’s approaches. Bengio et al. (1994) investigate methods such as simulated annealing, multi-grid random search, time-weighted pseudo-Newton optimization, and discrete error propagation. Their \latch” and \2-sequence” problems are very similar to problem 3a with minimal time lag 100 (see Experiment 3). Bengio and Frasconi (1994) also propose an EM approach for propagating targets. With n so-called \state networks”, at a given time, their system can be in one of only n dierent states. See also beginning of Section 5. But to solve continuous problems such as the \adding problem” (Section 5.4), their system would require an unacceptable number of states (i.e., state networks). Bengio等人的方法。Bengio等人(1994)研究了模拟退火、多网格随机搜索、时间加权伪牛顿优化和离散误差传播等方法。他们的”闩锁”和”2-序列”问题与3a问题非常相似，只有最小的滞后时间100(见实验3)。Bengio和Frasconi(1994)也提出了一种EM方法来传播目标。对于n个所谓的”状态网络”，在给定的时间内，它们的系统只能处于n种不同状态中的一种。参见第5节的开头。但是，为了解决诸如”\添加问题”(第5.4节)之类的连续问题，它们的系统将需要不可接受的状态数(即状态的网络)。 Kalman lters. Puskorius and Feldkamp (1994) use Kalman lter techniques to improve recurrent net performance. Since they use \a derivative discount factor imposed to decay exponentially the eects of past dynamic derivatives,” there is no reason to believe that their Kalman Filter Trained Recurrent Networks will be useful for very long minimal time lags. Second order nets. We will see that LSTM uses multiplicative units (MUs) to protect error ow from unwanted perturbations. It is not the rst recurrent net method using MUs though. For instance, Watrous and Kuhn (1992) use MUs in second order nets. Some dierences to LSTM are: (1) Watrous and Kuhn’s architecture does not enforce constant error ow and is not designed to solve long time lag problems. (2) It has fully connected second-order sigma-pi units, while the LSTM architecture’s MUs are used only to gate access to constant error ow. (3) Watrous and Kuhn’s algorithm costs O(W2 ) operations per time step, ours only O(W), where W is the number of weights. See also Miller and Giles (1993) for additional work on MUs. Kalman lters. Puskorius and Feldkamp (1994)使用Kalman lter技术来提高经常性净绩效。由于他们使用一个衍生品折扣因子来指数衰减过去动态衍生品的影响，”我们没有理由相信他们的卡尔曼滤波训练的递归网络在很长一段时间内都是有用的。”二阶网络。我们将看到LSTM使用乘法单位(MUs)来保护错误不受不必要的干扰。但它不是第一个使用MUs的递归网络方法。例如，Watrous和Kuhn(1992)在二阶网中使用MUs。LSTM的一些不同之处是: (1)Watrous和Kuhn的架构不强制恒定的错误，也不是为了解决长时间滞后的问题而设计的。 (2)它具有完全连通的二阶sigma-pi单元，而LSTM体系结构的MUs仅用于对恒定误差低的门访问。 (3) Watrous和Kuhn的算法每时间步需要O(W2)个操作，我们的算法只需要O(W)个操作，其中W是权值的个数。有关MUs的其他工作也见Miller和Giles(1993)。 Simple weight guessing. To avoid long time lag problems of gradient-based approaches we may simply randomly initialize all network weights until the resulting net happens to classify all training sequences correctly. In fact, recently we discovered (Schmidhuber and Hochreiter 1996, Hochreiter and Schmidhuber 1996, 1997) that simple weight guessing solves many of the problems in (Bengio 1994, Bengio and Frasconi 1994, Miller and Giles 1993, Lin et al. 1995) faster than the algorithms proposed therein. This does not mean that weight guessing is a good algorithm. It just means that the problems are very simple. More realistic tasks require either many free parameters (e.g., input weights) or high weight precision (e.g., for continuous-valued parameters), such that guessing becomes completely infeasible. 简单的猜测。为了避免基于梯度的方法的长时间滞后问题，我们可以简单地随机初始化所有网络权值，直到最终得到的网络正确地对所有训练序列进行分类。事实上，最近我们发现(Schmidhuber and Hochreiter 1996, Hochreiter and Schmidhuber 1996, 1997)简单的重量猜测解决了(Bengio 1994, Bengio and Frasconi 1994, Miller and Giles 1993, Lin et al. 1995)中的许多问题，比其中提出的算法更快。这并不意味着猜测权重是一个好的算法。这意味着问题很简单。更实际的任务需要许多自由参数(例如，输入权值)或较高的权值精度(例如，连续值参数)，这样猜测就变得完全不可行的。 Adaptive sequence chunkers. Schmidhuber’s hierarchical chunker systems (1992b, 1993) do have a capability to bridge arbitrary time lags, but only if there is local predictability across the subsequences causing the time lags (see also Mozer 1992). For instance, in his postdoctoral thesis (1993), Schmidhuber uses hierarchical recurrent nets to rapidly solve certain grammar learning tasks involving minimal time lags in excess of 1000 steps. The performance of chunker systems, however, deteriorates as the noise level increases and the input sequences become less compressible. LSTM does not suer from this problem. 自适应序列chunkers。Schmidhuber的分层chunker系统(1992b, 1993)确实具有桥接任意时间滞后的能力，但前提是子序列具有局部可预测性，从而导致时间滞后(参见Mozer 1992)。例如，在他的博士后论文(1993)中，Schmidhuber使用层次递归网络来快速解决某些语法学习任务，这些任务涉及的时间延迟最小，超过了1000步。然而，随着噪声水平的提高和输入序列的可压缩性的降低，chunker系统的性能会下降。LSTM不能解决这个问题。 3 CONSTANT ERROR BACKPROP 固定误差支持3.1 EXPONENTIALLY DECAYING ERROR 指数衰减误差Conventional BPTT (e.g. Williams and Zipser 1992). Output unit k’s target at time t is denoted by dk (t). Using mean squared error, k’s error signal is 传统的BPTT(如Williams和Zipser 1992)。输出单元k在t时刻的目标用dk (t)表示，利用均方误差，k的误差信号为 The corresponding contribution to wjl ‘s total weight update is #j (t)yl (t 1), where is the learning rate, and l stands for an arbitrary unit connected to unit j. Outline of Hochreiter’s analysis (1991, page 19-21). Suppose we have a fully connected net whose non-input unit indices range from 1 to n. Let us focus on local error ow from unit u to unit v (later we will see that the analysis immediately extends to global error ow). The error occurring at an arbitrary unit u at time step t is propagated \back into time” for q time steps, to an arbitrary unit v. This will scale the error by the following fact wjl的总权重更新的相应贡献是#j (t)yl (t 1)，其中为学习率，l表示连接到j单元的任意单元。Hochreiter分析概要(1991年，第19-21页)。假设我们有一个完全连通的网络，它的非输入单位指数范围从1到n。让我们关注从单位u到单位v的局部误差ow(稍后我们将看到分析立即扩展到全局误差ow)。发生在任意单位u上的时间步长t的误差被传播回时间中，对于q时间步长，传播回任意单位v 3.2 CONSTANT ERROR FLOW: NAIVE APPROACH 常量错误流:简单的方法A single unit. To avoid vanishing error signals, how can we achieve constant error ow through a single unit j with a single connection to itself? According to the rules above, at time t, j’s local error back ow is j (t) = f 0 j (netj (t))#j (t + 1)wjj . To enforce constant error ow through j, we h j, we 一个单元。为了避免消失的错误信号，我们如何通过一个单一的单位j与一个单一的连接到自己实现恒定的错误低?根据上面的规则，在t时刻，j的本地错误返回ow是#j (t) = f0 j (netj (t))#j (t + 1)wjj。为了通过j来执行常误差ow，我们h j，我们 In the experiments, this will be ensured by using the identity function fj : fj (x) = x; 8x, and by setting wjj = 1:0. We refer to this as the constant error carrousel (CEC). CEC will be LSTM’s central feature (see Section 4). Of course unit j will not only be connected to itself but also to other units. This invokes two obvious, related problems (also inherent in all other gradient-based approaches): 在实验中，利用恒等函数fj: fj (x) = x来保证;设置wjj = 1:0。我们称之为常误差卡鲁塞尔(CEC)。CEC将是LSTM的中心特性(参见第4节)。当然，单元j不仅与自身相连，还与其他单元相连。这引发了两个明显的、相关的问题(也是所有其他基于梯度的方法所固有的): Input weight con ict: for simplicity, let us focus on a single additional input weight wji . Assume that the total error can be reduced by switching on unit j in response to a certain input, and keeping it active for a long time (until it helps to compute a desired output). Provided i is nonzero, since the same incoming weight has to be used for both storing certain inputs and ignoring others, wji will often receive con icting weight update signals during this time (recall that j is linear): these signals will attempt to make wji participate in (1) storing the input (by switching on j) and (2) protecting the input (by preventing j from being switched o by irrelevant later inputs). This con ict makes learning dicult, and calls for a more context-sensitive mechanism for controlling \write operations” through input weights. Output weight con ict: assume j is switched on and currently stores some previous input. For simplicity, let us focus on a single additional outgoing weight wkj . The same wkj has to be used for both retrieving j’s content at certain times and preventing j from disturbing k at other times. As long as unit j is non-zero, wkj will attract con icting weight update signals generated during sequence processing: these signals will attempt to make wkj participate in (1) accessing the information stored in j and | at dierent times | (2) protecting unit k from being perturbed by j. For instance, with many tasks there are certain \short time lag errors” that can be reduced in early training stages. However, at later training stages j may suddenly start to cause avoidable errors in situations that already seemed under control by attempting to participate in reducing more dicult \long time lag errors”. Again, this con ict makes learning dicult, and calls for a more context-sensitive mechanism for controlling \read operations” through output weights. 输入权值约束:为了简单起见，我们将重点放在单个额外的输入权值wji上。假设可以通过打开单元j来响应某个输入，并长时间保持它处于活动状态(直到它有助于计算所需的输出)，从而减少总错误。提供我是零,因为相同的传入的重量必须是用于存储特定的输入和无视他人,wji通常会接收con ict重量更新信号在此期间(回想一下,j是线性):这些信号将试图使wji参与(1)存储输入(通过打开j)和(2)保护输入(通过阻止j被无关紧要了o后输入)。这使得学习变得困难，需要一种更上下文敏感的机制来”通过输入权重”控制写操作。 输出权值:假设j已经打开，并且当前存储了一些以前的输入。为了简单起见，让我们关注单个额外的输出权wkj。相同的wkj必须在特定时间用于检索j的内容，在其他时间用于防止j干扰k。只要单位j是零,wkj将吸引con ict重量更新信号生成的序列处理期间:这些信号将试图使wkj参与(1)访问的信息存储在j和| | dierent倍(2)保护单元凯西从被摄动j。例如,许多任务有些\短时间延迟错误”,可以减少在早期训练阶段。然而，在后来的训练阶段，j可能会突然开始在那些似乎已经在控制之中的情况下，通过尝试减少更多的长时间延迟错误来造成可避免的错误。同样，这一缺点使学习变得困难，需要一种更上下文敏感的机制来”通过输出权重”控制读操作。 Of course, input and output weight con icts are not specic for long time lags, but occur for short time lags as well. Their eects, however, become particularly pronounced in the long time lag case: as the time lag increases, (1) stored information must be protected against perturbation for longer and longer periods, and | especially in advanced stages of learning | (2) more and more already correct outputs also require protection against perturbation. 当然，输入和输出的权系数在长时间滞后时是不特定的，但在短时间滞后时也会出现。除,然而,在长时间滞后的情况下尤为明显:随着时间间隔的增加,(1)存储信息必须防止扰动时间却越来越长,学习|和|尤其是晚期(2)越来越多的正确输出也需要防止扰动。 Due to the problems above the naive approach does not work well except in case of certain simple problems involving local input/output representations and non-repeating input patterns (see Hochreiter 1991 and Silva et al. 1996). The next section shows how to do it right. 由于上述问题，天真的方法不能很好地工作，除非某些简单的问题涉及本地输入/输出表示和非重复输入模式(见Hochreiter 1991和Silva et al. 1996)。下一节将展示如何正确地执行此操作。 4 LONG SHORT-TERM MEMORYMemory cells and gate units. To construct an architecture that allows for constant error ow through special, self-connected units without the disadvantages of the naive approach, we extend the constant error carrousel CEC embodied by the self-connected, linear unit j from Section 3.2 by introducing additional features. A multiplicative input gate unit is introduced to protect the memory contents stored in j from perturbation by irrelevant inputs. Likewise, a multiplicative output gate unit is introduced which protects other units from perturbation by currently irrelevant memory contents stored in j. 记忆单元和门单元。为了构建一个允许通过特殊的、自连接的单元实现恒定误差的体系结构，同时又不存在朴素方法的缺点，我们通过引入额外的特性来扩展3.2节中自连接的线性单元j所包含的恒定误差carrousel CEC。为了保护存储在j中的存储内容不受无关输入的干扰，引入了乘法输入门单元。同样地，一个乘法输出门单元被引入，它保护其他单元不受当前不相关的存储在j中的内存内容的干扰。 net Figure 1: Architecture of memory cel l cj (the box) and its gate units inj ; outj . The self-recurrent connection (with weight 1.0) indicates feedback with a delay of 1 time step. It builds the basis of the \constant error carrousel” CEC. The gate units open and close access to CEC. See text and appendix A.1 for details. 图1:memory cel l cj(盒子)的结构和它的门单元inj;outj。自循环连接(权值为1.0)表示反馈延迟1个时间步长。它建立了恒定误差carrousel”CEC”的基础。星门单元打开和关闭CEC的入口。详情见正文和附录A.1。 ls. Why gate units? To avoid input weight con icts, inj controls the error ow to memory cell cj ‘s input connections wcj i . To circumvent cj ‘s output weight con icts, outj controls the error ow from unit j’s output connections. In other words, the net can use inj to decide when to keep or override information in memory cell cj , and outj to decide when to access memory cell cj and when to prevent other units from being perturbed by cj (see Figure 1). 为什么门单位?为了避免输入权值冲突，inj控制了内存单元cj的输入连接的误差。为了绕过cj的输出权值，outj控制来自单位j的输出连接的错误。换句话说，网络可以使用inj来决定何时在内存单元cj中保留或覆盖信息，而使用outj来决定何时访问内存单元cj以及何时防止其他单元受到cj的干扰(参见图1)。 Error signals trapped within a memory cell’s CEC cannot change { but dierent error signals owing into the cell (at dierent times) via its output gate may get superimposed. The output gate will have to learn which errors to trap in its CEC, by appropriately scaling them. The input gate will have to learn when to release errors, again by appropriately scaling them. Essentially, the multiplicative gate units open and close access to constant error ow through CEC. 存储单元的CEC中的错误信号不能改变{但是通过输出门进入单元的不同错误信号(在不同的时间)可以被叠加。通过适当地扩展，输出门必须了解在其CEC中应该捕获哪些错误。输入门必须学会何时释放错误，再次通过适当地扩展它们。从本质上说，乘性门单元通过CEC打开和关闭对恒定误差的访问。 Distributed output representations typically do require output gates. Not always are both gate types necessary, though | one may be sucient. For instance, in Experiments 2a and 2b in Section 5, it will be possible to use input gates only. In fact, output gates are not required in case of local output encoding | preventing memory cells from perturbing already learned outputs can be done by simply setting the corresponding weights to zero. Even in this case, however, output gates can be benecial: they prevent the net’s attempts at storing long time lag memories (which are usually hard to learn) from perturbing activations representing easily learnable short time lag memories. (This will prove quite useful in Experiment 1, for instance.) 分布式输出表示通常需要输出门。虽然|一个可能是必需的，但两个门不一定都是必需的。例如，在第5节的2a和2b实验中，将可能只使用输入门。事实上，在本地输出编码为|的情况下，不需要输出门，只要将相应的权值设置为0，就可以防止内存单元干扰已经学习过的输出。然而，即使在这种情况下，输出门也可能是有益的:它们阻止了网络存储长时间滞后记忆(通常很难学习)的尝试，从而干扰了代表容易学习的短时间滞后记忆的激活。(例如，这在实验1中将被证明非常有用。) Network topology. We use networks with one input layer, one hidden layer, and one output layer. The (fully) self-connected hidden layer contains memory cells and corresponding gate units (for convenience, we refer to both memory cells and gate units as being located in the hidden layer). The hidden layer may also contain \conventional” hidden units providing inputs to gate units and memory cells. All units (except for gate units) in all layers have directed connections (serve as inputs) to all units in the layer above (or to all higher layers { Experiments 2a and 2b). 网络拓扑结构。我们使用一个输入层、一个隐含层和一个输出层的网络。(完全)自连接的隐层包含内存单元和相应的栅极单元(为了方便起见，我们将位于隐层中的内存单元和栅极单元都称为隐层)。所述隐层还可以包含提供栅极单元和存储器单元输入的常规”隐单元”。所有层中的所有单元(门单元除外)都有指向连接(作为输入)到上面层中的所有单元(或所有更高的层{实验2a和2b)。 Memory cell blocks. S memory cells sharing the same input gate and the same output gate form a structure called a \memory cell block of size S”. Memory cell blocks facilitate information storage | as with conventional neural nets, it is not so easy to code a distributed input within a single cell. Since each memory cell block has as many gate units as a single memory cell (namely two), the block architecture can be even slightly more ecient (see paragraph \computational complexity”). A memory cell block of size 1 is just a simple memory cell. In the experiments (Section 5), we will use memory cell blocks of various sizes. 存储单元块。共享相同的输入门和输出门的内存单元形成一个称为大小为S的内存单元块的结构。记忆单元块促进信息存储|与传统的神经网络一样，在单个单元内编码分布式输入并不容易。由于每个内存单元块与单个内存单元(即两个)具有同样多的门单元，因此块架构甚至可以更特殊一些(请参阅段落”计算复杂性”)。大小为1的内存单元块只是一个简单的内存单元。在实验(第5部分)中，我们将使用不同大小的存储单元块。 Learning. We use a variant of RTRL (e.g., Robinson and Fallside 1987) which properly takes into account the altered, multiplicative dynamics caused by input and output gates. However, to ensure non-decaying error backprop through internal states of memory cells, as with truncated BPTT (e.g., Williams and Peng 1990), errors arriving at \memory cell net inputs” (for cell cj , this includes netcj , netinj , netoutj ) do not get propagated back further in time (although they do serve to change the incoming weights). Only within2 memory cells, errors are propagated back through previous internal states scj . To visualize this: once an error signal arrives at a memory cell output, it gets scaled by output gate activation and h0 . Then it is within the memory cell’s CEC, where it can ow back indenitely without ever being scaled. Only when it leaves the memory cell through the input gate and g, it is scaled once more by input gate activation and g 0 . It then serves to change the incoming weights before it is truncated (see appendix for explicit formulae). 学习。我们使用RTRL的一个变体(例如，Robinson和Fallside 1987)，它适当地考虑了输入和输出门所引起的变化的乘法动力学。然而,以确保non-decaying错误backprop通过内部状态的记忆细胞,与截断BPTT(例如,威廉姆斯和彭1990),错误到达\存储单元网络输入”(细胞cj,这包括netcj、netinj netoutj)得不到传播更久远的时代(尽管他们服务变化的权重)。只有在2个内存单元中，错误才会通过之前的内部状态scj传播回来。为了可视化这一点:一旦一个错误信号到达一个内存单元输出，它将被输出门激活和h0缩放。然后它在记忆细胞的CEC中，在那里它可以无限地慢下来而不需要被缩放。只有当它通过输入门和g离开存储单元时，它才通过输入门激活和g 0再次被缩放。然后，它用于在截断之前更改传入的权重(有关显式公式，请参阅附录)。 Computational complexity. As with Mozer’s focused recurrent backprop algorithm (Mozer 1989), only the derivatives @scj @wil need to be stored and updated. Hence the LSTM algorithm is very ecient, with an excellent update complexity of O(W), where W the number of weights (see details in appendix A.1). Hence, LSTM and BPTT for fully recurrent nets have the same update complexity per time step (while RTRL’s is much worse). Unlike full BPTT, however, LSTM is local in space and time3 : there is no need to store activation values observed during sequence processing in a stack with potentially unlimited size. 计算的复杂性。与Mozer的重点循环支持算法(Mozer 1989)一样，只需要存储和更新导数@scj @wil。因此LSTM算法非常特殊，更新复杂度为O(W)，其中W表示权值的数量(详见附录A.1)。因此，对于完全经常网，LSTM和BPTT的每一步更新复杂度是相同的(而RTRL要差得多)。但是，与完整的BPTT不同的是，LSTM在空间和时间上是局部的:不需要将序列处理期间观察到的激活值存储在具有无限大小的堆栈中。 Abuse problem and solutions. In the beginning of the learning phase, error reduction may be possible without storing information over time. The network will thus tend to abuse memory cells, e.g., as bias cells (i.e., it might make their activations constant and use the outgoing connections as adaptive thresholds for other units). The potential diculty is: it may take a long time to release abused memory cells and make them available for further learning. A similar \abuse problem” appears if two memory cells store the same (redundant) information. There are at least two solutions to the abuse problem: (1) Sequential network construction (e.g., Fahlman 1991): a memory cell and the corresponding gate units are added to the network whenever the error stops decreasing (see Experiment 2 in Section 5). (2) Output gate bias: each output gate gets a negative initial bias, to push initial memory cell activations towards zero. Memory cells with more negative bias automatically get \allocated” later (see Experiments 1, 3, 4, 5, 6 in Section 5). 滥用问题及解决方法。在学习阶段的开始，可以在不存储信息的情况下减少错误。因此，该网络将倾向于滥用记忆细胞，例如，作为偏见细胞。，它可能使它们的激活保持不变，并使用传出连接作为其他单元的自适应阈值)。潜在的问题是:释放被滥用的记忆细胞并使其用于进一步的学习可能需要很长时间。如果两个记忆单元存储相同的(冗余的)信息，就会出现类似的”滥用”问题。至少有两个解决滥用问题:(1)顺序网络建设(例如,Fahlman 1991):一个存储单元和相应的单元门时被添加到网络错误停止减少(见实验2节5)。(2)输出门偏见:每个输出门负初始偏差,将最初的记忆细胞激活为零。带有更多负偏差的记忆细胞将被自动分配”稍后(参见第5节中的实验1、3、4、5、6)。 Internal state drift and remedies. If memory cell cj ‘s inputs are mostly positive or mostly negative, then its internal state sj will tend to drift away over time. This is potentially dangerous, for the h0 (sj ) will then adopt very small values, and the gradient will vanish. One way to circumvent this problem is to choose an appropriate function h. But h(x) = x, for instance, has the disadvantage of unrestricted memory cell output range. Our simple but eective way of solving drift problems at the beginning of learning is to initially bias the input gate inj towards zero. Although there is a tradeo between the magnitudes of h0 (sj ) on the one hand and of yinj and f 0 inj on the other, the potential negative eect of input gate bias is negligible compared to the one of the drifting eect. With logistic sigmoid activation functions, there appears to be no need for ne-tuning the initial bias, as conrmed by Experiments 4 and 5 in Section 5.4. 内部状态漂移和补救措施。如果记忆细胞cj的输入大部分是正的或大部分是负的，那么它的内部状态sj会随着时间的推移而漂移。这是潜在的危险，因为h0 (sj)将采用非常小的值，而梯度将消失。解决这个问题的一种方法是选择一个合适的函数h，但是h(x) = x的缺点是不限制内存单元的输出范围。我们在学习之初解决漂移问题的简单而有效的方法是使输入门inj最初偏向于零。虽然在h0 (sj)与yinj和f0 inj的量级之间存在贸易，但与漂移效应相比，输入门偏差的潜在负效应可以忽略不计。对于logistic sigmoid激活函数，似乎不需要对初始偏差进行ne调节，正如5.4节中的实验4和实验5所证实的那样。 5 EXPERIMENTS 实验Introduction. Which tasks are appropriate to demonstrate the quality of a novel long time lag 介绍。哪些任务是合适的，以证明一个新的长时间滞后的质量 algorithm? First of all, minimal time lags between relevant input signals and corresponding teacher signals must be long for al l training sequences. In fact, many previous recurrent net algorithms sometimes manage to generalize from very short training sequences to very long test sequences. See, e.g., Pollack (1991). But a real long time lag problem does not have any short time lag exemplars in the training set. For instance, Elman’s training procedure, BPTT, oine RTRL, online RTRL, etc., fail miserably on real long time lag problems. See, e.g., Hochreiter (1991) and Mozer (1992). A second important requirement is that the tasks should be complex enough such that they cannot be solved quickly by simple-minded strategies such as random weight guessing. 算法?首先，对于all训练序列，相关输入信号与相应教师信号之间的最小时滞必须很长。事实上，许多以前的递归网络算法有时能够将非常短的训练序列推广到非常长的测试序列。参见，例如Pollack(1991)。但是一个真实的长时间滞后问题在训练集中没有任何短时间滞后的例子。例如，Elman的训练过程，BPTT, oine RTRL, online RTRL等，在真实的长时间滞后问题上严重失败。例如Hochreiter(1991)和Mozer(1992)。第二个重要的要求是，任务应该足够复杂，不能用简单的策略(如随机猜测权值)快速解决。 Guessing can outperform many long time lag algorithms. Recently we discovered (Schmidhuber and Hochreiter 1996, Hochreiter and Schmidhuber 1996, 1997) that many long time lag tasks used in previous work can be solved more quickly by simple random weight guessing than by the proposed algorithms. For instance, guessing solved a variant of Bengio and Frasconi’s \parity problem” (1994) problem much faster4 than the seven methods tested by Bengio et al. (1994) and Bengio and Frasconi (1994). Similarly for some of Miller and Giles’ problems (1993). Of course, this does not mean that guessing is a good algorithm. It just means that some previously used problems are not extremely appropriate to demonstrate the quality of previously proposed algorithms. 猜测可以胜过许多长时间延迟的算法。最近我们发现(Schmidhuber and Hochreiter 1996, Hochreiter and Schmidhuber 1996, 1997)，以前工作中使用的许多长时间延迟任务可以通过简单的随机猜测权值来快速解决，而不是通过所提出的算法。例如，猜测解决了Bengio和Frasconi’s奇偶校验问题(1994)的一个变体，比Bengio等人(1994)和Bengio和Frasconi(1994)测试的七种方法要快得多。类似地，米勒和贾尔斯的一些问题(1993年)。当然，这并不意味着猜测是一个好的算法。这只是意味着一些以前用过的问题不是非常适合用来演示以前提出的算法的质量。 What’s common to Experiments 1{6. All our experiments (except for Experiment 1) involve long minimal time lags | there are no short time lag training exemplars facilitating learning. Solutions to most of our tasks are sparse in weight space. They require either many parameters/inputs or high weight precision, such that random weight guessing becomes infeasible. 实验1{6。我们所有的实验(除了实验1)都涉及到长时间的最小滞后时间|没有短时间的滞后训练范例来促进学习。我们大多数任务的解在权值空间中是稀疏的。它们要么需要许多参数/输入，要么需要较高的权值精度，这样随机猜测权值就变得不可行了。 We always use on-line learning (as opposed to batch learning), and logistic sigmoids as activation functions. For Experiments 1 and 2, initial weights are chosen in the range [0:2; 0:2], for the other experiments in [0:1; 0:1]. Training sequences are generated randomly according to the various task descriptions. In slight deviation from the notation in Appendix A1, each discrete time step of each input sequence involves three processing steps: (1) use current input to set the input units. (2) Compute activations of hidden units (including input gates, output gates, memory cells). (3) Compute output unit activations. Except for Experiments 1, 2a, and 2b, sequence elements are randomly generated on-line, and error signals are generated only at sequence ends. Net activations are reset after each processed input sequence. 我们总是使用在线学习(而不是批量学习)，并使用逻辑sigmoids作为激活函数。实验1和实验2的初始权值选择在[0:2;0:2]，用于其他实验[0:1;0:1)。根据不同的任务描述，随机生成训练序列。与附录A1中的符号略有偏差，每个输入序列的每个离散时间步都涉及三个处理步骤: (1)使用电流输入设置输入单元。 (2)计算隐藏单元的激活(包括输入门、输出门、存储单元)。 (3)计算输出单元激活。除实验1、2a、2b外，序列元素在线随机生成，仅在序列末端产生误差信号。Net激活在每个处理的输入序列之后被重置。 For comparisons with recurrent nets taught by gradient descent, we give results only for RTRL, except for comparison 2a, which also includes BPTT. Note, however, that untruncated BPTT (see, e.g., Williams and Peng 1990) computes exactly the same gradient as oine RTRL. With long time lag problems, oine RTRL (or BPTT) and the online version of RTRL (no activation resets, online weight changes) lead to almost identical, negative results (as conrmed by additional simulations in Hochreiter 1991; see also Mozer 1992). This is because oine RTRL, online RTRL, and full BPTT all suer badly from exponential error decay. 对于用梯度下降法讲授的循环网的比较，我们只给出了RTRL的结果，除了比较2a，其中也包括了BPTT。但是，请注意未截断的BPTT(参见， Williams和Peng(1990)计算的梯度与oine RTRL完全相同。由于存在长时间滞后问题，oine RTRL(或BPTT)和RTRL的在线版本(没有激活重置，在线权重变化)导致几乎相同的负结果(如Hochreiter 1991中的额外模拟所证实的;参见Mozer 1992)。这是因为oine RTRL、online RTRL和full BPTT都严重依赖于指数误差衰减。 Our LSTM architectures are selected quite arbitrarily. If nothing is known about the complexity of a given problem, a more systematic approach would be: start with a very small net consisting of one memory cell. If this does not work, try two cells, etc. Alternatively, use sequential network construction (e.g., Fahlman 1991). 我们的LSTM架构是任意选择的。如果对给定问题的复杂性一无所知，那么一种更系统的方法是:从一个由一个记忆单元组成的非常小的网络开始。如果这不起作用，尝试两个单元格，等等。或者，使用顺序网络结构(例如，Fahlman 1991)。 Outline of experiments 试验大纲 Experiment 1 focuses on a standard benchmark test for recurrent nets: the embedded Reber grammar. Since it allows for training sequences with short time lags, it is not a long time lag problem. We include it because (1) it provides a nice example where LSTM’s output gates are truly benecial, and (2) it is a popular benchmark for recurrent nets that has been used by many authors | we want to include at least one experiment where conventional BPTT and RTRL do not fail completely (LSTM, however, clearly outperforms them). The embedded Reber grammar’s minimal time lags represent a border case in the sense that it is still possible to learn to bridge them with conventional algorithms. Only slightly long minimal time lags would make this almost impossible. The more interesting tasks in our paper, however, are those that RTRL, BPTT, etc. cannot solve at all. 实验1着重于递归网络的标准基准测试:嵌入式Reber语法。因为它允许训练序列有短的时间滞后，所以它不是一个长时间滞后的问题。我们包括是因为(1),它提供了一个很好的例子,LSTM输出门真正benecial,和(2)这是一个流行的复发性基准网,已经被许多作者|我们希望包括至少一个实验,常规BPTT和RTRL不完全失败(然而,LSTM明显优于他们)。嵌入式Reber语法的最小时间延迟代表了一种边界情况，在这种情况下，学习用传统算法桥接它们仍然是可能的。只要稍微长一点的时间延迟，这几乎是不可能的。然而，我们的论文中更有趣的任务是那些RTRL、BPTT等根本无法解决的任务。 Experiment 2 focuses on noise-free and noisy sequences involving numerous input symbols distracting from the few important ones. The most dicult task (Task 2c) involves hundreds of distractor symbols at random positions, and minimal time lags of 1000 steps. LSTM solves it, while BPTT and RTRL already fail in case of 10-step minimal time lags (see also, e.g., Hochreiter 1991 and Mozer 1992). For this reason RTRL and BPTT are omitted in the remaining, more complex experiments, all of which involve much longer time lags. 实验2着重于无噪声和有噪声的序列，这些序列涉及大量的输入符号，分散了对少数重要符号的注意力。最复杂的任务(task 2c)包含数百个随机位置的干扰符号，最小延迟为1000步。LSTM解决了这个问题，而BPTT和RTRL已经在10步最小时间延迟的情况下失败了(参见Hochreiter 1991和Mozer 1992)。因此，RTRL和BPTT在剩余的、更复杂的实验中被忽略，所有这些实验都涉及更长的时间滞后。 Experiment 3 addresses long time lag problems with noise and signal on the same input line. Experiments 3a/3b focus on Bengio et al.’s 1994 \2-sequence problem”. Because this problem actually can be solved quickly by random weight guessing, we also include a far more dicult 2-sequence problem (3c) which requires to learn real-valued, conditional expectations of noisy targets, given the inputs. 实验3解决了在同一输入线上存在噪声和信号的长时间滞后问题。实验3a/3b集中于Bengio等人的1994 \2-sequence问题”。因为这个问题实际上可以通过随机猜测权值来快速解决，所以我们还包括了一个更复杂的2-序列问题(3c)，该问题要求在给定输入的情况下学习噪声目标的实值、条件期望。 Experiments 4 and 5 involve distributed, continuous-valued input representations and require learning to store precise, real values for very long time periods. Relevant input signals can occur at quite dierent positions in input sequences. Again minimal time lags involve hundreds of steps. Similar tasks never have been solved by other recurrent net algorithms. 实验4和5涉及到分布式的连续值输入表示，需要学习长时间存储精确的、真实的值。相关的输入信号可以出现在输入序列的不同位置。同样，最小的时间延迟涉及数百个步骤。其他递归网络算法从未解决过类似的问题。 Experiment 6 involves tasks of a dierent complex type that also has not been solved by other recurrent net algorithms. Again, relevant input signals can occur at quite dierent positions in input sequences. The experiment shows that LSTM can extract information conveyed by the temporal order of widely separated inputs. 实验6涉及到不同复杂类型的任务，其他递归网络算法也没有解决这些任务。同样，相关的输入信号可以出现在输入序列的不同位置。实验结果表明，LSTM可以提取出由时间顺序的离散输入所传递的信息。Subsection 5.7 will provide a detailed summary of experimental conditions in two tables for reference. 第5.7款将提供两个表内实验条件的详细摘要，以供参考。 5.1 EXPERIMENT 1: EMBEDDED REBER GRAMMAR实验1:嵌入式REBER语法 Task. Our rst task is to learn the \embedded Reber grammar”, e.g. Smith and Zipser (1989), Cleeremans et al. (1989), and Fahlman (1991). Since it allows for training sequences with short time lags (of as few as 9 steps), it is not a long time lag problem. We include it for two reasons: (1) it is a popular recurrent net benchmark used by many authors | we wanted to have at least one experiment where RTRL and BPTT do not fail completely, and (2) it shows nicely how output gates can be bene cial. 任务。我们的首要任务是学习嵌入的Reber语法”，例如Smith和Zipser(1989)、Cleeremans等人(1989)和Fahlman(1991)。因为它允许训练序列有短的时间滞后(只有9个步骤)，所以它不是一个长时间滞后的问题。我们引入它有两个原因: (1)它是一个被许多作者|使用的流行的周期性网络基准，我们希望至少有一个RTRL和BPTT不会完全失败的实验， (2)它很好地展示了输出门是如何可以带来好处的。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[miktex+vscode错误]]></title>
    <url>%2F2021%2F05%2F03%2Fmiktex%2Bvscode%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[1. 错误的recipes 写在前面： 参考文章： 1. 错误的recipes 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401// // ======================== LaTeX 设置 BEGIN ========================// // bibtex 格式// "latex-workshop.bibtex-format.tab": "tab",// // 自动编译，全部关闭，当且仅当你认为有需要的时候才会去做编译// "latex-workshop.latex.autoBuild.run": "never",// "latex-workshop.latex.autoBuild.cleanAndRetry.enabled": false,// // 设置 latex-workshop 的 PDF 预览程序，external 指的是外部程序// "latex-workshop.view.pdf.viewer": "external",// "latex-workshop.view.pdf.ref.viewer": "external",// "latex-workshop.view.pdf.external.viewer.command": "D:/App/SumatraPDF/SumatraPDF.exe", // 注意修改路径// "latex-workshop.view.pdf.external.viewer.args": [// "%PDF%"// ],// // 配置正向、反向搜索：.tex -&gt; .pdf// "latex-workshop.view.pdf.external.synctex.command": "D:/App/SumatraPDF/SumatraPDF.exe", // 注意修改路径// "latex-workshop.view.pdf.external.synctex.args": [// // 正向搜索// "-forward-search",// "%TEX%",// "%LINE%",// "-reuse-instance",// // 反向搜索// "-inverse-search",// "\"D:/App/Microsoft VS Code/Code.exe\" \"D:/App/Microsoft VS Code/resources/app/out/cli.js\" -gr %f:%l",// "%PDF%"// ],// // 这是一些独立的编译选项，可以作为工具被编译方案调用// "latex-workshop.latex.tools": [// &#123;// // Windows 原生安装 TeX Live 2020 的编译选项// "name": "Windows XeLaTeX",// "command": "xelatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "-pdf",// "%DOCFILE%"// ]// &#125;,// &#123;// // Windows Biber 编译// "name": "Windows Biber",// "command": "biber",// "args": [// "%DOCFILE%"// ]// &#125;,// &#123;// // WSL XeLaTeX 编译一般的含有中文字符的文档// "name": "WSL XeLaTeX",// "command": "wsl",// "args": [// "/usr/local/texlive/2020/bin/x86_64-linux/xelatex",// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "-pdf",// //"-output-directory=%OUTDIR%",// //"-aux-directory=%OUTDIR%",// "%DOCFILE%"// ]// &#125;,// &#123;// // WSL biber / bibtex 编译带有 citation 标记项目的文档// "name": "WSL Biber",// "command": "wsl",// "args": [// "/usr/local/texlive/2020/bin/x86_64-linux/biber",// "%DOCFILE%"// ]// &#125;// ],// // 这是一些编译方案，会出现在 GUI 菜单里// "latex-workshop.latex.recipes": [// &#123;// // 1.1 Windows 编译简单的小文档，这个选项不太常用，因为绝大多数文章都需要有参考文献索引// "name": "Windows XeLaTeX 简单编译",// "tools": [// "Windows XeLaTeX"// ]// &#125;,// &#123;// // 1.2 Windows 编译带有索引的论文，需要进行四次编译；-&gt; 符号只是一种标记而已，没有程序上的意义// "name": "Windows xe-&gt;bib-&gt;xe-&gt;xe 复杂编译",// "tools": [// "Windows XeLaTeX",// "Windows Biber",// "Windows XeLaTeX",// "Windows XeLaTeX"// ]// &#125;,// &#123;// // 2.1 WSL 编译简单的小文档，这个选项不太常用，因为我绝大多数文章都需要有引用。// "name": "XeLaTeX 简单编译",// "tools": [// "WSL XeLaTeX"// ]// &#125;,// &#123;// // 2.2 带有 citation 索引的文档，需要进行四次编译；-&gt; 符号只是一种标记而已，没有程序上的意义// "name": "xe-&gt;bib-&gt;xe*2 复杂编译",// "tools": [// "WSL XeLaTeX",// "WSL Biber",// "WSL XeLaTeX",// "WSL XeLaTeX"// ]// &#125;// ],// // 清空中间文件// "latex-workshop.latex.clean.fileTypes": [// "*.aux",// "*.bbl",// "*.blg",// "*.idx",// "*.ind",// "*.lof",// "*.lot",// "*.out",// "*.toc",// "*.acn",// "*.acr",// "*.alg",// "*.glg",// "*.glo",// "*.gls",// "*.ist",// "*.fls",// "*.log",// "*.fdb_latexmk",// "*.bcf",// "*.run.xml",// "*.synctex.gz"// ],// "explorer.confirmDelete": false// // ======================== LaTeX 设置 END ========================// ##########################// try 1// "latex-workshop.latex.tools": [// &#123;// "name": "xelatex",// "command": "xelatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOC%"// ]// &#125;,// &#123;// "name": "latexmk",// "command": "latexmk",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "-pdf",// "%DOC%"// ]// &#125;,// &#123;// "name": "texify",// "command": "texify",// "args": [// "--synctex",// "--pdf",// "--tex-option=\"-interaction=nonstopmode\"",// "--tex-option=\"-file-line-error\"",// "%DOC%.tex"// ],// "env": &#123;&#125;// &#125;,// &#123;// "name": "pdflatex",// "command": "pdflatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOC%"// ]// &#125;,// &#123;// "name": "bibtex",// "command": "bibtex",// "args": [// "%DOCFILE%"// ]// &#125;,// &#123;// "name": "biber",// "command": "biber",// "args": [// "%DOCFILE%"// ]// &#125;// ]// ##########################// latex try// ******************** begin *************************// "latex-workshop.latex.recipes": [// &#123;// "name": "sjtu thesis 🔃",// "tools": [// "cleanall",// "latexmk",// "clean"// ]// &#125;,// &#123;// "name": "xelatex 😄",// "tools": [// "xelatex",// "clean"// ]// &#125;,// &#123;// "name": "bibtex 🐷",// "tools": [// "bibtex"// ]// &#125;,// &#123;// "name": "pdflatex ➞ bibtex ➞ pdflatex`×2",// "tools": [// "pdflatex",// "bibtex",// "pdflatex",// "pdflatex"// ]// &#125;// ],// "latex-workshop.latex.tools": [// &#123;// "name": "latexmk",// "command": "latexmk",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "-halt-on-error",// "%DOC%"// ],// "env": &#123;&#125;// &#125;,// &#123;// "name": "xelatex",// "command": "xelatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOC%"// ]// &#125;,// &#123;// "name": "pdflatex",// "command": "pdflatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOCFILE%"// ]// &#125;,// &#123;// "name": "bibtex",// "command": "bibtex",// "args": [// "%DOCFILE%"// ]// &#125;,// &#123;// "name": "clean",// "command": "latexmk",// "args": [// "-quiet",// "-c",// "%DOC%"// ] // &#125;,// &#123;// "name": "cleanall",// "command": "latexmk",// "args": [// "-quiet",// "-C",// "%DOC%"// ] // &#125;// ],// ******************** end *************************// Latex workshop try---1// ********************begin*************************// "latex-workshop.latex.tools": [// &#123;// "name": "latexmk",// "command": "latexmk",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "-pdf",// "%DOC%"// ]// &#125;,// &#123;// "name": "xelatex",// "command": "xelatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOC%"// ]// &#125;, // &#123;// "name": "pdflatex",// "command": "pdflatex",// "args": [// "-synctex=1",// "-interaction=nonstopmode",// "-file-line-error",// "%DOC%"// ]// &#125;,// &#123;// "name": "bibtex",// "command": "bibtex",// "args": [// "%DOCFILE%"// ]// &#125;// ],// "latex-workshop.latex.recipes": [// &#123;// "name": "latexmk 🔃",// "tools": [// "latexmk"// ]// &#125;, // &#123;// "name": "xelatex",// "tools": [// "xelatex"// ]// &#125;,// &#123;// "name": "pdflatex -&gt; bibtex -&gt; pdflatex*2",// "tools": [// "pdflatex",// "bibtex",// "pdflatex",// "pdflatex"// ]// &#125;// ],// "latex-workshop.view.pdf.viewer": "tab",// "latex-workshop.latex.clean.fileTypes": [// "*.aux",// "*.bbl",// "*.blg",// "*.idx",// "*.ind",// "*.lof",// "*.lot",// "*.out",// "*.toc",// "*.acn",// "*.acr",// "*.alg",// "*.glg",// "*.glo",// "*.gls",// "*.ist",// "*.fls",// "*.log",// "*.fdb_latexmk"// ],// //"latex-workshop.autoClean.run": "onBuilt",// //"latex-workshop.latex.autoBuild.cleanAndRetry.enabled": true,// "explorer.confirmDelete": false// ******************** end *************************]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之cat()函数]]></title>
    <url>%2F2021%2F04%2F30%2FPytorch%E4%B9%8Bcat()%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1. cat函数 写在前面： 参考文章： https://www.cnblogs.com/zhaoyingjie/p/14636468.html 1. cat函数cat是concatnate的意思：拼接，联系在一起。 先说cat( )的普通用法 如果我们有两个tensor是A和B，想把他们拼接在一起，需要如下操作： 12C = torch.cat( (A,B),0 ) #按维数0拼接（竖着拼）C \= torch.cat( (A,B),1 ) #按维数1拼接（横着拼） 12345678910111213141516171819202122232425262728\&gt;&gt;&gt; import torch\&gt;&gt;&gt; A=torch.ones(2,3) #2x3的张量（矩阵） &gt;&gt;&gt; Atensor(\[\[ 1., 1., 1.\], \[ 1., 1., 1.\]\])\&gt;&gt;&gt; B=2\*torch.ones(4,3) #4x3的张量（矩阵） &gt;&gt;&gt; Btensor(\[\[ 2., 2., 2.\], \[ 2., 2., 2.\], \[ 2., 2., 2.\], \[ 2., 2., 2.\]\])\&gt;&gt;&gt; C=torch.cat((A,B),0) #按维数0（行）拼接&gt;&gt;&gt; Ctensor(\[\[ 1., 1., 1.\], \[ 1., 1., 1.\], \[ 2., 2., 2.\], \[ 2., 2., 2.\], \[ 2., 2., 2.\], \[ 2., 2., 2.\]\])\&gt;&gt;&gt; C.size()torch.Size(\[6, 3\])\&gt;&gt;&gt; D=2\*torch.ones(2,4) #2x4的张量（矩阵）&gt;&gt;&gt; C=torch.cat((A,D),1)#按维数1（列）拼接&gt;&gt;&gt; Ctensor(\[\[ 1., 1., 1., 2., 2., 2., 2.\], \[ 1., 1., 1., 2., 2., 2., 2.\]\])\&gt;&gt;&gt; C.size()torch.Size(\[2, 7\])]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo博客打开空白]]></title>
    <url>%2F2021%2F04%2F29%2Fhexo%E5%8D%9A%E5%AE%A2%E6%89%93%E5%BC%80%E7%A9%BA%E7%99%BD%2F</url>
    <content type="text"><![CDATA[写在前面： 由于每个人遇到的问题不一样，因此我会将查到的解决方案都放入参考文章，请自行查阅 参考文章： https://github.com/hexojs/hexo/issues/3525 https://blog.csdn.net/zhouzixin053/article/details/53038679 https://blog.csdn.net/qq_45698055/article/details/104353763 https://github.com/iissnan/hexo-theme-next/issues/1214 我的解决方法：将两个主题来回切换上传 上面的各种方式我都试了一下，并无用。但是，在 issue 讨论中看到有人提出了切换主题的想法 我先将 next 主题换为自带的 landscape ，上传一次，发现可以查看然后再将 landscape 切换为 next 重新上传 最终出现了我的博文]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyTorch之scatter()与scatter_()函数]]></title>
    <url>%2F2021%2F04%2F28%2FPyTorch%E4%B9%8Bscatter()%E4%B8%8Escatter_()%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1. 参考一 scatter() scatter_() 2. 参考二 pytorch 深入理解 tensor.scatter_ ()用法 1 API格式 2 具体示例 2.1 dim = 0 下的结果分析 参考文章： https://blog.csdn.net/weixin_45999482/article/details/115728139?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-1&amp;spm=1001.2101.3001.4242 https://blog.csdn.net/ao1886/article/details/107749007?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_title-5&amp;spm=1001.2101.3001.4242 1. 参考一仔细看了PyTorch的文档才搞懂这两个函数PyTorch: torch.Tensor.scatter另一个文档: pytorch_scatter scatter()这个是scatter_()的out-of-place版本，即函数修改的不是原tensor在vscode里面看这个函数有两种： 12scatter(self: Tensor, dim: _int, index: Tensor, src: Tensor) -&gt; Tensor# param dim:_int 是让输入第一个参数（？ 12scatter(self: Tensor, dim: _int, index: Tensor, value: Number) -&gt; Tensor# param dim:_int 两个的区别在于最后一个参数，可以用Tensor作为src进行填充，也可以指定某个数值作为填充 scatter_()一句话总结：在一个tensor的基础上，在dim维上，根据index选择src的一些数填到原始的那个tensor里。对于scatter，向原始tensor填数得到另外一个tensor，原tensor不变；对于scatter 2. 参考二pytorch 深入理解 tensor.scatter_ ()用法在 pytorch 库下理解 torch.tensor.scatter()的用法。作者在网上搜索了很多方法，最后还是觉得自己写一篇更为详细的比较好，转载请注明。首先，scatter() 和 scatter_() 的作用是一样的，但是 scatter() 不会直接修改原来的 Tensor，而 scatter_() 会修改原先的 Tensor。 1 API格式1torch.Tensor.scatter_(dim, index, src) → Tensor 字面意思：对一个 torch.Tensor 进行操作，dim，index，src三个为输入的参数。 dim 就是在哪个维度进行操作，注意，dim 的不同，在其他条件相同的条件下得到的output 也不同。 index 是输入的索引。 src 就是输入的向量，也就是 input。 最后，函数返回一个 Tensor。 2 具体示例123456789101112131415161718192021222324252627282930313233import torch as th# import torch 包a = th.rand(2,5) # 初始化向量 a，size 为 (2, 5)，二维向量，2行5列，每个元素是 0 到 1 的均匀分布采样# 把 a 作为 src，也就是 input # a 的初始化数值如下: src tensor:tensor([[0.6789, 0.7350, 0.6104, 0.7777, 0.9613], [0.1432, 0.8788, 0.3269, 0.0063, 0.6070]]) # 初始化 b 为size 为 (3, 5) 的向量，二维向量，3行5列，每个元素被初始化为 0b = th.zeros(3, 5).scatter_( dim = 0, index = th.LongTensor([[0, 1, 2, 0, 0],[2, 0, 0, 1, 2]]), src = a )# dim = 0, out:tensor([[0.6789, 0.8788, 0.3269, 0.7777, 0.9613], [0.0000, 0.7350, 0.0000, 0.0063, 0.0000], [0.1432, 0.0000, 0.6104, 0.0000, 0.6070]]) # 初始化 c 为size 为 (3, 5) 的向量，二维向量，3行5列，每个元素被初始化为 0c = th.zeros(3, 5).scatter_( dim = 1, th.LongTensor([[0, 1, 2, 0, 0],[2, 0, 0, 1, 2]]), src = a )# dim = 1, out:tensor([[0.9613, 0.7350, 0.6104, 0.0000, 0.0000], [0.3269, 0.0063, 0.6070, 0.0000, 0.0000], [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]) 下面来解释一下，b，c 内的元素分别是怎么得到的。 2.1 dim = 0 下的结果分析先说 b，也就是 dim =0 下得到的结果。我们来看下官方给的说明文字： 123self[index[i][j][k]][j][k] = src[i][j][k] # if dim == 0self[i][index[i][j][k]][k] = src[i][j][k] # if dim == 1self[i][j][index[i][j][k]] = src[i][j][k] # if dim == 2 因为这时 dim = 0，且只有 2 个维度，所以我们只用看第一行就行。 self [index[i][j]] [j] = src[i][j] # if dim == 0 仅用这一个公式就确定了 b 中所有元素的取值，与 a 的映射关系。这里等号左边的 self 可看做 output，也就是 b；src 是我们的输入向量，也就是 a。这里的 i，j 分别是输入向量 src 的 size 的取值。比如，本例中 a 的 size 为 (2，5)，也就是说，对于 a 中的元素，i 的取值为 0，1；j 的取值为 0，1，2，3，4。a 中的元素的索引也就是(0，0)，(0，1)，… (0，4)；(1，0)，(1，1)，…(1，4) 完毕，一共 2*5 = 10 个元素。了解了这些以后，通过举例来说明 b 中的元素都是如何确定的。 123456789101112131415161718192021222324252627282930index = th.LongTensor([[0, 1, 2, 0, 0],[2, 0, 0, 1, 2]])，我们列举一些元素来说明其映射关系当 i = 0，j = 0 时，我们用类似上述确定 a 索引的方式确定了 index[i][j] = 0，这里的 0 就是 [0，1，2，0，0] 中最左边的 0，则 b = out[index[i][j]][j] = out[0][0] = src[0][0] = 0.6789当 i = 0，j = 1 时，index[0][1] = 1，这里的 1 就是 [0，1，2，0，0] 中的 1，同理，b = out[index[i][j]][j] = out[1][1] = src[0][1] = 0.7350当 i = 0，j = 2 时，index[0][2] = 2，这里的 2 就是 [0，1，2，0，0] 中的 2，同理，b = out[index[i][j]][j] = out[2][2] = src[0][2] = 0.6104注意，这里的out[2][2] 不是第 2 行，第 2 列的元素，是第 3 行，第 3 列的元素当 i = 1，j = 1 时，index[1][1] = 0，这里的 0 就是 [2，0，0，1，2] 中最**左**边的 0，同理，b = out[index[i][j]][j] = out[0][1] = src[1][1] = 0.8788当 i = 1，j = 3 时，index[1][3] = 0，这里的 0 就是 [2，0，0，1，2] 中最**右**边的 0，同理，b = out[index[i][j]][j] = out[0][1] = src[1][3] = 0.0063当 i = 1，j = 4 时，index[1][4] = 2，这里的 2 就是 [2，0，0，1，2] 中最**左**边的 0，同理，b = out[index[i][j]][j] = out[0][1] = src[1][4] = 0.6070由此得到了 b 中有映射关系的元素，剩余的元素，由于 b 被初始化为全 0 向量，所以剩余的元素均为 0 。 dim = 1的时候，同理。只是换了一种映射机制，如法炮制。 有任何关于内容不够详细，解释不清，错误等欢迎留言。转载请注明，支持原创，谢谢。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch错误集锦--那些年我们的血泪史]]></title>
    <url>%2F2021%2F04%2F27%2FPytorch%E9%94%99%E8%AF%AF%E9%9B%86%E9%94%A6--%E9%82%A3%E4%BA%9B%E5%B9%B4%E6%88%91%E4%BB%AC%E7%9A%84%E8%A1%80%E6%B3%AA%E5%8F%B2%2F</url>
    <content type="text"><![CDATA[已解决 1. IndexError: scatter_(): Expected dtype int64 for index. 2. TypeError: expected Long (got Float) 3. RuntimeError: unsupported operation: some elements of the input tensor and the written-to tensor refer to a single memory location. Please clone() the tensor before performing the operation. 未解决 参考文章： pytorch系列（一）常见错误 FloatTensor和LongTensor的转换，TypeError: expected Long (got Float) 已解决 1. IndexError: scatter_(): Expected dtype int64 for index. 错误分析： scatter要求数据是int64类型 解决方法： [x] 如果你定义的 tensor 时写的是 torch.Tensor(x) ，可改成 torch.LongTensor(x) ，指定为int64类型。 2. TypeError: expected Long (got Float) 错误分析： zero 是 FloatTensor 类型，在直接将其转换为LongTensor时失败 解决方法： [x] 先将 zero 转换为 numpy()，再转换为 LongTensor ，具体代码如下：torch.LongTensor(zero.numpy()) 3. RuntimeError: unsupported operation: some elements of the input tensor and the written-to tensor refer to a single memory location. Please clone() the tensor before performing the operation.错误分析： 运行时错误：不支持的操作：输入张量和写入张量的某些元素引用单个内存位置。请在执行操作前克隆（）张量。 解决方法： [x] 先将 zero 转换为 numpy()，再转换为 LongTensor ，具体代码如下：torch.LongTensor(zero.numpy()) 未解决]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之tensor个人总结]]></title>
    <url>%2F2021%2F04%2F26%2FPytorch%E4%B9%8Btensor%E4%B8%AA%E4%BA%BA%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[1. tensor 使用 onehot 编码 —-tensor的建立 2. tensor 进行维度扩展 —其中一维是奇数 3. 写在前面： 本文中的代码来自于我自己的项目，都是根据个人需要进行的编写 其中的调用函数可能也是自己的 如果有错，希望您能提出并给予一定的指导 参考文章： 1. tensor 使用 onehot 编码 —-tensor的建立123456789101112131415# label的权重矩阵 三维gt = np.random.randint(0, args.class_num, size=[args.embed_dim // 2, args.embed_dim // 2])# 先生成一个 （args.embed_dim // 2） * （args.embed_dim // 2） 的label，值在class_num以内，意思是class_num类分割任务gt = torch.LongTensor(gt)def get_one_hot(label, N): size = list(label.size()) label = label.view(-1) # reshape 为向量 ones = torch.sparse.torch.eye(N) ones = ones.index_select(0, label) # 用上面的办法转为换one hot size.append(N) # 把类别输目添到size的尾后，准备reshape回原来的尺寸 return ones.view(*size)args.label_weight = get_one_hot(gt, args.class_num) 2. tensor 进行维度扩展 —其中一维是奇数 我的期望值是进行0扩展朋友提出的思路是通过一次Liner虽然我觉得不对选择使用 torch.cat 实现 各种失败的尝试：expend label_att_2 = label_att_2.expand(128,128) # 报错 不为 1 的无法进行扩展 repeat label_att_2 = label_att_2.repeat(1,128.0/11.0) #报错 必须扩展为正数倍 reshape label_att_2 = label_att_2.reshape(128,128) # RuntimeError: shape ‘[128, 128]’ is invalid for input of size 1408 Linear1234# print(label_att_2.shape) # torch.Size([128, 11])connected_layer = nn.Linear(in_features=11,out_features=128)label_att_2 = connected_layer(label_att_2)# print(label_att_2.shape) # torch.Size([128, 128]) 123456789101112131415161718192021import torchimport numpy as nplabel = np.eye(11)label = torch.LongTensor(label)# print(label)# print(label.shape)zero = torch.zeros(11,(128-11))# print(zero)# print(zero.shape)res = torch.cat((label,zero),1)# print(res)# print(res.shape)zero1 = torch.zeros((128-11),128)# print(zero1.shape)res1 = torch.cat((res,zero1),0)print(res1.shape) 3.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之tensor的创建]]></title>
    <url>%2F2021%2F04%2F25%2FPytorch%E4%B9%8Btensor%E7%9A%84%E5%88%9B%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[1. torch.eye(n, m=None, out=None) 2. torch.from_numpy(ndarray) 3. torch.linspace(start, end, steps=100, out=None) 4. torch.logspace(start, end, steps=100, out=None) 5. torch.ones(*sizes, out=None) 6. torch.rand(*size, out=None) 7. torch.randn(*size, out=None) 8. torch.randperm(n, out=None) 9. torch.arange(start, end, step=1, out=None) 10. torch.range(start, end, step=1, out=None) 11. torch.zeros(*size, out=None) 参考文章： https://blog.csdn.net/gyt15663668337/article/details/90944442 1. torch.eye(n, m=None, out=None)说明：创建一个2维张量，对角线数字为1， 其他位置为0。也就是一个单位矩阵。 参数： n — 行数，m — 列数，如果为None，默认等于n，out — 输出张量 123456789&gt;&gt;&gt; import torch&gt;&gt;&gt; torch.eye(3)tensor([[1., 0., 0.], [0., 1., 0.], [0., 0., 1.]])&gt;&gt;&gt; torch.eye(3, 4)tensor([[1., 0., 0., 0.], [0., 1., 0., 0.], [0., 0., 1., 0.]]) 2. torch.from_numpy(ndarray)说明：将numpy.ndarray转换为Tensor。返回的Tensor和numpy的ndarray共享同一内存空间。修改一个会导致另外一个也被修改。返回的张量不能调整大小。 12345678&gt;&gt;&gt; import numpy&gt;&gt;&gt; a = numpy.array([1, 2, 3])&gt;&gt;&gt; t = torch.from_numpy(a)&gt;&gt;&gt; ttensor([1, 2, 3], dtype=torch.int32)&gt;&gt;&gt; t[0] = -1&gt;&gt;&gt; aarray([-1, 2, 3]) 3. torch.linspace(start, end, steps=100, out=None)说明：返回start和end之间长度为steps的一维张量，也就是start和end之间的steps个数。并且其返回的是一个等差数列。 参数： start(float) — 点集的起始值，end(float) — 点集的最终值，steps(int) — start和end之间的采样数，即返回多少个数out(Tensor,可选) — 结果张量1234567&gt;&gt;&gt; torch.linspace(-10, 10, steps=5)tensor([-10., -5., 0., 5., 10.])&gt;&gt;&gt; torch.linspace(0, 5, 5)tensor([0.0000, 1.2500, 2.5000, 3.7500, 5.0000])&gt;&gt;&gt; torch.linspace(start=-10, end=10, steps=10)tensor([-10.0000, -7.7778, -5.5556, -3.3333, -1.1111, 1.1111, 3.3333, 5.5556, 7.7778, 10.0000]) 4. torch.logspace(start, end, steps=100, out=None)说明：返回一个1维张量，包含在区间和上，以对数刻度均匀间隔的steps个点。输出1维张量的长度为steps。 参数： start(float) — 点集的起始点end(float) — 点集的最终点steps(int) — 在start和end间生成的样本数out(Tensor,可选) — 结果张量1234&gt;&gt;&gt; torch.logspace(start=-10, end=10, steps=5)tensor([1.0000e-10, 1.0000e-05, 1.0000e+00, 1.0000e+05, 1.0000e+10])&gt;&gt;&gt; torch.logspace(0.1, 1.0, 5)tensor([ 1.2589, 2.1135, 3.5481, 5.9566, 10.0000]) 5. torch.ones(*sizes, out=None)说明：返回一个全为1的张量，形状由可变参数sizes定义。 参数： sizes(int) — 整数序列，定义了输出的形状。如(3,3）out(Tensor, 可选) — 结果张量12345&gt;&gt;&gt; torch.ones(2, 3)tensor([[1., 1., 1.], [1., 1., 1.]])&gt;&gt;&gt; torch.ones(5)tensor([1., 1., 1., 1., 1.]) 6. torch.rand(*size, out=None)说明：返回一个张量，填充在[0,1]区间的一组均匀分布随机数。Tensor的形状由变量sizes定义。 参数： sizes(int) — 整数序列，定义了输出形状out(Tensor, 可选) — 结果张量12345&gt;&gt;&gt; torch.rand(4)tensor([0.4962, 0.0724, 0.0478, 0.3524])&gt;&gt;&gt; torch.rand(2, 3)tensor([[0.3200, 0.7308, 0.3226], [0.8039, 0.2359, 0.7256]]) 7. torch.randn(*size, out=None)说明：返回一个张量，包含了从正态分布(均值为0，方差为1)中抽取一组随机数。Tensor的形状由变量sizes定义。 参数： sizes(int) — 整数序列，定义了输出形状out(Tensor, 可选) — 结果张量12345&gt;&gt;&gt; torch.randn(4)tensor([ 0.3094, 0.4774, -0.1807, 0.9894])&gt;&gt;&gt; torch.randn(2, 3)tensor([[-0.3299, -0.0495, -1.4758], [-0.0680, -0.3875, 0.9846]]) 8. torch.randperm(n, out=None)说明：返回以LongTenor，输入参数n，返回一个从0到n-1的随机整数排列。 参数： n(int) — 上限，即最大值。 torch.randperm(4)tensor([3, 1, 0, 2]) 9. torch.arange(start, end, step=1, out=None)说明： 返回一个1维张量，长度为，中间计算值，向下取整的意思。包含从start到end，以step为步长的一组序列值。默认步长为1。 参数： start(float) — 该点集的起始点end(float) — 点集的终止点step(float) — 相邻点的间隔大小out(Tensor, 可选的) — 结果张量 1234&gt;&gt;&gt; torch.arange(1, 4)tensor([1, 2, 3])&gt;&gt;&gt; torch.arange(1, 2.5, 0.5)tensor([1.0000, 1.5000, 2.0000]) 10. torch.range(start, end, step=1, out=None)说明：返回一维张量，长度为+1，从start开始，到end结束。以step为步长的一组值。step是两个值之间的间隔。 参数： start(float) — 点集的起始点end(float) — 点集的最终值step(int) — 相邻点之间的间隔大小out(Tensor, 可选的) — 结果张量 1234567&gt;&gt;&gt; torch.range(1, 4)__main__:1: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].tensor([1., 2., 3., 4.])&gt;&gt;&gt; torch.range(1, 4)tensor([1., 2., 3., 4.])&gt;&gt;&gt; torch.range(1, 4, 0.5)tensor([1.0000, 1.5000, 2.0000, 2.5000, 3.0000, 3.5000, 4.0000]) 11. torch.zeros(*size, out=None)说明：返回一个全0的张量，形状由可变参数sizes定义。 参数： sizes(int) — 整数序列，定义了输出形状out(Tensor, 可选) — 结果张量 12345&gt;&gt;&gt; torch.zeros(2, 3)tensor([[0., 0., 0.], [0., 0., 0.]])&gt;&gt;&gt; torch.zeros(5)tensor([0., 0., 0., 0., 0.]) 总结：这部分内容主要是创建操作，创建一些随机数，或者是矩阵。在pytorch中，他们都是张量类型。简单的创建操作。反复练习。方可掌握。如果有numpy的基础。那就更加容易学习。其实无论numpy，tensorflow，pytorch等。在创建一些随机数/矩阵中，他们都是相同的。只不过是存在不同的第三方库中。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之tensor维度的扩展，挤压，扩张]]></title>
    <url>%2F2021%2F04%2F23%2FPytorch%E4%B9%8Btensor%E7%BB%B4%E5%BA%A6%E7%9A%84%E6%89%A9%E5%B1%95%EF%BC%8C%E6%8C%A4%E5%8E%8B%EF%BC%8C%E6%89%A9%E5%BC%A0%2F</url>
    <content type="text"><![CDATA[1. 维度的扩展 2. 挤压维度 3. 维度扩张 参考文章： https://www.cnblogs.com/52dxer/p/13771279.html https://blog.csdn.net/real_ilin/article/details/105874641?utm_medium=distribute.pc_relevant.none-task-blog-baidujs_baidulandingword-1&amp;spm=1001.2101.3001.4242 Pytorch Tensor维度变换 pytorch扩展tensor的一个维度或多个维度 数据本身不发生改变，数据的访问方式发生了改变 1. 维度的扩展函数： unsqueeze() 123456789101112131415# a是一个4维的 a = torch.randn(4, 3, 28, 28) print('a.shape\n', a.shape) print('\n维度扩展（变成5维的）：') print('第0维前加1维') print(a.unsqueeze(0).shape) print('第4维前加1维') print(a.unsqueeze(4).shape) print('在-1维前加1维') print(a.unsqueeze(-1).shape) print('在-4维前加1维') print(a.unsqueeze(-4).shape) print('在-5维前加1维') print(a.unsqueeze(-5).shape) 输出结果 1234567891011121314a.shape torch.Size([4, 3, 28, 28])维度扩展（变成5维的）：第0维前加1维torch.Size([1, 4, 3, 28, 28])第4维前加1维torch.Size([4, 3, 28, 28, 1])在-1维前加1维torch.Size([4, 3, 28, 28, 1])在-4维前加1维torch.Size([4, 1, 3, 28, 28])在-5维前加1维torch.Size([1, 4, 3, 28, 28]) ==注意,第5维前加1维，就会出错== 12# print(a.unsqueeze(5).shape)# Errot：Dimension out of range (expected to be in range of -5, 4], but got 5) 连续扩维：unsqueeze() 123456789101112# b是一个1维的b = torch.tensor([1.2, 2.3])print('b.shape\n', b.shape)print()# 0维之前插入1维，变成1,2]print(b.unsqueeze(0))print()# 1维之前插入1维，变成2,1]print(b.unsqueeze(1))# 连续扩维,然后再对某个维度进行扩张print(b.unsqueeze(1).unsqueeze(2).unsqueeze(0).shape) 输出结果 12345678b.shape torch.Size([2])tensor([[1.2000, 2.3000]])tensor([[1.2000], [2.3000]])torch.Size([1, 2, 1, 1]) 2. 挤压维度函数：squeeze() 1234567# 挤压维度，只会挤压shape为1的维度，如果shape不是1的话，当前值就不会变c = torch.randn(1, 32, 1, 2)print(c.shape)print(c.squeeze(0).shape)print(c.squeeze(1).shape) # shape不是1，不会变print(c.squeeze(2).shape)print(c.squeeze(3).shape) # shape不是1，不会变 输出结果 12345torch.Size([1, 32, 1, 2])torch.Size([32, 1, 2])torch.Size([1, 32, 1, 2])torch.Size([1, 32, 2])torch.Size([1, 32, 1, 2]) 3. 维度扩张函数1：expand()：扩张到多少 123456# shape的扩张# expand():对shape为1的进行扩展，对shape不为1的只能保持不变，因为不知道如何变换，会报错d = torch.randn(1, 32, 1, 1)print(d.shape)print(d.expand(4, 32, 14, 14).shape) 输出结果 12torch.Size([1, 32, 1, 1])torch.Size([4, 32, 14, 14]) 函数2：repeat()方法，扩张多少倍 123d=torch.randn([1,32,4,5])print(d.shape)print(d.repeat(4,32,2,3).shape) 输出结果 12torch.Size([1, 32, 4, 5])torch.Size([4, 1024, 8, 15])]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之nn.init中实现的初始化函数]]></title>
    <url>%2F2021%2F04%2F22%2FPytorch%E4%B9%8Bnn.init%E4%B8%AD%E5%AE%9E%E7%8E%B0%E7%9A%84%E5%88%9D%E5%A7%8B%E5%8C%96%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1. 均匀分布 2. 正太分布 3. 初始化为常数 4. Xavier 5. kaiming (He initialization) 参考文章： https://blog.csdn.net/dss_dssssd/article/details/83959474 torch.init 1. 均匀分布torch.nn.init.uniform_(tensor, a=0, b=1)服从~U(a,b) 2. 正太分布torch.nn.init.normal_(tensor, mean=0, std=1)服从~N(mean,std) 3. 初始化为常数torch.nn.init.constant_(tensor, val)初始化整个矩阵为常数val 4. Xavier基本思想是通过网络层时， 输入和输出的方差相同 ，包括前向传播和后向传播。具体看以下博文： 为什么需要Xavier 初始化？文章第一段通过sigmoid激活函数讲述了为何初始化？简答的说就是： 如果初始化值很小，那么随着层数的传递，方差就会趋于0，此时输入值 也变得越来越小，在sigmoid上就是在0附近，接近于线性， 失去了非线性 如果初始值很大，那么随着层数的传递，方差会迅速增加，此时输入值变得很大，而sigmoid在大输入值写倒数趋近于0，反向传播时会遇到 梯度消失 的问题 其他的激活函数同样存在相同的问题。 https://prateekvjoshi.com/2016/03/29/understanding-xavier-initialization-in-deep-neural-networks/ 所以论文提出，在每一层网络保证输入和输出的方差相同。 xavier初始化的简单推导https://blog.csdn.net/u011534057/article/details/51673458 对于Xavier初始化方式，pytorch提供了uniform和normal两种： torch.nn.init.xavier_uniform_(tensor, gain=1) 均匀分布 ~U(−a,a)其中， a的计算公式： torch.nn.init.xavier_normal_(tensor, gain=1) 正态分布~ N(0,std)其中std的计算公式： 5. kaiming (He initialization)Xavier在tanh中表现的很好，但在Relu激活函数中表现的很差，所何凯明提出了针对于Relu的初始化方法。Delving deep into rectifiers: Surpassing human-level performance on ImageNet classification He, K. et al. (2015)该方法基于He initialization,其简单的思想是：在ReLU网络中 ，假定每一层有一半的神经元被激活，另一半为0，所以，要保持方差不变，只需要在 Xavier 的基础上再除以2 也就是说在方差推到过程中 ，式子左侧除以2.pytorch也提供了两个版本： torch.nn.init.kaiminguniform(tensor, a=0, mode=’fan_in’, nonlinearity=’leaky_relu’)， 均匀分布 ~U(−bound,bound)其中，bound的计算公式： torch.nn.init.kaimingnormal(tensor, a=0, mode=’fan_in’, nonlinearity=’leaky_relu’), 正态分布~N(0,std) 其中，std的计算公式： 两函数的参数： a：该层后面一层的激活函数中负的斜率(默认为ReLU，此时a=0) mode：‘fan_in’ (default) 或者 ‘fan_out’. 使用fan_in保持weights的方差在前向传播中不变；使用fan_out保持weights的方差在反向传播中不变 针对于Relu的激活函数 ，基本使用He initialization，pytorch也是使用kaiming 初始化卷积层参数的]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之matmul函数]]></title>
    <url>%2F2021%2F04%2F21%2FPytorch%E4%B9%8Bmatmul%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1. 矩阵相乘 写在前面： 参考文章： https://blog.csdn.net/ganxiwu9686/article/details/95204013 1. 矩阵相乘从官方文档可以看出 mm只能进行矩阵乘法,也就是输入的两个tensor维度只能是（b m）, (m k) 得到（b * k） bmm是两个三维张量相乘, 两个tensor维度是，（b m n）, (b n k) 得到（b m k） matmul可以进行张量乘法, 输入可以是高维. 总结：对位相乘用torch.mul；二维矩阵乘法用torch.mm；batch二维矩阵用torch.bmm；batch，广播用torch.matmul]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch之permute函数]]></title>
    <url>%2F2021%2F04%2F21%2FPytorch%E4%B9%8Bpermute%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[1 先看看官方中英文doc： 1.1 permute(dims) 1.2 permute(*dims) → Tensor 2 pytorch permute的使用 2.1 transpose与permute的异同 2.2 permute函数与contiguous、view函数之关联 参考文章： https://zhuanlan.zhihu.com/p/76583143 1 先看看官方中英文doc：1.1 permute(dims) 将tensor的维度换位。 参数： - dims (int ..*) - 换位顺序 1.2 permute(*dims) → Tensor Permute the dimensions of this tensor. Parameters： *dims (int…) – The desired ordering of dimensions 2 pytorch permute的使用permute函数功能还是比较简单的，下面主要介绍几个细节点： 2.1 transpose与permute的异同Tensor.permute(a,b,c,d, …)：permute函数可以对任意高维矩阵进行转置，但没有 torch.permute() 这个调用方式， 只能 Tensor.permute()： torch.transpose(Tensor, a,b)：transpose只能操作2D矩阵的转置，有两种调用方式； 另：连续使用transpose也可实现permute的效果： 从以上操作中可知，permute相当于可以同时操作于tensor的若干维度，transpose只能同时作用于tensor的两个维度； 2.2 permute函数与contiguous、view函数之关联contiguous：view只能作用在contiguous的variable上，如果在view之前调用了transpose、permute等，就需要调用contiguous()来返回一个contiguous copy； 一种可能的解释是：有些tensor并不是占用一整块内存，而是由不同的数据块组成，而tensor的view()操作依赖于内存是整块的，这时只需要执行contiguous()这个函数，把tensor变成在内存中连续分布的形式； 判断ternsor是否为contiguous，可以调用torch.Tensor.is_contiguous()函数:]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法]]></title>
    <url>%2F2021%2F04%2F20%2F%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95%2F</url>
    <content type="text"><![CDATA[排序算法总结 1. 冒泡排序 2. 选择排序 3. 插入排序 4. 希尔排序 5. 快速排序 6. 归并排序 7. 堆排序(HeapSort) 8. 基数排序(RadixSort) 参考文章： https://www.runoob.com/w3cnote/sort-algorithm-summary.html https://blog.csdn.net/mengyujia1234/article/details/90179896 排序算法总结 1. 冒泡排序 基本思想：两个数比较大小，较大的数下沉，较小的数冒起来。 过程： 比较相邻的两个数据，如果第二个数小，就交换位置。 从后向前两两比较，一直到比较最前两个数据。最终最小数被交换到起始的位置，这样第一个最小数的位置就排好了。 继续重复上述过程，依次将第2.3…n-1个最小数排好位置。 2. 选择排序 基本思想：在长度为N的无序数组中，第一次遍历n-1个数，找到最小的数值与第一个元素交换；第二次遍历n-2个数，找到最小的数值与第二个元素交换；。。。第n-1次遍历，找到最小的数值与第n-1个元素交换，排序完成。 3. 插入排序基本思想：在要排序的一组数中，假定前n-1个数已经排好序，现在将第n个数插到前面的有序数列中，使得这n个数也是排好顺序的。如此反复循环，直到全部排好顺序。 4. 希尔排序https://blog.csdn.net/qq_41519304/article/details/106021319 基本思想：在要排序的一组数中，根据某一增量分为若干子序列，并对子序列分别进行插入排序。然后逐渐将增量减小,并重复上述过程。直至增量为1,此时数据序列基本有序,最后进行插入排序。 5. 快速排序基本思想：（分治） 先从数列中取出一个数作为key值；将比这个数小的数全部放在它的左边，大于或等于它的数全部放在它的右边；对左右两个小数列重复第二步，直至各区间只有1个数。 6. 归并排序基本思想：参考归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。首先考虑下如何将2个有序数列合并。这个非常简单，只要从比较2个数列的第一个数，谁小就先取谁，取了后就在对应数列中删除这个数。然后再进行比较，如果有数列为空，那直接将另一个数列的数据依次取出即可。 7. 堆排序(HeapSort)https://blog.csdn.net/mengyujia1234/article/details/90179896 8. 基数排序(RadixSort)基本思想：BinSort想法非常简单，首先创建数组A[MaxValue]；然后将每个数放到相应的位置上（例如17放在下标17的数组位置）；最后遍历数组，即为排序后的结果。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bilstm]]></title>
    <url>%2F2021%2F04%2F20%2FBilstm%2F</url>
    <content type="text"><![CDATA[一、介绍 1.1 文章组织 1.2 情感分类任务 1.3 什么是LSTM和BiLSTM？ 1.4 为什么使用LSTM与BiLSTM？ 二、BiLSTM原理简介 2.1 LSTM介绍 2.1.1 总体框架 2.1.2 详细介绍计算过程 计算遗忘门，选择要遗忘的信息。 2. 计算记忆门，选择要记忆的信息。 3. 计算当前时刻细胞状态 计算输出门和当前时刻隐层状态 2.2 BiLSTM介绍 三、BiLSTM代码实现样例 3.1 模型搭建 3.2 模型训练 3.3 模型测试 四、总结 五、参考资料 参考文章： https://www.jiqizhixin.com/articles/2018-10-24-13 http://colah.github.io/posts/2015-08-Understanding-LSTMs/ 一、介绍1.1 文章组织本文简要介绍了BiLSTM的基本原理，并以句子级情感分类任务为例介绍为什么需要使用LSTM或BiLSTM进行建模。在文章的最后，我们给出在PyTorch下BiLSTM的实现代码，供读者参考。 1.2 情感分类任务自然语言处理中情感分类任务是对给定文本进行情感倾向分类的任务，粗略来看可以认为其是分类任务中的一类。对于情感分类任务，目前通常的做法是先对词或者短语进行表示，再通过某种组合方式把句子中词的表示组合成句子的表示。最后，利用句子的表示对句子进行情感分类。 举一个对句子进行褒贬二分类的例子。 句子：我爱赛尔情感标签：褒义 1.3 什么是LSTM和BiLSTM？LSTM的全称是Long Short-Term Memory，它是RNN（Recurrent Neural Network）的一种。LSTM由于其设计的特点，非常适合用于对时序数据的建模，如文本数据。BiLSTM是Bi-directional Long Short-Term Memory的缩写，是由前向LSTM与后向LSTM组合而成。两者在自然语言处理任务中都常被用来建模上下文信息。 1.4 为什么使用LSTM与BiLSTM？将词的表示组合成句子的表示，可以采用相加的方法，即将所有词的表示进行加和，或者取平均等方法，但是这些方法没有考虑到词语在句子中前后顺序。如句子”我不觉得他好”。”不”字是对后面”好”的否定，即该句子的情感极性是贬义。使用LSTM模型可以更好的捕捉到较长距离的依赖关系。因为LSTM通过训练过程可以学到记忆哪些信息和遗忘哪些信息。 但是利用LSTM对句子进行建模还存在一个问题：无法编码从后到前的信息。在更细粒度的分类时，如对于强程度的褒义、弱程度的褒义、中性、弱程度的贬义、强程度的贬义的五分类任务需要注意情感词、程度词、否定词之间的交互。举一个例子，”这个餐厅脏得不行，没有隔壁好”，这里的”不行”是对”脏”的程度的一种修饰，通过BiLSTM可以更好的捕捉双向的语义依赖。 二、BiLSTM原理简介2.1 LSTM介绍2.1.1 总体框架LSTM模型是由t时刻的输入词$Xt$，细胞状态$C_t$，临时细胞状态$\tilde{C_t}$，隐层状态$h_t$，遗忘门$f_t$，记忆门$\dot{i_t}$，输出门$o_t$组成。LSTM的计算过程可以概括为，通过对细胞状态中信息遗忘和记忆新的信息使得对后续时刻计算有用的信息得以传递，而无用的信息被丢弃，并在每个时间步都会输出隐层状态$h{t-1}$，其中遗忘，记忆与输出由通过上个时刻的隐层状态$h_{t-1}$和当前输入$X_t$计算出来的遗忘门$f_t$，记忆门$\dot{i_t}$，输出门$o_t$来控制。 总体框架如图1所示。 图1. LSTM总体框架 2.1.2 详细介绍计算过程计算遗忘门，选择要遗忘的信息。 输入：前一时刻的隐层状态 $h_{t-1}$，当前时刻的输入词 $X_t$输出：遗忘门的值$f_t$ 图2. 计算遗忘门 2. 计算记忆门，选择要记忆的信息。 输入：前一时刻的隐层状态 $h_{t-1}$，当前时刻的输入词 $X_t$输出：记忆门的值$\dot{i_t}$，临时细胞状态$\tilde{C_t}$ 图3. 计算记忆门和临时细胞状态 3. 计算当前时刻细胞状态 输入：记忆门的值$\dot{it}$，遗忘门的值$f_t$，临时细胞状态$\tilde{C_t}$，上一刻细胞状态$C{t-1}$输出：当前时刻细胞状态$C_t$ 图4. 计算当前时刻细胞状态 计算输出门和当前时刻隐层状态 输入：前一时刻的隐层状态$h_{t-1}$，当前时刻的输入词$X_t$ ，当前时刻细胞状态$C_t$输出：输出门的值$o_t$，隐层状态$h_t$ 图5. 计算输出门和当前时刻隐层状态 最终，我们可以得到与句子长度相同的隐层状态序列{$ h0, h_1, … , h{n-1}$}。 2.2 BiLSTM介绍前向的LSTM与后向的LSTM结合成BiLSTM。比如，我们对”我爱中国”这句话进行编码，模型如图6所示。 图6. 双向LSTM编码句子前向的$LSTML$依次输入”我”，”爱”，”中国”得到三个向量{$h{L0}$, $h{L1}$,$h{L2}$}。后向的$LSTMR$依次输入”中国”，”爱”，”我”得到三个向量{$h{R0}$, $h{R1}$,$h{R2}$}。最后将前向和后向的隐向量进行拼接得到{[$h{L0}$, $h{R2}$],[$h{L1}$, $h{R1}$],[$h{L2}$, $h{R0}$]}，即{$h_0, h_1 , h_2$}。 对于情感分类任务来说，我们采用的句子的表示往往是[$h{L2}$, $h{R2}$]。因为其包含了前向与后向的所有信息，如图7所示。 图7. 拼接向量用于情感分类 三、BiLSTM代码实现样例3.1 模型搭建使用PyTorch搭建BiLSTM样例代码。代码地址为 https://github.com/albertwy/BiLSTM/。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394class BLSTM(nn.Module): """ Implementation of BLSTM Concatenation for sentiment classification task """ def __init__(self, embeddings, input_dim, hidden_dim, num_layers, output_dim, max_len=40, dropout=0.5): super(BLSTM, self).__init__() self.emb = nn.Embedding(num_embeddings=embeddings.size(0),embedding_dim=embeddings.size(1),padding_idx=0) self.emb.weight = nn.Parameter(embeddings) self.input_dim = input_dim self.hidden_dim = hidden_dim self.output_dim = output_dim # sen encoder self.sen_len = max_len self.sen_rnn = nn.LSTM(input_size=input_dim,hidden_size=hidden_dim,num_layers=num_layers,dropout=dropout,batch_first=True,bidirectional=True) self.output = nn.Linear(2 * self.hidden_dim, output_dim) def bi_fetch(self, rnn_outs, seq_lengths, batch_size, max_len): rnn_outs = rnn_outs.view(batch_size, max_len, 2, -1) # (batch_size, max_len, 1, -1) fw_out = torch.index_select(rnn_outs, 2, Variable(torch.LongTensor([0])).cuda()) fw_out = fw_out.view(batch_size * max_len, -1) bw_out = torch.index_select(rnn_outs, 2, Variable(torch.LongTensor([1])).cuda()) bw_out = bw_out.view(batch_size * max_len, -1) batch_range = Variable(torch.LongTensor(range(batch_size))).cuda() * max_len batch_zeros = Variable(torch.zeros(batch_size).long()).cuda() fw_index = batch_range + seq_lengths.view(batch_size) - 1 fw_out = torch.index_select(fw_out, 0, fw_index) # (batch_size, hid) bw_index = batch_range + batch_zeros bw_out = torch.index_select(bw_out, 0, bw_index) outs = torch.cat([fw_out, bw_out], dim=1) return outs def forward(self, sen_batch, sen_lengths, sen_mask_matrix): """ :param sen_batch: (batch, sen_length), tensor for sentence sequence :param sen_lengths: :param sen_mask_matrix: :return: """ ''' Embedding Layer | Padding | Sequence_length 40''' sen_batch = self.emb(sen_batch) batch_size = len(sen_batch) ''' Bi-LSTM Computation ''' sen_outs, _ = self.sen_rnn(sen_batch.view(batch_size, -1, self.input_dim)) sen_rnn = sen_outs.contiguous().view(batch_size, -1, 2 * self.hidden_dim) # (batch, sen_len, 2*hid) ''' Fetch the truly last hidden layer of both sides ''' sentence_batch = self.bi_fetch(sen_rnn, sen_lengths, batch_size, self.sen_len) # (batch_size, 2*hid) representation = sentence_batch out = self.output(representation) out_prob = F.softmax(out.view(batch_size, -1)) return out_prob init()函数中对网络进行初始化，设定词向量维度，前向/后向LSTM中隐层向量的维度，还有要分类的类别数等。 bifetch()函数的作用是将$h{L2}$与$h_{R2}$拼接起来并返回拼接后的向量。由于使用了batch，所以需要使用句子长度用来定位开始padding时前一个时刻的输出的隐层向量。 forward()函数里进行前向计算，得到各个类别的概率值。 3.2 模型训练12345678910111213141516171819202122232425262728293031323334def train(model, training_data, args, optimizer, criterion): model.train() batch_size = args.batch_size sentences, sentences_seqlen, sentences_mask, labels = training_data # print batch_size, len(sentences), len(labels) assert batch_size == len(sentences) == len(labels) ''' Prepare data and prediction''' sentences_, sentences_seqlen_, sentences_mask_ = \ var_batch(args, batch_size, sentences, sentences_seqlen, sentences_mask) labels_ = Variable(torch.LongTensor(labels)) if args.cuda: labels_ = labels_.cuda() assert len(sentences) == len(labels) model.zero_grad() probs = model(sentences_, sentences_seqlen_, sentences_mask_) loss = criterion(probs.view(len(labels_), -1), labels_) loss.backward() optimizer.step() 代码中training_data是一个batch的数据，其中包括输入的句子sentences（句子中每个词以词下标表示），输入句子的长度sentences_seqlen，输入的句子对应的情感类别labels。 训练模型前，先清空遗留的梯度值，再根据该batch数据计算出来的梯度进行更新模型。 123456789model.zero_grad() probs = model(sentences_, sentences_seqlen_, sentences_mask_) loss = criterion(probs.view(len(labels_), -1), labels_) loss.backward() optimizer.step() 3.3 模型测试以下是进行模型测试的代码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364def test(model, dataset, args, data_part="test"): """ :param model: :param args: :param dataset: :param data_part: :return: """ tvt_set = dataset[data_part] tvt_set = yutils.YDataset(tvt_set["xIndexes"], tvt_set["yLabels"], to_pad=True, max_len=args.sen_max_len) test_set = tvt_set sentences, sentences_seqlen, sentences_mask, labels = test_set.next_batch(len(test_set)) assert len(test_set) == len(sentences) == len(labels) tic = time.time() model.eval() ''' Prepare data and prediction''' batch_size = len(sentences) sentences_, sentences_seqlen_, sentences_mask_ = \ var_batch(args, batch_size, sentences, sentences_seqlen, sentences_mask) probs = model(sentences_, sentences_seqlen_, sentences_mask_) _, pred = torch.max(probs, dim=1) if args.cuda: pred = pred.view(-1).cpu().data.numpy() else: pred = pred.view(-1).data.numpy() tit = time.time() - tic print " Predicting &#123;:d&#125; examples using &#123;:5.4f&#125; seconds".format(len(test_set), tit) labels = numpy.asarray(labels) ''' log and return prf scores ''' accuracy = test_prf(pred, labels) return accuracy 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081def cal_prf(pred, right, gold, formation=True, metric_type=""): """ :param pred: predicted labels :param right: predicting right labels :param gold: gold labels :param formation: whether format the float to 6 digits :param metric_type: :return: prf for each label """ num_class = len(pred) precision = [0.0] * num_class recall = [0.0] * num_class f1_score = [0.0] * num_class for i in xrange(num_class): ''' cal precision for each class: right / predict ''' precision[i] = 0 if pred[i] == 0 else 1.0 * right[i] / pred[i] ''' cal recall for each class: right / gold ''' recall[i] = 0 if gold[i] == 0 else 1.0 * right[i] / gold[i] ''' cal recall for each class: 2 pr / (p+r) ''' f1_score[i] = 0 if precision[i] == 0 or recall[i] == 0 \ else 2.0 * (precision[i] * recall[i]) / (precision[i] + recall[i]) if formation: precision[i] = precision[i].__format__(".6f") recall[i] = recall[i].__format__(".6f") f1_score[i] = f1_score[i].__format__(".6f") ''' PRF for each label or PRF for all labels ''' if metric_type == "macro": precision = sum(precision) / len(precision) recall = sum(recall) / len(recall) f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0 elif metric_type == "micro": precision = 1.0 * sum(right) / sum(pred) if sum(pred) &gt; 0 else 0 recall = 1.0 * sum(right) / sum(gold) if sum(recall) &gt; 0 else 0 f1_score = 2 * precision * recall / (precision + recall) if (precision + recall) &gt; 0 else 0 return precision, recall, f1_score 四、总结本文中，我们结合情感分类任务介绍了LSTM以及BiLSTM的基本原理，并给出一个BiLSTM样例代码。除了情感分类任务，LSTM与BiLSTM在自然语言处理领域的其它任务上也得到了广泛应用，如机器翻译任务中使用其进行源语言的编码和目标语言的解码，机器阅读理解任务中使用其对文章和问题的编码等。 五、参考资料http://colah.github.io/posts/2015-08-Understanding-LSTMs/]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[剑指offer]]></title>
    <url>%2F2021%2F04%2F20%2F%E5%89%91%E6%8C%87offer%2F</url>
    <content type="text"><![CDATA[03. 数组中重复的数字 04. 二维数组中的查找 05. 替换空格 03. 数组中重复的数字找出数组中重复的数字。 在一个长度为 n 的数组 nums 里的所有数字都在 0～n-1 的范围内。数组中某些数字是重复的，但不知道有几个数字重复了，也不知道每个数字重复了几次。请找出数组中任意一个重复的数字。 示例 1： 输入：[2, 3, 1, 0, 2, 5, 3]输出：2 或 3 限制： 2 &lt;= n &lt;= 100000 思路： 新建一个等长数组，值全部为0，遍历一次，用当前数组的值当作下标，如果值改变了，说明已经出现过了 12345678910111213int findRepeatNumber(int* nums, int numsSize)&#123; for(int i = 0 ; i&lt; numsSize ; i++)&#123; if(nums[nums[i]] != nums[i])&#123; int temp; temp = nums[i]; nums[i] = nums[nums[i]]; nums[nums[i]] = temp; &#125;else if(nums[i] == nums[nums[i]] &amp;&amp; i != nums[i])&#123; return nums[i]; &#125; &#125; return 0;&#125; 1234567891011int findRepeatNumber(int* nums, int numsSize)&#123; int *hash=(int *)calloc(numsSize,sizeof(int)); for(int i=0 ; i&lt;numsSize ; i++)&#123; if(hash[nums[i]] == 1)&#123; return nums[i]; &#125;else&#123; hash[nums[i]]++; &#125; &#125; return -1;&#125; 04. 二维数组中的查找 在一个 n * m 的二维数组中，每一行都按照从左到右递增的顺序排序，每一列都按照从上到下递增的顺序排序。请完成一个高效的函数，输入这样的一个二维数组和一个整数，判断数组中是否含有该整数。 示例: 现有矩阵 matrix 如下： [ [1, 4, 7, 11, 15], [2, 5, 8, 12, 19], [3, 6, 9, 16, 22], [10, 13, 14, 17, 24], [18, 21, 23, 26, 30]]给定 target = 5，返回 true。给定 target = 20，返回 false。 限制：0 &lt;= n &lt;= 10000 &lt;= m &lt;= 1000 1234567891011121314151617181920212223242526272829303132333435// bool findNumberIn2DArray(int** matrix, int matrixSize, int* matrixColSize, int target)&#123;// int flag = 0;// for(int i = 0 ; i &lt; matrixSize-1 ; i++)&#123;// if( matrix[i][0] &lt; target &amp;&amp; matrix[i+1][0] &gt; target)&#123;// for(int j = 0 ; j &lt; matrixColSize-1 ; j++)&#123;// if(matrix[findline][j] == target)&#123;// flag = 1;// &#125;// &#125;// &#125;// &#125;// if(flag == 1)&#123;// return true;// &#125;// return false;// &#125; bool findNumberIn2DArray(int** matrix, int matrixSize, int* matrixColSize, int target)&#123; int row=0; int col=*matrixColSize-1; if(matrixSize==0||*matrixColSize==0) return false; while(row&lt;matrixSize&amp;&amp;col&gt;=0)&#123; if(target&gt;matrix[row][col])&#123; row++; &#125;else if(target&lt;matrix[row][col])&#123; col--; &#125;else if(target==matrix[row][col])&#123; return true; &#125; &#125; return false;&#125; 05. 替换空格 请实现一个函数，把字符串 s 中的每个空格替换成”%20”。 示例 1：输入：s = “We are happy.”输出：”We%20are%20happy.” 限制：0 &lt;= s 的长度 &lt;= 10000]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卷积神经网络超详细介绍]]></title>
    <url>%2F2021%2F04%2F19%2F%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E8%B6%85%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1、卷积神经网络的概念 2、 发展过程 3、如何利用CNN实现图像识别的任务 4、CNN的特征 5、CNN的求解 6、卷积神经网络注意事项 7、CNN发展综合介绍 8、LeNet-5结构分析 9、AlexNet 10、ZFNet 10.1 意义 10.2 实现方法 10.3 训练细节 参考： https://blog.csdn.net/jiaoyangwm/article/details/80011656/ 1、卷积神经网络的概念计算机视觉和 CNN 发展十一座里程碑 上世纪60年代，Hubel等人通过对猫视觉皮层细胞的研究，提出了感受野这个概念，到80年代，Fukushima在感受野概念的基础之上提出了神经认知机的概念，可以看作是卷积神经网络的第一个实现网络，神经认知机将一个视觉模式分解成许多子模式（特征），然后进入分层递阶式相连的特征平面进行处理，它试图将视觉系统模型化，使其能够在即使物体有位移或轻微变形的时候，也能完成识别。 卷积神经网络是多层感知机（MLP）的变种，由生物学家休博尔和维瑟尔在早期关于猫视觉皮层的研究发展而来，视觉皮层的细胞存在一个复杂的构造，这些细胞对视觉输入空间的子区域非常敏感，称之为感受野。 CNN由纽约大学的Yann Lecun于1998年提出，其本质是一个多层感知机，成功的原因在于其所采用的局部连接和权值共享的方式： 一方面减少了权值的数量使得网络易于优化 另一方面降低了模型的复杂度，也就是减小了过拟合的风险 该优点在网络的输入是图像时表现的更为明显，使得图像可以直接作为网络的输入，避免了传统识别算法中复杂的特征提取和数据重建的过程，在二维图像的处理过程中有很大的优势，如网络能够自行抽取图像的特征包括颜色、纹理、形状及图像的拓扑结构，在处理二维图像的问题上，特别是识别位移、缩放及其他形式扭曲不变性的应用上具有良好的鲁棒性和运算效率等。 名称 特点 LeNet5 没啥特点-不过是第一个CNN应该要知道 AlexNet 引入了ReLU和dropout，引入数据增强、池化相互之间有覆盖，三个卷积一个最大池化+三个全连接层 VGGNet 采用1_1和3_3的卷积核以及2*2的最大池化使得层数变得更深。常用VGGNet-16和VGGNet19 Google Inception Net 这个在控制了计算量和参数量的同时，获得了比较好的分类性能，和上面相比有几个大的改进：1、去除了最后的全连接层，而是用一个全局的平均池化来取代它； 2、引入Inception Module，这是一个4个分支结合的结构。所有的分支都用到了1_1的卷积，这是因为1_1性价比很高，可以用很少的参数达到非线性和特征变换。3、Inception V2第二版将所有的5_5变成2个3_3，而且提出来著名的Batch Normalization；4、Inception V3第三版就更变态了，把较大的二维卷积拆成了两个较小的一维卷积，加速运算、减少过拟合，同时还更改了Inception Module的结构。 微软ResNet残差神经网络(Residual Neural Network) 1、引入高速公路结构，可以让神经网络变得非常深2、ResNet第二个版本将ReLU激活函数变成y=x的线性函数 2、 发展过程1986年Rumelhart等人提出了人工神经网络的反向传播算法，掀起了神经网络在机器学习中的热潮，神经网络中存在大量的参数，存在 容易发生过拟合、训练时间长的缺点，但是对比Boosting、Logistic回归、SVM等基于统计学习理论的方法（也可以看做具有一层隐层节点或不含隐层节点的学习模型，被称为浅层模型）来说，具有较大的优越性。 浅层模型为什么效果没有深层模型好？ 浅层学习模型通常要由人工的方法来获得好的样本特性，在此基础上进行识别和预测，因此方法的有效性在很大程度上受到特征提取的制约。 深度学习的提出： 2006年，Hinton提出了深度学习，两个主要的观点是： 多隐层的人工神经网络具有优异的特征学习能力，学习到的数据更能反映数据的本质特征有利于可视化或分类 深度神经网络在训练上的难度，可以通过逐层无监督训练有效克服， 深度学习取得成功的原因： 大规模数据（例如ImageNet）：为深度学习提供了好的训练资源 计算机硬件的飞速发展：特别是GPU的出现，使得训练大规模上网络成为可能 深度学习的思想： 深度神经网络的基本思想是通过构建多层网络，对目标进行多层表示，以期通过多层的高层次特征来表示数据的抽象语义信息，获得更好的特征鲁棒性。 什么是卷积神经网络： 卷积神经网络是一种带有卷积结构的深度神经网络，卷积结构可以减少深层网络占用的内存量，其三个关键的操作， 其一是局部感受野，其二是权值共享，其三是pooling层，有效的减少了网络的参数个数，缓解了模型的过拟合问题。 1）网络结构 卷积神经网络整体架构：卷积神经网络是一种多层的监督学习神经网络，隐含层的卷积层和池采样层是实现卷积神经网络特征提取功能的核心模块。该网络模型通过采用梯度下降法最小化损失函数对网络中的权重参数逐层反向调节，通过频繁的迭代训练提高网络的精度。卷积神经网络的低隐层是由卷积层和最大池采样层交替组成，高层是全连接层对应传统多层感知器的隐含层和逻辑回归分类器。第一个全连接层的输入是由卷积层和子采样层进行特征提取得到的特征图像。最后一层输出层是一个分类器，可以采用逻辑回归，Softmax回归甚至是支持向量机对输入图像进行分类。 卷积神经网络结构包括：卷积层，降采样层，全链接层。每一层有多个特征图，每个特征图通过一种卷积滤波器提取输入的一种特征，每个特征图有多个神经元。 输入图像统计和滤波器进行卷积之后，提取该局部特征，一旦该局部特征被提取出来之后，它与其他特征的位置关系也随之确定下来了，每个神经元的输入和前一层的局部感受野相连，每个特征提取层都紧跟一个用来求局部平均与二次提取的计算层，也叫特征映射层，网络的每个计算层由多个特征映射平面组成，平面上所有的神经元的权重相等。 通常将输入层到隐藏层的映射称为一个特征映射，也就是通过卷积层得到特征提取层，经过pooling之后得到特征映射层。 2）局部感受野与权值共享 卷积神经网络的核心思想就是局部感受野、是权值共享和pooling层，以此来达到简化网络参数并使得网络具有一定程度的位移、尺度、缩放、非线性形变稳定性。 局部感受野：由于图像的空间联系是局部的，每个神经元不需要对全部的图像做感受，只需要感受局部特征即可，然后在更高层将这些感受得到的不同的局部神经元综合起来就可以得到全局的信息了，这样可以减少连接的数目。 权值共享：不同神经元之间的参数共享可以减少需要求解的参数，使用多种滤波器去卷积图像就会得到多种特征映射。权值共享其实就是对图像用同样的卷积核进行卷积操作，也就意味着第一个隐藏层的所有神经元所能检测到处于图像不同位置的完全相同的特征。其主要的能力就能检测到不同位置的同一类型特征，也就是卷积网络能很好的适应图像的小范围的平移性，即有较好的平移不变性（比如将输入图像的猫的位置移动之后，同样能够检测到猫的图像） 3）卷积层、下采样层、全连接层 卷积层：因为通过卷积运算我们可以提取出图像的特征，通过卷积运算可以使得原始信号的某些特征增强，并且降低噪声。 用一个可训练的滤波器fx去卷积一个输入的图像（第一阶段是输入的图像，后面的阶段就是卷积特征map了），然后加一个偏置bx，得到卷积层Cx。 下采样层：因为对图像进行下采样，可以减少数据处理量同时保留有用信息，采样可以混淆特征的具体位置，因为某个特征找出来之后，它的位置已经不重要了，我们只需要这个特征和其他特征的相对位置，可以应对形变和扭曲带来的同类物体的变化。 每邻域四个像素求和变为一个像素，然后通过标量Wx+1加权，再增加偏置bx+1，然后通过一个sigmoid激活函数，产生一个大概缩小四倍的特征映射图Sx+1。 * 全连接层：采用softmax全连接，得到的激活值即卷积神经网络提取到的图片特征。 卷积神经网络相比一般神经网络在图像理解中的优点： 网络结构能够较好的适应图像的结构 同时进行特征提取和分类，使得特征提取有助于特征分类 权值共享可以减少网络的训练参数，使得神经网络结构变得简单，适应性更强 3、如何利用CNN实现图像识别的任务输入层读入经过规则化（统一大小）的图像，每一层的每个神经元将前一层的一组小的局部近邻的单元作为输入，也就是局部感受野和权值共享，神经元抽取一些基本的视觉特征，比如边缘、角点等，这些特征之后会被更高层的神经元所使用。卷积神经网络通过卷积操作获得特征图，每个位置，来自不同特征图的单元得到各自不同类型的特征。一个卷积层中通常包含多个具有不同权值向量的特征图，使得能够保留图像更丰富的特征。卷积层后边会连接池化层进行降采样操作，一方面可以降低图像的分辨率，减少参数量，另一方面可以获得平移和形变的鲁棒性。卷积层和池化层的交替分布，使得特征图的数目逐步增多，而且分辨率逐渐降低，是一个双金字塔结构。 4、CNN的特征1）具有一些传统技术所没有的优点：良好的容错能力、并行处理能力和自学习能力，可处理环境信息复杂，背景知识不清楚，推理规则不明确情况下的问题，允许样品有较大的缺损、畸变，运行速度快，自适应性能好，具有较高的分辨率。它是通过结构重组和减少权值将特征抽取功能融合进多层感知器，省略识别前复杂的图像特征抽取过程。 2）泛化能力要显著优于其它方法，卷积神经网络已被应用于模式分类，物体检测和物体识别等方面。利用卷积神经网络建立模式分类器，将卷积神经网络作为通用的模式分类器，直接用于灰度图像。 3）是一个前溃式神经网络，能从一个二维图像中提取其拓扑结构，采用反向传播算法来优化网络结构，求解网络中的未知参数。 4）一类特别设计用来处理二维数据的多层神经网络。CNN被认为是第一个真正成功的采用多层层次结构网络的具有鲁棒性的深度学习方法。CNN通过挖掘数据中的空间上的相关性，来减少网络中的可训练参数的数量，达到改进前向传播网络的反向传播算法效率，因为CNN需要非常少的数据预处理工作，所以也被认为是一种深度学习的方法。在CNN中，图像中的小块区域（也叫做”局部感知区域”）被当做层次结构中的底层的输入数据，信息通过前向传播经过网络中的各个层，在每一层中都由过滤器构成，以便能够获得观测数据的一些显著特征。因为局部感知区域能够获得一些基础的特征，比如图像中的边界和角落等，这种方法能够提供一定程度对位移、拉伸和旋转的相对不变性。 5）CNN中层次之间的紧密联系和空间信息使得其特别适用于图像的处理和理解，并且能够自动的从图像抽取出丰富的相关特性。 6）CNN通过结合局部感知区域、共享权重、空间或者时间上的降采样来充分利用数据本身包含的局部性等特征，优化网络结构，并且保证一定程度上的位移和变形的不变性。 7）CNN是一种深度的监督学习下的机器学习模型，具有极强的适应性，善于挖掘数据局部特征，提取全局训练特征和分类，它的权值共享结构网络使之更类似于生物神经网络，在模式识别各个领域都取得了很好的成果。 8） CNN可以用来识别位移、缩放及其它形式扭曲不变性的二维或三维图像。CNN的特征提取层参数是通过训练数据学习得到的，所以其避免了人工特征提取，而是从训练数据中进行学习；其次同一特征图的神经元共享权值，减少了网络参数，这也是卷积网络相对于全连接网络的一大优势。共享局部权值这一特殊结构更接近于真实的生物神经网络使CNN在图像处理、语音识别领域有着独特的优越性，另一方面权值共享同时降低了网络的复杂性，且多维输入信号（语音、图像）可以直接输入网络的特点避免了特征提取和分类过程中数据重排的过程。 9）CNN的分类模型与传统模型的不同点在于其可以直接将一幅二维图像输入模型中，接着在输出端即给出分类结果。其优势在于不需复杂的预处理，将特征抽取，模式分类完全放入一个黑匣子中，通过不断的优化来获得网络所需参数，在输出层给出所需分类，网络核心就是网络的结构设计与网络的求解。这种求解结构比以往多种算法性能更高。 10）隐层的参数个数和隐层的神经元个数无关，只和滤波器的大小和滤波器种类的多少有关。隐层的神经元个数,它和原图像，也就是输入的大小（神经元个数）、滤波器的大小和滤波器在图像中的滑动步长都有关。 5、CNN的求解CNN在本质上是一种输入到输出的映射，它能够学习大量的输入与输出之间的映射关系，而不需要任何输入和输出之间的精确的数学表达式，只要用已知的模式对卷积网络加以训练，网络就具有输入输出对之间的映射能力。 卷积网络执行的是监督训练，所以其样本集是由形如：（输入向量，理想输出向量）的向量对构成的。所有这些向量对，都应该是来源于网络即将模拟系统的实际”运行”结构，它们可以是从实际运行系统中采集来。 1）参数初始化： 在开始训练前，所有的权都应该用一些不同的随机数进行初始化。”小随机数”用来保证网络不会因权值过大而进入饱和状态，从而导致训练失败；”不同”用来保证网络可以正常地学习。实际上，如果用相同的数去初始化权矩阵，则网络无学习能力。 2）训练过程包括四步 ① 第一阶段：前向传播阶段 从样本集中取一个样本，输入网络 计算相应的实际输出；在此阶段信息从输入层经过逐级的变换，传送到输出层，这个过程也是网络在完成训练之后正常执行时执行的过程 ② 第二阶段：后向传播阶段 计算实际输出与相应的理想输出的差 按照极小化误差的方法调整权值矩阵 *网络的训练过程如下： 选定训练组，从样本集中分别随机地寻求N个样本作为训练组； 将各权值、阈值，置成小的接近于0的随机值，并初始化精度控制参数和学习率； 从训练组中取一个输入模式加到网络，并给出它的目标输出向量； 计算出中间层输出向量，计算出网络的实际输出向量； 将输出向量中的元素与目标向量中的元素进行比较，计算出输出误差；对于中间层的隐单元也需要计算出误差； 依次计算出各权值的调整量和阈值的调整量； 调整权值和调整阈值； 当经历M后，判断指标是否满足精度要求，如果不满足，则返回(3)，继续迭代；如果满足就进入下一步； 训练结束，将权值和阈值保存在文件中。这时可以认为各个权值已经达到稳定，分类器已经形成。再一次进行训练，直接从文件导出权值和阈值进行训练，不需要进行初始化。 6、卷积神经网络注意事项1）数据集的大小和分块 数据驱动的模型一般依赖于数据集的大小，CNN和其他经验模型一样，能够适用于任意大小的数据集，但用于训练的数据集应该足够大， 能够覆盖问题域中所有已知可能出现的问题， 设计CNN的时候，数据集应该包含三个子集：训练集、测试集、验证集 训练集：包含问题域中的所有数据，并在训练阶段用来调整网络的权重 测试集：在训练的过程中用于测试网络对训练集中未出现的数据的分类性能，根据网络在测试集上的性能情况，网络的结构可能需要作出调整，或者增加训练循环次数。 验证集：验证集中的数据统一应该包含在测试集和训练集中没有出现过的数据，用于在网络确定之后能够更好的测试和衡量网络的性能 Looney等人建议，数据集中65%的用于训练，25%的用于测试，10%用于验证 2）数据预处理 为了加速训练算法的收敛速度，一般都会采用一些数据预处理技术，其中包括：去除噪声、输入数据降维、删除无关数据等。 数据的平衡化在分类问题中异常重要，一般认为训练集中的数据应该相对于标签类别近似于平均分布，也就是每一个类别标签所对应的数据集在训练集中是基本相等的，以避免网络过于倾向于表现某些分类的特点。 为了平衡数据集，应该移除一些过度富余的分类中的数据，并相应补充一些相对样例稀少的分类中的数据。 还有一个方法就是复制一部分这些样例稀少分类中的数据，并在这些数据中加入随机噪声。 3）数据规则化 将数据规则化到统一的区间（如[0,1]）中具有很重要的优点：防止数据中存在较大数值的数据造成数值较小的数据对于训练效果减弱甚至无效化，一个常用的方法是将输入和输出数据按比例调整到一个和激活函数相对应的区间。 4）网络权值初始化 CNN的初始化主要是初始化卷积层和输出层的卷积核（权值）和偏置 网络权值初始化就是将网络中的所有连接权重赋予一个初始值，如果初始权重向量处在误差曲面的一个相对平缓的区域的时候，网络训练的收敛速度可能会很缓慢，一般情况下网络的连接权重和阈值被初始化在一个具有0均值的相对小的区间内均匀分布。 5）BP算法的学习速率 如果学习速率选取的较大，则会在训练过程中较大幅度的调整权值w，从而加快网络的训练速度，但是这和造成网络在误差曲面上搜索过程中频繁抖动，且有可能使得训练过程不能收敛。 如果学习速率选取的较小，能够稳定的使得网络逼近于全局最优点，但也可能陷入一些局部最优，并且参数更新速度较慢。 自适应学习率设定有较好的效果。 6）收敛条件 有几个条件可以作为停止训练的判定条件，训练误差、误差梯度、交叉验证等。一般来说，训练集的误差会随着网络训练的进行而逐步降低。 7）训练方式 训练样例可以有两种基本的方式提供给网络训练使用，也可以是两者的结合：逐个样例训练(EET)、批量样例训练(BT)。 在EET中，先将第一个样例提供给网络，然后开始应用BP算法训练网络，直到训练误差降低到一个可以接受的范围，或者进行了指定步骤的训练次数。然后再将第二个样例提供给网络训练。 EET的优点是相对于BT只需要很少的存储空间，并且有更好的随机搜索能力，防止训练过程陷入局部最小区域。 EET的缺点是如果网络接收到的第一个样例就是劣质（有可能是噪音数据或者特征不明显）的数据，可能使得网络训练过程朝着全局误差最小化的反方向进行搜索。 相对的，BT方法是在所有训练样例都经过网络传播后才更新一次权值，因此每一次学习周期就包含了所有的训练样例数据。 BT方法的缺点也很明显，需要大量的存储空间，而且相比EET更容易陷入局部最小区域。 而随机训练（ST）则是相对于EET和BT一种折衷的方法，ST和EET一样也是一次只接受一个训练样例，但只进行一次BP算法并更新权值，然后接受下一个样例重复同样的步骤计算并更新权值，并且在接受训练集最后一个样例后，重新回到第一个样例进行计算。 ST和EET相比，保留了随机搜索的能力，同时又避免了训练样例中最开始几个样例如果出现劣质数据对训练过程的过度不良影响。 7、CNN发展综合介绍CNN的开山之作是LeCun提出的LeNet-5，而其真正的爆发阶段是2012年AlexNet取得ImageNet比赛的分类任务的冠军，并且分类准确率远远超过利用传统方法实现的分类结果，该模型能够取得成功的原因主要有三个： 海量的有标记的训练数据，也就是李飞飞团队提供的大规模有标记的数据集ImageNet 计算机硬件的支持，尤其是GPU的出现，为复杂的计算提供了强大的支持 算法的改进，包括网络结构加深、数据增强（数据扩充）、ReLU、Dropout等 AlexNet之后，深度学习便一发不可收拾，分类准确率每年都被刷榜，下图展示了模型的变化情况，随着模型的变深，Top-5的错误率也越来越低，目前已经降低到了3.5%左右，同样的ImageNet数据集，人眼的辨识错误率大概为5.1%，也就是深度学习的识别能力已经超过了人类。 8、LeNet-5结构分析 LeNet-5共包含8层 C1层是一个卷积层，由6个特征图Feature Map构成。特征图中每个神经元与输入为5 5的邻域相连。特征图的大小为28_28，这样能防止输入的连接掉到边界之外（32-5+1=28）。C1有156个可训练参数（每个滤波器5 _5=25个unit参数和一个bias参数，一共6个滤波器，共(5_5+1) _6=156个参数），共156(28*28)=122,304个连接。 S2层是一个下采样层，有6个14 14的特征图。特征图中的每个单元与C1中相对应特征图的2_2邻域相连接。S2层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。每个单元的2 _2感受野并不重叠，因此S2中每个特征图的大小是C1中特征图大小的1/4（行和列各1/2）。S2层有12（6（1+1）=12）个可训练参数和5880（14 14（22+1）6=5880）个连接。 C3层也是一个卷积层，它同样通过5x5的卷积核去卷积层S2，然后得到的特征map就只有10x10个神经元，但是它有16种不同的卷积核，所以就存在16个特征map了。 C3中每个特征图由S2中所有6个或者几个特征map组合而成。为什么不把S2中的每个特征图连接到每个C3的特征图呢？原因有2点。第一，不完全的连接机制将连接的数量保持在合理的范围内。第二，也是最重要的，其破坏了网络的对称性。由于不同的特征图有不同的输入，所以迫使他们抽取不同的特征（希望是互补的）。 例如，存在的一个方式是：C3的前6个特征图以S2中3个相邻的特征图子集为输入。接下来6个特征图以S2中4个相邻特征图子集为输入。然后的3个以不相邻的4个特征图子集为输入。最后一个将S2中所有特征图为输入。这样C3层有1516（6*（3 25+1）+6（4 25+1）+3（4 _25+1）+（25_6+1）=1516）个可训练参数和151600（10 _10_1516=151600）个连接。 S4层是一个下采样层，由16个5 _5大小的特征图构成。特征图中的每个单元与C3中相应特征图的2_2邻域相连接，跟C1和S2之间的连接一样。S4层有32个可训练参数（每个特征图1个因子和一个偏置16（1+1）=32）和2000（16（2*2+1） _5_5=2000）个连接。 C5层是一个卷积层，有120个特征图。每个单元与S4层的全部16个单元的5 _5邻域相连。由于S4层特征图的大小也为5_5（同滤波器一样），故C5特征图的大小为1 _1（5-5+1=1）：这构成了S4和C5之间的全连接。之所以仍将C5标示为卷积层而非全相联层，是因为如果LeNet-5的输入变大，而其他的保持不变，那么此时特征图的维数就会比1_1大。C5层有48120（120*（16 _5_5+1）=48120由于与全部16个单元相连，故只加一个偏置）个可训练连接。 F6层有84个单元（之所以选这个数字的原因来自于输出层的设计），与C5层全相连。有10164（84(120(1*1)+1)=10164）个可训练参数。如同经典神经网络，F6层计算输入向量和权重向量之间的点积，再加上一个偏置。然后将其传递给sigmoid函数产生单元i的一个状态。 最后，输出层由欧式径向基函数（Euclidean Radial Basis Function）单元组成，每类一个单元，每个有84个输入。 1、输入层：N个32x32的训练样本 输入图像大小为32x32，比MNIST数据库中的字母大，这样做的原因是希望潜在的明显特征，如笔画断点或角点能够出现在最高层特征监测子感受野的中心。 2、C1层 输入图像大小：32x32 卷积核大小：5x5 卷积核个数：6 输出特征图数量：6 输出特征图大小：28x28（32-5+1） 神经元数量：4707（28x28x6） 连接数：122304（（28x28x5x5x6）+（28x28x6）） 可训练参数：156（5x5x6+6，权值+偏置） 3、S2层 输入图像大小：（28x28x6） 卷积核大小：2x2 卷积核个数：6 输出特征图数量：6 输出特征图大小：14x14（28/2,28/2） 神经元数量：1176（14x14x6） 连接数：5880（（2x2x14x14x6）+（14x14x6）） 可训练参数：12（1x6+6，权值+偏置） 备注：S2层每个单元的4个输入相加，乘以一个可训练参数，再加上一个可训练偏置。结果通过sigmoid函数计算。可训练系数和偏置控制着sigmoid函数的非线性程度。 如果系数比较小，那么运算近似于线性运算，下采样相当于模糊图像。 如果系数比较大，根据偏置的大小下采样可以被看成是有噪声的”或”运算或者有噪声的”与”运算。 每个单元的2*2感受野并不重叠，因此S2中每个特征图的大小是C1中特征图大小的1/4（行和列各1/2）。 4、C3层 输入图像大小：（14x14x6） 卷积核大小：5x5 卷积核个数：16 输出特征图数量：16 输出特征图大小：10x10（14-5+1） 神经元数量：1600（10x10x16） 连接数：151600（1516x10x10） 可训练参数：1516 备注：C3层也是一个卷积层，通过5x5的卷积核去卷积S2层，然后得到的特征图map就有10x10个神经元，但是有16种不同的卷积核，就存在16个不同的特征map。 C3中每个特征图由S2中的所有6个或几个特征图组合而成，为什么不把S2中的所有特征图都连接到C3的特征图呢： 第一，不完全的连接机制将连接的数量保持在合理的范围内 第二，也是最重要的，这样一来就可以破坏网络的对称性，由于不同的特征图有不同的输入，所以迫使他们抽取不同的特征。 5、S4层 输入图像大小：（10x10x16） 卷积核大小：2x2 卷积核个数：16 输出特征图数量：16 输出特征图大小：5x5x16 神经元数量：400（5x5x16） 连接数：2000（（2x2x5x5x16）+(5x5x16）） 可训练参数：32（（1+1）x16） 备注：S4是一个下采样层，由16个5x5大小的特征图构成，特征图的每个单元与C3中相应的特征图的2x2邻域相连，S4层有32个可训练参数（每个特征图1个因子和一个偏置）和2000个连接。 6、C5层 输入图像大小：5x5x16 卷积核大小：5x5 卷积核个数：120 输出特征图数量：120 输出特征图大小：1X1（5-5+1） 神经元数量：120（1x120） 连接数：48120（5x5x16x120x1+120x1） 可训练参数：48120（5x5x16x120+120） 备注：C5层是一个卷积层，有120个特征图，每个单元与S4层的全部16个单元的5x5邻域相连，构成了S4和C5的全连接，之所以仍将C5标识为卷积层而非全连接层是因为如果LeNet-5的输入变大，而其他的保持不变，那么此时特征图的维数就会比1x1大。 7、F6层 输入图像大小：（1x1x120） 卷积核大小：1x1 卷积核个数：84 输出特征图数量：1 输出特征图大小：84 神经元数量：84 连接数：10164（120x84+84） 可训练参数：10164（120x84+84） 备注：F6有84个单元（之所以选择84是源于输出层的设计），与C5层相连，有10164个可训练参数，类似经典的全连接神经网络，F6层计算输入向量和权重向量之间的点积，再加上一个偏置，之后将其传递给sigmoid函数产生一个单元i的状态。 8、output层 输入图像大小：1x84 输出特征图数量：1x10 9、AlexNet超详细介绍AlexNet 这篇论文，题目叫做”ImageNet Classification with Deep Convolutional Networks”，迄今被引用6184次，被业内普遍视为行业最重要的论文之一。Alex Krizhevsky、Ilya Sutskever和 Geoffrey Hinton创造了一个”大型的深度卷积神经网络”，赢得了2012 ILSVRC(2012年ImageNet 大规模视觉识别挑战赛)。稍微介绍一下，这个比赛被誉为计算机视觉的年度奥林匹克竞赛，全世界的团队相聚一堂，看看是哪家的视觉模型表现最为出色。2012年是CNN首次实现Top 5误差率15.4%的一年(Top 5误差率是指给定一张图像，其标签不在模型认为最有可能的5个结果中的几率)，当时的次优项误差率为26.2%。这个表现不用说震惊了整个计算机视觉界。可以说，是自那时起，CNN才成了家喻户晓的名字。 ImageNet 2012比赛分类任务的冠军，将分类错误率降低到了15.315%，使用传统计算机视觉的第二名小组的分类错误率为26.172%。 上图所示是caffe中alexnet的网络结构，上图采用是两台GPU服务器，所有会看到两个流程图。下边把AlexNet的网络结构示意一下： 简化的结构： 架构： 因为使用了两台GPU训练，因而有两股”流”。使用两台GPU训练的原因是计算量太大，只能拆开来。 要点： 数据集：ImageNet数据集，含1500多万个带标记的图像，超过2.2万个类别激活函数：ReLU（训练速度快，一定程度上减小了梯度消失的问题）数据增强：平移、镜像、缩放等过拟合：dropout如何训练：批处理梯度下降训练模型，注明了动量衰减值和权值衰减值训练时间：使用两台GTX 580 GPU，训练了5到6天 Alex Krizhevsky等人于2012年的ImageNet比赛中提出了新型卷积神经网络AlexNet，并获得了图像分类问题的最好成绩（Top-5错误率为15.3%）。 网络结构： 其实AlexNet的结构很简单，只是LeNet的放大版，输入是一个224x224的图像，经过5个卷积层，3个全连接层（包含一个分类层），达到了最后的标签空间。 AlexNet学习出来的特征是什么样子的？ 第一层：都是一些填充的块状物和边界等特征 中间层：学习一些纹理特征 更高层：接近于分类器的层级，可以明显的看到物体的形状特征 最后一层：分类层，完全是物体的不同的姿态，根据不同的物体展现出不同姿态的特征了。 即无论对什么物体，学习过程都是：边缘→ \to →部分→ \to →整体 该方法训练了一个端到端的卷积神经网络实现对图像特征提取和分类，网络结构共7层，包含5层卷积层和2层全连接层。 AlexNet包含了6亿三千万个连接，6000万个参数和65万个神经元，拥有5个卷积层，其中3个卷积层后面连接了最大池化层，最后还有3个全连接层。 AlexNet可以说是神经网络在低谷期后的第一次发声，确立了深度学习（深度卷积神经网络）在计算机界的统治地位，同时也推动了深度学习在语音识别、自然语言处理、强化学习等方面的拓展。 训练技巧：dropout防止过拟合，提高泛化能力 训练阶段使用了Dropout技巧随机忽略一部分神经元，缓解了神经网络的过拟合现象，和防止对网络参数优化时陷入局部最优的问题，Dropout虽有单独的论文论述，但是AlexNet将其实用化，通过实践证实了它的效果。在AlexNet中主要是最后几个全连接层使用了Dropout。 该网络是利用Dropout在训练过程中将输入层和中间层的一些神经元随机置零，使得训练过程收敛的更慢，但得到的网络模型更加具有鲁棒性。 数据扩充 / 数据增强：防止过拟合 通过图像平移、水平翻转、调整图像灰度等方法扩充样本训练集，扩充样本训练集，使得训练得到的网络对局部平移、旋转、光照变化具有一定的不变性，数据经过扩充以后可以达到减轻过拟合并提升泛化能力。进行预测时，则是取图像的四个角加上中间共5个位置，并进行左右翻转，一共获得10张图像，对它们进行预测并对10次结果求均值。 水平翻转： 随机裁剪、平移旋转： 颜色变换： 池化方式： AlexNet全部使用最大池化的方式，避免了平均池化所带来的模糊化的效果，并且步长&lt;池化核的大小，这样一来池化层的输出之间会有重叠和覆盖，提升了特征的丰富性。 此前的CNN一直使用平均池化的操作。 激活函数：ReLU Relu函数：f(x)=max(0,x) 采用非饱和线性单元——ReLU代替传统的经常使用的tanh和sigmoid函数，加速了网络训练的速度，降低了计算的复杂度，对各种干扰更加具有鲁棒性，并且在一定程度上避免了梯度消失问题。 优势： ReLU本质上是分段线性模型，前向计算非常简单，无需指数之类操作； ReLU的偏导也很简单，反向传播梯度，无需指数或者除法之类操作； ReLU不容易发生梯度发散问题，Tanh和Logistic激活函数在两端的时候导数容易趋近于零，多级连乘后梯度更加约等于0； ReLU关闭了右边，从而会使得很多的隐层输出为0，即网络变得稀疏，起到了类似L1的正则化作用，可以在一定程度上缓解过拟合。 缺点：当然，ReLU也是有缺点的，比如左边全部关了很容易导致某些隐藏节点永无翻身之日，所以后来又出现pReLU、random ReLU等改进，而且ReLU会很容易改变数据的分布，因此ReLU后加Batch Normalization也是常用的改进的方法。 提出了LRN层（Local Response Normalization）： LRN即Local Response Normalization，局部响应归一化处理，实际就是利用临近的数据做归一化，该策略贡献了1.2%的准确率，该技术是深度学习训练时的一种提高准确度的技术方法，LRN一般是在激活、池化后进行的一种处理方法。 LRN是对局部神经元的活动创建竞争机制，使得其中响应较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。 为什么输入数据需要归一化（Normalized Data）？ 归一化后有什么好处呢？原因在于神经网络学习过程本质就是为了学习数据分布，一旦训练数据与测试数据的分布不同，那么网络的泛化能力也大大降低；另外一方面，一旦每批训练数据的分布各不相同(batch 梯度下降)，那么网络就要在每次迭代都去学习适应不同的分布，这样将会大大降低网络的训练速度，这也正是为什么我们需要对数据都要做一个归一化预处理的原因。 对于深度网络的训练是一个复杂的过程，只要网络的前面几层发生微小的改变，那么后面几层就会被累积放大下去。一旦网络某一层的输入数据的分布发生改变，那么这一层网络就需要去适应学习这个新的数据分布，所以如果训练过程中，训练数据的分布一直在发生变化，那么将会影响网络的训练速度。 分布式计算： AlexNet使用CUDA加速深度卷积网络的训练，利用GPU强大的并行计算能力，处理神经网络训练时大量的矩阵运算，AlexNet使用两个GTX580的GPU进行训练，单个GTX580只有3GB的显存，限制了可训练网络的最大规模，因此将其分布在两个GPU上，在每个GPU的显存中储存一般的神经元参数。 有多少层需要训练 整个AlexNet有8个需要训练参数的层，不包括池化层和LRN层，前5层为卷积层，后3层为全连接层，AlexNet的最后一层是由1000类输出的Softmax层用作分类，LRN层出现在第一个和第二个卷积层之后，最大池化层出现在两个LRN之后和最后一个卷积层之后。 每层的超参数、参数量、计算量： 虽然前几个卷积层的计算量很大，但是参数量都很小，在1M左右甚至更小。只占AlexNet总参数量的很小一部分，这就是卷积层的作用，可以通过较小的参数量有效的提取特征。 为什么使用多层全连接： 全连接层在CNN中起到分类器的作用，前面的卷积层、池化层和激活函数层等操作是将原始数据映射到隐层特征空间，全连接层是将学到的特征映射映射到样本标记空间，就是矩阵乘法，再加上激活函数的非线性映射，多层全连接层理论上可以模拟任何非线性变换。但缺点也很明显: 无法保持空间结构。 由于全连接网络的冗余（占整个我拿过来参数的80%），近期一些好的网络模型使用全局平均池化（GAP）取代FC来融合学到的深度特征，最后使用softmax等损失函数作为网络目标函数来指导学习过程，用GAP替代FC的网络通常有较好的预测性能。 全连接的一个作用是维度变换，尤其是可以把高维变到低维，同时把有用的信息保留下来。全连接另一个作用是隐含语义的表达(embedding)，把原始特征映射到各个隐语义节点(hidden node)。对于最后一层全连接而言，就是分类的显示表达。不同channel同一位置上的全连接等价与1x1的卷积。N个节点的全连接可近似为N个模板卷积后的均值池化(GAP)。 GAP：假如最后一层的数据是10个66的特征图，global average pooling是将每个特征图计算所有像素点的均值，输出一个数据值，10个特征图就会输出10个值，组成一个110的特征向量。 用特征图直接表示属于某类的置信率，比如有10个输出，就在最后输出10个特征图，每个特征图的值加起来求均值，然后将均值作为其属于某类的置信值，再输入softmax中，效果较好。 因为FC的参数众多，这么做就减少了参数的数量（在最近比较火的模型压缩中，这个优势可以很好的压缩模型的大小）。 因为减少了参数的数量，可以很好的减轻过拟合的发生。 为什么过了20年才卷土重来： 大规模有标记数据集的出现，防止以前不可避免的过拟合现象 2. 计算机硬件的突飞猛进，卷积神经网络对计算机的运算要求比较高，需要大量重复可并行化的计算，在当时CPU只有单核且运算能力比较低的情况下，不可能进行个很深的卷积神经网络的训练。随着GPU计算能力的增长，卷积神经网络结合大数据的训练才成为可能。 卷积神经网络有一批一直在坚持的科学家（如Lecun）才没有被沉默，才没有被海量的浅层方法淹没。然后最后终于看到卷积神经网络占领主流的曙光。 10、ZFNet和AlexNet很像，只是把参数优化了。 2012年AlexNet出尽了风头，ILSVRC 2013就有一大批CNN模型冒了出来。2013年的冠军是纽约大学Matthew Zeiler 和 Rob Fergus设计的网络 ZF Net，错误率 11.2%。ZF Net模型更像是AlexNet架构的微调优化版，但还是提出了有关优化性能的一些关键想法。还有一个原因，这篇论文写得非常好，论文作者花了大量时间阐释有关卷积神经网络的直观概念，展示了将滤波器和权重可视化的正确方法。 在这篇题为“Visualizing and Understanding Convolutional Neural Networks”的论文中，Zeiler和Fergus从大数据和GPU计算力让人们重拾对CNN的兴趣讲起，讨论了研究人员对模型内在机制知之甚少，一针见血地指出“发展更好的模型实际上是不断试错的过程”。虽然我们现在要比3年前知道得多一些了，但论文所提出的问题至今仍然存在!这篇论文的主要贡献在于提出了一个比AlexNet稍微好一些的模型并给出了细节，还提供了一些制作可视化特征图值得借鉴的方法。 10.1 意义该论文是在AlexNet基础上进行了一些细节的改动，网络结构上并没有太大的突破。该论文最大的贡献在于通过使用可视化技术揭示了神经网络各层到底在干什么，起到了什么作用。 从科学的观点出发，如果不知道神经网络为什么取得了如此好的效果，那么只能靠不停的实验来寻找更好的模型。 使用一个多层的反卷积网络来可视化训练过程中特征的演化及发现潜在的问题；同时根据遮挡图像局部对分类结果的影响来探讨对分类任务而言到底那部分输入信息更重要。 10.2 实现方法训练过程： 对前一层的输入进行卷积 -&gt; relu -&gt; max pooling(可选) -&gt; 局部对比操作(可选) -&gt; 全连接层 -&gt; softmax分类器。 输入是(x,y)，计算y与y的估计值之间的交叉熵损失，反向传播损失值的梯度，使用随机梯度下降算法来更新参数（w和b）以完成模型的训练。 反卷积可视化： 一个卷积层加一个对应的反卷积层； 输入是feature map，输出是图像像素； 过程包括反池化操作、relu和反卷积过程。 反池化： 严格意义上的反池化是无法实现的。作者采用近似的实现，在训练过程中记录每一个池化操作的一个z*z的区域内输入的最大值的位置，这样在反池化的时候，就将最大值返回到其应该在的位置，其他位置的值补0。 relu: 卷积神经网络使用relu非线性函数来保证输出的feature map总是为正数。在反卷积的时候，也需要保证每一层的feature map都是正值，所以这里还是使用relu作为非线性激活函数。 滤波： 使用原卷积核的转秩和feature map进行卷积。反卷积其实是一个误导，这里真正的名字就是转秩卷积操作。 上图左边是一个解卷积层，右边为一个卷积层，解卷积层将会重建一个来自下一层的卷积特征近似版本，图中使用switch来记录在卷积网中进行最大池化操作时每个池化区域的局部最大值的位置，经过非池化操作后，原来的非最大值的位置全都置为0。 预处理： 网络对输入图片进行预处理，裁剪图片中间的256x256区域，并减去整个图像每个像素的均值，然后用10个不同的对256x256图像进行224x224的裁剪（中间区域加上四个角落，以及他们的水平翻转图像），对以128个图片分的块进行随机梯度下降法来更新参数。起始学习率为$10 ^{−2} $ ，动量为0.9，当验证集误差停滞时，手动调整学习率。在全连接网络中使用概率为0.5的dropout，并且所有权值都初始化为$10 ^{−2} $ ，偏置设为0。 在训练时第一层的可视化揭露了一些占主导的因素，为了了解这些，我们采用重新归一化每个卷积层的滤波器，这些滤波器的均方根值超过了一个固定半径的$10 ^{−1} $ 。这是非常关键的，尤其是在模型中的第一层，因为输出图片大约在[-128,128]的范围内。 特征可视化： 每个特征单独投影到像素空间揭露了不同的结构能刺激不同的一个给定的特征图，因此展示了它对于变形的输入内在的不变性。下图即在一个已经训练好的网络中可视化后的图。 10.3 训练细节网络结构类似于AlexNet，有两点不同，一是将3，4，5层的变成了全连接，二是卷积核的大小减小。 图像预处理和训练过程中的参数设置也和AlexNet很像。 AlexNet用了1500万张图像，ZFNet用了130万张图像。 AlexNet在第一层中使用了大小为11×11的滤波器，而ZF使用的滤波器大小为7x7，整体处理速度也有所减慢。做此修改的原因是，对于输入数据来说，第一层卷积层有助于保留大量的原始象素信息。11×11的滤波器漏掉了大量相关信息，特别是因为这是第一层卷积层。 随着网络增大，使用的滤波器数量增多。 利用ReLU的激活函数，将交叉熵代价函数作为误差函数，使用批处理随机梯度下降进行训练。 使用一台GTX 580 GPU训练了12天。 开发可视化技术“解卷积网络”(Deconvolutional Network)，有助于检查不同的特征激活和其对输入空间关系。名字之所以称为“deconvnet”，是因为它将特征映射到像素(与卷积层恰好相反)。 解卷积层DeConvNet： DeConvNet工作的基本原理是，每层训练过的CNN后面都连一层“deconvet”，它会提供一条返回图像像素的路径。输入图像进入CNN之后，每一层都计算激活。然而向前传递。现在，假设我们想知道第4层卷积层某个特征的激活值，我们将保存这个特征图的激活值，并将这一层的其他激活值设为0，再将这张特征图作为输入送入deconvnet。Deconvnet与原来的CNN拥有同样的滤波器。输入经过一系列unpool(maxpooling倒过来)，修正，对前一层进行过滤操作，直到输入空间满。 这一过程背后的逻辑在于，我们想要知道是激活某个特征图的是什么结构。下面来看第一层和第二层的可视化。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[BiGRU-Attention 模型]]></title>
    <url>%2F2021%2F04%2F18%2FBiGRU-Attention%20%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[BiGRU-Attention 模型 1. 输入层 2. 隐含层 3. 输出层 参考文章： https://www.pianshen.com/article/15191431794/ https://blog.csdn.net/qq_40900196/article/details/88998290 BiGRU-Attention 模型BiGRU-Attention 模型共分为三部分：文本向量化输入层、 隐含层和输出层。其中，隐含层由 BiGRU 层、attention 层和 Dense 层（全连接层）三层构成。BiGRU-Attention 模型结构如图 6 所示。 下面对这三层的功能分别进行介绍： 1. 输入层输入层即文本向量化输入层主要是对IMDB电影评论的25 000条数据的预处理。即把这些评论数据处理成 BiGRU 层能够直接接收并能处理的序列向量形式。m 个单词组成 l 个句子的文本 a 即 a = {$s1, s_2, \cdot\cdot\cdot ,s_l$}， 样本中的第 j 个句子表示为 $s_j $ = { $ w{j1} , w{j2} , \cdot\cdot\cdot , w{jm}$ }，进行文本向量操作，使 $ w \in w^a$。文本向量化具体操作步骤如下： a)读取数据并进行数据清洗； b)将数据向量化为规定长度 1000 的形式（句子长度小于规定值的，默认自动在后面填充特殊的符号；句子长度大于规定值的，默认保留前 1000 个，多余部分截去。） c)随机初始化数据，按 8:2 划分训练集和测试集； d)将数据向量化后，每一条电影评论都变成了统一长度的索引向量，每一个索引对应一个词向量。 经过上面的四步的操作之后，输入的 IMDB 数据就变成根据索引对应词向量的形成词矩阵，即设处理后词向量的统一长度为1000，使用 glove.6B.100d 的 100 维向量的形式，在 glove.6B.100d 中不能查找到的词向量随机初始化。设 $c{ji}$ 为第 j 个句子的第 i 个词向量，则一条长度为 1000 的 IMDB 评论数据可以表示为：$ c{j1:j1000} = c{j1} \oplus c{j2} \oplus \cdot\cdot\cdot \oplus c_{j1000} $ 其中：$c{j1:j1000}$ 表示词向量与词向量的连接操作符，$c{j1:j1000}$ 表示为 $c{j1}, c{j2} \cdot\cdot\cdot c_{j1000} $ 即为第 j 个句子的词向量矩阵。把 IMDB 每一条评论中的每一个词按照索引去对应 glove.6B.100d 中词向量，生成词向量矩阵。 2. 隐含层隐含层的计算主要分为两个步骤完成： a) 计算 BiGRU 层输出的词向量。文本词向量为 BiGRU 层的输入向量。BiGRU 层的目的主要是对输入的文本向量进行文本深层次特征的提取。根据 BiGRU 神经网络模型图，可以把 BiGRU 模型看做由向前 GRU 和反向 GRU 两部分组成，在这里简化为式(11)。在第 i 时刻输入的第 j 个句子的第 t 个单词的词向量为 $c{ijt}$ ,通过 BiGRU 层特征提取后，可以更加充分地学习上下文之间的关系，进行语义编码，具体计算公式如式(11)所示。$h{ijt} = BiGRU(c_{ijt}) , t \in [1,m] \qquad(11)$ b)计算每个词向量应分配的概率权重。这个步骤主要是 为不同的词向量分配相应的概率权重，进一步提取文本特征，突出文本的关键信息。在文本中，不同的词对文本情感分类起着不同的作用。地点状语、时间状语对文本情感分类来说，重要程度极小；而具有情感色彩的形容词对文本情感分类却至关重要。 为了突出不同词对整个文本情感分类的重要度， BiGRU-Attention 模型中引入了 attention 机制层。Attention 机制层的输入为上一层中经过 BiGRU 神经网络层处理的输出向量 $h{ijt}$ ，attention 机制层的权重系数具体通过以下几个公式进行计算：$ u{ijt} = tanh(wwh{ijt} + bw)$$ \alpha{ijt} = \frac{exp(u{ijt}^Tu_w)}{ \sum_i exp(u{ijt}^Tuw)} \qquad\qquad\qquad (12) $$ s{ijt} = \sum{i=1}^n \alpha{ijt} h_{ijt} $ 其中: $h_{ijt}$ 为上一层 BiGRU 神经网络层的输出向量， $w_w$ 表示权重系数， $b_w$ 表示偏置系数， $u_w$ 表示随机初始化的注意力矩阵。 Attention 机制矩阵由 attention 机制分配的不同概率权重与各个隐层状态的乘积的累加和，使用 softmax 函数做归一化操作得到。 3. 输出层输出层的输入为上一层 attention 机制层的输出。利用 softmax 函数对输出层的输入进行相应计算的方式从而进行文本分类，具体公式如下： $yj = softmax(w_1s{ijt} + b_1)$ 其中: $w_1$ 表示 attention 机制层到输出层的待训练的权重系数矩阵， $b_1$ 表示待训练相对应的偏置， $y_j$ 为输出的预测标签。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>文本分类模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深度学习笔记——RNN（LSTM、GRU、双向RNN）学习总结]]></title>
    <url>%2F2021%2F04%2F17%2F%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%E2%80%94%E2%80%94RNN%EF%BC%88LSTM%E3%80%81GRU%E3%80%81%E5%8F%8C%E5%90%91RNN%EF%BC%89%E5%AD%A6%E4%B9%A0%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[RNN（ Recurrent Neural Networks循环神经网络） 长期依赖（Long-Term Dependencies）问题 LSTM 网络 GRU网络 双向RNN 参考文章：https://blog.csdn.net/mpk_no1/article/details/72875185 RNN（ Recurrent Neural Networks循环神经网络）一般需要用到当前单词以及前面的单词，因为句子中前后单词并不是独立的，比如，当前单词是”很”，前一个单词是”天空”，那么下一个单词很大概率是”蓝”。循环神经网络的来源就循环神经网络的主要用途是处理和预测序列数据，在全连接神经网络或卷积神经网络中，网络结果都是从输入层到隐含层再到输出层，层与层之间是全连接或部分连接的，但每层之间的结点是无连接的。考虑这样一个问题，如果要预测句子的下一个单词是什么，是为了刻画一个序列当前的输出与之前信息的关系。从网络结果上来说，RNN会记忆之前的信息，并利用之前的信息影响后面的输出。也就是说，RNN的隐藏层之间的结点是有连接的，隐藏层的输入不仅包括输入层的输出，还包含上一时刻隐藏层的输出。 典型的RNN结构如下图所示，对于RNN来说，一个非常重要的概念就是时刻，RNN会对于每一个时刻的输入结合当前模型的状态给出一个输出，从图中可以看出，RNN的主体结构A的输入除了来自输入层的Xt,还有一个循环的边来提供当前时刻的状态。同时A的状态也会从当前步传递到下一步。 我们将这个循环展开，可以很清晰地看到信息在隐藏层之间的传递： 链式的特征揭示了 RNN 本质上是与序列和列表相关的。他们是对于这类数据的最自然的神经网络架构。并且 RNN 也已经被人们应用了！在过去几年中，应用 RNN 在语音识别，语言建模，翻译，图片描述等问题上已经取得一定成功，并且这个列表还在增长。 RNN的隐藏层的计算是一个全连接 长期依赖（Long-Term Dependencies）问题RNN 的关键点之一就是他们可以用来连接先前的信息到当前的任务上，例如使用过去的视频段来推测对当前段的理解。如果 RNN 可以做到这个，他们就变得非常有用。但是真的可以么？答案是，还有很多依赖因素。有时候，我们仅仅需要知道先前的信息来执行当前的任务。例如，我们有一个语言模型用来基于先前的词来预测下一个词。如果我们试着预测 “the clouds are in the sky” 最后的词，我们并不需要任何其他的上下文 —— 因此下一个词很显然就应该是 sky。在这样的场景中，相关的信息和预测的词位置之间的间隔是非常小的，RNN 可以学会使用先前的信息。 但是同样会有一些更加复杂的场景。假设我们试着去预测”I grew up in France… I speak fluent French”最后的词。当前的信息建议下一个词可能是一种语言的名字，但是如果我们需要弄清楚是什么语言，我们是需要先前提到的离当前位置很远的 France 的上下文的。这说明相关信息和当前预测位置之间的间隔就肯定变得相当的大。不幸的是，在这个间隔不断增大时，RNN 会丧失学习到连接如此远的信息的能力。 在理论上，RNN 绝对可以处理这样的 长期依赖 问题。人们可以仔细挑选参数来解决这类问题中的最初级形式，但在实践中，RNN 肯定不能够成功学习到这些知识。如果序列过长会导致优化时出现梯度消散的问题。然而，幸运的是，LSTM 并没有这个问题！ LSTM 网络Long Short Term Memory 网络—— 一般就叫做 LSTM ——是一种特殊的 RNN 类型，可以学习长期依赖信息。LSTM 由Hochreiter &amp; Schmidhuber (1997)提出，并在近期被Alex Graves进行了改良和推广。在很多问题，LSTM 都取得相当巨大的成功，并得到了广泛的使用。 LSTM 通过刻意的设计来避免长期依赖问题。记住长期的信息在实践中是 LSTM 的默认行为，而非需要付出很大代价才能获得的能力！所有 RNN 都具有一种重复神经网络模块的链式的形式。在标准的 RNN 中，这个重复的模块只有一个非常简单的结构，例如一个 tanh 层。LSTM 同样是这样的结构，但是重复的模块拥有一个不同的结构。不同于 单一神经网络层，这里是有四个，以一种非常特殊的方式进行交互。LSTM是一种拥有三个”门”结构的特殊网络结构。 LSTM 靠一些”门”的结构让信息有选择性地影响RNN中每个时刻的状态。所谓”门”的结构就是一个使用sigmod神经网络和一个按位做乘法的操作，这两个操作合在一起就是一个”门”结构。之所以该结构叫做门是因为使用sigmod作为激活函数的全连接神经网络层会输出一个0到1之间的值，描述当前输入有多少信息量可以通过这个结构，于是这个结构的功能就类似于一扇门，当门打开时（sigmod输出为1时），全部信息都可以通过；当门关上时（sigmod输出为0），任何信息都无法通过。 如上图所示，我们用以下几个公式来描述LSTM一个循环体的结构组成： 输入门： $ it = \sigma(W_i \cdot[h{t-1},x_t] + b_i)$ 遗忘门：$ ft = \sigma(W_f \cdot[h{t-1},x_t] + b_f)$ 候选记忆单元：$ \tilde{Ct} = tanh(W_C \cdot [h{t-1},x_t] + b_C) $ 当前时刻记忆单元：$ Ct = f_t\ast C{t-1} + i_t \ast \tilde{C_t} $ 输出门：$ ot = \sigma(W_o [h{t-1},x_t] + b_o)$ 输出：$h_t = o_t \ast tanh(C_t)$ GRU网络GRU可以看成是LSTM的变种，GRU把LSTM中的遗忘门和输入们用更新门来替代。 把cell state和隐状态ht进行合并，在计算当前时刻新信息的方法和LSTM有所不同。 下图是GRU更新ht的过程： 重置门：$ rt = \sigma(W_rX_t + U_rh{t-1} + b_r)$ 更新门：$ Zt = \sigma(W_ZX_t + U_Zh{t-1} + b_Z)$ 候选记忆单元：$ \widehat{ht} = tanh(WX_t + r_tUh{t-1} + b)$ 当前时刻记忆单元：$ ht = (1-z_t)\widehat{h_t} + z_th{t-1}$ 双向RNN在经典的循环神经网络中，状态的传输是从前往后单向的。然而，在有些问题中，当前时刻的输出不仅和之前的状态有关系，也和之后的状态相关。这时就需要双向RNN（BiRNN）来解决这类问题。例如预测一个语句中缺失的单词不仅需要根据前文来判断，也需要根据后面的内容，这时双向RNN就可以发挥它的作用。 双向RNN是由两个RNN上下叠加在一起组成的。输出由这两个RNN的状态共同决定。 从上图可以看出，双向RNN的主题结构就是两个单向RNN的结合。在每一个时刻t，输入会同时提供给这两个方向相反的RNN，而输出则是由这两个单向RNN共同决定（可以拼接或者求和等）。 同样地，将双向RNN中的RNN替换成LSTM或者GRU结构，则组成了BiLSTM和BiGRU。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[torch.nn学习(1)]]></title>
    <url>%2F2021%2F04%2F16%2Ftorch-nn%E5%AD%A6%E4%B9%A0-1%2F</url>
    <content type="text"><![CDATA[1、设置MNIST数据 2、从头构建神经网络（不使用 torch.nn ） 3、使用 torch.nn.functional 4、使用 nn.Module 重构 5、使用 nn.Linear 重构 6、使用 optim 重构 7、使用 Dataset 重构 8、使用 DataLoader 重构 9、增加验证 10、创建 fit() 和 get_data() 11、总结 PyTorch 提供了设计优雅的模块和类： torch.nn， torch.optim， Dateset 和 DataLoader，以帮助你创建和训练神经网络。为了逐渐理解，我们首先在 MNIST 数据集上训练基本的神经网络，而不使用这些模块的任何特征。最初只会使用最基本的 PyTorch tensor 功能。然后，我们逐步添加来自 torch.nn， torch.optim， Dataset 和 DataLoader 的一个特征，以显示每一部分的功能，以及它如何使得代码更简洁或灵活。 1、设置MNIST数据我们将使用经典的 MNIST 数据集，该数据集由手写数字（0-9）的黑白图像组成。 MNIST 数据集它包含了四个部分: Training set images: train-images-idx3-ubyte.gz (9.9 MB, 解压后 47 MB, 包含 60,000 个样本) Training set labels: train-labels-idx1-ubyte.gz (29 KB, 解压后 60 KB, 包含 60,000 个标签) Test set images: t10k-images-idx3-ubyte.gz (1.6 MB, 解压后 7.8 MB, 包含 10,000 个样本) Test set labels: t10k-labels-idx1-ubyte.gz (5KB, 解压后 10 KB, 包含 10,000 个标签) 我们将使用 pathlib 来处理路径（Python3标准库的一部分），用 requests 下载数据。只有当我们需要模块的时候才会导入它们，因此你可以清楚地看到正在使用的模块。 1234567891011121314from pathlib import Pathimport requestsDATA_PATH = Path(&quot;data&quot;)PATH = DATA_PATH / &quot;mnist&quot;PATH.mkdir(parents=True, exist_ok=True)URL = &quot;http://deeplearning.net/data/mnist/&quot;FILENAME = &quot;mnist.pkl.gz&quot;if not (PATH / FILENAME).exists(): content = requests.get(URL + FILENAME).content (PATH / FILENAME).open(&quot;wb&quot;).write(content) 该数据集的格式为 NumPy array，使用 pickle 存储。 12345import pickleimport gzipwith gzip.open((PATH / FILENAME).as_posix(), &quot;rb&quot;) as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding=&quot;latin-1&quot;) 每个图片大小为28x28，并存储为长度为784（=28x28）的扁平行。 查看其中的一个图片： 12345from matplotlib import pyplotimport numpy as nppyplot.imshow(x_train[0].reshape((28, 28)), cmap=&quot;gray&quot;)print(x_train.shape) 输出为： 1(50000, 784) PyTorch使用 tensor 而不是 NumPy array，所以我们需要将其转换。 12345678910import torchx_train, y_train, x_valid, y_valid = map( torch.tensor, (x_train, y_train, x_valid, y_valid))n, c = x_train.shapex_train, x_train.shape, y_train.min(), y_train.max()print(x_train, y_train)print(x_train.shape)print(y_train.min(), y_train.max()) 输出： 123456789tensor([[0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], ..., [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.], [0., 0., 0., ..., 0., 0., 0.]]) tensor([5, 0, 4, ..., 8, 4, 8])torch.Size([50000, 784])tensor(0) tensor(9) 2、从头构建神经网络（不使用 torch.nn ）我们首先只使用PyTorch tensor 操作创建一个模型。PyTorch提供了创建随机tensor或零填充tensor的方法，我们将使用这些方法为简单线性模型创建权重（weight）和偏置值（bias）。它们都是普通的tensor，除此之外，我们增加了一点：我们告诉PyTorch它们需要梯度。这将使得PyTorch记录tensor上的所有操作，因此PyTorch可以在反向传播中自动计算梯度。 对于权重，我们在初始化之后设置 requires_grad，因为我们不想在梯度中包含这一步。 1234567###initializing the weights with Xavier initialisation (by multiplying with 1/sqrt(n)).import mathweights = torch.randn(784, 10) / math.sqrt(784)weights.requires_grad_()bias = torch.zeros(10, requires_grad=True) 由于PyTorch可以自动计算梯度，我们可以使用任何标准Python函数（或可调用对象）作为模型。因此我们只编写一个矩阵乘法和广播加法来创建一个简单的线性模型。我们还需要一个激活函数，因此我们将编写 log_softmax 并使用它。记住：虽然PyTorch提供了许多的预先编写好的损失函数、激活函数等，但是你可以使用普通的Python编写自己的函数。PyTorch甚至可以自动为你的函数创建快速GPU或矢量化CPU代码。 12345def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)def model(xb): return log_softmax(xb @ weights + bias) 上面的代码中，”@”代表点积操作。我们将会在一批数据（64个图片）上调用我们编写的函数。这是一个前向传播。注意，现阶段我们的预测情况比随机猜测好不到哪里，因为我们是从随机权重开始的。 123456bs = 64 ### batch sizexb = x_train[0:bs] ### a mini-batch from xpreds = model(xb) ### predictionspreds[0], preds.shapeprint(preds[0], preds.shape) 输出： 123tensor([-1.7022, -3.0342, -2.4138, -2.6452, -2.7764, -2.0892, -2.2945, -2.5480, -2.3732, -1.8915], grad_fn=&lt;selectbackward&gt;) torch.Size([64, 10])&lt;/selectbackward&gt; 如你所见，pred tensor不只包含tensor值，还包含一个梯度函数，我们随后将会使用它来来进行反向传播。 我们编写负对数似然函数并将其用作损失函数（我们可以只使用标准的Python实现）： 1234def nll(input, target): return -input[range(target.shape[0]), target].mean()loss_func = nll 查看随机初始化模型的损失，这样我们随后就可以看到在使用了反向传播后，是否改进了模型。 12yb = y_train[0:bs]print(loss_func(preds, yb)) 输出： 12tensor(2.3783, grad_fn=&lt;negbackward&gt;)&lt;/negbackward&gt; 编写函数计算模型的精确度。对于每一次预测，如果最大值的索引和目标值匹配，则表示预测正确。 123def accuracy(out, yb): preds = torch.argmax(out, dim=1) return (preds == yb).float().mean() 查看随机初始化模型的精确度，因此我们可以观察随着损失的改善，精确度是否提升。 1print(accuracy(preds, yb)) 输出： 1tensor(0.0938) 现在我们可以进行训练。对于每次迭代，将会做以下几件事： 选择一批数据（mini-batch） 使用模型进行预测 计算损失 loss.backward() 更新模型的梯度，即权重和偏置 我们现在使用这些梯度来更新权重和偏置。我们将在 torch.no_grad() 中执行，因为我们不想记录这些操作来进行下一次梯度计算。 我们随后将梯度设置为0，以便为下一次循环做好准备。否则，梯度将会记录所有发生的操作。（也就是说， loss.backward() 将梯度增加到已经存在的值上，而不是替代它） 123456789101112131415161718192021from IPython.core.debugger import set_tracelr = 0.5 ### learning rateepochs = 2 ### how many epochs to train forfor epoch in range(epochs): for i in range((n - 1) // bs + 1): ###set_trace() start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 到此，我们已经从头编写并训练了一个小型的神经网络。 1print(loss_func(model(xb), yb), accuracy(model(xb), yb)) 输出： 12tensor(0.0806, grad_fn=&lt;negbackward&gt;) tensor(1.)&lt;/negbackward&gt; 将损失和精确度与前边的比较，发现损失减少，精确度提升。 3、使用 torch.nn.functional我们现在来重构代码，代码的功能和前边的一样，我们只是利用 PyTorch 的 nn 类来使得代码更简洁和灵活。 第一步并且最简单的一步是用 torch.nn.functional（通常导入到命名空间F中）中的函数替代我们手工编写的激活函数和损失函数来缩短代码。该模块包含 torch.nn 库中所有的函数（而库的其他部分还包含类）。除了各种损失函数和激活函数，在还模块中你还可以发现许多用于创建神经网络的方便的函数，如池化函数等。 如果使用了负对数似然损失函数和 log softnax 激活函数，那么Pytorch提供的 F.cross_entropy 结合了两者。所以我们甚至可以从我们的模型中移除激活函数。 123456import torch.nn.functional as Floss_func = F.cross_entropydef model(xb): return xb @ weights + bias 注意，在 model 函数中我们不再需要调用 log_softmax。让我们确认一下，损失和精确度与前边计算的一样： 1print(loss_func(model(xb), yb), accuracy(model(xb), yb)) 输出： 12tensor(0.0806, grad_fn=&lt;nlllossbackward&gt;) tensor(1.)&lt;/nlllossbackward&gt; 4、使用 nn.Module 重构下一步，我们将使用 nn.Module 和 nn.Parameter,以获得更清晰更简洁的训练循环。我们继承 nn.Module（它本身是一个类并且能够跟踪状态）建立子类。我们想要建立一个包含权重、偏置和前向传播的方法的类。 nn.Module 拥有许多我们将会使用的属性和方法（例如： .parameters() 和 .zero_grad()）。 12345678910from torch import nnclass Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.weights = nn.Parameter(torch.randn(784, 10) / math.sqrt(784)) self.bias = nn.Parameter(torch.zeros(10)) def forward(self, xb): return xb @ self.weights + self.bias 因为我们现在使用一个对象而不是一个函数，所以我们首先需要实例化我们的模型： 1model = Mnist_Logistic() 现在我们可以像之前那样计算损失。注意， nn.Module 对象像是函数一样被使用（即它们能被调用），但在幕后， PyTorch 将自动调用我们的 forward 方法。 1print(loss_func(model(xb), yb)) 输出： 12tensor(2.3558, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 以前对于我们的训练循环，我们需要按名字更新每个参数的值，并且手动将每个参数的梯度归零，像下面这样： 12345with torch.no_grad(): weights -= weights.grad * lr bias -= bias.grad * lr weights.grad.zero_() bias.grad.zero_() 现在我们可以利用 model.paremeters() 和 model.zero_grad() 使得这些步骤更简洁，特别是，当我们有一个更复杂的模型时，使得我们更不容忘记某些参数。 123with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 我们将训练循环包装到一个 fit 函数中，以便我们以后运行。 1234567891011121314151617def fit(): for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad()fit() 再次检查损失是否下降 1print(loss_func(model(xb), yb)) 输出： 12tensor(0.0826, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 5、使用 nn.Linear 重构继续重构代码。我们将会使用PyTorch 的 nn.Linear 类建立一个线性层，以替代手动定义和初始化 self.weights 和 self.bias、计算 xb @ self.weights + self.bias 等工作。PyTorch拥有多中类型预先定义好的层可以帮助我们极大简化代码，并且通常可以使之运行更快。 1234567class Mnist_Logistic(nn.Module): def __init__(self): super().__init__() self.lin = nn.Linear(784, 10) def forward(self, xb): return self.lin(xb) 我们像之前一样实例化模型并且计算损失 12model = Mnist_Logistic()print(loss_func(model(xb), yb)) 输出： 12tensor(2.3156, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 我们仍然能够像之前那样使用 fit 方法 123fit()print(loss_func(model(xb), yb)) 输出： 12tensor(0.0809, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 6、使用 optim 重构PyTorch还有一个包含各种优化算法的包 torch.optim 。我们可以使用优化器中的 step 方法来执行前向步骤，而不是手动更新参数。 这将使得我们替换之前手动编写的优化步骤： 123with torch.no_grad(): for p in model.parameters(): p -= p.grad * lr model.zero_grad() 替换为： 12opt.step()opt.zero_grad() optim.zero_grad() 将梯度重置为0，我们需要在计算下一个minibatch的梯度前调用它。 1from torch import optim 我们将要定义一个函数来创建模型和优化器，以便将来可以重用它。 123456789101112131415161718192021def get_model(): model = Mnist_Logistic() return model, optim.SGD(model.parameters(), lr=lr)model, opt = get_model()print(loss_func(model(xb), yb))for epoch in range(epochs): for i in range((n - 1) // bs + 1): start_i = i * bs end_i = start_i + bs xb = x_train[start_i:end_i] yb = y_train[start_i:end_i] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad()print(loss_func(model(xb), yb)) 输出： 123tensor(2.2861, grad_fn=&lt;nlllossbackward&gt;)tensor(0.0815, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt;&lt;/nlllossbackward&gt; 7、使用 Dataset 重构PyTorch 有一个抽象的 Dataset 类。任何具有 __len__（通过Python的标准len函数调用）函数和 __getitem__ 函数的类都可以是一个 Dataset。 Pytorch 的 TensorDataset 是一个包装 tensor 的 Dataset。通过定义长度和索引方式，这也为我们提供了一种沿tensor第一维迭代、索引、切片的方法。这将使我们更容易在我们训练的同一行中访问独立变量和因变量。 1from torch.utils.data import TensorDataset x_train 和 y_train 可以组合在一个单独的 TensorDataset 中，这将更容易迭代和切片。 1train_ds = TensorDataset(x_train, y_train) 之前，我们必须分别迭代x和y的小批量值： 12xb = x_train[start_i:end_i]yb = y_train[start_i:end_i] 现在，我们可以一起做这两步： 1xb,yb = train_ds[i*bs : i*bs+bs] 12345678910111213model, opt = get_model()for epoch in range(epochs): for i in range((n - 1) // bs + 1): xb, yb = train_ds[i * bs: i * bs + bs] pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad()print(loss_func(model(xb), yb)) 输出： 12tensor(0.0800, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 8、使用 DataLoader 重构PyTorch 的 DataLoader 负责管理批次。你可以从任何 Dataset 创建 DataLoader。 DataLoader 使得迭代批次更简单。 DataLoader 自动地提供每个批次，而不必使用 train_ds[i*bs : i*bs+bs]。 1234from torch.utils.data import DataLoadertrain_ds = TensorDataset(x_train, y_train)train_dl = DataLoader(train_ds, batch_size=bs) 之前，我们像下面这样迭代批次： 123for i in range((n-1)//bs + 1): xb,yb = train_ds[i*bs : i*bs+bs] pred = model(xb) 现在，我们的循环更加简洁，因为 &amp;###xFF08;xb&amp;###xFF0C;yb&amp;###xFF09;可以自动从 DataLoader 自动加载： 123for xb,yb in train_dl: pred = model(xb)model, opt = get_model() 12345678910for epoch in range(epochs): for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad()print(loss_func(model(xb), yb)) 输出： 12tensor(0.0821, grad_fn=&lt;nlllossbackward&gt;)&lt;/nlllossbackward&gt; 由于PyTorch的 nn.Module、 nn.Parameter、 Dataset 和 DataLoader，现在我们的训练循环变得更小、更容易理解。现在让我们尝试添加在实践中创建有效模型所需的基本功能。 9、增加验证在第1部分中，我们只是尝试去设置合理的训练循环以用于我们的训练数据。 实际上，你总是应该有一个验证集，以确定你是否过度拟合。 打乱训练数据对于防止批次与过度拟合之间的相关性非常重要。 另一方面，无论我们是否打乱验证集，验证损失都是相同的。 由于打乱需要额外的时间，因此打乱验证数据是没有意义的。 我们将要使用的验证集的大小是训练集的两倍。这是因为验证集不需要反向传播，因此占用更少的内存（不需要存储梯度）。 我们利用这一点来使用更大的批次大小并更快地计算损失。 12345train_ds = TensorDataset(x_train, y_train)train_dl = DataLoader(train_ds, batch_size=bs, shuffle=True)valid_ds = TensorDataset(x_valid, y_valid)valid_dl = DataLoader(valid_ds, batch_size=bs * 2) 我们将在每个epoch结束时计算和打印验证损失。（注意，我们总是在训练之前调用 model.train()，在推理之前调用 model.eval()，因为这些由诸如 nn.BatchNorm2d 和 nn.Dropout 等层使用，以确保这些不同阶段的适当行为。） 1234567891011121314151617model, opt = get_model()for epoch in range(epochs): model.train() for xb, yb in train_dl: pred = model(xb) loss = loss_func(pred, yb) loss.backward() opt.step() opt.zero_grad() model.eval() with torch.no_grad(): valid_loss = sum(loss_func(model(xb), yb) for xb, yb in valid_dl) print(epoch, valid_loss / len(valid_dl)) 输出： 120 tensor(0.2981)1 tensor(0.3033) 10、创建 fit() 和 get_data()我们现在将进行一些重构。因为计算训练集和验证集的损失，我们进行了两次相似的处理，让我们将其作为一个 loss_batch 函数来计算每个批次的损失。 我们为训练集传递一个优化器，并使用它来执行反向传播。 对于验证集，我们不传递优化器，因此该方法不执行反向传播。 123456789def loss_batch(model, loss_func, xb, yb, opt=None): loss = loss_func(model(xb), yb) if opt is not None: loss.backward() opt.step() opt.zero_grad() return loss.item(), len(xb) fit 运行必要的操作来训练我们的模型并计算每个epoch的训练和验证损失。 12345678910111213141516import numpy as npdef fit(epochs, model, loss_func, opt, train_dl, valid_dl): for epoch in range(epochs): model.train() for xb, yb in train_dl: loss_batch(model, loss_func, xb, yb, opt) model.eval() with torch.no_grad(): losses, nums = zip( *[loss_batch(model, loss_func, xb, yb) for xb, yb in valid_dl] ) val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) print(epoch, val_loss) get_data 为训练集合验证集返回 DataLoader。 12345def get_data(train_ds, valid_ds, bs): return ( DataLoader(train_ds, batch_size=bs, shuffle=True), DataLoader(valid_ds, batch_size=bs * 2), ) 现在，我们获取 DataLoader 和拟合模型的整个过程可以在3行代码中运行： 123train_dl, valid_dl = get_data(train_ds, valid_ds, bs)model, opt = get_model()fit(epochs, model, loss_func, opt, train_dl, valid_dl) 输出： 120 0.30550819134712221 0.31777948439121245 11、总结我们现在有一个通用数据流水线和训练循环，你可以使用它来训练多种类型PyTorch模型。 各部分的功能总结如下： torch.nn Module：创建一个可调用的对象，其行为类似于一个函数，但也可以包含状态（例如神经网络层权重）。 它知道它包含哪些参数，并且可以将所有梯度归零，循环遍历它们更新权重等。 Parameter： tensor 的包装器（wrapper），它告诉 Module 它具有在反向传播期间需要更新的权重。 只更新具有 requires_grad 属性的 tensor。 functional：一个模块（通常按惯例导入到F命名空间中），它包含激活函数，损失函数等，以及非状态（non-stateful）版本的层，如卷积层和线性层。 torch.optim：包含 SGD 等优化器，可在后向传播步骤中更新 Parameter 的权重。 Dataset：带有 __len__ 和 __getitem__ 的对象的抽象接口，包括 PyTorch 提供的类，如 TensorDataset。 DataLoader：获取任何 Dataset 并创建一个返回批量数据的迭代器。 参考文章： https://blog.csdn.net/Spring_24/article/details/100128412 https://blog.csdn.net/Spring_24/article/details/100170304 https://www.cnblogs.com/xianhan/p/9145966.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[论文阅读__label-wise-attention]]></title>
    <url>%2F2021%2F04%2F12%2F%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB-label-wise-attention%2F</url>
    <content type="text"><![CDATA[论文作者讲解Interpretable Emoji Prediction via Label-Wise Attention LSTMs from ACL on Vimeo. 论文脉络 和普通的attention的区别就是每个标签单独进行处理 正常的attention： label-wise-attention:]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>文本分类模型</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-hot]]></title>
    <url>%2F2021%2F04%2F01%2Fleetcode-hot%2F</url>
    <content type="text"><![CDATA[01. 两数之和 01. 两数之和给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 的那 两个 整数，并返回它们的数组下标。 你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。 你可以按任意顺序返回答案。 思路：]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[calloc和malloc的区别--offer03]]></title>
    <url>%2F2021%2F04%2F01%2Fcalloc%E5%92%8Cmalloc%E7%9A%84%E5%8C%BA%E5%88%AB-offer03%2F</url>
    <content type="text"><![CDATA[本文为多篇文章的总汇 https://blog.csdn.net/firecityplans/article/details/4490124]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 实现复制文件夹]]></title>
    <url>%2F2021%2F01%2F19%2Fpython-%E5%AE%9E%E7%8E%B0%E5%A4%8D%E5%88%B6%E6%96%87%E4%BB%B6%E5%A4%B9%2F</url>
    <content type="text"><![CDATA[1. 文件夹下的所有文件（包括子目录文件）拷贝到目标文件夹下 2. 文件夹整体拷贝 3. 复制文件夹以及文件夹下的子文件 4. python复制时不覆盖重命名 本文的形成：首先查找理解网上提供的各种方法，然后在本地进行调试，确定可以使用后进行综合，并发布记录。 本文为转载文章，但由于时间比较急，所以忘记保存转载的地址，之后能找到的话会补上。 方法排序按照我的需求，无优劣之分 1. 文件夹下的所有文件（包括子目录文件）拷贝到目标文件夹下代码： 1234567891011121314151617# 文件夹下的所有文件（包括子目录文件）拷贝到目标文件夹下def copy1(source_path, target_path): if not os.path.exists(target_path): os.makedirs(target_path) if os.path.exists(source_path): # root 所指的是当前正在遍历的这个文件夹的本身的地址 # dirs 是一个 list，内容是该文件夹中所有的目录的名字(不包括子目录) # files 同样是 list, 内容是该文件夹中所有的文件(不包括子目录) for root, dirs, files in os.walk(source_path): for file in files: src_file = os.path.join(root, file) shutil.copy(src_file, target_path) # print(src_file) print('end') print('copy files finished!') 2. 文件夹整体拷贝代码： 123456789101112# 文件夹整体拷贝def copy_all_dir(source_path, target_path): if not os.path.exists(target_path): # 如果目标路径不存在原文件夹的话就创建 os.makedirs(target_path) if os.path.exists(source_path): # 如果目标路径存在原文件夹的话就先删除 shutil.rmtree(target_path) shutil.copytree(source_path, target_path) print('copy dir finished!') 3. 复制文件夹以及文件夹下的子文件代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980def copyDir(sourcePath, targetPath): if not os.path.isdir(sourcePath): return '源目录不存在' # 创建两个栈,一个用来存放原目录路径,另一个用来存放需要复制的目标目录 sourceStack = collections.deque() sourceStack.append(sourcePath) targetStack = collections.deque() targetStack.append(targetPath) # 创建一个循环当栈里面位空时结束循环 while True: if len(sourceStack) == 0: break # 将路径从栈的上部取出 sourcePath = sourceStack.pop() # sourcePath = sourceStack.popleft() # 遍历出该目录下的所有文件和目录 listName = os.listdir(sourcePath) # 将目录路径取出来 targetPath = targetStack.pop() # targetPath = targetStack.popleft() # 判断该目标目录是否存在,如果不存在就创建 if not os.path.isdir(targetPath): os.makedirs(targetPath) # 遍历目录下所有文件组成的列表,判断是文件,还是目录 for name in listName: # 拼接新的路径 sourceAbs = os.path.join(sourcePath, name) targetAbs = os.path.join(targetPath, name) # 判断是否时目录 if os.path.isdir(sourceAbs): # 判断目标路径是否存在,如果不存在就创建一个 if not os.path.exists(targetAbs): os.makedirs(targetAbs) # 将新的目录添加到栈的顶部 sourceStack.append(sourceAbs) targetStack.append(targetAbs) # 判断是否是文件 if os.path.isfile(sourceAbs): shutil.copyfile(sourceAbs,targetAbs)#远程push文件以zip形式，方式文件出现不可预期问题def unzip_files(obj): ss = os.listdir(obj) for file in ss: if file.endswith(".zip"): zip_fileName = obj+file zip_file = zipfile.ZipFile(zip_fileName) zz = file.split(".zip")[0] ff =obj + zz if os.path.isdir(ff): pass else: os.mkdir(ff) for names in zip_file.namelist(): zip_file.extract(names,ff) zip_file.close() time.sleep(2) os.remove(zip_fileName) return zz#实现更新功能，判断要更新文件夹下，若为文件夹则复制替换，若非文件夹则跳过def update_dest_folder(object): dd = [] if os.path.isdir(object): updatefoldername = os.listdir(object) for ff in updatefoldername: updatefoldername = object+ "/" +ff if os.path.isdir(updatefoldername): dd.append(updatefoldername) else: pass return ddif __name__ == '__main__': #要复制的文件夹地址 srcPath = "E:/update/" ss = unzip_files(srcPath) #要复制更新的目标文件地址 tPath = "E:/test" names = update_dest_folder(tPath) sorce_real = srcPath + "/"+str(ss)+"/"+str(ss) print(sorce_real) for destPath in names: copyDir(sorce_real, destPath) 4. python复制时不覆盖重命名代码： 12345678910def get_new_name(dir, f): if os.path.exists(os.path.join(dir, f)): # 拆分文件名和文件后缀，获取新命名 s="%s_%s%s" % (os.path.splitext(f)[0], "copy", os.path.splitext(f)[1]) return get_new_name(dir, s)# 新命名文件是否存在 return os.path.join(dir, f)# 返回新文件路径p=get_new_name(r"C:\Users\lishihang\Desktop\新建文件夹","1.txt")shutil.copy(r"C:\Users\lishihang\Desktop\1.txt",p)]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>python学习应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PyCharm常用配置和常用插件]]></title>
    <url>%2F2021%2F01%2F17%2FPyCharm%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E5%92%8C%E5%B8%B8%E7%94%A8%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[常用配置 配置Python解释器 文件编码 文件和代码模板 修改主题 修改字体 快捷键风格 显示行数和方法线 代码自动提示快捷键 鼠标悬停显示文档说明 关闭自动更新 安装 autopep8 工具 启动不打开上一个项目 导出导入配置 常用插件 转载于 ThinkWon 常用配置以下配置能使用 File -&gt; New Projects Settings -&gt; Settings for New Projects进行配置的尽量用这个配置，因为这个配置是作用于所有新建项目的，不能用的选择 File -&gt; Settings 配置Python解释器 文件编码 文件和代码模板 修改主题 修改字体 快捷键风格 显示行数和方法线 代码自动提示快捷键移除占用Alt+斜杠的快捷键 设置Basic快捷键为Alt+斜杠 鼠标悬停显示文档说明 关闭自动更新 安装 autopep8 工具PEP8是 Python Enhancement Proposal 8的缩写，翻译过来就是 Python增强建议书，也就是Python编码规范。 Mac安装方式 命令行输入 pip install autopep8，如果执行 autopep8 --version命令，输出类似 autopep8 1.5.4 (pycodestyle: 2.6.0)的信息，则说明安装成功 Win10安装方式 搜索autopep8，点击 Install Package 安装完成之后左下角会出现 Packages autopep8 installed successful等信息 Name：autopep8（可以随便取） Tools settings Programs： C:\dev\anaconda3\Lib\site-packages\autopep8.py Parameters： --in-place --aggressive --aggressive $FilePath$ Working directory： ProjectFileDir Output Filters设置： regular expression to match output： $FILE_PATH$:$LINE$:$COLUMN$:.* autopep8在pycharm中的使用：在Pycharm编辑其中新建一个python文件，编辑一些不符合pep8风格的代码；将鼠标放在该文件的编辑器中→右键→External Tools→点击Autopep8。这样你的代码就符合pep8的风格了。 启动不打开上一个项目 导出导入配置导出配置 file -&gt; Manage IDE Settings -&gt; export setting，设置导出的settings.jar包的位置，然后点击OK 导入配置 file -&gt; Manage IDE Settings -&gt; import settings，选择你想要导入的 settings.jar即可 常用插件 Translation -翻译插件 CodeGlance -代码地图 .ignore -git忽略文件 Key Promoter X -一款可以进行快捷键提示的插件 AceJump -一款可以彻底摆脱鼠标的插件 String Manipulation -一款强大的字符串转换工具 GsonFormat -将JSON字符串转换为内部类实体类插件 ideaVim -让我们在 Pycharm 中 使用 vim 来编辑代码 Markdown -md文件编辑查看 Regex Tester -PyCharm的第三方插件，可以测试正则表达式 Json Parser -json格式化工具 Statistic -statistic项目统计插件，统计整体代码量，包括所有文件的统计数量和行数 Rainbow Brackets -彩虹颜色的括号，清除分清括号个数，防止括号错乱]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>Pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pycharm 安装 autopep8 运行报错]]></title>
    <url>%2F2021%2F01%2F17%2FPycharm-%E5%AE%89%E8%A3%85-autopep8-%E8%BF%90%E8%A1%8C%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[1. pycharm 插件 autopep8 2. 在 Pycharm 中安装 autopep8 配置 2.1 查看是否成功安装 autopep8 2.2 查看 autopep8 配置 3. autopep8在pycharm中的使用 4. 可能出现的其他错误 1. No such file or directory错误 2. failed to create process 3.不是有效的 Win32 应用程序 4. 已经安装插件成功但是报错没有找到该模块 5. 安装配置Autopep8 1. pycharm 插件 autopep8 昨天看到一个有用的 pycharm 插件 autopep8 按照网上的教程安装 不嫌弃的话 可以看这个2018版pycharm手把手教你安装配置Autopep8(看了就不可能学不会) 运行报错 Error running ‘autopep8’: Cannot run program “D:\App\Anaconda\anaconda3\Lib\site-packages\autopep8.py” (in directory “D:\App\PyCharm\pycharm_test\netease-cloud-master”): CreateProcess error=193, %1 不是有效的 Win32 应用程序。 内心复杂，进行debug 2. 在 Pycharm 中安装 autopep8 配置2.1 查看是否成功安装 autopep8 找到你当前项目所用的python环境 比如我就是 D:\App\Anaconda\anaconda3\envs\py36\python.exe import autopep8如果不报错就是安装成功 2.2 查看 autopep8 配置 file -&gt; setting -&gt; Tools → Extends Tools → 点击加号 Name：Autopep8（可以随便取） ==Programs：autopep8 此处是亮点== 注意最后要定位到一个 .exe 的可运行文件 比如我就是“D:\App\Anaconda\anaconda3\envs\py36\Scripts\autopep8.exe” Parameters: 1--in-place --aggressive --aggressive $FilePath$ Working directory: 1$ProjectFileDir$ Advanced Options: 点击Output Files→添加 在对话框中的：Regular expression to match output中输入：1$FILE_PATH$\:$LINE$\:$COLUMN$\:.* 3. autopep8在pycharm中的使用 在Pycharm编辑其中新建一个python文件，编辑一些不符合pep8风格的代码； 将鼠标放在该文件的编辑器中→右键→External Tools→点击Autopep8。这样你的代码就符合pep8的风格了。 4. 可能出现的其他错误1. No such file or directory错误 (1) autopep8出现[Errno 2] No such file or directory错误的可能情况之一 (2) Autopep8 安装时出现的两种报错 failed to create process 和 [Errno 2] No such file or directory 2. failed to create process (1) Autopep8 安装时出现的两种报错 failed to create process 和 [Errno 2] No such file or directory 3.不是有效的 Win32 应用程序4. 已经安装插件成功但是报错没有找到该模块 (1) PyCharm报错CreateProcess error=193, %1 不是有效的 Win32 应用程序或者已经安装插件成功但是报错没有找到该模块 (2) 使用pep8报“Error running ‘autopep8’: Cannot run program “autopep8” (in directory “xxx”): CreateProcess error=2, 系统找不到指定的文件” 5. 安装配置Autopep8 (1) 2018版pycharm手把手教你安装配置Autopep8(看了就不可能学不会) (2) Autopep8的使用]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>Pycharm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows Defender CPU 占用100%问题解决]]></title>
    <url>%2F2021%2F01%2F13%2FWindows%20Defender%20CPU%20%E5%8D%A0%E7%94%A8100%25%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3%2F</url>
    <content type="text"><![CDATA[笔记本突然CPU飙升，看了一下发现windows Defender Antivirsus占用大量CPU和内存（100%），查了下发现需要组策略来关闭Defender 运行bat文件，然后同时按win+r键，在”运行”中输入”gpedit.msc”: 在组策略中选择： 计算机配置 –&gt; 管理模板–&gt; windows组件 –&gt; windows definder –&gt; 扫描 –&gt; “指定扫描期间占用CPU最大.百分比” 在设置中选择”已启用”，设置CPU最大占用比例为5% 重启电脑就可以了]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关闭迅雷更新到新版本的提示]]></title>
    <url>%2F2021%2F01%2F13%2F%E5%85%B3%E9%97%AD%E8%BF%85%E9%9B%B7%E6%9B%B4%E6%96%B0%E5%88%B0%E6%96%B0%E7%89%88%E6%9C%AC%E7%9A%84%E6%8F%90%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[转载于 xiongtianci.com每次打开迅雷都会自动检查是否是最新版本，如果不是最新版本，迅雷会一直重复弹窗弹出 更新到新版本 的提示： 解决方案简介：迅雷提示升级是因为每次迅雷主程序启动时都会同时启动一个叫XLLiveUD.exe的程序，这个程序会检查更新，所以如果不想让他检查更新，就只需要把他替换掉就可以了（因为如果删除它，每次迅雷启动时都会弹出一个错误对话框，提示找不到文件XLLiveUD.exe） 进入迅雷安装目录，找到 XLLiveUD.exe( 可直接在迅雷安装目录中搜索这个文件 )，将其删除。这个就是自动升级的程序，但是删除之后下次开启迅雷会提示该文件丢失。 在同一个目录找到迅雷执行程序文件 Thunder.exe，这个是就是迅雷桌面快捷方式指到的程序也就是迅雷开启程序。然后复制拷贝 Thunder.exe副本，然后将副本文件名更改为迅雷更新执行程序名： XLLiveUD.exe 当迅雷程序调用检查更新的执行文件时，实际上相当于重复点击打开迅雷，而迅雷本身不允许重复打开。这样既不会报错也不会造成重复弹屏的问题。从而算是比较完美的解决了 关闭迅雷更新到新版本提示 的问题(❁´◡`❁) ✲ﾟ]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo 写文章创建文件自动打开编辑器！]]></title>
    <url>%2F2021%2F01%2F13%2Fhexo%20%E5%86%99%E6%96%87%E7%AB%A0%E5%88%9B%E5%BB%BA%E6%96%87%E4%BB%B6%E8%87%AA%E5%8A%A8%E6%89%93%E5%BC%80%E7%BC%96%E8%BE%91%E5%99%A8%EF%BC%81%2F</url>
    <content type="text"><![CDATA[问题根源 官方解法 实际应用 问题解决 hexo gitHub地址：https://github.com/hexojs/hexo hexo 文档：https://hexo.io/zh-cn/api/events.html 备份Hexo博客源文件参考Blog！： https://notes.wanghao.work/2015-04-06-%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html https://notes.wanghao.work/2015-07-06-%E8%87%AA%E5%8A%A8%E5%A4%87%E4%BB%BDHexo%E5%8D%9A%E5%AE%A2%E6%BA%90%E6%96%87%E4%BB%B6.html 问题根源正常情况下通过 hexo new “文件名” 创建文章。就会在在 Hexo 的根目录的 source 文件夹下的 _posts 目录下自动帮你创建相应的 md 文件。 1hexo new " hexo 添加文章时自动打开编辑 ! " 如果_post文件夹下文章很多的时候，找起来就会很不方便。 官方解法Hexo作者也给出来解决办法：https://github.com/hexojs/hexo you can try to listen to the new event. For example:123456789var spawn = require('child_process').exec; // Hexo 2.x hexo.on('new', function(path)&#123; exec('vi', [path]); &#125;); // Hexo 3 hexo.on('new', function(data)&#123; exec('vi', [data.path]); &#125;); 实际应用 在Hexo目录下的scripts目录中创建一个JavaScript脚本文件。如果没有这个scripts目录，则新建一个。 scripts目录新建的 js 脚本文件可以任意取名。 windows平台的Hexo用户操作如下： auto_open.js 内容如下： var spawn = require(&#39;child_process&#39;).exec; // Hexo 2.x 用户复制这段 //hexo.on(&#39;new&#39;, function(path){ // spawn(&#39;start &quot;markdown编辑器绝对路径.exe&quot; &#39; + path); //}); //D:\App\Microsoft VS Code\Code.exe // 是VS Code编辑器在我本地的路径！ // Hexo 3 用户复制这段 hexo.on(&#39;new&#39;, function(data){ spawn(&#39;start &quot;D:\App\Microsoft VS Code\Code.exe&quot; &#39; + data.path); }); 问题解决然后再创建文件输入命令之后就会自动打开VS Code编辑器来编辑了。 hexo new &quot;auto open editor test&quot;]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>js</tag>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Han 翻译]]></title>
    <url>%2F2021%2F01%2F11%2FHan%20%E7%BF%BB%E8%AF%91%2F</url>
    <content type="text"><![CDATA[Hierarchical Attention Networks for Document Classification 用于文本分类的分层注意力网络 文章目录 0 Abstract 1 Introduction 2 Hierarchical Attention Networks 2.1 GRU-based sequence encoder 2.2 Hierarchical Attention 2.3 Document Classification 3 Experiments 3.1 Data sets 3.2 Baselines 3.2.1 Linear methods 3.2.2 SVMs 3.2.3 Neural Network methods 3.3 Model configuration and training 3.4 Results and analysis 3.5 Context dependent attention weights 3.6 Visualization of attention 4 Related Work 5 Conclusion Referencesd 0 AbstractWe propose a hierarchical attention network for document classification. Our model has two distinctive characteristics: (i) it has a hierarchical structure that mirrors the hierarchical structure of documents; (ii) it has two levels of attention mechanisms applied at the word and sentence-level, enabling it to attend differentially to more and less important content when constructing the document representation. Experiments conducted on six large scale text classification tasks demonstrate that the proposed architecture outperform previous methods by a substantial margin. Visualization of the attention layers illustrates that the model selects qualitatively informative words and sentences. 我们提出了一个用于文本分类的分层注意力网络。 我们的模型有两个显著的特征： （1） 具有反映文档结构的层次结构 （2） 他有两层应用在单词和句子层面的注意力机制，使它能够在构造文本特征的时候分别注意重要和不重要的内容 在六个大型的文本分类任务上的实验表明 (我们)提出的结构在很大程度上比之前的方法好。 注意力层可视化显示该模型选择定性的信息丰富的单词和句子。 1 Introduction paragraph 1 Text classification is one of the fundamental task in Natural Language Processing. The goal is to assign labels to text. It has broad applications including topic labeling (Wang and Manning, 2012),sentiment classification (Maas et al., 2011; Pang and Lee,2008), and spam detection (Sahami et al., 1998). Traditional approaches of text classification represent documents with sparse lexical features, such as n-grams, and then use a linear model or kernel methods on this representation (Wang and Manning,2012; Joachims, 1998). More recent approaches used deep learning, such as convolutional neural networks (Blunsom et al., 2014) and recurrent neural networks based on long short-term memory (LSTM)(Hochreiter and Schmidhuber, 1997) to learn text representations. 文本分类是自然语言处理中的基础任务之一。 目的是为文本分配标签。 它具有广泛的应用，包括 主题标签（Wang和Manning，2012年） ，情感分析（Maas等人，2011年；Pang和Lee，2008年），和垃圾电邮检测（Sahami等，1998年）。 传统的文本分类方法 具有稀疏词典特征（例如n-gram）的文档,然后对该表示使用线性模型或核方法（Wang和Manning，2012;Joachims，1998年）。 最近的方法使用深度学习，例如卷积神经网络（Blunsom等人，2014）和基于长短期记忆（LSTM）的递归神经网络（Hochreiter and Schmidhuber，1997）来学习文本表示。 paragraph 2 Although neural-network–based approaches to text classification have been quite effective (Kim,2014; Zhang et al., 2015; Johnson and Zhang, 2014;Tang et al., 2015), in this paper we test the hypothesis that better representations can be obtained by incorporating knowledge of document structure in the model architecture. The intuition underlying our model is that not all parts of a document are equally relevant for answering a query and that determining the relevant sections involves modeling the interactions of the words, not just their presence in isolation. 尽管基于神经网络的文本分类方法已经非常有效（Kim，2014； Zhang等，2015； Johnson和Zhang，2014；Tang等，2015），但在本文中，我们还是检验了更好的表示方法的假设。 通过将文档结构的知识合并到模型体系结构中可以获得。 我们模型所基于的直觉是，并非文档的所有部分对于回答查询都具有同等的相关性，并且确定相关部分涉及对单词的交互进行建模，而不仅仅是对它们的单独存在进行建模。 paragraph 3 Our primary contribution is a new neural architecture (§2), the Hierarchical Attention Network(HAN) that is designed to capture two basic insights about document structure. First, since documents have a hierarchical structure (words form sentences,sentences form a document), we likewise construct a document representation by first building representations of sentences and then aggregating those into a document representation. Second, it is observed that different words and sentences in a documents are differentially informative. Moreover, the importance of words and sentences are highly context dependent,i.e. the same word or sentence may be differentially important in different context (§3.5). 我们的主要贡献是新的神经体系结构（§2），即分层注意网络（HAN），其目的是捕获有关文档结构的两个基本见解。 首先，由于文档具有层次结构（单词构成句子，句子构成文档），我们同样地通过首先构建句子的表示形式，然后将其汇总为文档表示形式来构造文档表示形式。 其次，可以观察到文档中不同的单词和句子具有差异性。 而且，单词和句子的重要性在很大程度上取决于上下文，即，相同的单词或句子在不同的上下文中可能具有不同的重要性（第3.5节）。 To include sensitivity to this fact, our model includes two levels of attention mechanisms (Bahdanau et al.,2014; Xu et al., 2015) — one at the word level andone at the sentence level — that let the model to pay more or less attention to individual words and sentences when constructing the representation of the document. To illustrate, consider the example in Fig. 1, which is a short Yelp review where the task is to predict the rating on a scale from 1–5. 为了包括对这一事实的敏感性，我们的模型包括两个级别的注意力机制（Bahdanau等，2014；Xu等，2015）–一个在单词级别，另一个在句子级别–使模型付出更多或更高构建文档表示时，对单个单词和句子的关注较少。 为了说明这一点，请考虑图1中的示例，该示例是Yelp的简短回顾，其任务是以1-5的等级预测等级。 Intuitively, the first and third sentence have stronger information in assisting the prediction of the rating; within these sentences, the word delicious, a-m-a-z-i-n-g contributes more in implyingthe positive attitude contained in this review. Attention serves two benefits: not only does it often result in better performance, but it also provides insight into which words and sentences contribute to the classification decision which can be of value in applications and analysis (Shen et al., 2014; Gao et al., 2014). 从直觉上讲，第一和第三句话在帮助评估评分方面具有更强的信息；在这些句子中，美味（a-m-a-z-i-n-g）一词在暗示本评论中所包含的积极态度方面起了更大的作用。 注意有两个好处：不仅可以经常带来更好的性能，而且还可以洞察哪些词和句子有助于分类决策，这在应用和分析中可能是有价值的（Shen等人，2014；Gao等人，2014）。 paragraph 4 The key difference to previous work is that our system uses context to discover when a sequence of tokens is relevant rather than simply filtering for (sequences of) tokens, taken out of context. To evaluate the performance of our model in comparison to other common classification architectures, we look at six data sets (§3). Our model outperforms previous approaches by a significant margin. 与先前工作的主要区别在于，我们的系统使用上下文来发现令牌序列何时相关，而不是简单地过滤掉上下文中的令牌（序列）。 为了评估模型与其他常见分类体系结构相比的性能，我们查看了六个数据集（第3节）。 我们的模型大大优于以前的方法。 2 Hierarchical Attention NetworksThe overall architecture of the Hierarchical Attention Network (HAN) is shown in Fig. 2. It consists of several parts: a word sequence encoder, a word-level attention layer, a sentence encoder (and) a sentence-level attention layer. We describe the details of different components in the following sections. 分层注意力网络（HAN）的总体体系结构如图2所示。 它由几个部分组成： 单词序列编码器， 单词级别的注意力层， 句子编码器(和) 句子级别的注意力层。 我们将在以下各节中描述不同组件的详细信息。 2.1 GRU-based sequence encoder paragraph 1 The GRU (Bahdanau et al., 2014) uses a gating mechanism to track the state of sequences without using separate memory cells. GRU（Bahdanau等人，2014）使用门控机制来跟踪序列状态，而无需使用单独的存储单元。 There are two types of gates: the reset gate $r_t$ and the update gate $z_t$. They together control how information is updated to the state.At time t, the GRU computes the new state as $ ht = (1-z_t) \odot h{t-1} + z_t \odot \tilde{h_t} \quad (1)$ 门有两种类型：重置门 $rt$ 和更新门 $z_t$ 。它们一起控制如何将信息更新为状态。在时间t，GRU计算新状态为$ h_t = (1-z_t) \odot h{t-1} + z_t \odot \tilde{h_t} \quad (1)$ This is a linear interpolation between the previous state $h_{t−1}$ and the current new state $ \tilde{h_t} $ computed with new sequence information.The gate $z_t$ decides how much past information is kept and how much new information is added. $z_t$ is updated as: $ zt = \sigma(W_zx_t+U_zh{t-1}+b_z), \quad (2)$ where $x_t$ is the sequence vector at time t. 这是在先前状态$ h {t-1} $和使用新序列信息计算出的当前新状态$ \tilde {h_t} $之间的线性插值。门$ z_t $决定保留多少过去信息以及添加多少新信息。 $ z_t $更新为：$ z_t = \sigma(W_zx_t+U_zh{t-1}+b_z), \quad (2)$其中$ x_t $是时间t的序列向量。 The candidate state $\tilde{ht}$ is computed in a way similar to a traditional recurrent neural network (RNN):$\tilde{h_t}=tanh(W_hx_t+r_t\odot(U_hh{t-1})+b_h), \qquad (3)$ 候选状态$ \tilde {ht} $的计算方式类似于传统的递归神经网络（RNN）：$\tilde{h_t}=tanh(W_hx_t+r_t\odot(U_hh{t-1})+b_h), \qquad (3)$ Here $rt$ is the reset gate which controls how much the past state contributes to the candidate state. If $r_t$ is zero, then it forgets the previous state. The reset gate is updated as follows:$r_t = \sigma(W_r x_t + U_r h{t-1} + b_r)\qquad (4)$ $ rt $是复位门，它控制过去状态对候选状态的贡献量。 如果$ r_t $为零，则它将忘记先前的状态。 重置门更新如下：$r_t = \sigma(W_r x_t + U_r h{t-1} + b_r)\qquad (4)$ 2.2 Hierarchical Attention paragraph 1 We focus on document-level classification in this work. Assume that a document has $ \it L$ sentences $si$ and each sentence contains $T_i$ words. $w{it}$ with t $\in$ $[0,T]$ represents the words in the $\it i$ th sentence. The proposed model projects the raw document into a vector representation, on which we build a classifier to perform document classification. In the following, we will present how we build the document level vector progressively from word vectors by using the hierarchical structure. 在这项工作中，我们专注于文档级分类。 假设一个文档有$ \it L $个句子$ si $，每个句子包含$ T_i $个单词。 $ w{it} $表示第i个句子中的单词,其中 t $\in$ $[0,T]$。 提出的模型将原始文档投影到矢量表示中，我们在其上构建分类器以执行文档分类。 在下面，我们将介绍如何使用层次结构从单词向量逐步构建文档级别向量。 paragraph 2 $\bf Word \ \ Encoder$ Given a sentence with words $ w{it} $,t $\in$ $[0,T]$, we first embed the words to vectors through an embedding matrix $W_e$, $x{ij}$ = $Wew{ij}$. We use a bidirectional GRU (Bahdanau et al., 2014) to get annotations of words by summarizing information from both directions for words, and therefore incorporate the contextual information in the annotation.The bidirectional GRU contains the forward GRU $\overrightarrow{f}$ which reads the sentence $si$ from $w{i1}$ to ${wiT}$ and a backward GRU $\overleftarrow{f}$ which reads from $w{iT}$ to $w_{i1}$: $x{it} = W_ew{it},\ t \in$ $[1,T],$$\overrightarrow{h}{it} = \overleftarrow{GRU}(x{it}) ,\ t \in$ $[1,T],$$\overleftarrow{h}{it} = \overrightarrow{GRU}(x_{it}) ,\ t \in$ $[T,1],$ $\bf Word \ \ Encoder$ 给定包含单词$ w {it} $，t $ \in $ $ [0，T] $的句子，我们首先通过嵌入矩阵$ W_e $将单词嵌入向量中，$ x{ij} $ = $ Wew{ij} $。 我们使用双向GRU（Bahdanau等人，2014）通过汇总来自两个方向的单词信息来获取单词注释，因此将上下文信息合并到注释中。双向GRU包含前向GRU $ \overrightarrow {f} $，将句子$ si $从$ w{i1} $读到${wiT}$；向后GRU $ \overleftarrow {f} $，从$ w{iT} $读取到$ w {i1} $：$x{it} = Wew{it},\ t \in$ $[1,T],$$\overrightarrow{h}{it} = \overleftarrow{GRU}(x{it}) ,\ t \in$ $[1,T],$$\overleftarrow{h}{it} = \overrightarrow{GRU}(x_{it}) ,\ t \in$ $[T,1],$ We obtain an annotation for a given word $ w{iT} $ by concatenating the forward hidden state $\overrightarrow{h}{it}$ and backward hidden state $\overleftarrow{h}{it}$, i.e., ${h}{it}$ = [ $\overrightarrow{h}{it} , \overleftarrow{h}{it} ]$, which summarizes the information of the whole sentence centered around $ w_{iT} $. 我们通过将前向隐藏状态$\overrightarrow{h}{it}$和后向隐藏状态$\overleftarrow{h}{it}$（即${h}{it}$ = [ $\overrightarrow{h}{it} , \overleftarrow{h}{it} ]$）进行级联来获得给定单词 $ w{it} $的注释，该注释总结了以$ w_{it} $为中心的整个句子的信息。 paragraph 3 Note that we directly use word embeddings. For a more complete model we could use a GRU to get word vectors directly from characters, similarly to (Ling et al., 2015). We omitted this for simplicity. 请注意，我们直接使用单词嵌入。 对于更完整的模型，类似于（Ling等人，2015），我们可以使用GRU直接从字符中获取单词向量。 为了简单起见，我们省略了这一点。 paragraph 4 $\bf Word \ \ Attention$ Not all words contribute equally to the representation of the sentence meaning. Hence, we introduce attention mechanism to extract such words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector. Specifically, $ u{it} = tanh(W_wh{it} + bw) \qquad (5)$$ \alpha{it} = \frac{exp(u{it}\top u_w)}{\sum_t exp(u{it}\top uw)} \qquad \qquad \ \ (6)$$ s_i = \sum_t \alpha{it}h_{it} \qquad \qquad \qquad \ (7)$ $\bf Word \ \ Attention$ 并非所有单词都对句子含义的表示有同等的贡献。 因此，我们引入注意力机制来提取对句子的意义很重要的单词，并汇总这些信息性单词的表示形式以形成句子向量。 特别，$ u{it} = tanh(W_wh{it} + bw) \qquad (5)$$ \alpha{it} = \frac{exp(u{it}\top u_w)}{\sum_t exp(u{it}\top uw)} \qquad \qquad \ \ (6)$$ s_i = \sum_t \alpha{it}h_{it} \qquad \qquad \qquad \ (7)$ That is, we first feed the word annotation hit through a one-layer $\sf MLP$ to get $u{it}$ as a hidden representation of $h{it}$, then we measure the importance of the word as the similarity of $u{it}$ with a word level context vector $u_w$ and get a normalized importance weight $\alpha{it}$ through a softmax function. 也就是说，我们首先通过一层$ \sf MLP $来输入单词注释命中，以获取$ u{it} $作为$ h{it} $的隐藏表示，然后我们将单词的重要性作为 $ u{it} $与词级上下文向量$ u_w $的相似性，并通过softmax函数获得归一化的重要性权重$ \alpha{it} $。 After that, we compute the sentence vector $ s_ i $ (we abuse the notation here) as a weighted sum of the word annotations based on the weights. 之后，我们根据权重计算句子向量$ s_i $（在这里我们滥用了表示法）作为单词注释的加权总和。 The context vector $ u_w $ can be seen as a high level representation of a fixed query “what is the informative word” over the words like that used in memory networks (Sukhbaatar et al., 2015; Kumar et al., 2015). The word context vector $ u_w $ is randomly initialized and jointly learned during the training process. 上下文向量$ u_w $可以看作是固定查询“什么是信息性单词”的高级表示，类似于存储网络中使用的单词（Sukhbaatar等，2015； Kumar等，2015）。 单词上下文向量$ u_w $在训练过程中被随机初始化并共同学习。 paragraph 5 $\bf Sentence \ \ Encoder$ Given the sentence vectors $s_i$, we can get a document vector in a similar way. We use a bidirectional GRU to encode the sentences:$\overrightarrow{h_i} = \overrightarrow{GRU}(s_i), i \in [1,L],$$\overleftarrow{h_i} = \overleftarrow{GRU}(s_i), i \in [L,1].$We concatenate $\overrightarrow{h_i}$ and $\overleftarrow{h_j}$ to get an annotation of sentence $i$, i.e., $h_i$ = [ $\overrightarrow{h_i}, \overleftarrow{h_i}$]. $h_i$ summarizes the neighbor sentences around sentence $i$ but still focus on sentence $i$. $ \bf Sentence \ \ Encoder $ 给定句子向量$ s_i $，我们可以以类似的方式获得文档向量。 我们使用双向GRU对句子进行编码：$\overrightarrow{h_i} = \overrightarrow{GRU}(s_i), i \in [1,L],$$\overleftarrow{h_i} = \overleftarrow{GRU}(s_i), i \in [L,1].$我们将$ \overrightarrow{h_i} $和$ \overleftarrow{h_j} $连接起来，得到句子$ i $的注释，即$ h_i $ = [$ \overrightarrow {h_i}，\overleftarrow {h_i} $]。 $ h_i $总结了句子$ i $周围的相邻句子，但仍关注句子$ i $。 paragraph 6 $\bf Sentence \ \ Attention$ To reward sentences that are clues to correctly classify a document, we again use attention mechanism and introduce a sentence level context vector $u_s$ and use the vector to measure the importance of the sentences. This yields $u_i = tanh(W_ih_i+b_s) , \qquad (8)$$\alpha_i = \frac{exp(u_i\top u_s)}{\sum_t exp(u_i\top u_s)} ,\qquad \qquad (9)$$ v = \sum\limits_i \alpha_ih_i \qquad \qquad \qquad \ \ (10)$ $ \bf Sentence \ Attention $ 为了奖励正确分类文档的线索，我们再次使用注意机制并引入句子级别上下文向量$ u_s $，并使用该向量来衡量句子的重要性。 这产生$u_i = tanh(W_ih_i+b_s) , \qquad (8)$$\alpha_i = \frac{exp(u_i\top u_s)}{\sum_t exp(u_i\top u_s)} ,\qquad \qquad (9)$$ v = \sum\limits_i \alpha_ih_i \qquad \qquad \qquad \ \ (10)$ where $v$ is the document vector that summarizes all the information of sentences in a document. Similarly, the sentence level context vector can be randomly initialized and jointly learned during the training process. 其中$ v $是总结文档中句子所有信息的文档向量。 类似地，可以在训练过程中随机初始化句子级别的上下文向量并共同学习。 2.3 Document Classification paragraph 1 The document vector $v$ is a high level representation of the document and can be used as features for document classification: $ p $ = softmax$(W_cv+b_c). \qquad (11)$ We use the negative log likelihood of the correct labels as training loss: $L = - \sum\limitsd logp{dj}, \qquad \qquad \ (12)$ where $j$ is the label of document $d$. 文档向量$ v $是文档的高级表示，可以用作文档分类的特征：$ p $ = softmax$(Wcv+b_c). \qquad (11)$我们使用正确标签的负对数似然作为训练损失：$L = - \sum\limits_d logp{dj}, \qquad \qquad \ (12)$其中$ j $是文档$ d $的标签。 3 Experiments3.1 Data sets paragraph 1 We evaluate the effectiveness of our model on six large scale document classification data sets. These data sets can be categorized into two types of document classification tasks: sentiment estimation and topic classification. The statistics of the data sets are summarized in Table 1. We use 80% of the data for training, 10% for validation, and the remaining 10% for test, unless stated otherwise. 我们在六个大型文档分类数据集上评估了模型的有效性。 这些数据集可以分为两种类型的文档分类任务：情感估计和主题分类。 数据集的统计信息汇总在表1中。除非另有说明，否则我们将80％的数据用于训练，10％的数据用于验证，将其余10％的数据用于测试。 $\bf Yelp \ \ reviews$ are obtained from the Yelp Dataset Challenge in 2013, 2014 and 2015 (Tang et al., 2015). There are five levels of ratings from 1 to 5 (higher is better). $\bf Yelp \ \ reviews$ 来自2013、2014和2015年的Yelp数据集挑战赛（Tang et al。，2015）。 评分分为5级（从1到5）（越高越好）。 $\bf IMDB \ \ reviews$ are obtained from (Diao et al., 2014). The ratings range from 1 to 10. $\bf IMDB \ \ reviews$来自（Diao等人，2014）。 评分范围是1到10。 $\bf Yahoo \ \ answers$ are obtained from (Zhang et al., 2015). This is a topic classification task with 10 classes: Society &amp; Culture, Science &amp; Mathematics, Health, Education &amp; Reference, Computers &amp; Internet, Sports, Business &amp; Finance, Entertainment &amp; Music, Family &amp; Relationships and Politics &amp; Government. The document we use includes question titles, question contexts and best answers. There are 140,000 training samples and 5000 testing samples. The original data set does not provide validation samples. We randomly select 10% of the training samples as validation. $\bf Yahoo \ \ answers$ 来自（Zhang et al。，2015）。 这是一个主题分类任务，共有10个班级：社会与文化，科学与数学，健康，教育与参考，计算机与互联网，体育，商业与金融，娱乐与音乐，家庭与人际关系以及政治与政府。 我们使用的文档包括问题标题，问题上下文和最佳答案。 有140,000个训练样本和5000个测试样本。 原始数据集不提供验证样本。 我们随机选择10％的训练样本作为验证。 $\bf Amazon \ \ reviews$ are obtained from (Zhang et al., 2015). The ratings are from 1 to 5. 3,000,000 reviews are used for training and 650,000 reviews for testing. Similarly, we use 10% of the training samples as validation. $\bf Amazon \ \ reviews$ 来自（Zhang et al。，2015）。 评分为1-5。3,000,000条评论用于培训，650,000条评论用于测试。 同样，我们使用10％的训练样本作为验证。 3.2 Baselines paragraph 1 We compare HAN with several baseline methods, including traditional approaches such as linear methods, SVMs and paragraph embeddings using neural networks, LSTMs, word-based CNN, character-based CNN, and Conv-GRNN, LSTMGRNN. These baseline methods and results are reported in (Zhang et al., 2015; Tang et al., 2015). 我们将 HAN 与几种基线方法进行了比较，包括使用神经网络、LSTM、基于词的 CNN、基于字符的 CNN 和 Conv-GRNN、LSTMGRNN 的线性方法、SVM 和段落嵌入等传统方法。 这些基线方法和结果在（Zhang 等人，2015 年；Tang 等人，2015 年）中报告。 3.2.1 Linear methods paragraph 1 Linear methods (Zhang et al., 2015) use the constructed statistics as features. A linear classifier based on multinomial logistic regression is used to classify the documents using the features. BOW and BOW+TFIDF The 50,000 most frequent words from the training set are selected and the count of each word is used features. Bow+TFIDF, as implied by the name, uses the TFIDF of counts as features. n-grams and n-grams+TFIDF used the most frequent 500,000 n-grams (up to 5-grams). Bag-of-means The average word2vec embedding (Mikolov et al., 2013) is used as feature set. 3.2.2 SVMs paragraph 1 SVMs-based methods are reported in (Tang et al., 2015), including SVM+Unigrams, Bigrams, Text Features, AverageSG, SSWE. In detail, Unigrams and Bigrams uses bag-of-unigrams and bagof-bigrams as features respectively.(Tang et al., 2015) 报告了基于 SVM 的方法，包括 SVM+Unigrams、Bigrams、Text Features、AverageSG、SSWE。 具体来说，Unigrams 和 Bigrams 分别使用 bag-of-unigrams 和 bagof-bigrams 作为特征。 Text Features are constructed according to (Kiritchenko et al., 2014), including word and character n-grams, sentiment lexicon features etc.根据 (Kirichenko et al., 2014) 构建，包括单词和字符 n-gram、情感词典特征等。 AverageSG constructs 200-dimensional word vectors using word2vec and the average word embeddings of each document are used.AverageSG 使用 word2vec 构建 200 维词向量，并使用每个文档的平均词嵌入。 SSWE uses sentiment specific word embeddings according to (Tang et al., 2014).SSWE 根据 (Tang et al., 2014) 使用特定于情感的词嵌入。 3.2.3 Neural Network methods paragraph 1 The neural network based methods are reported in (Tang et al., 2015) and (Zhang et al., 2015).基于神经网络的方法在 (Tang et al., 2015) 和 (Zhang et al., 2015) 中有报道。 CNN-word Word based CNN models like that of (Kim, 2014) are used.使用了像 (Kim, 2014) 那样的基于 CNN 词 Word 的 CNN 模型。 CNN-char Character level CNN models are reported in (Zhang et al., 2015).CNN-char 字符级 CNN 模型在 (Zhang et al., 2015) 中有报道。 LSTM takes the whole document as a single sequence and the average of the hidden states of all words is used as feature for classification. LSTM 将整个文档作为单个序列，所有单词的隐藏状态的平均值作为分类特征。 Conv-GRNN and LSTM-GRNN were proposed by (Tang et al., 2015). They also explore the hierarchical structure: a CNN or LSTM provides a sentence vector, and then a gated recurrent neural network (GRNN) combines the sentence vectors from a document level vector representation for classification.Conv-GRNN 和 LSTM-GRNN 是由 (Tang et al., 2015) 提出的。 他们还探索了层次结构：CNN 或 LSTM 提供了一个句子向量，然后门控循环神经网络 (GRNN) 将来自文档级向量表示的句子向量组合起来进行分类。 3.3 Model configuration and training paragraph 1 We split documents into sentences and tokenize each sentence using Stanford’s CoreNLP (Manning et al., 2014). We only retain words appearing more than 5 times in building the vocabulary and replace the words that appear 5 times with a special UNK token. We obtain the word embedding by training an unsupervised word2vec (Mikolov et al., 2013) model on the training and validation splits and then use the word embedding to initialize We.我们使用斯坦福的 CoreNLP (Manning et al., 2014) 将文档分成句子并标记每个句子。 我们在构建词汇表时只保留出现 5 次以上的词，并用特殊的 UNK 标记替换出现 5 次的词。 我们通过在训练和验证分割上训练一个无监督的 word2vec (Mikolov et al., 2013) 模型来获得词嵌入，然后使用词嵌入来初始化 We。 paragraph 2 The hyper parameters of the models are tuned on the validation set. In our experiments, we set the word embedding dimension to be 200 and the GRU dimension to be 50. In this case a combination of forward and backward GRU gives us 100 dimensions for word/sentence annotation. The word/sentence context vectors also have a dimension of 100, initialized at random.模型的超参数在验证集上进行了调整。 在我们的实验中，我们将词嵌入维度设置为 200，将 GRU 维度设置为 50。在这种情况下，前向和后向 GRU 的组合为我们提供了 100 个维度的词/句子注释。 词/句子上下文向量也有 100 维，随机初始化。 paragraph 3 For training, we use a mini-batch size of 64 and documents of similar length (in terms of the number of sentences in the documents) are organized to be a batch. We find that length-adjustment can accelerate training by three times. We use stochastic gradient descent to train all models with momentum of 0.9. We pick the best learning rate using grid search on the validation set.对于训练，我们使用 64 的 mini-batch 大小，并将长度相似（就文档中的句子数而言）的文档组织为一个批次。 我们发现长度调整可以将训练速度提高三倍。 我们使用随机梯度下降来训练动量为 0.9 的所有模型。 我们在验证集上使用网格搜索选择最佳学习率。 3.4 Results and analysis paragraph 1 The experimental results on all data sets are shown in Table 2. We refer to our models as HN-{AVE, MAX, ATT}. Here HN stands for Hierarchical Network, AVE indicates averaging, MAX indicates max-pooling, and ATT indicates our proposed hierarchical attention model. Results show that HNATT gives the best performance across all data sets.所有数据集的实验结果如表 2 所示。我们将我们的模型称为 HN-{AVE, MAX, ATT}。 这里 HN 代表分层网络，AVE 表示平均，MAX 表示最大池化，ATT 表示我们提出的分层注意力模型。 结果表明，HNATT 在所有数据集上都提供了最佳性能。 paragraph 2 The improvement is regardless of data sizes. For smaller data sets such as Yelp 2013 and IMDB, our model outperforms the previous best baseline methods by 3.1% and 4.1% respectively. This finding is consistent across other larger data sets. Our model outperforms previous best models by 3.2%, 3.4%, 4.6% and 6.0% on Yelp 2014, Yelp 2015, Yahoo Answers and Amazon Reviews. The improvement also occurs regardless of the type of task: sentiment classification, which includes Yelp 2013-2014, IMDB, Amazon Reviews and topic classification for Yahoo Answers.改进与数据大小无关。 对于 Yelp 2013 和 IMDB 等较小的数据集，我们的模型分别比之前的最佳基线方法高 3.1% 和 4.1%。 这一发现在其他更大的数据集上是一致的。 我们的模型在 Yelp 2014、Yelp 2015、Yahoo Answers 和 Amazon Reviews 上的表现分别比之前的最佳模型高 3.2%、3.4%、4.6% 和 6.0%。 无论任务类型如何，都会发生改进：情感分类，包括 Yelp 2013-2014、IMDB、亚马逊评论和雅虎问答的主题分类。 paragraph 3 From Table 2 we can see that neural network based methods that do not explore hierarchical document structure, such as LSTM, CNN-word, CNNchar have little advantage over traditional methods for large scale (in terms of document size) text classification. E.g. SVM+TextFeatures gives performance 59.8, 61.8, 62.4, 40.5 for Yelp 2013, 2014, 2015 and IMDB respectively, while CNN-word has accuracy 59.7, 61.0, 61.5, 37.6 respectively.从表 2 中我们可以看出，基于神经网络的不探索分层文档结构的方法，如 LSTM、CNN-word、CNNchar，在大规模（在文档大小方面）文本分类的传统方法几乎没有优势。 例如。 SVM+TextFeatures 在 Yelp 2013、2014、2015 和 IMDB 上的性能分别为 59.8、61.8、62.4、40.5，而 CNN-word 的准确度分别为 59.7、61.0、61.5、37.6。 paragraph 4 Exploring the hierarchical structure only, as inHN-AVE, HN-MAX, can significantly improve over LSTM, CNN-word and CNN-char. For example, our HN-AVE outperforms CNN-word by 7.3%, 8.8%, 8.5%, 10.2% than CNN-word on Yelp 2013, 2014, 2015 and IMDB respectively. Our model HN-ATT that further utilizes attention mechanism combined with hierarchical structure improves over previous models (LSTM-GRNN) by 3.1%, 3.4%, 3.5% and 4.1% respectively. More interestingly, in the experiments, HN-AVE is equivalent to using non-informative global word/sentence context vectors (e.g., if they are all-zero vectors, then the attention weights in Eq. 6 and 9 become uniform weights). Compared to HN-AVE, the HN-ATT model gives superior performance across the board. This clearly demonstrates the effectiveness of the proposed global word and sentence importance vectors for the HAN. 3.5 Context dependent attention weights上下文相关的注意力权重 paragraph 1 If words were inherently important or not important, models without attention mechanism might work well since the model could automatically assign low weights to irrelevant words and vice versa. However, the importance of words is highly context dependent. For example, the word good may appear in a review that has the lowest rating either because users are only happy with part of the product/service or because they use it in a negation, such as not good. To verify that our model can capture context dependent word importance, we plot the distribution of the attention weights of the words good and bad from the test split of Yelp 2013 data set as shown in Figure 3(a) and Figure 4(a). We can see that the distribution has a attention weight assigned to a word from 0 to 1. This indicates that our model captures diverse context and assign context-dependent weight to the words. 如果单词本质上很重要或不重要，那么没有注意力机制的模型可能会很好地工作，因为模型可以自动为不相关的单词分配较低的权重，反之亦然。 然而，单词的重要性高度依赖于上下文。 例如，单词 good 可能出现在评分最低的评论中，因为用户只对产品/服务的一部分感到满意，或者因为他们在否定中使用它，例如不好。 为了验证我们的模型可以捕获上下文相关的单词重要性，我们从 Yelp 2013 数据集的测试拆分中绘制了单词 good 和 bad 的注意力权重分布，如图 3(a) 和图 4(a) 所示。 我们可以看到该分布分配给单词的注意力权重从 0 到 1。这表明我们的模型捕获了不同的上下文，并为单词分配了上下文相关的权重。 paragraph 2 For further illustration, we plot the distribution when conditioned on the ratings of the review. Subfigures 3(b)-(f) in Figure 3 and Figure 4 correspond to the rating 1-5 respectively. In particular, Figure 3(b) shows that the weight of good concentrates on the low end in the reviews with rating 1. As the rating increases, so does the weight distribution. This means that the word good plays a more important role for reviews with higher ratings. We can observe the converse trend in Figure 4 for the word bad. This confirms that our model can capture the context-dependent word importance. 为了进一步说明，我们绘制了以评论评分为条件的分布。 图 3 和图 4 中的子图 3(b)-(f) 分别对应于等级 1-5。 特别是，图 3(b) 显示，商品的权重集中在评分为 1 的评论中的低端。随着评分的增加，权重分布也随之增加。 这意味着，good 这个词在评分较高的评论中扮演着更重要的角色。 我们可以观察到图 4 中单词 bad 的相反趋势。 这证实了我们的模型可以捕获上下文相关的单词重要性。 3.6 Visualization of attention注意力的可视化 paragraph 1 In order to validate that our model is able to select informative sentences and words in a document, we visualize the hierarchical attention layers in Figures 5 and 6 for several documents from the Yelp 2013 and Yahoo Answers data sets.为了验证我们的模型能够选择文档中信息丰富的句子和单词，我们将图 5 和图 6 中的分层注意力层可视化为来自 Yelp 2013 和 Yahoo Answers 数据集中的几个文档。 paragraph 2 Every line is a sentence (sometimes sentences spill over several lines due to their length). Red denotes the sentence weight and blue denotes the word weight. Due to the hierarchical structure, we normalize the word weight by the sentence weight to make sure that only important words in important sentences are emphasized. For visualization purposes we display √pspw. The √ps term displays the important words in unimportant sentences to ensure that they are not totally invisible. 每一行都是一个句子（有时，由于长度的原因，句子会跨越几行）。 红色表示句子权重，蓝色表示词权重。 由于层次结构，我们通过句子权重对词权重进行归一化，以确保仅强调重要句子中的重要词。 出于可视化目的，我们显示√pspw。 √ps 术语显示不重要的句子中的重要词，以确保它们不会完全不可见。 paragraph 3 Figure 5 shows that our model can select the words carrying strong sentiment like delicious, amazing, terrible and their corresponding sentences. Sentences containing many words like cocktails, pasta, entree are disregarded. Note that our model can not only select words carrying strong sentiment, it can also deal with complex across-sentence context. For example, there are sentences like i don’t even like scallops in the first document of Fig. 5, if looking purely at the single sentence, we may think this is negative comment. However, our model looks at the context of this sentence and figures out this is a positive review and chooses to ignore this sentence.图 5 显示我们的模型可以选择带有强烈情感的词，如美味、惊人、可怕及其对应的句子。 包含许多单词的句子，如鸡尾酒、意大利面、主菜将被忽略。 请注意，我们的模型不仅可以选择带有强烈情感的词，还可以处理复杂的跨句上下文。 比如图5的第一个文档里有我什至不喜欢扇贝这样的句子，如果单纯看单个句子，我们可能会认为这是负面评论。 然而，我们的模型查看了这句话的上下文，并认为这是一个正面评价，并选择忽略这句话。 paragraph 4 Our hierarchical attention mechanism also works well for topic classification in the Yahoo Answer data set. For example, for the left document in Figure 6 with label 1, which denotes Science and Mathematics, our model accurately localizes the words zebra, strips, camouflage, predator and their corresponding sentences. For the right document with label 4, which denotes Computers and Internet, our model focuses on web, searches, browsers and their corresponding sentences. Note that this happens in a multiclass setting, that is, detection happens before the selection of the topic! 我们的分层注意力机制也适用于 Yahoo Answer 数据集中的主题分类。 例如，对于图 6 中带有标签 1 的左侧文档，它表示科学和数学，我们的模型准确地定位了单词 zebra、strips、camouflage、predictor 及其对应的句子。 对于带有标签 4 的右侧文档，表示计算机和互联网，我们的模型侧重于网络、搜索、浏览器及其相应的句子。 请注意，这发生在多类设置中，即在选择主题之前进行检测！ 4 Related Work paragraph 1 Kim (2014) use neural networks for text classification. The architecture is a direct application of CNNs, as used in computer vision (LeCun et al., 1998), albeit with NLP interpretations. Johnson and Zhang (2014) explores the case of directly using a high-dimensional one hot vector as input. They find that it performs well. Unlike word level modelings, Zhang et al. (2015) apply a character-level CNN for text classification and achieve competitive results. Socher et al. (2013) use recursive neural networks for text classification. Tai et al. (2015) explore the structure of a sentence and use a treestructured LSTMs for classification. There are also some works that combine LSTM and CNN structure to for sentence classification (Lai et al., 2015; Zhou et al., 2015). Tang et al. (2015) use hierarchical structure in sentiment classification. They first use a CNN or LSTM to get a sentence vector and then a bi-directional gated recurrent neural network to compose the sentence vectors to get a document vectors. There are some other works that use hierarchical structure in sequence generation (Li et al., 2015) and language modeling (Lin et al., 2015).Kim (2014) 使用神经网络进行文本分类。该架构是 CNN 的直接应用，用于计算机视觉 (LeCun et al., 1998)，尽管有 NLP 解释。 Johnson 和 Zhang (2014) 探讨了直接使用高维单热向量作为输入的情况。他们发现它表现良好。与词级建模不同，Zhang 等人。 (2015) 将字符级 CNN 应用于文本分类并取得有竞争力的结果。索切尔等人。 (2013) 使用递归神经网络进行文本分类。泰等人。 (2015) 探索句子的结构并使用树结构的 LSTM 进行分类。还有一些作品将 LSTM 和 CNN 结构结合起来进行句子分类（Lai et al., 2015; Zhou et al., 2015）。唐等人。 (2015) 在情感分类中使用层次结构。他们首先使用 CNN 或 LSTM 得到一个句子向量，然后使用双向门控循环神经网络来组合句子向量以得到一个文档向量。还有一些其他作品在序列生成（Li et al., 2015）和语言建模（Lin et al., 2015）中使用层次结构。 paragraph 2 The attention mechanism was proposed by (Bahdanau et al., 2014) in machine translation. The encoder decoder framework is used and an attention mechanism is used to select the reference words in original language for words in foreign language before translation. Xu et al. (2015) uses the attention mechanism in image caption generation to select the relevant image regions when generating words in the captions. Further uses of the attention mechanism include parsing (Vinyals et al., 2014), natural language question answering (Sukhbaatar et al., 2015; Kumar et al., 2015; Hermann et al., 2015), and image question answering (Yang et al., 2015). Unlike these works, we explore a hierarchical attention mechanism (to the best of our knowledge this is the first such instance).注意机制是由 (Bahdanau et al., 2014) 在机器翻译中提出的。 使用编码器解码器框架，并使用注意力机制在翻译前为外语词选择原始语言中的参考词。 徐等人。 (2015) 在生成标题中的单词时使用图像标题生成中的注意力机制来选择相关的图像区域。 注意力机制的进一步用途包括解析（Vinyals et al., 2014）、自然语言问答（Sukhbaatar et al., 2015; Kumar et al., 2015; Hermann et al., 2015）和图像问答（Yang 等，2015）。 与这些作品不同，我们探索了一种分层注意力机制（据我们所知，这是第一个这样的例子）。 5 Conclusion paragraph 1 In this paper, we proposed hierarchical attention networks (HAN) for classifying documents. As a convenient side-effect we obtained better visualization using the highly informative components of a document. Our model progressively builds a document vector by aggregating important words into sentence vectors and then aggregating important sentences vectors to document vectors. Experimental results demonstrate that our model performs significantly better than previous methods. Visualization of these attention layers illustrates that our model is effective in picking out important words and sentences.在本文中，我们提出了用于文档分类的分层注意力网络（HAN）。 作为一个方便的副作用，我们使用文档的高信息组件获得了更好的可视化。 我们的模型通过将重要单词聚合为句子向量，然后将重要句子向量聚合为文档向量来逐步构建文档向量。 实验结果表明，我们的模型性能明显优于以前的方法。 这些注意力层的可视化说明我们的模型可以有效地挑选出重要的单词和句子。 Acknowledgments This work was supported byMicrosoft Research. 致谢 这项工作得到了微软研究院的支持。 ReferencesdReferencesDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.Phil Blunsom, Edward Grefenstette, Nal Kalchbrenner, et al. 2014. A convolutional neural network for modelling sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.Qiming Diao, Minghui Qiu, Chao-Yuan Wu, Alexander J Smola, Jing Jiang, and Chong Wang. 2014. Jointly modeling aspects, ratings and sentiments for movie recommendation (jmars). In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 193– 202. ACM.Jianfeng Gao, Patrick Pantel, Michael Gamon, Xiaodong He, Li Deng, and Yelong Shen. 2014. Modeling interestingness with deep neural networks. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.Karl Moritz Hermann, Toma´s Koˇ ciskˇ y, Edward Grefen-` stette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. 2015. Teaching machines to read and comprehend. arXiv preprint arXiv:1506.03340.Sepp Hochreiter and Jurgen Schmidhuber. 1997. Long¨ short-term memory. Neural computation, 9(8):1735– 1780.Thorsten Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. Springer.Rie Johnson and Tong Zhang. 2014. Effective use of word order for text categorization with convolutional neural networks. arXiv preprint arXiv:1412.1058.Yoon Kim. 2014. Convolutional neural networks for sentence classification. arXiv preprint arXiv:1408.5882.Svetlana Kiritchenko, Xiaodan Zhu, and Saif M Mohammad. 2014. Sentiment analysis of short informal texts. Journal of Artificial Intelligence Research, pages 723– 762.Ankit Kumar, Ozan Irsoy, Jonathan Su, James Bradbury, Robert English, Brian Pierce, Peter Ondruska, Ishaan Gulrajani, and Richard Socher. 2015. Ask me anything: Dynamic memory networks for natural language processing. arXiv preprint arXiv:1506.07285.Siwei Lai, Liheng Xu, Kang Liu, and Jun Zhao. 2015. Recurrent convolutional neural networks for text classification. In Twenty-Ninth AAAI Conference on Artificial Intelligence.Yann LeCun, Leon Bottou, Yoshua Bengio, and Patrick´Haffner. 1998. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278–2324.Jiwei Li, Minh-Thang Luong, and Dan Jurafsky. 2015. A hierarchical neural autoencoder for paragraphs and documents. arXiv preprint arXiv:1506.01057.Rui Lin, Shujie Liu, Muyun Yang, Mu Li, Ming Zhou, and Sheng Li. 2015. Hierarchical recurrent neural network for document modeling. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 899–907.Wang Ling, Tiago Lu´ıs, Lu´ıs Marujo, Ramon Fernan-´ dez Astudillo, Silvio Amir, Chris Dyer, Alan W Black, and Isabel Trancoso. 2015. Finding function in form: Compositional character models for open vocabulary word representation. arXiv preprint arXiv:1508.02096.Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analysis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 142–150. Association for Computational Linguistics.Christopher D Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J Bethard, and David McClosky. 2014. The stanford corenlp natural language processing toolkit. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, pages 55–60.Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pages 3111–3119.Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.Mehran Sahami, Susan Dumais, David Heckerman, and Eric Horvitz. 1998. A bayesian approach to filtering junk e-mail. In Learning for Text Categorization: Papers from the 1998 workshop, volume 62, pages 98– 105.Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gregoire Mesnil. 2014. A latent semantic model with convolutional-pooling structure for information retrieval. In Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management, pages 101–110. ACM.Richard Socher, Alex Perelygin, Jean Y. Wu, Jason Chuang, Christopher D. Manning, Andrew Y. Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proc. EMNLP.Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, and Rob Fergus. 2015. End-to-end memory networks. arXiv preprint arXiv:1503.08895.Kai Sheng Tai, Richard Socher, and Christopher D. Manning. 2015. Improved semantic representations from tree-structured long short-term memory networks. In Proc. ACL.Duyu Tang, Furu Wei, Nan Yang, Ming Zhou, Ting Liu, and Bing Qin. 2014. Learning sentiment-specific word embedding for twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, volume 1, pages 1555–1565.Duyu Tang, Bing Qin, and Ting Liu. 2015. Document modeling with gated recurrent neural network for sentiment classification. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1422–1432. Oriol Vinyals, Lukasz Kaiser, Terry Koo, Slav Petrov, Ilya Sutskever, and Geoffrey Hinton. 2014. Grammar as a foreign language. arXiv preprint arXiv:1412.7449.Sida Wang and Christopher D Manning. 2012. Baselines and bigrams: Simple, good sentiment and topic classification. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short Papers-Volume 2, pages 90–94. Association for Computational Linguistics.Kelvin Xu, Jimmy Ba, Ryan Kiros, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, and Yoshua Bengio. 2015. Show, attend and tell: Neural image caption generation with visual attention. arXiv preprint arXiv:1502.03044.Zichao Yang, Xiaodong He, Jianfeng Gao, Li Deng, and Alex Smola. 2015. Stacked attention networks for image question answering. arXiv preprint arXiv:1511.02274.Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015.Character-level convolutional networks for text classification. arXiv preprint arXiv:1509.01626.Chunting Zhou, Chonglin Sun, Zhiyuan Liu, and Francis Lau. 2015. A c-lstm neural network for text classification. arXiv preprint arXiv:1511.08630.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>文本分类模型</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[油猴脚本文件自用版]]></title>
    <url>%2F2021%2F01%2F09%2F%E6%B2%B9%E7%8C%B4%E8%84%9A%E6%9C%AC%E6%96%87%E4%BB%B6%E8%87%AA%E7%94%A8%E7%89%88%2F</url>
    <content type="text"><![CDATA[懂的人都知道，油猴添加脚本之后神仙般的感觉 我在浏览 JerusalemSky 大佬的基础上添加了自己使用的一些脚本 各个都是经过仔细筛选的，保证实用性和可用性，油猴插件导出的脚本列表压缩包，需要的伙计可直接导入到自己浏览器的油猴中。 JerusalemSky 大佬使用的是 Firefox 我用的是 Windows 自带的Edge浏览器，测试了一下 chrome 也可以 先放一下链接 度盘 12链接：https://pan.baidu.com/s/1v4U3-qeyAa8sL_pZswtpjg 提取码：46p9 蓝奏 12https://wws.lanzous.com/b01ztko5a密码:3uhk 使用方法 下载上述脚本压缩包； 点击油猴插件，找到最下方的管理面板图标，点击打开设置选项； 右上角找到工具选项 浏览选项 选择前面下载好的压缩包导入，然后快乐起飞！ 简单介绍一下 吾爱破解论坛增强 - 自动签到、翻页 –&gt; 自动签到、自动无缝翻页（全站） Github 增强 - 高速下载 –&gt; 高速下载 Clone、Release、Raw、Code(ZIP) 等文件、项目列表单文件快捷下载 (☁)]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>js</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HTML 中表格型数据的处理]]></title>
    <url>%2F2021%2F01%2F07%2FHTML%20%E4%B8%AD%E8%A1%A8%E6%A0%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[本文用于个人的总结 PS:根据我浏览的顺序进行罗列，方法没有好坏之分 利用现有的成型工具，在进行 HTML 转 markdown 的时候， 对表格数据的处理并不是很友好，故而浏览记录总结 我才不会告诉你，是我自己看的乱掉啦&lt;/p&gt; 我才不会告诉你，是我自己看乱掉啦 关于python获取网页表格数据（read_html()方法） 使用beautifulsoup解析网页爬取的表格信息 【爬虫实例1】python3下使用beautifulsoup爬取数据并存储txt文件 使用Python3和BeautifulSoup4处理本地html文件]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>HTML</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NEXT主题美化]]></title>
    <url>%2F2021%2F01%2F06%2FNEXT%E4%B8%BB%E9%A2%98%E7%BE%8E%E5%8C%96%2F</url>
    <content type="text"><![CDATA[本文仅作为个人记录用添加： 进度条 网站的建站时间 显示近期文章 显示当前浏览进度 代码块复制功能 自定义样式博文加密 添加网易云音乐 缺陷： 近期文章标题混乱 Hexo+NexT(v7.0+) 搭建博客：主题美化 修改内容： 1. Font 1.1 修改字体 1.2 设置三角丝带背景 2. Top 2.1 加载进度条 2.2 右上角的Follow-Github 2.3 菜单背景收缩 3. Footer 3.1 网站的建站时间 3.2 网站的运行时间 4. Sidebar 4.1 显示近期文章 4.2 显示当前浏览进度 4.3 侧边栏移到左边 4.4 侧边栏目录展开 Hexo NexT 代码块复制功能 修改内容： - [1.1 下载 clipboard.js](#11-下载-clipboardjs) - [1.2 clipboardjs 使用](#12-clipboardjs-使用) - [1.3 添加下面代码](#13-添加下面代码) - [1.4 添加引用](#14-添加引用) Hexo+NexT 自定义样式博文加密 修改内容： - [1.1 插入代码](#11-插入代码) - [1.2 然后在文章上写成类似这样：==注意空格==](#12-然后在文章上写成类似这样注意空格) Hexo NexT 添加网易云音乐 修改内容： - [1.1 找到自己需要添加的歌曲](#11-找到自己需要添加的歌曲) - [1.2 生成外链播放器](#12-生成外链播放器) - [1.3 自定义设置](#13-自定义设置) - [1.4 添加外链接](#14-添加外链接) next文章目录跳转_hexo的next主题个性化配置 hexo的NexT主题，怎么取消“文章目录”对标题的自动编号？ 参考文章 Hexo+NexT(v7.0+) 搭建博客：主题美化Hexo+NexT(v7.0+) 搭建博客：主题美化 修改内容：1. Font1.1 修改字体 1.2 设置三角丝带背景建议不要开启，如果没有进行加速优化 2. Top2.1 加载进度条 2.2 右上角的Follow-Github 2.3 菜单背景收缩 头部和底部颜色修改 网站标题加粗和颜色修改 菜单字体增大显示 12345678910111213141516171819202122232425262728293031323334353637383940414243//窗口效果相关样式.sidebar &#123;box-shadow: none;&#125;// 为Header和Footer添加背景色#header, #footer &#123;background-color: rgb(245, 245, 245);&#125;//防止sidebar和footer同时开启动效时堆叠异常#sidebar, header &#123;z-index: 1 !important;&#125;//防止挡住页末文章的阅读全文按钮.main &#123;padding-bottom: 30px;&#125;// 加宽菜单间距，放大菜单图标#menu .menu-item &#123;margin: 0px 14px;.fa &#123; font-size: 16px;&#125;&#125;// Muse主题下自定义样式if hexo-config('scheme') == "Muse" &#123;.site-meta &#123; .brand &#123; color: rgb(34, 34, 34); background: none; &#125; .site-title &#123; font-size: 24px; font-weight: bold; &#125;&#125;&#125; 改完才发现顶部菜单的空间太大了，于是调节菜单高度，在自定义布局文件中添加以下代码： 123456&#123;# 页面加载时header高度收缩动效 #&#125;&lt;script&gt;$(document).ready(function () &#123; $(".header-inner").animate(&#123;padding: "25px 0 25px"&#125;, 1000);&#125;);&lt;/script&gt; 如果 custom.swig 文件不存在，需要手动新建并在布局页面中 body 末尾引入： 123456&#123;% include '_third-party/copy-code.swig' %&#125;&#123;% include '_third-party/chatra.swig' %&#125;&#123;% include '_third-party/tidio.swig' %&#125;+ &#123;% include '_custom/custom.swig' %&#125;&lt;/body&gt;&gt; 调节移动端显示的高度 12345678mobile() &#123;position: absolute;left: 0;- top: 52px;+ top: 95px;margin: 0;...&#125; 3. Footer3.1 网站的建站时间 12345678910footer:# Specify the date when the site was setup. If not defined, current year will be used.since: 2018 # 修改建站时间# Icon between year and copyright info.icon: # `heart` is recommended with animation in red (#ff0000). name: heart # 改成心型图标 # Change the color of icon, using Hex Code. color: "#ff0000" # 改成红色图标 3.2 网站的运行时间 1234ages: # site running timeenable: truebirthday: 20190419 # 网站运行时间color: "#1094e8" 12345678910111213141516171819202122232425&#123;# 页脚站点运行时间统计 #&#125;&#123;% if theme.footer.ages.enable %&#125; &lt;script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/moment.min.js"&gt;&lt;/script&gt; &lt;script src="https://cdn.jsdelivr.net/npm/moment-precise-range-plugin@1.3.0/moment-precise-range.min.js"&gt;&lt;/script&gt; &lt;script&gt; function timer() &#123; var ages = moment.preciseDiff(moment(),moment(&#123;&#123; theme.footer.ages.birthday &#125;&#125;,"YYYYMMDD")); //去除时分秒信息 ages = ages.replace(/\s?\d&#123;0,2&#125;\s+hours?/, ""); ages = ages.replace(/\s?\d&#123;0,2&#125;\s+minutes?/, ""); ages = ages.replace(/\s?\d&#123;0,2&#125;\s+seconds?/, ""); //将年月日转换为中文 ages = ages.replace(/years?/, "年"); ages = ages.replace(/months?/, "月"); ages = ages.replace(/days?/, "天"); ages = ages.replace(/\d+/g, '&lt;span style="color:&#123;&#123; theme.footer.ages.color &#125;&#125;"&gt;$&amp;&lt;/span&gt;'); span.innerHTML = `&#123;&#123; __('footer.age')&#125;&#125; $&#123;ages&#125;`; &#125; var span = document.createElement("span"); //插入到agesicon之后 var agesicon = document.querySelector(".footer-ages-icon"); document.querySelector(".copyright").insertBefore(span, agesicon.nextSibling); timer(); &lt;/script&gt;&#123;% endif %&#125; 4. Sidebar4.1 显示近期文章 12345678910111213141516171819202122 &#123;% if theme.social %&#125; ... &#123;% endif %&#125;+ &lt;!-- 添加近期文章 --&gt;+ &#123;% if theme.recent_posts %&#125;+ &lt;div class="links-of-blogroll motion-element &#123;&#123; "links-of-blogroll-" + theme.recent_posts_layout &#125;&#125;"&gt;+ &lt;div class="links-of-blogroll-title"&gt;+ &lt;!-- modify icon to fire by szw --&gt;+ &lt;i class="fa fa-history fa-&#123;&#123; theme.recent_posts_icon | lower &#125;&#125;" aria-hidden="true"&gt;&lt;/i&gt;+ &#123;&#123; __('sidebar.recent_posts') &#125;&#125;+ &lt;/div&gt;+ &lt;ul class="links-of-blogroll-list"&gt;+ &#123;% set posts = site.posts.sort('-date') %&#125;+ &#123;% for post in posts.slice('0', '5') %&#125;+ &lt;li&gt;+ &lt;a href="&#123;&#123; url_for(post.path) &#125;&#125;" title="&#123;&#123; post.title &#125;&#125;" target="_blank"&gt;&#123;&#123; post.title &#125;&#125;&lt;/a&gt;+ &lt;/li&gt;+ &#123;% endfor %&#125;+ &lt;/ul&gt;+ &lt;/div&gt;+ &#123;% endif %&#125; 4.2 显示当前浏览进度 4.3 侧边栏移到左边4.4 侧边栏目录展开 Hexo NexT 代码块复制功能Hexo NexT 代码块复制功能 修改内容：1.1 下载 clipboard.js 保存文件clipboard.js 或者 clipboard.min.js 推荐 ，目录如下：.\themes\next\source\js\src 1.2 clipboardjs 使用 也是在.\themes\next\source\js\src目录下，创建clipboard-use.js，文件内容如下： 1234567891011121314151617/*页面载入完成后，创建复制按钮*/!function (e, t, a) &#123; /* code */var initCopyCode = function()&#123; var copyHtml = ''; copyHtml += '&lt;button class="btn-copy" data-clipboard-snippet=""&gt;'; copyHtml += ' &lt;i class="fa fa-globe"&gt;&lt;/i&gt;&lt;span&gt;copy&lt;/span&gt;'; copyHtml += '&lt;/button&gt;'; $(".highlight .code pre").before(copyHtml); new ClipboardJS('.btn-copy', &#123; target: function(trigger) &#123; return trigger.nextElementSibling; &#125; &#125;);&#125;initCopyCode();&#125;(window, document); 1.3 添加下面代码 在.\themes\next\source\css_custom\custom.styl样式文件中添加下面代码： 123456789101112131415161718192021222324252627282930313233343536//代码块复制按钮.highlight&#123;//方便copy代码按钮（btn-copy）的定位position: relative;&#125;.btn-copy &#123; display: inline-block; cursor: pointer; background-color: #eee; background-image: linear-gradient(#fcfcfc,#eee); border: 1px solid #d5d5d5; border-radius: 3px; -webkit-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none; -webkit-appearance: none; font-size: 13px; font-weight: 700; line-height: 20px; color: #333; -webkit-transition: opacity .3s ease-in-out; -o-transition: opacity .3s ease-in-out; transition: opacity .3s ease-in-out; padding: 2px 6px; position: absolute; right: 5px; top: 5px; opacity: 0;&#125;.btn-copy span &#123; margin-left: 5px;&#125;.highlight:hover .btn-copy&#123;opacity: 1;&#125; 1.4 添加引用 在.\themes\next\layout_layout.swig文件中，添加引用（注：在 swig 末尾或 body 结束标签（&lt;/body&gt;）之前添加）： 123&lt;!-- 代码块复制功能 二选一即可--&gt;&lt;script type="text/javascript" src="/js/src/clipboard.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript" src="/js/src/clipboard-use.js"&gt;&lt;/script&gt; Hexo+NexT 自定义样式博文加密Hexo+NexT 自定义样式博文加密 修改内容：1.1 插入代码 打开 themes-&gt;next-&gt;layout-&gt;_partials-&gt;head.swig文件,在以下位置插入这样一段代码：1234567891011121314&lt;script&gt; (function () &#123; if ('&#123;&#123; page.password &#125;&#125;') &#123; if (prompt('请输入文章密码') !== '&#123;&#123; page.password &#125;&#125;') &#123; alert('密码错误！'); if (history.length === 1) &#123; location.replace("http://xxxxxxx.xxx"); // 这里替换成你的首页 &#125; else &#123; history.back(); &#125; &#125; &#125; &#125;)();&lt;/script&gt; 1.2 然后在文章上写成类似这样：==注意空格==12345---title: tags:password: *** //你自己的密码--- Hexo NexT 添加网易云音乐修改内容：1.1 找到自己需要添加的歌曲进入网页版的网易云音乐找到自己需要添加的歌曲 1.2 生成外链播放器在歌曲详情页点击生成外链播放器 1.3 自定义设置设置外链播放器的类型，尺寸等参数，设置完成过后复制下面的外链接 1.4 添加外链接在根目录下的/theme/next/layout/_macro/sidebar.swig文件（侧边栏布局文件）中选择你要添加播放器的位置，然后粘贴外链接 next文章目录跳转_hexo的next主题个性化配置next文章目录跳转_hexo的next主题个性化配置 hexo的NexT主题，怎么取消“文章目录”对标题的自动编号？hexo的NexT主题，怎么取消“文章目录”对标题的自动编号？ 修改主题配置文件那里的number为false]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>js</tag>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[html与markdown在线互转工具]]></title>
    <url>%2F2021%2F01%2F06%2Fhtml%E4%B8%8Emarkdown%E5%9C%A8%E7%BA%BF%E4%BA%92%E8%BD%AC%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[个人体验： 在线转换网站对表格支持极差,表格真的是硬伤 tomd , html2text, pandoc 大多数还可以 槽点：不论是 pandoc 还是 html2text 等强大的工具 ， 在表格面前一败涂地 2023年10月更新html与markdown在线互转工具 转载最完善的markdown转html/pdf方法、带目录生成 html与markdown在线互转工具 在线Html代码转Markdown工具 【自动化】【公众号运营】爬取博文并转为Markdown文件 用pandoc自由转换markdown与html格式 将 HTML 转成 Markdown Remark-java JSON在线格式化,JSON在线解析 python-爬虫-使用 tomd 库，将 html 转换为 markdown文档 整理最全的 python之markdown与HTML的互转的几个模块]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Html方式转载CSDN博客 & CSDN博客转换成Markdown文件]]></title>
    <url>%2F2021%2F01%2F06%2FHtml%E6%96%B9%E5%BC%8F%E8%BD%AC%E8%BD%BDCSDN%E5%8D%9A%E5%AE%A2%20%26%20CSDN%E5%8D%9A%E5%AE%A2%E8%BD%AC%E6%8D%A2%E6%88%90Markdown%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[文章目录 文章目录 内容简介 Html方式转载CSDN博客 保存CSDN博客的Markdown文件 安装html2text 内容简介主要分为两个部分第一部分：将CSDN博客的html源码进行复制并转发到自己的blog上（大家记得发文章的时候要选择转载哦）第二部分：将CSDN博客的页面转换成Markdown代码形式，这样可以方便自己的修改和保存，也方便大家部分的截取别人博客中的精华内容 Html方式转载CSDN博客以如下这篇bolg做例子https://blog.csdn.net/qq_41554005/article/details/97107087打开要转载的博客，然后鼠标右键就会出现下面的菜单点击审查或者有的是检查 反正就是查看他的html源代码，选中”article_content”从图片左边我们也可以看到，博客的内容已经被我们选中了，也就是我们想要转载的内容选中之后右键复制保存为HTML之后走正常发布自己的bolg流程就可以了调整到markdown文本编辑器之后把之前复制的内容粘贴进去就可以了如下图所示 保存CSDN博客的Markdown文件如果需要对bolg中的内容进行修改或者部分截取或者只想自己写好了保存成比较符合自己审美的md文件的话可以采用如下方式还是找一个blog为例子，复制完成HTML文件之后进行如下操作 ==备注：这种方法在拷贝html文件的时候对表格和代码段的转换可能会出一些问题 代码段可能会出现一个代码行号 大量不规则的表格的时候可能会出现一个对不齐的问题，但是相对于文字和图片等等基本是没有问题的（如果还有其他的问题请留言反馈我去看看有没有更好的转换方式，谢谢大家啦）== 安装html2textwin或者linux中均可使用html2text是一个Python模块，用来把HTML格式转换为文本（Markdown）格式。$ pip install html2text 112345678910 1import html2texthtml = &apos;&apos;&apos;(你复制的html代码)&apos;&apos;&apos;markdown = html2text.html2text(html)print(type(markdown))print(markdown)f2 = open(&apos;blog.md&apos;,&apos;w&apos;)f2.write(markdown)f2.close() eg.复制之后运行就可以输出一个md文件啦打开这个md文件就是这样的 同学们可以修改或者自己进行增补之后在发布]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pytorch中Torch 工具包的数学操作汇总速查]]></title>
    <url>%2F2021%2F01%2F06%2FPytorch%E4%B8%ADTorch%20%E5%B7%A5%E5%85%B7%E5%8C%85%E7%9A%84%E6%95%B0%E5%AD%A6%E6%93%8D%E4%BD%9C%E6%B1%87%E6%80%BB%E9%80%9F%E6%9F%A5%2F</url>
    <content type="text"><![CDATA[Pytorch中Torch 工具包的数学操作汇总速查 torch package 包含了多维张量的数据结构, 以及基于其上的多种数学操作. 此外,它还提供了许多用于高效序列化 Tensor 和任意类型的实用工具包, 以及一起其它有用的实用工具包. 变量 | 解释 ||—-|—-|Tensors (张量) |torch.istensor(obj) | 如果 obj 是一个 pytorch tensor, 则返回True.torch.is_storage(obj) | 如果 obj 是一个 pytorch storage object, 则返回Truetorch.set_default_tensor_type(t) | 设置默认类型torch.numel(input) → int | 返回 input Tensor 中的元素总数torch.set_printoptions(precision=None, threshold=None,edgeitems=None,linewidth=None, profile=None) | 设置打印选项. 从 Numpy 中采集数据torch.set_flush_denormal(mode) | 为了防止一些不正常的元素产生，比如特别小的数，pytorch支持如下设置Creation Ops (创建操作) | |torch.from_numpy(ndarray) → Tensor | 从 numpy.ndarray 类 创建一个 Tensor 类torch.as_tensor(data, dtype=None, device=None) | |torch.eye(n, m=None, out=None) | 返回对角线位置全为1, 其它位置全为0的二维 tensortorch.zeros(sizes, out=None) → Tensor | 返回填充了标量值为 0 的 Tensor, 其形状由可变参量 sizes 定义torch.zeros_like(input, out=None) → Tensor | 返回一个用标量值 0 填充的 Tensor, 其大小与 input 相同.torch.ones(sizes, out=None) → Tensor | 返回填充了标量值 1 的 Tensor, 其形状由可变参数 sizes 定义torch.ones_like(input, out=None) → Tensor | 返回一个用标量值 1 填充的张量, 大小与 input 相同torch.empty() |torch.empty_like() |torch.full(size, fill_value, …) | 返回大小为sizes,单位值为fill_value的矩阵torch.full_like(input, fill_value, …) | 返回与input相同size，单位值为fill_value的矩阵torch.linspace(start, end, steps=100, out=None) → Tensor | 返回 start 和 end 之间等间隔 steps 点的一维 Tensor.输出 是尺寸 steps 为一维 tensortorch.logspace(start, end, steps=100, out=None) → Tensor | 返回一个在 10^start 和 10^end之间的对数间隔 steps 点的一维 Tensor，输出是长度为 steps 的一维 tensortorch.arange(start=0, end, step=1, out=None) → Tensor | 从 start 用步长为 step 开始, 间隔在 [start, end) 中的值返回大小层次为 floor((end−start)/step)floor((end−start)/step) 的一维 Tensor.torch.range(start, end, step=1, out=None) → Tensor | 返回一个在 start 到 end 并且步长为 step 的区间内, 大小为 floor((end−start)/step)+1floor((end−start)/step)+1 为一维 Tensor.Indexing, Slicing, Joining, Mutating Ops (索引, 切片, 连接, 换位) 操作 |torch.cat(seq, dim=0, out=None) → Tensor | 在给定维度上对输入的张量序列 seq 进行连接操作. 所有张量必须具有相同的形状(在 cat 维度中除外) 或为空.torch.chunk(tensor, chunks, dim=0) | 在给定维度(轴)上将输入张量进行分块处理.torch.gather(input, dim, index, out=None) → Tensor | 沿给定轴 dim ,将输入索引张量 index 指定位置的值进行聚合.torch.index_select(input, dim, index, out=None) → Tensor | 沿着指定维度 dim 对输入进行切片,取 index 中指定的相应项 ( index 为一个 LongTensor ),然后返回到一个新的张量.返回的张量与原始张量 Tensor 有相同的维度(在指定轴上)torch.masked_select(input, mask, out=None) → Tensor | 根据掩码张量 mask 中的二元值,取输入张量中的指定项 ( mask 为一个 ByteTensor ),将取值返回到一个新的一维张量.张量 mask 与 input 的shape 或维度不需要相同,但是他们必须是 broadcastable .torch.nonzero(input, out=None) → LongTensor | 返回一个包含输入 input 中非零元素索引的张量. 输出张量中的每行包含 input 中非零元素的索引.如果输入张量 input 有 n 维,则输出的索引张量 out 的 size 为 z x n , 这里 z 是输入张量 input 中所有非零元素的个数.torch.where(condition, x, y) | 按照条件从x和y中选出满足条件的元素组成新的tensor。torch.split(tensor, split_size, dim=0) | 将输入张量分割成相等 size 的 chunks (如果可分).如果沿指定维的张量形状大小不能被 split_size 整分, 则最后一个分块会小于其它分块torch.squeeze(input, dim=None, out=None) | 将 input 张量 size 中的 1 去除并返回.如果 input 的 shape 如 (Ax1xBxCx1xD)(Ax1xBxCx1xD) ,那么输出 shape 就为: (AxBxCxD)torch.stack(sequence, dim=0, out=None) | 沿着一个新维度对输入张量序列进行连接.序列中所有的张量都应该为相同 size .torch.reshape(input, shape) |torch.view |torch.t(input, out=None) → Tensor | 预期 input 为一个矩阵 (2 维张量), 并转置 0, 1 维.可以被视为函数 transpose(input, 0, 1) 的简写函数torch.take(input, indices) → Tensor | 在给定的索引处返回一个新的 Tensor ,其元素为 input . 输入张量被看作是一维张量.结果与索引具有相同的 shapetorch.transpose(input, dim0, dim1, out=None) → Tensor | 返回输入矩阵 input 的转置.交换给定维度 dim0 和 dim1 .out 张量与 input 张量共享内存,所以改变其中一个会导致另外一个也被修改.torch.unbind(tensor, dim=0) | 移除一个张量的维度torch.unsqueeze(input, dim, out=None) | 返回在指定位置插入维度 size 为 1 的新张量.返回张量与输入张量共享内存,所以改变其中一个的内容会改变另一个.如果 dim 为负,则将会被转化 dim+input.dim()+1Random sampling (随机采样) |torch.manual_seed(seed) | 设置生成随机数的种子,并返回一个torch.initial_seed() | 返回用于生成随机数字的初始种子 (python long)torch.get_rng_state() | 以ByteTensor的形式返回随机数发生器的状态torch.set_rng_state(new_state) | 设置随机数发生器的参数torch.bernoulli(input, out=None) → Tensor | 从伯努利分布中抽取二进制随机数 (0 或 1)torch.multinomial(input, num_samples, replacement=False, out=None)→ LongTensor| 返回一个张量, 其中每一行包含在 input 张量对应行中多项式分布取样的 num_samples 索引 |torch.normal(means, std, out=None) | 返回一个随机数张量, 随机数从给定平均值和标准差的离散正态分布中抽取.torch.normal(mean=0.0, std, out=None) | 功能与上面函数类似, 但所有被抽取的元素共享均值torch.normal(means, std=1.0, out=None) | 功能与上面函数类似, 但所有被抽取的元素共享标准差torch.rand(sizes, out=None) → Tensor | 在区间 [0,1)[0,1) 中,返回一个填充了均匀分布的随机数的张量.这个张量的形状由可变参数 sizes 来定义torch.randn(sizes, out=None) → Tensor | 返回一个从正态分布中填充随机数的张量, 其均值为 0 , 方差为 1.这个张量的形状被可变参数 sizes 定义torch.randperm(n, out=None) → LongTensor | 返回一个从 0 to n - 1 的整数的随机排列torch.rand(sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) | 生成[0，1）的随机数torch.rand_like(input, dtype=None, layout=None, device=None,requires_grad=False) | 按照输入的tensor的尺寸生成torch.randint(low=0, high, size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) | 在一个范围内生成整型的随机torch.randint_like(input, low=0, high, dtype=None, layout=torch.strided, device=None, requires_grad=False) | 不解释torch.randn(sizes, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) | 返回01正太分布torch.randn_like(input, dtype=None, layout=None, device=None, requires_grad=False) | 不解释torch.randperm(n, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False) | 返回0到输入n的之间整数随机排列不含nIn-place random sampling (直接随机采样) |torch.Tensor.bernoulli() | torch.bernoulli()的 in-place 版本torch.Tensor.cauchy() | 从柯西分布中抽取数字torch.Tensor.exponential() | 从指数分布中抽取数字torch.Tensor.geometric() | 从几何分布中抽取元素torch.Tensor.log_normal() | 对数正态分布中的样本torch.Tensor.normal() | 是 torch.normal() 的 in-place 版本torch.Tensor.random() | 离散均匀分布中采样的数字torch.Tensor.uniform_() | 正态分布中采样的数字Serialization (序列化) |torch.save(obj, f, pickle_module=, pickle_protocol=2) |将一个对象保存到一个磁盘文件中.torch.load(f, map_location=None, pickle_module=) | 从磁盘文件中加载一个用 torch.save()保存的对象.Parallelism (并行化) |torch.get_num_threads() → int | 获得 OpenMP 并行化操作的线程数目torch.set_num_threads(int) | 设置 OpenMP 并行化操作的线程数目Math operations (数学操作) |Pointwise Ops (逐点操作) |torch.abs(input, out=None) → Tensor | 计算给定 input 张量的元素的绝对值torch.acos(input, out=None) → Tensor | 用 input 元素的反余弦返回一个新的张量torch.add(input, value, out=None) | 将标量值 value 添加到输入张量 attr:input 的每个元素并返回一个新的结果张量torch.add(input, value=1, other, out=None) | 张量 other 的每个元素乘以标量值 value 并加到张量 input 上, 返回生成的张量 outtorch.addcdiv(tensor, value=1, tensor1, tensor2, out=None) → Tensor | 将张量 tensor1 逐元素除以张量 tensor2, 然后乘以标量值 value 并加到张量 tensor 上.torch.addcmul(tensor, value=1, tensor1, tensor2, out=None) → Tensor | 将张量 tensor1 逐元素与张量 tensor2 相乘, 然后乘以标量值 value 并加到张量 tensor 上.torch.asin(input, out=None) → Tensor | 返回一个新的 Tensor , 其元素为张量 input 的每个元素的反正弦torch.atan(input, out=None) → Tensor | 返回一个新的 Tensor , 其元素为张量 input 的每个元素的反正切torch.atan2(input1, input2, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是输入张量 input1 和输入张量 input2 元素的反正切.torch.ceil(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 的元素向上取整(取不小于每个元素的最小整数).torch.clamp(input, min, max, out=None) → Tensor | 将输入张量 input 所有元素限制在区间 [min,max] 中并返回一个结果张量torch.clamp(input, , min, out=None) → Tensor | 张量 input 的所有元素值大于或者等于 mintorch.clamp(input, , max, out=None) → Tensor | 张量 input 的所有元素值小于或者等于 max.torch.cos(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 每个元素的余弦torch.cosh(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 每个元素的双曲余弦torch.div(input, value, out=None) | 将张量 input 的元素逐一除以标量值 value ,其结果作为一个新的张量返回.torch.div(input, other, out=None) | 张量 input 的元素与张量 other 的元素逐一相除. 返回一个新的结果张量 out . 张量 input 与张量 other 的形状必须可 broadcastable.outi=inputi/otheritorch.erf(tensor, out=None) → Tensor | 计算每个元素的误差函数torch.erfinv(tensor, out=None) → Tensor | 计算每个元素的反向误差函数torch.exp(tensor, out=None) → Tensor | 计算每个元素的指数torch.floor(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 的元素向下取整(取不大于每个元素的最大整数).torch.fmod(input, divisor, out=None) → Tensor | 计算除法余数.torch.frac(tensor, out=None) → Tensor | 计算张量 tensor 每个元素的分数部分.torch.lerp(start, end, weight, out=None) | 基于标量值 weight: , 在张量 start 与张量 end 之间做线性插值 并返回结果张量 out 。outi=starti+weight∗(endi−starti)torch.log(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 所有元素的自然对数.torch.log1p(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是(1 + input) 的自然对数.yi=log(xi+1)torch.mul(input, value, out=None) | 将输入张量 input 的每个元素与标量值 value 相乘并返回一个新的结果张量.out=tensor∗valuetorch.mul(input, other, out=None) | 张量 input 的元素与张量 other 的元素逐一相乘. 其结果作为一个新的张量返回.torch.neg(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 的元素的负值.out=−1∗inputtorch.pow(input, exponent, out=None) | 对输入张量 input 按元素求 exponent 次幂值并返回结果张量(其值作为结果张量的元素).torch.pow(base, input, out=None) | base 是一个标量浮点值, input 是一个张量. 返回的张量 out 的形状与张量 input 的形状相同.torch.reciprocal(input, out=None) → Tensor | 返回一个新的 Tensor , 其元素是张量 input 元素的倒数, i.e. 1.0/xtorch.remainder(input, divisor, out=None) → Tensor | 计算元素的除法的余数.torch.round(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是输入张量的元素四舍五入到最近的整数torch.rsqrt(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的平方根的倒数.torch.sigmoid(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的sigmoid值torch.sign(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的符号.torch.sin(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的正弦.torch.sinh(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的双曲正弦torch.sqrt(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的平方根torch.tan(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的正切torch.tanh(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的双曲正切torch.trunc(input, out=None) → Tensor | 返回一个新的张量 Tensor , 其元素是张量 input 元素的截断整数值 (直接去除小数部分) .Reduction Ops (归约操作) |torch.cumprod(input, dim, out=None) → Tensor | 返回元素 input 在给定维度 dim 下的累积积torch.cumsum(input, dim, out=None) → Tensor | 返回元素 input 在给定维度 dim 下的累积和torch.dist(input, other, p=2) → float | 返回(input - other)的p-范数 input 和 other 的形状必须满足 broadcastable.torch.mean(input) → float | 返回张量 input 所有元素的均值.torch.mean(input, dim, keepdim=False, out=None) → Tensor | 返回张量 input 在给定维度 dim 上每行的均值torch.median(input) → float | 返回输出张量 input 所有元素的中位数.torch.median(input, dim=-1, keepdim=False, values=None, indices=None) -&gt; (Tensor, LongTensor) | 返回输出张量 input 在给定维度 dim 下每行的中位数. 同时返回一个包含中位数的索引 LongTensor.torch.mode(input, dim=-1, keepdim=False, values=None, indices=None) -&gt; | (Tensor, LongTensor) | 返回输入张量 input 在给定维数 dim 下每行元素的众数值. 同时也返回众数值的索引LongTensor.torch.norm(input, p=2) → float | 返回输入张量 input 的p-范数torch.norm(input, p, dim, keepdim=False, out=None) → Tensor | 返回输入张量 input 在给定维度 dim 下每行元素的p-范数.torch.prod(input) → float | 返回输入张量 input 所有元素的乘积.torch.prod(input, dim, keepdim=False, out=None) → Tensor | 返回输入张量 input 在给定维度 dim 下每行元素的积.torch.unique(input, sorted=False, return_inverse=False) |以1D向量保存张量中不同的元素。剔除tensor中的重复元素，如果设置return_inverse=True，会得到一个元素在在原tensor中的映射表torch.std(input, unbiased=True) → float | 返回输入张量 input 所有元素的标准差torch.std(input, dim, keepdim=False, unbiased=True, out=None) → Tensor | 返回输入张量 input 在给定维度 dim 下每行元素的标准差torch.sum(input) → float | 返回输入张量 input 所有元素的和torch.sum(input, dim, keepdim=False, out=None) → Tensor | 返回输入张量 input 在给定维度 dim 下每行元素的和torch.var(input, unbiased=True) → float | 返回输入张量 input 的方差.torch.var(input, dim, keepdim=False, unbiased=True, out=None) → Tensor | 返回输入张量 input 在给定维度 dim 下每行的方差Comparison Ops (比较操作) |torch.eq(input, other, out=None) → Tensor | 比较元素是否相等torch.equal(tensor1, tensor2) → bool | 如果两个张量有相同的形状和元素值, 则返回 True , 否则 False .torch.ge(input, other, out=None) → Tensor | 逐元素比较 input 和 other , 即是否 input&gt;=other .torch.gt(input, other, out=None) → Tensor | 逐元素比较 input 和 other , 即是否 input&gt;other 如果两个张量有相同的形状和元素值, 则返回 True ,否则 Falsetorch.kthvalue(input, k, dim=None, keepdim=False, out=None) -&gt; (Tensor, | LongTensor) | 取输入张量 input 指定维上第 k 个最小值. 如果不指定 dim , 则默认为 input 的最后一维torch.le(input, other, out=None) → Tensor | 逐元素比较 input 和 other , 即是否input&lt;=other 如果两个张量有相同的形状和元素值, 则返回 True ,否则 False .torch.lt(input, other, out=None) → Tensor | 逐元素比较 input 和other , 即是否 input (Tensor, LongTensor) | 返回输入张量 input 在给定维度 dim 上每行的最大值, 并同时返回每个最大值的位置索引.torch.max(input, other, out=None) → Tensor | 输入 input 每一个元素和对应的比较张量 other 进行比较, 留下较大的元素 max.torch.min(input) → float | 返回输入张量 input 所有元素的最小值torch.min(input, dim, keepdim=False, out=None) -&gt; (Tensor, LongTensor) | 返回输入张量 input 在给定维度 dim 下每行元素的最小值. 其中第二个返回值是每个被找出的最小值的索引位置 ( argmin )torch.min(input, other, out=None) → Tensor | 输入 input 每一个元素和对应的比较张量 other 进行比较, 留下较小的元素 min .torch.ne(input, other, out=None) → Tensor | 逐元素比较 input 和 other , 即是否 tensor != other 如果两个张量有相同的形状和元素值, 则返回 True , 否则 False .torch.sort(input, dim=None, descending=False, out=None) -&gt; (Tensor, | LongTensor) | 对输入张量 input 沿着指定维按升序排序.torch.topk(input, k, dim=None, largest=True, sorted=True, out=None) -&gt; (Tensor, LongTensor) | 沿给定 dim 维度返回输入张量 input 中 k 个最大值. 如果不指定 dim , 则默认为 input的最后一维. 如果为 largest 为 False ,则返回最小的 k 个值. 返回一个元组 (values, indices) , 其中 indices是原始输入张量 input 中测元素下标. 如果设定布尔值 sorted 为 True , 将会确保返回的 k 个值被排序.torch.isfinite(tensor) / torch.isinf(tensor) / torch.isnan(tensor) | 返回一个标记元素是否为 finite/inf/nan 的mask 张量。Other Operations (其它操作) |torch.bincount(self, weights=None, minlength=0) | 返回每个值得频数。torch.cross(input, other, dim=-1, out=None) → Tensor | 返回沿着维度 dim 上, 两个张量 input 和 other 的向量积 (叉积), input 和 other 必须有相同的形状, 且指定的 dim 维上 size 必须为 3.torch.diag(input, diagonal=0, out=None) → Tensor | 如果输入是一个向量( 1D 张量), 则返回一个以 input 为对角线元素的 2D 方阵.如果输入是一个矩阵( 2D 张量), 则返回一个包含 input 对角线元素的1D张量.torch.flip(input, dims) | 按照给定维度翻转张量torch.histc(input, bins=100, min=0, max=0, out=None) → Tensor | 计算输入张量的直方图torch.meshgrid(seq) | 生成网格（可以生成坐标）。torch.renorm(input, p, dim, maxnorm, out=None) → Tensor | 返回一个张量, 包含规范化后的各个子张量, 使得沿着 dim 维划分的各子张量的 p 范数小于 maxnormtorch.trace(input) → float | 返回输入 2 维矩阵对角线元素的和(迹).torch.tril(input, diagonal=0, out=None) → Tensor | 返回一个张量, 包含输入矩阵 ( 2D 张量)的下三角部分, 其余部分被设为 0.torch.triu(input, diagonal=0, out=None) → Tensor | 返回一个张量, 包含输入矩阵 ( 2D 张量)的上三角部分, 其余部分被设为 0.BLAS and LAPACK Operations (BLAS和LAPACK操作) |torch.addbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor | 执行保存在 batch1 和 batch2 中的矩阵的批量点乘, 伴随着一个减少的相加步骤 (所有的矩阵乘法沿第一维累加). mat 被相加到最终的结果中.torch.addmm(beta=1, mat, alpha=1, mat1, mat2, out=None) → Tensor | 执行矩阵 mat1 和 mat2 的相乘. 矩阵 mat 将与相乘的最终计算结果相加.torch.addmv(beta=1, tensor, alpha=1, mat, vec, out=None) → Tensor | 执行矩阵 mat 和向量 vec 的相乘. 矩阵 tensor 将与相乘的最终计算结果相加.torch.addr(beta=1, mat, alpha=1, vec1, vec2, out=None) → Tensor | 执行向量:attr:vec1 和 vec2 的外积, 并把外积计算结果与矩阵 mat相加torch.baddbmm(beta=1, mat, alpha=1, batch1, batch2, out=None) → Tensor | 执行保存在 batch1 和 batch2 中的矩阵的批量点乘. mat 被相加到最终的结果中.torch.bmm(batch1, batch2, out=None) → Tensor | 执行保存在 batch1 和 batch2 中的矩阵的批量点乘.torch.btrifact(A, info=None, pivot=True) → Tensor, IntTensor | 批量 LU 分解.torch.btrisolve(b, LU_data, LU_pivots) → Tensor | 批量 LU 解.返回线性系统 Ax = b 的 LU 解torch.dot(tensor1, tensor2) → float | 计算两个张量的点乘 (内积).torch.eig(a, eigenvectors=False, out=None) -&gt; (Tensor, Tensor) | 计算实数方阵的特征值和特征向量.torch.det(A) | 返回矩阵A的行列式torch.gels(B, A, out=None) → Tensor | 计算秩为 mm 的， 大小为 m x n 的矩阵 AA 最小二乘和最小范数问题的解torch.geqrf(input, out=None) -&gt; (Tensor, Tensor) | 直接调用 LAPACK 的低层函数torch.ger(vec1, vec2, out=None) → Tensor | 计算 vec1 和 vec2 的外积. 如果 vec1 是一个长度为n 的向量, vec2 是一个长度为 m 的向量, 那么 out 必须是一个 n x m 的矩阵torch.gesv(B, A, out=None) -&gt; (Tensor, Tensor) | X, LU = torch.gesv(B, A) ,该函数返回线性系统 AX=B 的解torch.inverse(input, out=None) → Tensor | 计算方阵 input 的逆.torch.matmul(tensor1, tensor2, out=None) | Matrix product of two tensorstorch.mm(mat1, mat2, out=None) → Tensor | 执行 mat1 和 mat2 的矩阵乘法.torch.mv(mat, vec, out=None) → Tensor | 执行矩阵 mat 与向量 vec 的乘法操作.torch.potrf(a, out=None) | 计算半正定矩阵 a: 的 Cholesky 分解torch.potri(u, out=None) | 给定一个半正定矩阵的 Cholesky 分解因子 u, 计算该半正定矩阵的逆.torch.potrs(b, u, out=None) | Solves a linear system of equations with a positive semidefinite matrix to be inverted given its given a Cholesky factor matrix utorch.pstrf(a, out=None) | Computes the pivoted Cholesky decomposition of a positive semidefinite matrix a: returns matrices u and pivtorch.qr(input, out=None) -&gt; (Tensor, Tensor) | 计算矩阵 input 的 QR 分解. 返回矩阵 q 和 r 使得 x=q∗rx=q∗r, 且 q 是一个 正交矩阵, r 是一个上三角矩阵torch.svd(input, some=True, out=None) -&gt; (Tensor, Tensor, Tensor) | U, S, V =torch.svd(A) 返回大小为 (n x m) 的实矩阵 A 的奇异值分解, 使得A=USV′∗torch.symeig(input, eigenvectors=False, upper=True, out=None) -&gt; (Tensor, Tensor) | e, V = torch.symeig(input) 返回实对称矩阵 input 的特征值和特征向量.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAN_pytorch版复现]]></title>
    <url>%2F2021%2F01%2F05%2FHAN_pytorch%E7%89%88%E5%A4%8D%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[模型 代码 模型 代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import torch.nn.functional as Ffrom torch import nn class SelfAttention(nn.Module): def __init__(self, input_size, hidden_size): super(SelfAttention, self).__init__() self.W = nn.Linear(input_size, hidden_size, True) self.u = nn.Linear(hidden_size, 1) def forward(self, x): u = torch.tanh(self.W(x)) a = F.softmax(self.u(u), dim=1) x = a.mul(x).sum(1) return x class HAN(nn.Module): def __init__(self): super(HAN1, self).__init__() num_embeddings = 5844 + 1 num_classes = 10 num_sentences = 30 num_words = 60 embedding_dim = 200 # 200 hidden_size_gru = 50 # 50 hidden_size_att = 100 # 100 self.num_words = num_words self.embed = nn.Embedding(num_embeddings, embedding_dim, 0) self.gru1 = nn.GRU(embedding_dim, hidden_size_gru, bidirectional=True, batch_first=True) self.att1 = SelfAttention(hidden_size_gru * 2, hidden_size_att) self.gru2 = nn.GRU(hidden_size_att, hidden_size_gru, bidirectional=True, batch_first=True) self.att2 = SelfAttention(hidden_size_gru * 2, hidden_size_att) # 这里fc的参数很少，不需要dropout self.fc = nn.Linear(hidden_size_att, num_classes, True) def forward(self, x): # 64 512 200 x = x.view(x.size(0) * self.num_words, -1).contiguous() x = self.embed(x) x, _ = self.gru1(x) x = self.att1(x) x = x.view(x.size(0) // self.num_words, self.num_words, -1).contiguous() x, _ = self.gru2(x) x = self.att2(x) x = self.fc(x) x = F.log_softmax(x, dim=1) # softmax return x]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>文本分类模型</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAN_学习指导_未完待续]]></title>
    <url>%2F2021%2F01%2F05%2FHAN_%E5%AD%A6%E4%B9%A0%E6%8C%87%E5%AF%BC_%E6%9C%AA%E5%AE%8C%E5%BE%85%E7%BB%AD%2F</url>
    <content type="text"><![CDATA[RNN+Attention(HAN) 文本分类 阅读笔记 - 今天做作业没的文章 -知乎Hierarchical Attention Networks for Document Classification 阅读笔记 - 滨城之恋的文章 -知乎 关于GRU不同门的介绍 pytorch的实现 实现 github: HAN HAN_pytorch]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>文本分类模型</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[把简书、掘金、CSDN上一些优秀的文章保存成markdown文件]]></title>
    <url>%2F2021%2F01%2F05%2F%E6%8A%8A%E7%AE%80%E4%B9%A6%E3%80%81%E6%8E%98%E9%87%91%E3%80%81CSDN%E4%B8%8A%E4%B8%80%E4%BA%9B%E4%BC%98%E7%A7%80%E7%9A%84%E6%96%87%E7%AB%A0%E4%BF%9D%E5%AD%98%E6%88%90markdown%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[本文二次转载于https://blog.csdn.net/qq_16546829/article/details/81784096 推荐 ➹ Clean-mark, 将博客文章转换为干净的Markdown文本文件。 安装： 1npm install clean-mark --global 使用: 1clean-mark &quot;http://some-website.com/fancy-article&quot; 示例： 1clean-mark &quot;https://jeffjade.com/2017/12/31/136-talk-about-nicelinks-site/&quot;]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>HTML</tag>
        <tag>markdown</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAN_论文阅读]]></title>
    <url>%2F2021%2F01%2F05%2FHAN_%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%2F</url>
    <content type="text"><![CDATA[论文： Hierarchical Attention Networks for Document Classification 发表会议： NAACL2016 作者： 单位： 1.Carnegie Mellon University 2.Microsoft Research, Redmond 链接： Hierarchical Attention Networks for Document Classification 前言： 本文针对文本分类任务提出了一个层次化attention机制模型(HAN)，有两个显著的特点： (1)采用”词-句子-文章”的层次化结构来表示一篇文本。 (2)该模型有两个层次的attention机制，分别存在于词层次(word level)和句子层次(sentence level)。从而使该模型具有对文本中重要性不同的句子和词的能力给予不同”注意力”的能力。作者在6个数据集合上进行了测试，并且相较以往的模型效果提升显著。最后，通过可视化说明该模型可以选择出含有丰富信息的词语和句子。 一 、写作动机 文本分类是一项基础的NLP任务，在主题分类，情感分析，垃圾邮件检测等应用上有广泛地应用。其目标是給每篇文本分配一个类别标签。本文中模型的直觉是，不同的词和句子对文本信息的表达有不同的影响，词和句子的重要性是严重依赖于上下文的，即使是相同的词和句子，在不同的上下文中重要性也不一样。就像人在阅读一篇文本时，对文本不同的内容是有着不同的注意度的。而本文在attention机制的基础上，联想到文本是一个层次化的结构，提出用词向量来表示句子向量，再由句子向量表示文档向量，并且在词层次和句子层次分别引入attention操作的模型。 二、模型构建 HAN的模型结构如图所示，它包含一个词序列编码器，一个词层面的attention层，一个句子序列编码器，一个句子层级的attention层。 1. 基于GRU的词序列编码器 GRU是RNN的一个变种，使用门机制来记录序列当前的状态。隐藏层有两个门(gate)，重置门(reset gate)和更新门(update gate)。这两个门一起来控制当前状态有多少信息要更新。在时刻t，隐藏层状态的计算公式： 更新门(update gate)是用来决定有多少过去的信息被保留，以及有多少新信息被加进来： 这里是在时刻t输入的单词的词向量，候选状态的计算方法和普通的RNN相似： 重置门决定有多少过去的信息作用于候选状态，如果是0，即忘记之前的所有状态： 2 层次化attention 2.1 词编码器（Word Encoder） 由词序列组成,组成的句子,首先把词转化成词向量，,然后用双向的GRU网络,可以将正向和反向的上下文信息结合起来，获得隐藏层输出。 对于一个给定的词语,经过GRU网络后，我们获得了一种新的表示： 包含了周围两个方向的信息。 2.2 词级别的attention机制 attention机制的目的是要把一个句子中，对句子的含义最重要，贡献最大的词语找出来。我们通过将输入到一个单层的感知机(MLP)中得到的结果作为的隐含表示。 为了衡量单词的重要性,我们用和一个随机初始化的上下文向量的相似度来表示，然后经过softmax操作获得了一个归一化的attention权重矩阵，代表句子i中第t个词的权重。 有了attention权重矩阵以后，我们可以将句子向量看作组成这些句子的词向量的加权求和。这里的上下文向量是在训练网络的过程中学习获得的。我们可以把当作一种询问的高级表示，比如”哪些词含有比较重要的信息？” 2.3 语句编码器(Sentence Encoder) 得到了句子向量表示以后，我们用类似的办法获得文档向量： 对于给定的句子我们得到了相应的句子表示。这样获得的表示可以包含两个方向的上下文信息。 2.4 句子级别的attention 和词级别的attention类似，我们也提出了一个句子级别的上下文向量,来衡量一个句子在整篇文本的重要性。 我们获得了整篇文章的向量表示,最后可以使用全链接的softmax层进行分类。 三、实验 1 数据集 论文中使用了六个数据集，Yelp reviews2013,2014,2015;IMDB reviews;Yahoo Answers;Amazon reviews。每个数据集合中80%的数据用作训练集合，10%的数据用作验证集合，剩余10%的集合用作测试集合。 2 实验指标与对比模型 线性模型：使用手工构建的统计数据作为特征，多项式logistic回归作为分类器 SVM：支持向量机+unigr，bigrams word-based CNN:基于词的卷积神经网络 Character-based CNN：字符级别的卷积神经网络 Conv/LSTM-GRNN：使用”词-句子-文本”的层次化结构表示文档，然后用带有门限制的RNN做分类。 3 实验结果 4 结果分析 根据上表的实验结果可以看出来，层次化attention模型在所有的六个数据集合上均取得了最好的效果。这种效果的提升是不受数据集大小限制的。在相对较小的数据集比如Yelp2013和IMDB上，我们的HAN模型超过基准模型的最好表现的比率分别为3.1%和4.1%。相同的在，大数据集上，我们的模型优于之前的最好模型的比例分别为3.2%，3.4%，4.6%，6.0%，分别在Yelp2014，Yelp2015，Yahoo Answer,Amazon Answer。 一些没有使用层次结构来表示文本的神经网络分类算法比如CNN-word，CNN-char，LSTM在一些大数据集合上并没有超过基准模型太多。单从文本的结构化表示来看，HN-MAX,HN-AVG都可以显著提升CNN-word，LSTM等模型的性能。我们将层次话结构和Attention机制联合起来的模型，更是超过了单纯的层次化模型LSTM-GRNN。 5 可视化分析 上图是词”good”在IMDB数据集合种的的attention权值分布，可以看出，当评价等级为1时Fig3（b）,good的权值集中在比较低的一端，当评论的变得向好评方向时，good的权重也开始在高的一端分布。 相反的，词”bad”在评价等级较低的评论里权值较大，在评价高的评论里权值小。 情感分析任务种，从上图我们可以看到，在好评里，delicious,fun,amazing,recommend 等词所在的句子颜色深，权值大。在差评里，terrible，not等词占的比重大。 在主题分类任务中，在科学自然类别里，权值比较大的词zebra,strips,camouflage,predator。 在计算机网络类别里web,searches, browsers的权值较大。 四 总结 本文提出了一种基于层次化attention的文本分类模型，可以利用attention机制识别出一句话中比较重要的词语，利用重要的词语形成句子的表示，同样识别出重要的句子，利用重要句子表示来形成整篇文本的表示。实验证明，该模型确实比基准模型获得了更好的效果，可视化分析也表明，该模型能很好地识别出重要的句子和词语。 转载于 知乎]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>文本分类模型</tag>
        <tag>python</tag>
        <tag>论文阅读</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_torchtext学习笔记_1]]></title>
    <url>%2F2021%2F01%2F03%2Fpython_torchtext%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_1%2F</url>
    <content type="text"><![CDATA[0. 整体介绍torchtext的组件 1. Field 2. Dataset 3. Iterator 4. 其他 0. 整体介绍torchtext的组件torchtext包含以下组件： Field :主要包含以下数据预处理的配置信息，比如指定分词方法，是否转成小写，起始字符，结束字符，补全字符以及词典等等 Dataset :继承自pytorch的Dataset，用于加载数据，提供了TabularDataset可以指点路径，格式，Field信息就可以方便的完成数据加载。同时torchtext还提供预先构建的常用数据集的Dataset对象，可以直接加载使用，splits方法可以同时加载训练集，验证集和测试集。 Iterator : 主要是数据输出的模型的迭代器，可以支持batch定制 1. FieldField 包含一写文本处理的通用参数的设置，同时还包含一个词典对象，可以把文本数据表示成数字类型，进而可以把文本表示成需要的tensor类型 以下是Field对象包含的参数： sequential: 是否把数据表示成序列，如果是False, 不能使用分词 默认值: True. use_vocab: 是否使用词典对象. 如果是False 数据的类型必须已经是数值类型. 默认值: True. init_token: 每一条数据的起始字符 默认值: None. eos_token: 每条数据的结尾字符 默认值: None. fix_length: 修改每条数据的长度为该值，不够的用pad_token补全. 默认值: None. tensor_type: 把数据转换成的tensor类型 默认值: torch.LongTensor. preprocessing:在分词之后和数值化之前使用的管道 默认值: None. postprocessing: 数值化之后和转化成tensor之前使用的管道默认值: None. lower: 是否把数据转化为小写 默认值: False. tokenize: 分词函数. 默认值: str.split. include_lengths: 是否返回一个已经补全的最小batch的元组和和一个包含每条数据长度的列表 . 默认值: False. batch_first: Whether to produce tensors with the batch dimension first. 默认值: False. pad_token: 用于补全的字符. 默认值: “ unk_token: 不存在词典里的字符. 默认值: “ pad_first: 是否补全第一个字符. 默认值: False. 重要的几个方法： pad(minibatch): 在一个batch对齐每条数据 build_vocab(): 建立词典 numericalize(): 把文本数据数值化，返回tensor 简单的栗子如下，建一个Field对象12TEXT = data.Field(tokenize=data.get_tokenizer('spacy'), init_token='&lt;SOS&gt;', eos_token='&lt;EOS&gt;',lower=True) 2. Datasettorchtext的Dataset是继承自pytorch的Dataset，提供了一个可以下载压缩数据并解压的方法（支持.zip, .gz, .tgz） splits方法可以同时读取训练集，验证集，测试集 TabularDataset可以很方便的读取CSV, TSV, or JSON格式的文件，例子如下： 1234train, val, test = data.TabularDataset.splits( path='./data/', train='train.tsv', validation='val.tsv', test='test.tsv', format='tsv', fields=[('Text', TEXT), ('Label', LABEL)]) 加载数据后可以建立词典，建立词典的时候可以使用与训练的word vector 1TEXT.build_vocab(train, vectors="glove.6B.100d") 3. IteratorIterator是torchtext到模型的输出，它提供了我们对数据的一般处理方式，比如打乱，排序，等等，可以动态修改batch大小，这里也有splits方法可以同时输出训练集，验证集，测试集 参数如下： dataset: 加载的数据集 batch_size: Batch 大小. batch_size_fn: 产生动态的batch大小 的函数 sort_key: 排序的key train: 是否是一个训练集 repeat: 是否在不同epoch中重复迭代 shuffle: 是否打乱数据 sort: 是否对数据进行排序 sort_within_batch: batch内部是否排序 device: 建立batch的设备 -1:CPU ；0,1 …：对应的GPU 使用方式如下： 123train_iter, val_iter, test_iter = data.Iterator.splits( (train, val, test), sort_key=lambda x: len(x.Text), batch_sizes=(32, 256, 256), device=-1) 4. 其他torchtext提供常用文本数据集，并可以直接加载使用： 1train,val,test = datasets.WikiText2.splits(text_field=TEXT) 现在包含的数据集包括： Sentiment analysis: SST and IMDb Question classification: TREC Entailment: SNLI Language modeling: WikiText-2 Machine translation: Multi30k, IWSLT, WMT14 完整例子如下，短短几行就把词典和数据batch做好了。 12345678910111213141516171819202122232425import jiebaimport torchfrom torchtext import data, datasetsregex = re.compile(r'[^\u4e00-\u9fa5aA-Za-z0-9]')def tokenizer(text): # create a tokenizer function text = regex.sub(' ', text) return [word for word in jieba.cut(text) if word.strip()]text = data.Field(sequential=True, tokenize=tokenizer, fix_length=150)label = data.Field(sequential=False, use_vocab=False)train, val = data.TabularDataset.splits( path='./data/', train='/brucewu/projects/pytorch_tutorials/chinese_text_cnn/data/train.tsv', validation='/brucewu/projects/pytorch_tutorials/chinese_text_cnn/data/dev.tsv', format='tsv', fields=[('text', text), ('label', label)])text.build_vocab(train, val, vectors=Vectors(name="/brucewu/projects/pytorch_tutorials/chinese_text_cnn/data/eco_article.vector"))train_iter, val_iter = data.Iterator.splits( (train, val), sort_key=lambda x: len(x.text), batch_sizes=(32, 256), device=-1)vocab = text.vocab 需要注意的一些点 如果运行在 CPU 上，需要设置 device=-1， 如果运行在GPU 上，需要设置device=0 torchtext 使用了动态 padding，意味着 batch内的所有句子会 pad 成 batch 内最长的句子长度 参考自 https://zhuanlan.zhihu.com/p/31139113]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
        <tag>python模块学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_torchtext学习笔记_2]]></title>
    <url>%2F2021%2F01%2F03%2Fpython_torchtext%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_2%2F</url>
    <content type="text"><![CDATA[主要内容： torchtext预处理流程： 1. 定义Field： 2. 定义Dataset： 3. 建立vocab： 4. 构造迭代器： 实操 1. 下载数据： 读取文件，查看文件 train.tsv test.tsv 2. 划分验证集 3. 定义Field 4. 定义Dataset 5. 建立vocab 6. 构造迭代器 迭代器使用 7. 完整代码 主要内容： 如何使用torchtext建立语料库 如何使用torchtext将词转下标，下标转词，词转词向量 如何建立相应的迭代器 torchtext预处理流程：1. 定义Field： 声明如何处理数据 2. 定义Dataset：得到数据集，此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 wordlist 3. 建立vocab：在这一步建立词汇表，词向量(word embeddings) 4. 构造迭代器：构造迭代器，用来分批次训练模型 实操1. 下载数据：kaggle：Movie Review Sentiment Analysis (Kernels Only)train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence. test.tsv contains just phrases. You must assign a sentiment label to each phrase. The sentiment labels are:0 - negative1 - somewhat negative2 - neutral3 - somewhat positive4 - positive 下载得到：train.tsv和test.tsv 读取文件，查看文件123import pandas as pd data = pd.read_csv('train.tsv', sep='\t') test = pd.read_csv('test.tsv', sep='\t') train.tsv1data[:5] test.tsv1test[:5] 2. 划分验证集123456from sklearn.model_selection import train_test_split # create train and validation set train, val = train_test_split(data, test_size=0.2) train.to_csv("train.csv", index=False) val.to_csv("val.csv", index=False) 3. 定义Field首先导入需要的包和定义pytorch张量使用的DEVICE 1234567import spacy import torch from torchtext import data, datasets from torchtext.vocab import Vectors from torch.nn import init DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu") Torchtext采用了一种声明式的方法来加载数据：你来告诉Torchtext你希望的数据是什么样子的，剩下的由torchtext来处理。实现这种声明的是Field，Field确定了一种你想要怎么去处理数据。data.Field(…) Field的参数如下： sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True. use_vocab: Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True. init_token: A token that will be prepended to every example using this field, or None for no initial token. Default: None. eos_token: A token that will be appended to every example using this field, or None for no end-of-sentence token. Default: None. fix_length: A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. Default: None. dtype: The torch.dtype class that represents a batch of examples of this kind of data. Default: torch.long. preprocessing: The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None. postprocessing: A Pipeline that will be applied to examples using this field after numericalizing but before the numbers are turned into a Tensor. The pipeline function takes the batch as a list, and the field’s Vocab. Default: None. lower: Whether to lowercase the text in this field. Default: False. tokenize: The function used to tokenize strings using this field into sequential examples. If “spacy”, the SpaCy tokenizer is used. If a non-serializable function is passed as an argument, the field will not be able to be serialized. Default: string.split. tokenizer_language: The language of the tokenizer to be constructed. Various languages currently supported only in SpaCy. include_lengths: Whether to return a tuple of a padded minibatch and a list containing the lengths of each examples, or just a padded minibatch. Default: False. batch_first: Whether to produce tensors with the batch dimension first. Default: False. pad_token: The string token used as padding. Default: “ unk_token: The string token used to represent OOV words. Default: “ pad_first: Do the padding of the sequence at the beginning. Default: False. truncate_first: Do the truncating of the sequence at the beginning. Default: False stop_words: Tokens to discard during the preprocessing step. Default: None is_target: Whether this field is a target variable. Affects iteration over batches. Default: False 例：12345678910111213141516spacy_en = spacy.load('en')def tokenizer(text): # create a tokenizer function """ 定义分词操作 """ return [tok.text for tok in spacy_en.tokenizer(text)]"""field在默认的情况下都期望一个输入是一组单词的序列，并且将单词映射成整数。这个映射被称为vocab。如果一个field已经被数字化了并且不需要被序列化，可以将参数设置为use_vocab=False以及sequential=False。"""LABEL = data.Field(sequential=False, use_vocab=False)TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True) 4. 定义DatasetThe fields知道当给定原始数据的时候要做什么。现在，我们需要告诉fields它需要处理什么样的数据。这个功能利用Datasets来实现。 TabularDataset官网介绍: Defines a Dataset of columns stored in CSV, TSV, or JSON format. 对于csv/tsv类型的文件，TabularDataset很容易进行处理，故我们选它来生成Dataset 1234567891011"""我们不需要 'PhraseId' 和 'SentenceId'这两列, 所以我们给他们的field传递 None如果你的数据有列名，如我们这里的'Phrase','Sentiment',...设置skip_header=True,不然它会把列名也当一个数据处理"""train,val = data.TabularDataset.splits( path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])test = data.TabularDataset('test.tsv', format='tsv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)]) 注意：传入的(name, field)必须与列的顺序相同。 查看生成的dataset： 123print(train[5]) print(train[5].__dict__.keys()) print(train[5].Phrase,train[0].Sentiment) 输出： 5. 建立vocab我们可以看到第6行的输入，它是一个Example对象。Example对象绑定了一行中的所有属性，可以看到，句子已经被分词了，但是没有转化为数字。 这是因为我们还没有建立vocab，我们将在下一步建立vocab。 Torchtext可以将词转化为数字，但是它需要被告知需要被处理的全部范围的词。我们可以用下面这行代码： 123TEXT.build_vocab(train, vectors='glove.6B.100d')#, max_size=30000)# 当 corpus 中有的 token 在 vectors 中不存在时 的初始化方式.TEXT.vocab.vectors.unk_init = init.xavier_uniform 这行代码使得 Torchtext遍历 训练集 中的绑定TEXTfield的数据，将单词注册到vocabulary，并自动构建embedding矩阵。 ‘glove.6B.100d’ 为torchtext支持的词向量名字，第一次使用是会自动下载并保存在当前目录的 .vector_cache里面。 torchtext支持的词向量 charngram.100d fasttext.en.300d fasttext.simple.300d glove.42B.300d glove.840B.300d glove.twitter.27B.25d glove.twitter.27B.50d glove.twitter.27B.100d glove.twitter.27B.200d glove.6B.50d glove.6B.100d glove.6B.200d glove.6B.300d 例：如果打算使用fasttext.en.300d词向量，只需把上面的代码里的vector=’…’里面的词向量名字换一下即可，具体如下： 1TEXT.build_vocab(train, vectors=&apos;fasttext.en.300d&apos;) 到这一步，我们已经可以把 词转为数字，数字转为词，词转为词向量 了 1234567print(TEXT.vocab.itos[1510])print(TEXT.vocab.stoi['bore'])# 词向量矩阵: TEXT.vocab.vectorsprint(TEXT.vocab.vectors.shape)word_vec = TEXT.vocab.vectors[TEXT.vocab.stoi['bore']]print(word_vec.shape)print(word_vec) 输出： 6. 构造迭代器我们日常使用pytorch训练网络时，每次训练都是输入一个batch，那么，我们怎么把前面得到的dataset转为迭代器，然后遍历迭代器获取batch输入呢？下面将介绍torchtext时怎么实现这一功能的。 和Dataset一样，torchtext有大量内置的迭代器，我们这里选择的是BucketIterator，官网对它的介绍如下： Defines an iterator that batches examples of similar lengths together. Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch. 123456train_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序test_iter = data.Iterator(dataset=test, batch_size=128, train=False, sort=False, device=DEVICE) 迭代器使用方法一12345batch = next(iter(train_iter)) data = batch.Phrase label = batch.Sentiment print(batch.Phrase.shape) print(batch.Phrase) 输出结果： 可以发现，它输出的是word index，后面的128是batch size 方法二123for batch in train_iter: data = batch.Phrase label = batch.Sentiment 7. 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129import spacyimport torchfrom torchtext import data, datasetsfrom torchtext.vocab import Vectorsfrom torch.nn import initimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport numpy as npfrom sklearn.model_selection import train_test_splitimport pandas as pdDEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")data = pd.read_csv('train.tsv', sep='\t')test = pd.read_csv('test.tsv', sep='\t')# create train and validation set train, val = train_test_split(data, test_size=0.2)train.to_csv("train.csv", index=False)val.to_csv("val.csv", index=False)spacy_en = spacy.load('en')def tokenizer(text): # create a tokenizer function return [tok.text for tok in spacy_en.tokenizer(text)]# FieldTEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True)LABEL = data.Field(sequential=False, use_vocab=False)# Datasettrain,val = data.TabularDataset.splits( path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])test = data.TabularDataset('test.tsv', format='tsv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)])# build vocabTEXT.build_vocab(train, vectors='glove.6B.100d')#, max_size=30000)TEXT.vocab.vectors.unk_init = init.xavier_uniform# Iteratortrain_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序test_iter = data.Iterator(dataset=test, batch_size=128, train=False, sort=False, device=DEVICE)"""由于目的是学习torchtext的使用，所以只定义了一个简单模型"""len_vocab = len(TEXT.vocab)class Enet(nn.Module): def __init__(self): super(Enet, self).__init__() self.embedding = nn.Embedding(len_vocab,100) self.lstm = nn.LSTM(100,128,3,batch_first=True)#,bidirectional=True) self.linear = nn.Linear(128,5) def forward(self, x): batch_size,seq_num = x.shape vec = self.embedding(x) out, (hn, cn) = self.lstm(vec) out = self.linear(out[:,-1,:]) out = F.softmax(out,-1) return outmodel = Enet()"""将前面生成的词向量矩阵拷贝到模型的embedding层这样就自动的可以将输入的word index转为词向量"""model.embedding.weight.data.copy_(TEXT.vocab.vectors) model.to(DEVICE)# 训练optimizer = optim.Adam(model.parameters())#,lr=0.000001)n_epoch = 20best_val_acc = 0for epoch in range(n_epoch): for batch_idx, batch in enumerate(train_iter): data = batch.Phrase target = batch.Sentiment target = torch.sparse.torch.eye(5).index_select(dim=0, index=target.cpu().data) target = target.to(DEVICE) data = data.permute(1,0) optimizer.zero_grad() out = model(data) loss = -target*torch.log(out)-(1-target)*torch.log(1-out) loss = loss.sum(-1).mean() loss.backward() optimizer.step() if (batch_idx+1) %200 == 0: _,y_pre = torch.max(out,-1) acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float))) print('epoch: %d \t batch_idx : %d \t loss: %.4f \t train acc: %.4f' %(epoch,batch_idx,loss,acc)) val_accs = [] for batch_idx, batch in enumerate(val_iter): data = batch.Phrase target = batch.Sentiment target = torch.sparse.torch.eye(5).index_select(dim=0, index=target.cpu().data) target = target.to(DEVICE) data = data.permute(1,0) out = model(data) _,y_pre = torch.max(out,-1) acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float))) val_accs.append(acc) acc = np.array(val_accs).mean() if acc &gt; best_val_acc: print('val acc : %.4f &gt; %.4f saving model'%(acc,best_val_acc)) torch.save(model.state_dict(), 'params.pkl') best_val_acc = acc print('val acc: %.4f'%(acc)) 转载Torchtext使用教程]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>python模块学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch_torchtext学习笔记_2]]></title>
    <url>%2F2021%2F01%2F03%2Fpytorch_torchtext%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0_2%2F</url>
    <content type="text"><![CDATA[主要内容： torchtext预处理流程： 1. 定义Field： 2. 定义Dataset： 3. 建立vocab： 4. 构造迭代器： 实操 1. 下载数据： 读取文件，查看文件 train.tsv test.tsv 2. 划分验证集 3. 定义Field 4. 定义Dataset 5. 建立vocab 6. 构造迭代器 迭代器使用 7. 完整代码 主要内容： 如何使用torchtext建立语料库 如何使用torchtext将词转下标，下标转词，词转词向量 如何建立相应的迭代器 torchtext预处理流程：1. 定义Field： 声明如何处理数据 2. 定义Dataset：得到数据集，此时数据集里每一个样本是一个 经过 Field声明的预处理 预处理后的 wordlist 3. 建立vocab：在这一步建立词汇表，词向量(word embeddings) 4. 构造迭代器：构造迭代器，用来分批次训练模型 实操1. 下载数据：kaggle：Movie Review Sentiment Analysis (Kernels Only)train.tsv contains the phrases and their associated sentiment labels. We have additionally provided a SentenceId so that you can track which phrases belong to a single sentence. test.tsv contains just phrases. You must assign a sentiment label to each phrase. The sentiment labels are:0 - negative1 - somewhat negative2 - neutral3 - somewhat positive4 - positive 下载得到：train.tsv和test.tsv 读取文件，查看文件123import pandas as pd data = pd.read_csv('train.tsv', sep='\t') test = pd.read_csv('test.tsv', sep='\t') train.tsv1data[:5] test.tsv1test[:5] 2. 划分验证集123456from sklearn.model_selection import train_test_split # create train and validation set train, val = train_test_split(data, test_size=0.2) train.to_csv("train.csv", index=False) val.to_csv("val.csv", index=False) 3. 定义Field首先导入需要的包和定义pytorch张量使用的DEVICE 1234567import spacy import torch from torchtext import data, datasets from torchtext.vocab import Vectors from torch.nn import init DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu") Torchtext采用了一种声明式的方法来加载数据：你来告诉Torchtext你希望的数据是什么样子的，剩下的由torchtext来处理。实现这种声明的是Field，Field确定了一种你想要怎么去处理数据。data.Field(…) Field的参数如下： sequential: Whether the datatype represents sequential data. If False, no tokenization is applied. Default: True. use_vocab: Whether to use a Vocab object. If False, the data in this field should already be numerical. Default: True. init_token: A token that will be prepended to every example using this field, or None for no initial token. Default: None. eos_token: A token that will be appended to every example using this field, or None for no end-of-sentence token. Default: None. fix_length: A fixed length that all examples using this field will be padded to, or None for flexible sequence lengths. Default: None. dtype: The torch.dtype class that represents a batch of examples of this kind of data. Default: torch.long. preprocessing: The Pipeline that will be applied to examples using this field after tokenizing but before numericalizing. Many Datasets replace this attribute with a custom preprocessor. Default: None. postprocessing: A Pipeline that will be applied to examples using this field after numericalizing but before the numbers are turned into a Tensor. The pipeline function takes the batch as a list, and the field’s Vocab. Default: None. lower: Whether to lowercase the text in this field. Default: False. tokenize: The function used to tokenize strings using this field into sequential examples. If “spacy”, the SpaCy tokenizer is used. If a non-serializable function is passed as an argument, the field will not be able to be serialized. Default: string.split. tokenizer_language: The language of the tokenizer to be constructed. Various languages currently supported only in SpaCy. include_lengths: Whether to return a tuple of a padded minibatch and a list containing the lengths of each examples, or just a padded minibatch. Default: False. batch_first: Whether to produce tensors with the batch dimension first. Default: False. pad_token: The string token used as padding. Default: “ unk_token: The string token used to represent OOV words. Default: “ pad_first: Do the padding of the sequence at the beginning. Default: False. truncate_first: Do the truncating of the sequence at the beginning. Default: False stop_words: Tokens to discard during the preprocessing step. Default: None is_target: Whether this field is a target variable. Affects iteration over batches. Default: False 例：12345678910111213141516spacy_en = spacy.load('en')def tokenizer(text): # create a tokenizer function """ 定义分词操作 """ return [tok.text for tok in spacy_en.tokenizer(text)]"""field在默认的情况下都期望一个输入是一组单词的序列，并且将单词映射成整数。这个映射被称为vocab。如果一个field已经被数字化了并且不需要被序列化，可以将参数设置为use_vocab=False以及sequential=False。"""LABEL = data.Field(sequential=False, use_vocab=False)TEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True) 4. 定义DatasetThe fields知道当给定原始数据的时候要做什么。现在，我们需要告诉fields它需要处理什么样的数据。这个功能利用Datasets来实现。 TabularDataset官网介绍: Defines a Dataset of columns stored in CSV, TSV, or JSON format. 对于csv/tsv类型的文件，TabularDataset很容易进行处理，故我们选它来生成Dataset 1234567891011"""我们不需要 'PhraseId' 和 'SentenceId'这两列, 所以我们给他们的field传递 None如果你的数据有列名，如我们这里的'Phrase','Sentiment',...设置skip_header=True,不然它会把列名也当一个数据处理"""train,val = data.TabularDataset.splits( path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])test = data.TabularDataset('test.tsv', format='tsv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)]) 注意：传入的(name, field)必须与列的顺序相同。 查看生成的dataset： 123print(train[5]) print(train[5].__dict__.keys()) print(train[5].Phrase,train[0].Sentiment) 输出： 5. 建立vocab我们可以看到第6行的输入，它是一个Example对象。Example对象绑定了一行中的所有属性，可以看到，句子已经被分词了，但是没有转化为数字。 这是因为我们还没有建立vocab，我们将在下一步建立vocab。 Torchtext可以将词转化为数字，但是它需要被告知需要被处理的全部范围的词。我们可以用下面这行代码： 123TEXT.build_vocab(train, vectors='glove.6B.100d')#, max_size=30000)# 当 corpus 中有的 token 在 vectors 中不存在时 的初始化方式.TEXT.vocab.vectors.unk_init = init.xavier_uniform 这行代码使得 Torchtext遍历 训练集 中的绑定TEXTfield的数据，将单词注册到vocabulary，并自动构建embedding矩阵。 ‘glove.6B.100d’ 为torchtext支持的词向量名字，第一次使用是会自动下载并保存在当前目录的 .vector_cache里面。 torchtext支持的词向量 charngram.100d fasttext.en.300d fasttext.simple.300d glove.42B.300d glove.840B.300d glove.twitter.27B.25d glove.twitter.27B.50d glove.twitter.27B.100d glove.twitter.27B.200d glove.6B.50d glove.6B.100d glove.6B.200d glove.6B.300d 例：如果打算使用fasttext.en.300d词向量，只需把上面的代码里的vector=’…’里面的词向量名字换一下即可，具体如下： 1TEXT.build_vocab(train, vectors=&apos;fasttext.en.300d&apos;) 到这一步，我们已经可以把 词转为数字，数字转为词，词转为词向量 了 1234567print(TEXT.vocab.itos[1510])print(TEXT.vocab.stoi['bore'])# 词向量矩阵: TEXT.vocab.vectorsprint(TEXT.vocab.vectors.shape)word_vec = TEXT.vocab.vectors[TEXT.vocab.stoi['bore']]print(word_vec.shape)print(word_vec) 输出： 6. 构造迭代器我们日常使用pytorch训练网络时，每次训练都是输入一个batch，那么，我们怎么把前面得到的dataset转为迭代器，然后遍历迭代器获取batch输入呢？下面将介绍torchtext时怎么实现这一功能的。 和Dataset一样，torchtext有大量内置的迭代器，我们这里选择的是BucketIterator，官网对它的介绍如下： Defines an iterator that batches examples of similar lengths together. Minimizes amount of padding needed while producing freshly shuffled batches for each new epoch. 123456train_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序test_iter = data.Iterator(dataset=test, batch_size=128, train=False, sort=False, device=DEVICE) 迭代器使用方法一12345batch = next(iter(train_iter)) data = batch.Phrase label = batch.Sentiment print(batch.Phrase.shape) print(batch.Phrase) 输出结果： 可以发现，它输出的是word index，后面的128是batch size 方法二123for batch in train_iter: data = batch.Phrase label = batch.Sentiment 7. 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129import spacyimport torchfrom torchtext import data, datasetsfrom torchtext.vocab import Vectorsfrom torch.nn import initimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport numpy as npfrom sklearn.model_selection import train_test_splitimport pandas as pdDEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")data = pd.read_csv('train.tsv', sep='\t')test = pd.read_csv('test.tsv', sep='\t')# create train and validation set train, val = train_test_split(data, test_size=0.2)train.to_csv("train.csv", index=False)val.to_csv("val.csv", index=False)spacy_en = spacy.load('en')def tokenizer(text): # create a tokenizer function return [tok.text for tok in spacy_en.tokenizer(text)]# FieldTEXT = data.Field(sequential=True, tokenize=tokenizer, lower=True)LABEL = data.Field(sequential=False, use_vocab=False)# Datasettrain,val = data.TabularDataset.splits( path='.', train='train.csv',validation='val.csv', format='csv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT), ('Sentiment', LABEL)])test = data.TabularDataset('test.tsv', format='tsv',skip_header=True, fields=[('PhraseId',None),('SentenceId',None),('Phrase', TEXT)])# build vocabTEXT.build_vocab(train, vectors='glove.6B.100d')#, max_size=30000)TEXT.vocab.vectors.unk_init = init.xavier_uniform# Iteratortrain_iter = data.BucketIterator(train, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)val_iter = data.BucketIterator(val, batch_size=128, sort_key=lambda x: len(x.Phrase), shuffle=True,device=DEVICE)# 在 test_iter , sort一定要设置成 False, 要不然会被 torchtext 搞乱样本顺序test_iter = data.Iterator(dataset=test, batch_size=128, train=False, sort=False, device=DEVICE)"""由于目的是学习torchtext的使用，所以只定义了一个简单模型"""len_vocab = len(TEXT.vocab)class Enet(nn.Module): def __init__(self): super(Enet, self).__init__() self.embedding = nn.Embedding(len_vocab,100) self.lstm = nn.LSTM(100,128,3,batch_first=True)#,bidirectional=True) self.linear = nn.Linear(128,5) def forward(self, x): batch_size,seq_num = x.shape vec = self.embedding(x) out, (hn, cn) = self.lstm(vec) out = self.linear(out[:,-1,:]) out = F.softmax(out,-1) return outmodel = Enet()"""将前面生成的词向量矩阵拷贝到模型的embedding层这样就自动的可以将输入的word index转为词向量"""model.embedding.weight.data.copy_(TEXT.vocab.vectors) model.to(DEVICE)# 训练optimizer = optim.Adam(model.parameters())#,lr=0.000001)n_epoch = 20best_val_acc = 0for epoch in range(n_epoch): for batch_idx, batch in enumerate(train_iter): data = batch.Phrase target = batch.Sentiment target = torch.sparse.torch.eye(5).index_select(dim=0, index=target.cpu().data) target = target.to(DEVICE) data = data.permute(1,0) optimizer.zero_grad() out = model(data) loss = -target*torch.log(out)-(1-target)*torch.log(1-out) loss = loss.sum(-1).mean() loss.backward() optimizer.step() if (batch_idx+1) %200 == 0: _,y_pre = torch.max(out,-1) acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float))) print('epoch: %d \t batch_idx : %d \t loss: %.4f \t train acc: %.4f' %(epoch,batch_idx,loss,acc)) val_accs = [] for batch_idx, batch in enumerate(val_iter): data = batch.Phrase target = batch.Sentiment target = torch.sparse.torch.eye(5).index_select(dim=0, index=target.cpu().data) target = target.to(DEVICE) data = data.permute(1,0) out = model(data) _,y_pre = torch.max(out,-1) acc = torch.mean((torch.tensor(y_pre == batch.Sentiment,dtype=torch.float))) val_accs.append(acc) acc = np.array(val_accs).mean() if acc &gt; best_val_acc: print('val acc : %.4f &gt; %.4f saving model'%(acc,best_val_acc)) torch.save(model.state_dict(), 'params.pkl') best_val_acc = acc print('val acc: %.4f'%(acc)) 转载Torchtext使用教程]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>pytorch</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python_argparse学习]]></title>
    <url>%2F2021%2F01%2F03%2Fpython_argparse%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[argparse模块 1. 命令行参数分为位置参数和选项参数： 2. 使用步骤： 3. argparse.ArgumentParser（）方法参数 4. add_argument()方法参数须知： 5. add 1. 一般形式 2. 必需参数 3. 位置参数（positional arguments） 4. 输入类型 5. 参数默认值 6. 候选参数选择 6. action参数 argparse模块 作用 ： argparse 是 Python 内置的一个用于命令项选项与参数解析的模块，通过在程序中定义好我们需要的参数，argparse 将会从sys.argv 中解析出这些参数，并自动生成帮助和使用信息。当然，Python 也有第三方的库可用于命令行解析，而且功能也更加强大，比如 docopt ，Click 。 1. 命令行参数分为位置参数和选项参数： 位置参数就是程序根据该参数出现的位置来确定的如：[root@openstack_1 /]# ls root/ #其中root/是位置参数 选项参数是应用程序已经提前定义好的参数，不是随意指定的如：[root@openstack_1 /]# ls -l # -l 就是ls命令里的一个选项参数 2. 使用步骤：（1）import argparse 首先导入模块（2）parser = argparse.ArgumentParser（） 创建一个解析对象（3）parser.add_argument() 向该对象中添加你要关注的命令行参数和选项（4）parser.parse_args() 进行解析 3. argparse.ArgumentParser（）方法参数==一般我们只选择用description== description - 命令行帮助的开始文字，大部分情况下，我们只会用到这个参数 epilog - 命令行帮助的结尾文字 prog - (default: sys.argv[0])程序的名字，一般不需要修改，另外，如果你需要在help中使用到程序的名字，可以使用%(prog)s prefix_chars - 命令的前缀，默认是-，例如-f/–file。有些程序可能希望支持/f这样的选项，可以使用prefix_chars=”/” fromfile_prefix_chars - (default: None)如果你希望命令行参数可以从文件中读取，就可能用到。例如，如果fromfile_prefix_chars=’@’,命令行参数中有一个为” @args.txt”，args.txt的内容会作为命令行参数 add_help - 是否增加-h/-help选项 (default: True)，一般help信息都是必须的，所以不用设置啦。 parents - 类型是list，如果这个parser的一些选项跟其他某些parser的选项一样，可以用parents来实现继承，例如parents=[parent_parser] 三个允许的值：(1) # class argparse.RawDescriptionHelpFormatter 直接输出description和epilog的原始形式（不进行自动换行和消除空白的操作）(2) # class argparse.RawTextHelpFormatter 直接输出description和epilog以及add_argument中的help字符串的原始形式（不进行自动换行和消除空白的操作）(3) # class argparse.ArgumentDefaultsHelpFormatter 在每个选项的帮助信息后面输出他们对应的缺省值，如果有设置的话。==这个最常用吧！== argument_default - (default: None)设置一个全局的选项的缺省值，一般每个选项单独设置，所以这个参数用得少，不细说 usage - (default: generated)如果你需要修改usage的信息（usage: PROG [-h] [–foo [FOO]] bar [bar …]），那么可以修改这个，一般不要修改。 conflict_handler - 不建议使用。这个在极端情况下才会用到，主要是定义两个add_argument中添加的选项的名字发生冲突时怎么处理，默认处理是抛出异常。 4. add_argument()方法参数须知： name or flags - 指定参数的形式，想写几个写几个，不过我们一般就写两个，一个短参数，一个长参数，看下面的例子”-f”, “–file” 可选的选项，位置不固定，想怎么写就怎么写，默认是可选的 # parser.add_argument(“-f”, “–file”, help=”test test test”) 位置固定的选项，例如”prog i_am_bar”，这样子的话，i_am_bar就是bar选项的值啦，默认是必须有的 # parser.add_argument(“bar”, help=”test test test”) nargs - 指定这个参数后面的value有多少个，例如，我们希望使用-n 1 2 3 4，来设置n的值为[1, 2, 3, 4] #parser.add_argument(“-n”, “–num”, nargs=”+”, type=int) # 这里nargs=”+”表示，如果你指定了-n选项，那么-n后面至少要跟一个参数，+表示至少一个,?表示一个或0个,0个或多个 。 default - 如果命令行没有出现这个选项，那么使用default指定的默认值 #parser.add_argument(“+g”, “++gold”, help=”test test test”,default=”test_gold”)#需要prefix_chars包含”+” 。 type - 如果希望传进来的参数是指定的类型（例如 float, int or file等可以从字符串转化过来的类型），可以使用 #parser.add_argument(“-x”, type=int) 。 choices - 设置参数值的范围，如果choices中的类型不是字符串，记得指定type哦 #parser.add_argument(“-y”, choices=[‘a’, ‘b’, ‘d’]) required - 通常-f这样的选项是可选的，但是如果required=True那么就是必须的了 #parser.add_argument(“-z”, choices=[‘a’, ‘b’, ‘d’], required=True) metavar - 参数的名字，在显示 帮助信息时才用到. # parser.add_argument(“-o”, metavar=”OOOOOO”) help - 设置这个选项的帮助信息 dest - 设置这个选项的值就是解析出来后放到哪个属性中 #parser.add_argument(“-q”, dest=”world”) args = parser.parse_args(args) # 如果你没有args参数，那么就使用sys.argv，也就是命令行参数啦。有这个参数，就方便我们调试啊 。# args.world就是-q的值啦 action - The basic type of action to be taken when this argument is encountered at the command line. const - A constant value required by some action and nargs selections. 123456import argparse parser = argparse.ArgumentParser() parser.add_argument('echo') # add_argument()指定程序可以接受的命令行选项 args = parser.parse_args() # parse_args()从指定的选项中返回一些数据 print(args) print(args.echo) 12345678parser = argparse.ArgumentParser(description = 'this is a description') parser.add_argument('--ver', '-v', action = 'store_true', help = 'hahaha') # 将变量以标签-值的字典形式存入args字典 args = parser.parse_args() if args.ver: print("Ture") else: print("False") 12# required标签就是说--ver参数是必需的，并且类型为int，输入其它类型会报错 parser.add_argument('--ver', '-v', required = True, type = int) 123parser.add_argument('file', choices = ['test1', 'test2']) args = parser.parse_args() print('read in %s'%(args.file)) 1234# 表示脚本可以读入两个整数赋予num键（此时的值为2个整数的数组） parser.add_argument('filename', nargs = 2, type = int) args = parser.parse_args() print('read in %s'%(args.filename)) 分析：nargs还可以’*‘用来表示如果有该位置参数输入的话，之后所有的输入都将作为该位置参数的值；‘+’表示读取至少1个该位置参数。’?’表示该位置参数要么没有，要么就只要一个。（PS：跟正则表达式的符号用途一致。）如： 123parser.add_argument('filename', nargs = '+', type = int) args = parser.parse_args() print('read in %s'%(args.filename)) dest - 设置这个选项的value解析出来后放到哪个属性中 123parser.add_argument('-file', choices = ['test1', 'test2'], dest = 'world') args = parser.parse_args() print('read in %s'%(args.world)) 5. add如果脚本很简单或临时使用，没有多个复杂的参数选项，可以直接利用sys.argv将脚本后的参数依次读取(读进来的默认是字符串格式)。比如如下名为test.py的脚本： 12import sys print "Input argument is %s" %(sys.argv) 在shell脚本中运行python test.py help可以得到Input argument is help的结果。 1. 一般形式但是大多数情况下，脚本很可能需要多个参数，而且每次参数的类型用处各不相同，那么这个时候在参数前添加标签表明参数的类型和用途便十分有用，而利用argparse模块可以很方便得实现这一目的。 同样用名为test.py的脚本举个栗子： 123456789import argparse parser = argparse.ArgumentParser(description="your script description") # description参数可以用于插入描述脚本用途的信息，可以为空 parser.add_argument('--verbose', '-v', action='store_true', help='verbose mode') # 添加--verbose标签，标签别名可以为-v，这里action的意思是当参数字典的verbose建对应的值为True，而help参数用于描述--v args = parser.parse_args() # 将变量以标签-值的字典形式存入args字典 if args.verbose: print "Verbose mode on!" else: print "Verbose mode off!" 运行python test.py后面跟了–verbose/-v的时候会输出前者，如果什么都没有会输出后者。如果输入了–verbose/-v以外的参数则会报错：unrecognized arguments 稍微提一下，action参数表示值赋予键的方式，这里用到的是bool类型；如果是’count’表示将–verbose标签出现的次数作为verbose的值；’append’表示将每次出现的该便签后的值都存入同一个数组再赋值。（嘛，一般后面两种用的比较少就不多说了）PS：–help标签在使用argparse模块时会自动创建，因此一般情况不需要我们主动定义帮助信息。 12345678$ python test.py --help usage: test.py [-h] [--verbose] your script description optional arguments: -h, --help show this help message and exit --verbose, -v verbose mode 2. 必需参数这种模式用于确保某些必需的参数有输入。 1parser.add_argument('--verbose', required=True, type=int) required标签就是说–verbose参数是必需的，并且类型为int，输入别的类型会报错。 3. 位置参数（positional arguments）位置参数与sys.argv调用比较像，参数没有显式的–xxx或者-xxx标签，因此调用属性也与sys.argv相同。 12345678910111213141516171819202122232425262728 parser.add_argument('filename') # 输入的第一个参数赋予名为filename的键 args = parser.parse_args() print "Read in %s" %(args.filename) ``` 输入python test.py test.txt则会输出Read in test.txt此外，可以用nargs参数来限定输入的位置参数的个数，默认为1。当然nargs参数也可用于普通带标签的参数。parser.add_argument(‘num’, nargs=2, type=int) 表示脚本可以读入两个整数赋予num键（此时的值为2个整数的数组）。nargs还可以’*‘用来表示如果有该位置参数输入的话，之后所有的输入都将作为该位置参数的值；‘+’表示读取至少1个该位置参数。’?’表示该位置参数要么没有，要么就只要一个。（PS：跟正则表达式的符号用途一致。）比如用：```python parser.add_argument('filename') parser.add_argument('num', nargs='*) ``` 就可以运行python test.py text.txt 1 2 由于没有标签，所以用位置参数的时候需要比较小心。##### 4. 输入类型 之前已经提到了用type参数就可以指定输入的参数类型。而这个type类型还可以表示文件操作的类型从而直接进行文件的读写操作。```python parser.add_argument('file', type=argparser.FileType('r')) # 读取文件 args = parser.parse_args() for line in args.file: print line.strip() 5. 参数默认值一般情况下会设置一些默认参数从而不需要每次输入某些不需要变动的参数，利用default参数即可实现。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566 parser.add_argument('filename', default='text.txt') ``` 这个时候直接运行python text.py就能得到Read in text.txt而不需要输入文件名了。##### 6. 候选参数选择 表示该参数能接受的值只能来自某几个值候选值中，除此以外会报错，用choices参数即可。比如：```python parser.add_argument('filename', choices=['test1.txt', 'text2.txt']) ``` #### 6. action参数argparse内置6种动作可以在解析到一个参数时进行触发：name | desperation ---|--- store | 保存参数值，可能会先将参数值转换成另一个数据类型。若没有显式指定动作，则默认为该动作。 store_const | 保存一个被定义为参数规格一部分的值，而不是一个来自参数解析而来的值。这通常用于实现非布尔值的命令行标记。 store_ture/store_false | 保存相应的布尔值。这两个动作被用于实现布尔开关。 append | 将值保存到一个列表中。若参数重复出现，则保存多个值。 append_const | 将一个定义在参数规格中的值保存到一个列表中。 version | 打印关于程序的版本信息，然后退出 ```python import argparse parser = argparse.ArgumentParser() parser.add_argument('-s', action='store', dest='simple_value', help='Store a simple value') parser.add_argument('-c', action='store_const', dest='constant_value', const='value-to-store', help='Store a constant value') parser.add_argument('-t', action='store_true', default=False, dest='boolean_switch', help='Set a switch to true') parser.add_argument('-f', action='store_false', default=False, dest='boolean_switch', help='Set a switch to false') parser.add_argument('-a', action='append', dest='collection', default=[], help='Add repeated values to a list') parser.add_argument('-A', action='append_const', dest='const_collection', const='value-1-to-append', default=[], help='Add different values to list') parser.add_argument('-B', action='append_const', dest='const_collection', const='value-2-to-append', help='Add different values to list') parser.add_argument('--version', action='version', version='%(prog)s 1.0') results = parser.parse_args() print 'simple_value =', results.simple_value print 'constant_value =', results.constant_value print 'boolean_switch =', results.boolean_switch print 'collection =', results.collection print 'const_collection =', results.const_collection 123456789101112131415$ python argparse_action.py -h usage: argparse_action.py [-h] [-s SIMPLE_VALUE] [-c] [-t] [-f] [-a COLLECTION] [-A] [-B] [--version] optional arguments: -h, --help show this help message and exit -s SIMPLE_VALUE Store a simple value -c Store a constant value -t Set a switch to true -f Set a switch to false -a COLLECTION Add repeated values to a list -A Add different values to list -B Add different values to list --version show program's version number and exit 1234567$ python argparse_action.py -s value simple_value = value constant_value = None boolean_switch = False collection = [] const_collection = [] 1234567$ python argparse_action.py -c simple_value = None constant_value = value-to-store boolean_switch = False collection = [] const_collection = [] 1234567$ python argparse_action.py -t simple_value = None constant_value = None boolean_switch = True collection = [] const_collection = [] 1234567$ python argparse_action.py -f simple_value = None constant_value = None boolean_switch = False collection = [] const_collection = [] 1234567$ python argparse_action.py -a one -a two -a three simple_value = None constant_value = None boolean_switch = False collection = ['one', 'two', 'three'] const_collection = [] 1234567$ python argparse_action.py -B -A simple_value = None constant_value = None boolean_switch = False collection = [] const_collection = ['value-2-to-append', 'value-1-to-append'] 123$ python argparse_action.py --version argparse_action.py 1.0 参考 https://mkaz.tech/python-argparse-cookbook.html https://docs.python.org/2/howto/argparse.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>python</tag>
        <tag>python模块学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java Swing 图形界面开发（目录）]]></title>
    <url>%2F2021%2F01%2F03%2FJava%20Swing%20%E5%9B%BE%E5%BD%A2%E7%95%8C%E9%9D%A2%E5%BC%80%E5%8F%91%EF%BC%88%E7%9B%AE%E5%BD%95%EF%BC%89%2F</url>
    <content type="text"><![CDATA[0. JavaSwing 简介 1. JavaSwing 布局管理器 2. JavaSwing 基本组件 3. JavaSwing 面板组件 4. JavaSwing 其他组件 5. JavaSwing 相关特性 扩展：Java AWT/Swing 其他相关 0. JavaSwing 简介 Java Swing 图形界面开发简介 1. JavaSwing 布局管理器 JavaSwing_1.1: FlowLayout（流式布局） JavaSwing_1.2: GridLayout（网格布局） JavaSwing_1.3: GridBagLayout（网格袋布局） JavaSwing_1.4: BoxLayout（箱式布局） JavaSwing_1.5: GroupLayout（分组布局） JavaSwing_1.6: CardLayout（卡片布局） JavaSwing_1.7: BorderLayout（边界布局） JavaSwing_1.8: SpringLayout（弹性布局） JavaSwing_1.9: null（绝对布局） 2. JavaSwing 基本组件 JavaSwing_2.1: JLabel（标签） JavaSwing_2.2: JButton（按钮） JavaSwing_2.3: JRadioButton（单选按钮） JavaSwing_2.4: JCheckBox（复选框） JavaSwing_2.5: JToggleButton（开关按钮） JavaSwing_2.6: JTextField（文本框） JavaSwing_2.7: JPasswordField（密码框） JavaSwing_2.8: JTextArea（文本区域） JavaSwing_2.9: JComboBox（下拉列表框） JavaSwing_2.10: JList（列表框） JavaSwing_2.11: JProgressBar（进度条） JavaSwing_2.12: JSlider（滑块） 3. JavaSwing 面板组件 JavaSwing_3.1: JPanel（面板） JavaSwing_3.2: JScrollPane（滚动面板） JavaSwing_3.3: JSplitPane（分隔面板） JavaSwing_3.4: JTabbedPane（选项卡面板） JavaSwing_3.5: JLayeredPane（层级面板） 4. JavaSwing 其他组件 JavaSwing_4.1: JFrame（窗口） JavaSwing_4.2: JDialog、JOptionPane（对话框） JavaSwing_4.3: JFileChooser（文件选择器） JavaSwing_4.4: JColorChooser（颜色选择器） JavaSwing_4.5: JMenuBar（菜单栏） JavaSwing_4.6: JToolBar（工具栏） JavaSwing_4.7: JPopupMenu（弹出菜单） JavaSwing_4.8: JTable（表格） JavaSwing_4.9: JTree（树） JavaSwing_4.10: JInternalFrame（内部窗口） 5. JavaSwing 相关特性 JavaSwing_5.1: 组件的位置和尺寸 JavaSwing_5.2: 组件边框（Border） JavaSwing_5.3: 事件处理 JavaSwing_5.4: 多线程并发与线程安全 JavaSwing_5.5: 拖拽功能 JavaSwing_5.6: 系统托盘（System Tray） JavaSwing_5.7: 闪屏（Splash Screen） 扩展：Java AWT/Swing 其他相关 Java绘图: 使用Graphics类绘制线段、矩形、椭圆/圆弧/扇形、图片、文本 Java图片操作 — 图片的读取、绘制、缩放、裁剪、保存 Java代码截屏：使用 Java 代码截取电脑屏幕并保存 Java模拟鼠标键盘输入事件 — Robot 类 Java操作桌面应用 — Desktop 类 Java操作系统剪贴板(Clipboard)实现复制和粘贴 转载于 CSDN]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>java模块学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[强制删除文件（文件不存在，句柄失效都可解决）]]></title>
    <url>%2F2021%2F01%2F03%2F%E5%BC%BA%E5%88%B6%E5%88%A0%E9%99%A4%E6%96%87%E4%BB%B6%EF%BC%88%E6%96%87%E4%BB%B6%E4%B8%8D%E5%AD%98%E5%9C%A8%EF%BC%8C%E5%8F%A5%E6%9F%84%E5%A4%B1%E6%95%88%E9%83%BD%E5%8F%AF%E8%A7%A3%E5%86%B3%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1、新建一个记事本文件，并输入以下内容： 2、保存文件，并修改扩展名为 .bat, 3、把要删除的文件，拖动到上一步创建的文件上即可。 使用电脑的过程中，经常会遇到，删除一个文件时，提示文件不存在，但是文件又确实存在的情况，下面这个方法可以让你无需安装任何软件，就删除掉。 1、新建一个记事本文件，并输入以下内容： DEL /F /A /Q \\?\%1 RD /S /Q \\?\%1 2、保存文件，并修改扩展名为 .bat,我这里命名为：“把文件拖动到这个图标以强制删除.bat”，方便记住操作方法。 PS: 如果电脑默认不显示文件名，可以打开右键 我的电脑–&gt;属性–&gt;工具–&gt;文件夹选项—&gt;查看—&gt;不勾选”隐藏已知文件类型的扩展名”—&gt;确定即可 3、把要删除的文件，拖动到上一步创建的文件上即可。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Verilog中溢出的判断]]></title>
    <url>%2F2021%2F01%2F03%2FVerilog%E4%B8%AD%E6%BA%A2%E5%87%BA%E7%9A%84%E5%88%A4%E6%96%AD%2F</url>
    <content type="text"><![CDATA[因为需要完成计组的实验一，简单来说就是一个ALU的设计，实现对两个32位数的算数和逻辑运算。 设计思路，根据输入的指令的不同，进行case的判断。 需要执行的是16种操作，而输入的指令是5位的，远远超出需要，因而我将指令的最高位默认为0，指令按照顺序为5’b00000-5’b01111。 前八位指令完成的是算术运算，后八位完成的是逻辑运算。 第一位加法运算，容易产生的问题就是，溢出。 溢出的检测和判断方法有三种。 适用于补码的加法。 第一种是，检测输入的两个32位数的符号位xf,yf，和运算结果的符号位zf 如果xf=yf=0,即两个数都是正数的时候，zf=1，结果符号位为负数，负溢出。 当出现xf=yf=1，两个输入数均为负数的时候，结果zf的符号位=0，正溢出。 第二种是，Cs表示符号位的进位，Cp表示最高数值位进位， 当 Cs⊕Cp = 0 ,无溢出。 当 Cs⊕Cp = 1 ,有溢出。 第三种方法，用变形补码进行双符号位位运算，正数符为00，负数符号为11 若运算结果为 10 ，负溢出 若运算结果为 01 ，正溢出 若运算结果为00 或 11，无溢出]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>verilog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JFileChooser（文件选择器）学习笔记]]></title>
    <url>%2F2021%2F01%2F03%2FJFileChooser%EF%BC%88%E6%96%87%E4%BB%B6%E9%80%89%E6%8B%A9%E5%99%A8%EF%BC%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[JFileChooser，文件选取器。JFileChooser为用户选择文件提供了一种简单的机制，包括 打开文件 和 保存文件。 JFileChooser 常用构造方法: 12345678910/** * 参数说明: * currentDirectory: 打开文件选取器时默认显示的文件夹（默认为用户文件夹） * currentDirectoryPath: 打开文件选取器时默认显示的文件夹（默认为用户文件夹） */ JFileChooser() JFileChooser(File currentDirectory) JFileChooser(String currentDirectoryPath) JFileChooser 常用方法:123456789101112131415161718192021222324252627282930313233343536373839// 设置默认显示的文件夹void setCurrentDirectory(File dir)// 设置文件选择模式, 可选值如下:// JFileChooser.FILES_ONLY: 只能选文件// JFileChooser.DIRECTORIES_ONLY: 只能选文件夹// JFileChooser.FILES_AND_DIRECTORIES: 文件和文件夹都可以选void setFileSelectionMode(int mode)// 设置是否允许同时选择多个（默认为不允许）void setMultiSelectionEnabled(boolean b)// 添加可供用户选择的文件过滤器void addChoosableFileFilter(FileFilter filter)// 设置默认使用的文件过滤器void setFileFilter(FileFilter filter)// 设置默认被选中的文件void setSelectedFile(File file)void setSelectedFiles(File[] selectedFiles)/** 显示 打开文件 或 保存文件 的对话框（线程将被阻塞, 直到选择框被关闭）。** 参数: * parent: 文件选取器对话框的父组件, 对话框将会尽量显示在靠近 parent 的中心; 如果传 null, 则显示在屏幕中心。* * 返回值:* JFileChooser.CANCEL_OPTION: 点击了取消或关闭* JFileChooser.APPROVE_OPTION: 点击了确认或保存* JFileChooser.ERROR_OPTION: 出现错误*/int showOpenDialog(Component parent)int showSaveDialog(Component parent)// 获取选择的文件（一般在用户选择完文件点击了确认或保存后通过该方法获取选中的文件）File getSelectedFile()File[] getSelectedFiles() 代码实例 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101package com.xiets.swing;import javax.swing.*;import javax.swing.filechooser.FileNameExtensionFilter;import java.awt.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;import java.io.File;public class Main &#123; public static void main(String[] args) throws Exception &#123; final JFrame jf = new JFrame("测试窗口"); jf.setSize(400, 250); jf.setLocationRelativeTo(null); jf.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE); JPanel panel = new JPanel(); // 创建文本区域, 用于显示相关信息 final JTextArea msgTextArea = new JTextArea(10, 30); msgTextArea.setLineWrap(true); panel.add(msgTextArea); JButton openBtn = new JButton("打开"); openBtn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; showFileOpenDialog(jf, msgTextArea); &#125; &#125;); panel.add(openBtn); JButton saveBtn = new JButton("保存"); saveBtn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; showFileSaveDialog(jf, msgTextArea); &#125; &#125;); panel.add(saveBtn); jf.setContentPane(panel); jf.setVisible(true); &#125; /* * 打开文件 */ private static void showFileOpenDialog(Component parent, JTextArea msgTextArea) &#123; // 创建一个默认的文件选取器 JFileChooser fileChooser = new JFileChooser(); // 设置默认显示的文件夹为当前文件夹 fileChooser.setCurrentDirectory(new File(".")); // 设置文件选择的模式（只选文件、只选文件夹、文件和文件均可选） fileChooser.setFileSelectionMode(JFileChooser.FILES_AND_DIRECTORIES); // 设置是否允许多选 fileChooser.setMultiSelectionEnabled(true); // 添加可用的文件过滤器（FileNameExtensionFilter 的第一个参数是描述, 后面是需要过滤的文件扩展名 可变参数） fileChooser.addChoosableFileFilter(new FileNameExtensionFilter("zip(*.zip, *.rar)", "zip", "rar")); // 设置默认使用的文件过滤器 fileChooser.setFileFilter(new FileNameExtensionFilter("image(*.jpg, *.png, *.gif)", "jpg", "png", "gif")); // 打开文件选择框（线程将被阻塞, 直到选择框被关闭） int result = fileChooser.showOpenDialog(parent); if (result == JFileChooser.APPROVE_OPTION) &#123; // 如果点击了"确定", 则获取选择的文件路径 File file = fileChooser.getSelectedFile(); // 如果允许选择多个文件, 则通过下面方法获取选择的所有文件 // File[] files = fileChooser.getSelectedFiles(); msgTextArea.append("打开文件: " + file.getAbsolutePath() + "\n\n"); &#125; &#125; /* * 选择文件保存路径 */ private static void showFileSaveDialog(Component parent, JTextArea msgTextArea) &#123; // 创建一个默认的文件选取器 JFileChooser fileChooser = new JFileChooser(); // 设置打开文件选择框后默认输入的文件名 fileChooser.setSelectedFile(new File("测试文件.zip")); // 打开文件选择框（线程将被阻塞, 直到选择框被关闭） int result = fileChooser.showSaveDialog(parent); if (result == JFileChooser.APPROVE_OPTION) &#123; // 如果点击了"保存", 则获取选择的保存路径 File file = fileChooser.getSelectedFile(); msgTextArea.append("保存到文件: " + file.getAbsolutePath() + "\n\n"); &#125; &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JFrame 和 getContentPane() 方法]]></title>
    <url>%2F2021%2F01%2F03%2FJFrame%20%E5%92%8C%20getContentPane()%20%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[JFrame 提供了两个方法：getContentPane 和 setContentPane 就是用于获取和设置其 Content Pane 的。 对JFrame添加组件有两种方式： 用getContentPane()方法获得JFrame的内容面板，再对其加入组件：frame.getContentPane().add(childComponent) 建立一个Jpanel或JDesktopPane之类的中间容器，把组件添加到容器中，用setContentPane()方法把该容器置为JFrame的内容面板： 1234 JPanel contentPane=new JPanel(); ……//把其它组件添加到Jpanel中; frame.setContentPane(contentPane); //把contentPane对象设置成为frame的内容面板]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>java</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java程序设计中setFont()函数的用法(转)]]></title>
    <url>%2F2021%2F01%2F03%2FJava%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E4%B8%ADsetFont()%E5%87%BD%E6%95%B0%E7%9A%84%E7%94%A8%E6%B3%95(%E8%BD%AC)%2F</url>
    <content type="text"><![CDATA[java.awt.Font 设计字体显示效果 Font mf = new Font(String 字体，int 风格，int 字号); 字体：TimesRoman, Courier, Arial等 风格：三个常量 lFont.PLAIN, Font.BOLD, Font.ITALIC 字号：字的大小（磅数） 设置组件当前使用的字体：setFont(Font fn) 获取组件当前使用的字体：getFont() int i= font.stringWidth（String str）；获取str字符的长度 详细说明 123456789101112131415161718getFont(int face,int style,int size). 例如： Font font = Font.getFont(Font.FACE_SYSTEM,Font.STYLE_BOLD,Font. SIZE_MEDIUM). 无论哪一个参数，都只能使用系统设置的数值，这些数值具体的大小在不同的手机上可能不同。下面对于其中的三个参数的取值做详细的介绍： face参数指字体的外观，其的值： FACE_MONOSPACE——等宽字体l FACE_PROPORTIONAL——均衡字体l FACE_SYSTEM——系统字体style参数指字体的样式，其的取值：l STYLE_BOLD——粗体l STYLE_ITALIC——斜体l STYLE_PLAIN——普通l STYLE_UNDERLINED——下划线l STYLE_BOLD | STYLE_ITALIC——粗斜体l STYLE_UNDERLINED | STYLE_BOLD——带下划线粗体l STYLE_UNDERLINED | STYLE_ITALIC——带下划线斜体l STYLE_UNDERLINED | STYLE_ITALIC | STYLE_BOLD——带下划线的粗斜体size参数指字体的大小，其的取值：l SIZE_SMALL——小l SIZE_MEDIUM——中l SIZE_LARGE——大通过上面的参数的值，可以组合出你需要的字体对象。下面是一些常用的字体操作： 1. 获得系统的默认字体：Font font = Font.getDefaultFont(). 2. 在panit方法内部，假设Graphics参数的名称为g，则获得当前字体的方法是：Font font = g.getFont(). 3. 在panit方法内部，假设Graphics参数的名称为g，则设置当前字体的方法是：g.setFont(font).其中font为你构造好的字体对象。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JPanel（面板）学习笔记]]></title>
    <url>%2F2021%2F01%2F03%2FJPanel%EF%BC%88%E9%9D%A2%E6%9D%BF%EF%BC%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[为了完成实验，强行学习GUI。 JPanel，面板。JPanel 是在开发中使用频率非常高的一般轻量级面板容器组件。 JPanel 常用构造方法: 12345// 创建默认使用流式布局的面板 JPanel() // 创建指定布局管理器的面板 JPanel(LayoutManager layout) 代码实例 12345678910111213141516171819202122232425262728293031323334353637383940package com.xiets.swing;import javax.swing.*;import java.awt.*;public class Main &#123; public static void main(String[] args) &#123; JFrame jf = new JFrame("用户登录"); jf.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE); // 第 1 个 JPanel, 使用默认的浮动布局 JPanel panel01 = new JPanel(); panel01.add(new JLabel("用户名")); panel01.add(new JTextField(10)); // 第 2 个 JPanel, 使用默认的浮动布局 JPanel panel02 = new JPanel(); panel02.add(new JLabel("密 码")); panel02.add(new JPasswordField(10)); // 第 3 个 JPanel, 使用浮动布局, 并且容器内组件居中显示 JPanel panel03 = new JPanel(new FlowLayout(FlowLayout.CENTER)); panel03.add(new JButton("登录")); panel03.add(new JButton("注册")); // 创建一个垂直盒子容器, 把上面 3 个 JPanel 串起来作为内容面板添加到窗口 Box vBox = Box.createVerticalBox(); vBox.add(panel01); vBox.add(panel02); vBox.add(panel03); jf.setContentPane(vBox); jf.pack(); jf.setLocationRelativeTo(null); jf.setVisible(true); &#125;&#125; 结果展示 其中函数的解释： setDefaultCloseOperation(int operation)：设置用户在此窗体上发起 “close” 时默认执行的操作。 123456789101112131415161718192021方法中的参数解释如下： 1.为“0”或DO_NOTHING_ON_CLOSE：（在 WindowConstants 中定义）：不执行任何操作；要求程序在已注册的WindowListener 对象的 windowClosing 方法中处理该操作。比如实例代码中更改为f.setDefaultCloseOperation(f. DO_NOTHING_ON_CLOSE);或者f.setDefaultCloseOperation(0),可以发现窗口无法关闭。 2.为“1”或HIDE_ON_CLOSE:调用任意已注册的 WindowListener 对象后自动隐藏该窗体。此时没有关闭程序，只是将程序界面隐藏了。可以打开任务管理器，可以看到一个叫“java.exe”的进程（如果调试运行了多个java程序，则会看到多个“java.exe”的进程），如果此时用EditPlus测试程序，会发现当单击窗口的关闭按钮关闭窗口后，却无法再次对程序进行调试，因为程序线程没有关闭，在任务管理器中关闭java.exe（如果有多个“java.exe”的进程，则先都关闭掉，再来测试该问题）基础后，EditPlus才可以重新编译改程序。3.为“2”或DISPOSE_ON_CLOSE:调用任意已注册 WindowListener 的对象后自动隐藏并释放该窗体。但继续运行应用程序，释放了窗体中占用的资源。 4.为“3”EXIT_ON_CLOSE（在 JFrame 中定义）：使用 System exit 方法退出应用程序。仅在应用程序中使用。结束了应用程序。PS:默认情况下，该值被设置为 HIDE_ON_CLOSE。当注释掉实例中的f.setDefaultCloseOperation(f.EXIT_ON_CLOSE)语句时，起到的效果和f.setDefaultCloseOperation(f. HIDE_ON_CLOSE)或者f.setDefaultCloseOperation(1)一样。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>java</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JTextArea（文本区域）学习笔记]]></title>
    <url>%2F2021%2F01%2F03%2FJTextArea%EF%BC%88%E6%96%87%E6%9C%AC%E5%8C%BA%E5%9F%9F%EF%BC%89%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[为了完成实验，强行学习GUI。本次的目的是定义出 一个文本区域，并从指定的路径读取相应的文件进行处理。 JTextArea，文本区域。JTextArea 用来编辑多行的文本。JTextArea 除了允许多行编辑外，其他基本用法和 JTextField 基本一致。 JTextArea 常用构造方法: 123456789101112131415/*** 参数说明:* text: 默认显示的文本* rows: 默认可见的行数* columns: 默认可见的列数* * 默认由 rows 和 columns 决定首选大小*/JTextArea()JTextArea(String text)JTextArea(int rows, int columns)JTextArea(String text, int rows, int columns) JTextArea 常用方法:123456789101112131415161718192021222324252627282930313233343536373839404142434445// 是否自动换行，默认为 falsevoid setLineWrap(boolean wrap)// 设置自动换行方式。如果为 true，则将在单词边界（空白）处换行; 如果为 false，则将在字符边界处换行。默认为 false。void setWrapStyleWord(boolean word)// 获取文本框中的文本String getText()// 追加文本到文档末尾void append(String str)// 替换部分文本void replaceRange(String str, int start, int end)// 设置文本框的 文本、字体 和 字体颜色void setText(String text)void setFont(Font font)void setForeground(Color fg)// 获取内容的行数（以换行符计算，满行自动换下一行不算增加行数）int getLineCount()// 获取指定行（行数从0开始）的行尾（包括换行符）在全文中的偏移量int getLineEndOffset(int line)// 获取指定偏移量所在的行数（行数从0开始）int getLineOfOffset(int offset)// 设置颜色，分别为: 光标颜色、呈现选中部分的背景颜色、选中部分文本的颜色、不可用时文本的颜色void setCaretColor(Color c)void setSelectionColor(Color c)void setSelectedTextColor(Color c)void setDisabledTextColor(Color c)// 设置文本框是否可编辑void setEditable(boolean b)/* 下面方法定义在 java.awt.Component 基类中 */// 判断组件当前是否拥有焦点boolean isFocusOwner()// 设置组件是否可用void setEnabled(boolean b) JTextArea 复制粘贴相关方法:1234567891011121314// 设置光标开始位置，selectionStart &gt;= 0void setSelectionStart(int selectionStart)// 设置光标结束位置，selectionEnd &gt;= selectionStartvoid setSelectionEnd(int selectionEnd)// 复制选中部分文本void copy()// 剪切选中部分文本void cut()// 粘贴文本到文本框void paste() JTextArea 常用监听器: 12345678// 添加焦点事件监听器void addFocusListener(FocusListener listener)// 添加文本框内的 文本改变 监听器textField.getDocument().addDocumentListener(DocumentListener listener)// 添加按键监听器void addKeyListener(KeyListener listener) PS: JTextArea 在使用时通常把它放到 JScrollPane 容器中来使用，以此来实现内容增多时可水平/垂直滚动的效果。 代码示例：1234567891011121314151617181920212223242526272829303132333435363738package com.xiets.swing;import javax.swing.*;import java.awt.event.ActionEvent;import java.awt.event.ActionListener;public class Main &#123; public static void main(String[] args) &#123; JFrame jf = new JFrame("测试窗口"); jf.setSize(250, 250); jf.setLocationRelativeTo(null); jf.setDefaultCloseOperation(WindowConstants.EXIT_ON_CLOSE); JPanel panel = new JPanel(); // 创建一个 5 行 10 列的文本区域 final JTextArea textArea = new JTextArea(5, 10); // 设置自动换行 textArea.setLineWrap(true); // 添加到内容面板 panel.add(textArea); // 创建一个提交按钮，点击按钮获取输入文本 JButton btn = new JButton("提交"); btn.addActionListener(new ActionListener() &#123; @Override public void actionPerformed(ActionEvent e) &#123; System.out.println("提交: " + textArea.getText()); &#125; &#125;); panel.add(btn); jf.setContentPane(panel); jf.setVisible(true); &#125;&#125; 运行结果]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>java</tag>
        <tag>GUI</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[华为云耀云服务器+wordpress搭建个人小博客]]></title>
    <url>%2F2021%2F01%2F03%2F%E5%8D%8E%E4%B8%BA%E4%BA%91%E8%80%80%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%2Bwordpress%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%B0%8F%E5%8D%9A%E5%AE%A2%2F</url>
    <content type="text"><![CDATA[最近受到疫情的影响，高校大学生只能蜷缩在家中上课。于是，各大服务器厂商纷纷各显身手，提供性价比极高的服务器。在社团的推荐下，我先是购入了阿里云，没忍住又买了华为78一年的云耀云服务器。 相比较于阿里云，我个人认为华为云的配置比较麻烦。许多内容都需要自己搭建。 我之前在阿里云上用了centos7的系统，这次就尝试一下Ubuntu18.04. 使用到的相关教程如下： https://blog.csdn.net/shiliang97/article/details/104856218 https://blog.csdn.net/u014663631/article/details/86518551?depth_1-utm_source=distribute.pc_relevant.none-task&amp;utm_source=distribute.pc_relevant.none-task https://blog.csdn.net/iAlong2001/article/details/104985253 https://blog.csdn.net/weixin_44071851/article/details/86297110 https://paaatrick.com/2019-01-29-build-wordpress-blog/ 因为一些原因，使用wget命令无法直接从WP的下载界面下载安装包，因此，我分享一下自己的安装包（2020.3.22） https://pan.baidu.com/s/1zkI8SkNjpEMWEiGSITRUCQ提取码：13b6 具体的使用方法只需将wget命令那步修改为：文件上传（我用的xshell，直接使用Ctrl+alt+F,就可以打开当前目录，直接点击上传） 搭建完成后，自然是要美化。 1.破除上传文件大小限制 https://www.wpzhiku.com/zeng-jia-wordpress-shang/ 2.查找自己满意的主题 主题提供网站（免费和收费） https://www.xintheme.com/ https://www.iztwp.com/tag/blog-theme https://www.mywpku.com/ https://www.boke8.net/ https://shapedtheme.com/checkout/purchase-confirmation/ http://www.zhutihome.net/ https://www.boke8.net/wordpress-personal-theme.html 主题美化教程 https://blog.csdn.net/guozhaohui628/article/details/89471013 https://www.jianshu.com/p/f0453dd0d53f]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[有趣的bat文件-1]]></title>
    <url>%2F2019%2F09%2F13%2F%E6%9C%89%E8%B6%A3%E7%9A%84bat%E6%96%87%E4%BB%B6-1%2F</url>
    <content type="text"><![CDATA[紧接上文[科学上网-查漏补缺](https://behappy00.github.io/2019/09/12/1/) 初步了解可爱而又神奇的bat脚本 测速脚本点击下载提取码：shp1 解压之后双击.bat文件自动对15个vultr的地区进行测速，帮助你选择最快的vps新建。 鼠标右键点击bat文件，选择编辑。记事本会帮你打开。同时可以运行bat脚本，左右对照着看。 然后我们发现 echo ============================= echo 04 法国 巴黎 ping par-fr-ping.vultr.com -n 10 echo= 这四句应该是一组，表示ping 10次给定的巴黎的ip地址。 然后系统会自动计算给定ip地址的丢包情况和延迟。]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网-查漏补缺]]></title>
    <url>%2F2019%2F09%2F12%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%2F</url>
    <content type="text"><![CDATA[昨天晚上复习的时候，突然服务器崩了，导致我Google瞬间瘫痪，科学上网成为泡影。 我修了一晚上，vultr大佬们给出的方案是重建，通过测试所有地区的速度，最终选择了Los Angeles来重开。 测速脚本测速脚本点击下载提取码：shp1 具体的操作步骤，详见科学上网-搭建 不同的是，这次我尝试了Ubuntu18.04，最后成功了。 其实严格意义上来讲，不同的操作系统在安装的时候都是使用秋水大佬的一键安装脚本， 故而选择没有什么区别。 不同的是，在之后进行配置的时候，不同的操作系统的相关的指令不一样而已，你可以直接上网查找相应的指令进行配置，最终的结果是一样的。 这次重开，我没有采用之前总是使用的snapshot功能，而是重新进行了配置安装。这样选择的原因是，看到有人说snapshot会关联相应的主机IP和硬件地址，容易导致不能上网的结果。 我想吐槽寝室的蚊虫，麻烦你们雨露均沾好嘛。四个人，就逮着我欺负，结果我凌晨四点被弄醒之后就一直没睡成，哭唧唧。不过，我算是能够在整一下vultr，也凑活。。。。。。。 重装之后还是出现了一堆的问题比如说我刚配置好，油管4K的视频嗖嗖的，洗漱回来之后，就GG了 能ping通，端口不确定本着问题要解决的原则，我ping了一下ip地址，发现可以ping通，但是通过不同的网站查看端口是否开启的时候，发现有的网址显示我的端口已经开启，然后有的就显示CLOSE，不太明白原因。vultr怎末看端口对此，我的解决方法是，putty登陆vps，然后查看防火墙状态，发现防火墙显示不存在？？？额，这就有些尴尬了。仔细寻找原因，发现自己把命令输错了，我用centos7的命令对Ubuntu18.04进行操作自然出错。 所以，Ubuntu18.04的命令如下：ubuntu防火墙状态查看、开启和关闭1.安装（以防万一） 1sudo apt-get install ufw 2.启用 123sudo ufw enablesudo ufw default deny (目前不知道干啥用的) 3.查看状态 1sudo ufw status 4.开启/禁用相应端口 123sudo ufw allow 80 允许外部访问80端口sudo ufw deny 80 禁止外部访问80端口 这样一波操作之后，神奇的好了。。我建议大家存一些备用的ss，省的查找和配置起来麻烦]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-2-两数相加]]></title>
    <url>%2F2019%2F09%2F10%2Fleetcode-2-%E4%B8%A4%E6%95%B0%E7%9B%B8%E5%8A%A0%2F</url>
    <content type="text"><![CDATA[题目来自leetcode给出两个 非空 的链表用来表示两个非负的整数。其中，它们各自的位数是按照 逆序 的方式存储的，并且它们的每个节点只能存储 一位 数字。 如果，我们将这两个数相加起来，则会返回一个新的链表来表示它们的和。 您可以假设除了数字 0 之外，这两个数都不会以 0 开头。 示例： 输入：(2 -&gt; 4 -&gt; 3) + (5 -&gt; 6 -&gt; 4)输出：7 -&gt; 0 -&gt; 8原因：342 + 465 = 807 这次尝试使用c++，测试结果比较喜人，最起码，不向昨天一样奇妙的出现不知道为什莫的错误，我其实认真想了一下，似乎是用中文进行了输入导致的。 12345678910111213141516171819202122232425262728293031323334 /** * Definition for singly-linked list. * struct ListNode &#123; * int val; * ListNode *next; * ListNode(int x) : val(x), next(NULL) &#123;&#125; * &#125;; */class Solution &#123;public: ListNode* addTwoNumbers(ListNode* l1, ListNode* l2) &#123; ListNode vHead(0), *p = &amp;vHead; int flag = 0; while (l1 || l2 || flag) &#123; int tmp = 0; if (l1 != nullptr) tmp += l1-&gt;val; if (l2 != nullptr) tmp += l2-&gt;val; tmp += flag; flag = tmp / 10; tmp %= 10; ListNode *next = l1 ? l1 : l2; if (next == nullptr) next = new ListNode(tmp); next-&gt;val = tmp; p-&gt;next = next; p = p-&gt;next; l1 = l1 ? l1-&gt;next : nullptr; l2 = l2 ? l2-&gt;next : nullptr; &#125; return vHead.next; &#125;&#125;; 下面引入官方的解法：（Java）12345678910111213141516171819public ListNode addTwoNumbers(ListNode l1, ListNode l2) &#123; ListNode dummyHead = new ListNode(0); ListNode p = l1, q = l2, curr = dummyHead; int carry = 0; while (p != null || q != null) &#123; int x = (p != null) ? p.val : 0; int y = (q != null) ? q.val : 0; int sum = carry + x + y; carry = sum / 10; curr.next = new ListNode(sum % 10); curr = curr.next; if (p != null) p = p.next; if (q != null) q = q.next; &#125; if (carry &gt; 0) &#123; curr.next = new ListNode(carry); &#125; return dummyHead.next;&#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>leetcode</tag>
        <tag>原创</tag>
        <tag>c++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[leetcode-1-两数之和]]></title>
    <url>%2F2019%2F09%2F09%2Fleetcode-1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C%2F</url>
    <content type="text"><![CDATA[题目来自leetcode给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。 你可以假设每种输入只会对应一个答案。但是，你不能重复利用这个数组中同样的元素。 示例: 给定 nums = [2, 7, 11, 15], target = 9 因为 nums[0] + nums[1] = 2 + 7 = 9 所以返回 [0, 1] c语言： 123456789101112131415161718/** * Note: The returned array must be malloced, assume caller calls free(). */int* twoSum(int* nums, int numsSize, int target, int* returnSize)&#123; int* res = (int *)malloc(sizeof(int) * 2); for(int i = 0; i &lt; numsSize-1; i++) &#123; for(int j = i + 1; j &lt; numsSize; j++) &#123; if(nums[i] + nums [j] == target) &#123; res[0] = i; res[1] = j; *returnSize = 2; return res; &#125; &#125; &#125; return res;&#125; 然后玄幻的事情出现了，测试结果和实际提交之后的结果居然不一样，然后就失败了。。虽然这里莫得问题。认真思考，似乎是中文输入法乱入导致的惨案。 官方解法：（Java）不一一列举123456789101112class Solution &#123; public int[] twoSum(int[] nums, int target) &#123; for (int i = 0; i &lt; nums.length; i++) &#123; for (int j = i + 1; j &lt; nums.length; j++) &#123; if (nums[j] == target - nums[i]) &#123; return new int[] &#123; i, j &#125;; &#125; &#125; &#125; throw new IllegalArgumentException(“No two sum solution”); &#125; &#125;]]></content>
      <categories>
        <category>编程</category>
      </categories>
      <tags>
        <tag>c</tag>
        <tag>leetcode</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[insertyoutube]]></title>
    <url>%2F2019%2F09%2F05%2Finsertyoutube%2F</url>
    <content type="text"><![CDATA[在油管上看到一个十分温馨和感动的视频，讲的是两个外国朋友的婚礼的记录]]></content>
      <categories>
        <category>美好生活</category>
      </categories>
      <tags>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[科学上网-搭建]]></title>
    <url>%2F2019%2F08%2F01%2F%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91-%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[先说一句，本人尝试在Ubuntu18.04上进行安装配置，然后不太明白，也没有好的教程，故而失败了所以本文是win10+vultr+Centos7(服务器系统的选择)进行配置的方法可以根据自己的能力，我选择centos7是因为网上的教程多，并且终于成功了，所以就没有探索 此处为正文地开始作为一个离开 Google生活就无法自理的人类，我曾经发帖、提问、翻遍各种网站，四处寻找靠谱的科学上网利器。确实也找到过一些能满足当下需求的产品，但是不久后，就被封的被封、跑路的跑路了。而且这些服务通常价格不低，稳定性也差强人意。这时候我想，反正都是通过海外服务器来提供建服务的，为什么不干脆自己来搭呢？既能独享带宽，又安心可控，而且选取合适的提供商的话，价格也很平易近人。所以，如果你和我一样不满足那些服务，又有耐心的话，这里有一份详细而对小白友好的折腾指南。事先说明，如果你希望不花钱就能用上优质的服务──醒醒，别做梦了，免费和优质从来不可能划上等号。 1 背景和原理1.1 shadowsocks简介Shadowsocks(ss) 是由 Clowwindy 开发的一款软件，其作用本来是加密传输资料。当然，也正因为它加密传输资料的特性，使得 GFW没法将由它传输的资料和其他普通资料区分开来（上图），也就不能干扰我们访问那些「不存在」的网站了。但是时至今日，Shadowsocks 的安全性被发现是存在缺陷的，其 IP 和端口可以被嗅探到。因而，有了基于它但增加了混淆能力的 ShadowsocksR项目、Simple-obfs 插件，以及 v2ray 项目等。它们本质上，都是依托墙外服务器的网络代理软件。ssR 和官方版 ss 均已不再更新，目前还在更新的只有 shadowsocks-libev，可以说是最轻量的ss 版本，也是本文推荐安装使用的版本。 1.2 什么是 VPS 和 VultrVPS (Virtual private server)译作虚拟专用伺服器。你可以把它简单地理解为一台在远端的强劲电脑。当你租用了它以后，可以给它安装操作系统、软件，并通过一些工具连接和远程操控它。 Vultr 是一家 VPS 服务器提供商，有美国、亚洲、欧洲等多地的 VPS。它家的服务器以性价比高闻名，按时间计费，最低的资费为每月 $2.5。 比 Vultr 价格更低的服务商也有许多，最知名的莫过于「搬瓦工」，和 V 家差不多的配置只要 $19.9 每年。不过后者过于出名，据说超售严重，实测夜间速度足以让人痛哭流涕。 VULTR注册快速通道–免费送50美元PS:这就是官网的注册，不放心的可以自行搜索，实质是一个分享码 1.3 什么是 Linux 和 SSHLinux 是免费开源的操作系统，大概被世界上过半服务器所采用。有大量优秀的开源软件可以安装，上述 Shadowsocks 就是其一。你可以通过命令行来直接给 Linux 操作系统「下命令」，比如 $ cd ~/Desktop 就是进入你根目录下的 Desktop 文件夹。 2 购买和连接 VPS首先，访问 Vultr.com 注册帐号，网站目前还没有被墙，访问速度不错。 2.1 注册 VultrVultr 官网定期会有一些促销活动，可以留意。另外，如果使用我的推荐链接1 注册，激活后可以获赠 $50 试用金，有效期两个月。 换句话说，注册后两个月内可以免费使用 5 个最低配置的 VPS。可以趁这段时间，把不同国家的节点试个遍，不过到期后记着删除多余的服务器。 推荐链接1 推荐链接2 送的少一点，不过也是可以省钱的 2.2 部署 VPS注册完成后，在左边选择“Servers”标签，点击右边的加号部署新的服务器。 选择一个你想要的节点。推荐东京和洛杉矶，速度较快，不过这也受运营商网络、你的地理位置影响，如果有试用金可以多建几个自行对比。 为 VPS 选择安装系统。这里因为安装脚本限制的原因，请选择 CentOS 6+，Debian 7+，Ubuntu 12+ 的系统，具体哪个可以随自己喜欢。下面的教程以 Ubuntu 18.10 为例。 只供个人科学上网用的话，$5 绰绰有余 剩下都可以使用默认值。最后一项你可以自定义服务器的名字和标签，以方便区分。 等待系统安装完成。当显示“Running”时，就表示部署已完成。之后你可以随时停用、重启或销毁它。 2.3 连接 VPS如果你使用的是 PC，连接 VPS 需要借助一些工具，比如 Putty或者xshell。 首先，在 Vultr 上你刚部署的服务器右边点“Manage”，找到服务器的 IP 地址（标黄部分）和密码。 用xshell进行连接，具体方法进行百度。 当出现上图那串 [root@vultr ~]# 时，说明已成功登录。 3 部署 ShadowsocksShadowsocks 需要同时具备客户端和服务器端，所以它的安装也需要分两步。 3.1 部署 Shadowsocks 服务器端这里使用 @秋水逸冰 的一键安装脚本，几乎不需要多余的操作，只需根据提示做选择即可。首先输入以下 3 行命令，每次输入一行、回车，等待屏幕上的操作完成后再输入下一条。 123456wget –no-check-certificate -O shadowsocks-all.sh&lt;https://raw.githubusercontent.com/teddysun/shadowsocks_install/master/shadowsocks-all.sh&gt;chmod +x shadowsocks-all.sh./shadowsocks-all.sh 2&gt;&amp;1 | tee shadowsocks-all.log 最后一步输完，你应该会看到下图中内容──是要你选择需要安装的 Shadowsocks 版本。这里选择 4)shadowsocks-libev，因为正如上文所说，这是目前唯一在持续更新且最为轻量的版本。 选好输入回车后，会让你输入 Shadowsocks 的密码。 然后选择一个端口，输入 1-65535 间的任意数字都行。 之后可以选择加密方式，默认是 aes-256-gcm。如果没有特殊偏好，保持默认即可。 之后会提示你是否需要安装 simple-obfs。这是 ss 的一个插件工具，可以起到混淆的作用，防止 IP 和端口被嗅探到，建议选 y 安装。 如果上一步选择了 y，这里可以选择一种混淆方式。通常 tls 要比 http 的混淆效果更好，所以选 tls。 之后所有的配置就完成了，按任意键开始部署 Shadowsocks-libev。这时你什么都不用做，只需要耐心地等它运行完就好。 结束后就会看到你所部署的 Shadowsocks 的配置信息。 记住红色的内容，也就是服务器 IP、服务器 ss 端口、你设的密码、混淆方式和加密方式。 3.2 检查和配置 Shadowsocks安装完成以后，Shadowsocks 的服务器端就已经配置完了，你可以输入以下命令检查是否已经开始运行。/etc/init.d/shadowsocks-libev status如果出现类似 Shadowsocks-libev is running… 的字样，说明已经开始正常运行了。这时你已经可以在自己的任意设备上进行登录使用了。如果你要修改 ss 的配置，或者忘了当初自己设置的密码和端口，可以用以下命令来打开配置文件。nano /etc/shadowsocks-libev/config.json意为用 nano 这个编辑器打开 config.json 这个配置文件。你的「终端」会刷新一下，出现下图。如果某天你的 ss 突然无法使用了，很可能就是端口被封了。这时你可以直接在这里，将端口修改为 1-65535 间任意其他数字。编辑完成后，按 Ctrl +X ，再输入 Y 并回车确认退出。需注意的是，如果你更新了配置文件，得重启 ss 才能生效。重启命令如下：/etc/init.d/shadowsocks-libev restart另外，如需添加多端口或多用户——很遗憾，shadowsocks-libev 无法通过简单的修改配置文件来实现。不过，作者另外开发了一个 ss-manager，来管理和开启多端口，感兴趣的话可以参考 这篇教程。 3.3 安装 Shadowsocks 客户端下载相应的软件进行安装，然后按照自己前一步配置的最终结果进行输入，运行之后就能享受相应的科学上网了。 4 开启 BBR完成上述步骤后，使用过程中可能会发现连接速度有时不太令人满意。这就是加速工具们发挥功能的时候了。常用的加速工具有「锐速」、TCPBBR、kcptun，等等。原理虽各不相同，但都是通过一些技术手段，来实现连接和传输速度的提升。 4.1 什么是 BBRTCP BBR 是 Google 于 2016 年发布的，一种避免网络拥塞的算法。目的是要尽量跑满带宽, 并且尽可能避免排队的情况。实际使用下来，BBR 的速度提升效果并不比「锐速」（据说已倒闭）、kcptun（多倍发包耗流量）等差。而且 BBR 已植入 Linux 4.9+版本的内核中，服务器开启后就能有显著的效果提升。 4.2 安装 BBR和 2.3 中的步骤一样，首先需要使用 SSH 登录 VPS。ssh root@这里依然使用 @秋水逸冰的一键安装脚本，输入以下命令。wget –no-check-certificate https://github.com/teddysun/across/raw/master/bbr.sh &amp;&amp; chmod +x bbr.sh &amp;&amp; ./bbr.sh按任意键开始安装，安装需要一段时间，等待一会即可安装完成后，脚本会提示需要重启 VPS，输入 y 并回车后重启。 感谢为我指路的各位大佬：win10上的教程：1.科学上网的终极姿势 2.SS&amp;SSR的搭建、配置与加速 3.基于Vultr+Ubuntu18.04+BBR的ShadowsocksR配置教程 4.Vultr 搭建 ShadowSocks 5.Vultr搭建ShadowSocks教程 6.从零开始于Vultr上搭建属于自己的VPN服务器【CentOS7+Shadowsocks+serverspeeder加速+防坑指北】【适合新手】 7.使用vultr(vps)搭建ss并开启BBR快速上网教程 超简单10分钟搞定 Linux下的教程：1.linux配置shadowsocks客户端 2.Ubuntu18.04 配置Shadowsocks（亲测可用） 作为踩坑大王的我，不负众望地遇到了很多问题，比如所bbr加速没好使，解决方案 还有两个网址也可以参考一下，但经常会打不开网址一网址二]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-learning-game-2]]></title>
    <url>%2F2019%2F07%2F24%2Fpython-learning-game-2%2F</url>
    <content type="text"><![CDATA[继续昨天的学习，今天从实验楼中练习的项目是–2048小游戏详细记录看这里windows下出现问题，看这里主要过程不做记录，直接上最终代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293import cursesfrom random import randrange, choicefrom collections import defaultdictactions = [‘Up’, ’Left’, ’Down’, ’Right’, ’Restart’, ’Exit’]letter_codes = [ord(ch) for ch in ‘WASDRQwasdrq’]actions_dict = dict(zip(letter_codes, actions * 2))def main(stdscr):def init(): return 'Game'def not_game(state): responses = defaultdict(lambda: state) responses['Restart'], responses['Exit'] = 'Init', 'Exit'return responses[action]def game(): if action == 'Restart': return 'Init'if action == 'Exit': return 'Exit' if Win: return 'Win' if Gameover: return 'Gameover'return 'Game'state_actions = &#123; 'Init': init, 'Win': lambda: not_game('Win'), 'Gameover': lambda: not_game('Gameover'), 'Game': game&#125;state = 'Init'while state != 'Exit': state = state_actions[state]()def get_user_action(keyboard): char = 'N' while char not in actions_dict: char = keyboard.getch() return actions_dict[char]def transpose(field): return [list(row) for row in zip(*field)]def invert(field): return [row[::-1] for row in field]class GameField(object): def init(self, height=4, width=4, win=2048): self.height = height self.width = width self.win_value = 2048 self.hightscore = 0 self.reset()def spawn(self): new_element = 4 if randrange(100) &gt; 89 else 2 (i, j) = chioce([(i, j) for i in range(self, width) for j in range(self, height) self.field[i][j] = new_elementdef reset(self): if self.score &gt; self.highscore:]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>python</tag>
        <tag>python学习应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python-learning-game-1]]></title>
    <url>%2F2019%2F07%2F23%2Fpython-learning-game-1%2F</url>
    <content type="text"><![CDATA[今天学习–将彩色的图片处理成字符画的形式 1.实验原理 2.实验步骤 2.1 安装图像处理库 2.2 编写代码 2.3 处理命令行参数 2.4 实现 RGB 值转字符的函数 2.5 处理图片 2.6 完整代码参考 2.7 运行测试 3.1-1 3.1-2 看了半个月的视频，自我感觉python的基本语法已经差不多明了了，今天就开始进行python项目的研究，从知乎上看到了实验楼这一免费的资源，就利用起来 今天学习–将彩色的图片处理成字符画的形式1.实验原理字符画是一系列字符的组合，我们可以把字符看作是比较大块的像素，一个字符能表现一种颜色（为了简化可以这么理解），字符的种类越多，可以表现的颜色也越多，图片也会更有层次感。 问题来了，我们是要转换一张彩色的图片，这么多的颜色，要怎么对应到单色的字符画上去？这里就要介绍灰度值的概念了。 灰度值：指黑白图像中点的颜色深度，范围一般从0到255，白色为255，黑色为0，故黑白图片也称灰度图像。 另外一个概念是 RGB 色彩： RGB色彩模式是工业界的一种颜色标准，是通过对红(R)、绿(G)、蓝(B)三个颜色通道的变化以及它们相互之间的叠加来得到各式各样的颜色的，RGB即是代表红、绿、蓝三个通道的颜色，这个标准几乎包括了人类视力所能感知的所有颜色，是目前运用最广的颜色系统之一。- 来自百度百科介绍 我们可以使用灰度值公式将像素的 RGB 值映射到灰度值（注意这个公式并不是一个真实的算法，而是简化的 sRGB IEC61966-2.1公式，真实的公式更复杂一些，不过在我们的这个应用场景下并没有必要）： gray ＝ 0.2126 r + 0.7152 g + 0.0722 * b 这样就好办了，我们可以创建一个不重复的字符列表，灰度值小（暗）的用列表开头的符号，灰度值大（亮）的用列表末尾的符号。 2.实验步骤2.1 安装图像处理库首先，安装 Python 图像处理库 pillow（PIL）： 12$ sudo pip3 install –upgrade pip $ sudo pip3 install pillow 然后在/home/shiyanlou/ 目录下创建 ascii.py 代码文件进行编辑： 12$ cd /home/shiyanlou/ $ touch ascii.py 2.2 编写代码使用 vim 或者 gedit 打开代码文件： 12$ cd /home/shiyanlou $ gedit ascii.py 文件打开后依次输入以下的代码内容。 首先导入必要的库，argparse 库是用来管理命令行参数输入的 12from PIL import Image import argparse 2.3 处理命令行参数 这部分的代码如下 1234567891011121314151617181920212223# 首先，构建命令行输入参数处理 ArgumentParser 实例parser = argparse.ArgumentParser()# 定义输入文件、输出文件、输出字符画的宽和高parser.add_argument('file') #输入文件parser.add_argument('-o', '--output') #输出文件parser.add_argument('--width', type = int, default = 80) #输出字符画宽parser.add_argument('--height', type = int, default = 80) #输出字符画高# 解析并获取参数args = parser.parse_args()# 输入的图片文件路径IMG = args.file# 输出字符画的宽度WIDTH = args.width# 输出字符画的高度HEIGHT = args.height# 输出字符画的路径OUTPUT = args.output 2.4 实现 RGB 值转字符的函数首先将 RGB 值转为灰度值，然后使用灰度值映射到字符列表中的某个字符。 下面是我们的字符画所使用的字符集，一共有 70个字符，为了方便写入到实验环境中，可以使用实验环境右边工具栏上的剪切板将以下代码内容拷贝到实验环境中，注意需要使用右键复制和拷贝，不要使用Ctrl-C/Ctrl-V 快捷键。字符的种类与数量可以自己根据字符画的效果反复调试： 12ascii_char =list(“$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,^`’. “) 下面是 RGB 值转字符的函数，注意 alpha 值为 0 的时候表示图片中该位置为空白： 123456789101112131415161718def get_char(r,g,b,alpha = 256): # 判断 alpha 值 if alpha == 0: return ' ' # 获取字符集的长度，这里为 70 length = len(ascii_char) # 将 RGB 值转为灰度值 gray，灰度值范围为 0-255 gray = int(0.2126 * r + 0.7152 * g + 0.0722 * b) # 灰度值范围为 0-255，而字符集只有 70 # 需要进行如下处理才能将灰度值映射到指定的字符上 unit = (256.0 + 1)/length # 返回灰度值对应的字符 return ascii_char[int(gray/unit)] 2.5 处理图片完成上面的代码之后，我们进入到最后一个步骤，对图片进行处理。 这一个步骤我们放入到 if name == ‘ main ‘: 代码块中（表示如果 ascii.py 被当作 python 模块import 的时候，这部分代码不会被执行）。图片的处理步骤如下： 首先使用 PIL 的 Image.open 打开图片文件，获得对象 im 使用 PIL 库的 im.resize() 调整图片大小对应到输出的字符画的宽度和高度，注意这个函数第二个参数使用 Image.NEAREST，表示输出低质量的图片。 遍历提取图片中每行的像素的 RGB 值，调用 getchar 转成对应的字符 将所有的像素对应的字符拼接在一起成为一个字符串 txt 打印输出字符串 txt 如果执行时配置了输出文件，将打开文件将 txt 输出到文件，如果没有，则默认输出到 output.txt 文件 这个过程中需要注意的是调用 getchar 时候的参数是通过 PIL 库的 getpixel 获取的，见如下代码： 1char = get_char(*im.getpixel((j,i))) 其中 im.getpixel((j,i)) 获取得到坐标 (j,i) 位置的 RGB 像素值（有的时候会包含 alpha 值），返回的结果是一个元组，例如(1,2,3) 或者 (1,2,3,0)。我们使用 * 可以将元组作为参数传递给 get_char，同时元组中的每个元素都对应到 get_char函数的每个参数。 该部分的代码实现如下（注意 name 和 main 前后都是两个下划线）： 123456789101112131415161718192021222324252627if **name** == ‘ **main** ‘: # 打开并调整图片的宽和高 im = Image.open(IMG) im = im.resize((WIDTH,HEIGHT), Image.NEAREST) # 初始化输出的字符串 txt = "" # 遍历图片中的每一行 for i in range(HEIGHT): # 遍历该行中的每一列 for j in range(WIDTH): # 将 (j,i) 坐标的 RGB 像素转为字符后添加到 txt 字符串 txt += get_char(*im.getpixel((j,i))) # 遍历完一行后需要增加换行符 txt += '\n' # 输出到屏幕 print(txt) # 字符画输出到文件 if OUTPUT: with open(OUTPUT,'w') as f: f.write(txt) else: with open("output.txt",'w') as f: f.write(txt) 2.6 完整代码参考下面是 ascii.py 的完整代码，供参考： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# -*- coding=utf-8 -*-from PIL import Imageimport argparse#命令行输入参数处理parser = argparse.ArgumentParser()parser.add_argument('file') #输入文件parser.add_argument('-o', '--output') #输出文件parser.add_argument('--width', type = int, default = 80) #输出字符画宽parser.add_argument('--height', type = int, default = 80) #输出字符画高#获取参数args = parser.parse_args()IMG = args.fileWIDTH = args.widthHEIGHT = args.heightOUTPUT = args.outputascii_char = list("$@B%8&amp;WM#*oahkbdpqwmZO0QLCJUYXzcvunxrjft/\|()1&#123;&#125;[]?-_+~&lt;&gt;i!lI;:,\"^`'. ")# 将256灰度映射到70个字符上def get_char(r,g,b,alpha = 256): if alpha == 0: return ' ' length = len(ascii_char) gray = int(0.2126 * r + 0.7152 * g + 0.0722 * b) unit = (256.0 + 1)/length return ascii_char[int(gray/unit)]if __name__ == '__main__': im = Image.open(IMG) im = im.resize((WIDTH,HEIGHT), Image.NEAREST) txt = "" for i in range(HEIGHT): for j in range(WIDTH): txt += get_char(*im.getpixel((j,i))) txt += '\n' print(txt) #字符画输出到文件 if OUTPUT: with open(OUTPUT,'w') as f: f.write(txt) else: with open("output.txt",'w') as f: f.write(txt) 2.7 运行测试然后，我们还要从实验楼下载用来测试的图片： 1$ wget &lt;http://labfile.oss.aliyuncs.com/courses/370/ascii_dora.png&gt; 3.1-1最后，使用刚刚编写的 ascii.py 来将下载的 ascii_dora.png转换成字符画，此时执行过程没有指定其他的参数，比如输出文件、输出文件的宽和高，这些参数都将使用默认的参数值： 1$ python3 ascii.py ascii_dora.png 然后使用 vim 打开 output.txt 文件： 1$ vim output.txt 如果使用 vim 可以按 ESC 键，然后输入 :q 进行退出。 你会看到下面的图片： 提示：菜单栏-&gt;编辑-&gt;首选项-&gt;外观-&gt;字体 可以调节字体的大小。 下面图片中的字号大小为 6。 3.1-2注意，不同的环境中显示的效果可能不尽相同 终端显示的字体是不是等宽字体，终端显示的行高和行宽，输入输出的图像宽高等等，这些都会影响显示效果 如果你在实验中遇到问题，可以通过下面的命令下载由实验楼提供的代码以作参考。 $ wget http://labfile.oss.aliyuncs.com/courses/370/ascii.py]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>python</tag>
        <tag>python学习应用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[尼古拉斯赵四-learning-1]]></title>
    <url>%2F2019%2F07%2F17%2F%E5%B0%BC%E5%8F%A4%E6%8B%89%E6%96%AF%E8%B5%B5%E5%9B%9B-learning-1%2F</url>
    <content type="text"><![CDATA[Android中的Apk的加固（加壳）原理解析和实现- [1. Apk是什么？](#1-apk是什么) - [2. Android分层中native是哪一层？其他层是什么？](#2-android分层中native是哪一层其他层是什么) - [3. 加壳程序项目：DexShellTools](#3-加壳程序项目dexshelltools) - [4. 脱壳程序项目：ReforceApk](#4-脱壳程序项目reforceapk) Android中的Apk的加固（加壳）原理解析和实现本文学习自-尼古拉斯赵四 1. Apk是什么？Apk是什么？ Apk是AndroidPackage的缩写，即Android安装包。Apk是类似Symbian sis或者sisx的文件格式。通过将apk文件直接传到Android模拟器或Android手机中执行即可安装。apk文件和sis一样，把Android sdk编译的工程打包成一个安装程序文件，格式为apk。Apk文件其实是zip格式，但后缀名被修改为apk，可以通过WinRAR等压缩工具进行解压缩。APK文件的结构如下图： META-INF : 签名信息 res : 资源文件 anim color drawable drawable-hdpi drawable-land drawable-land-hdpi drawable-mdpi drawable-port drawable-port-hdpi layout layout-land layout-port xml AndroidManifest.xml ：应用的名称，版本，权限，引用的库文件等 classes.dex ：针对嵌入式优化 resources.arsc : 本地化，汉化资源存储 2. Android分层中native是哪一层？其他层是什么？Android分层中native是哪一层？其他层是什么？ 看到Android的分4层:java应用程序，java框架，本地框架和java运行环境，Linux内核空间。那么native层又是指什么？ 在这个分层方式当中，Native层就是本地框架。 这些层大致如此区分： Java应用程序无需过多解释，基本可以理解为各个App，由Java语言实现。 Java框架层就是常说的Framework，这层里东西很多也很复杂，比如说主要的一些系统服务如ActivityManagerService、PackageManagerService等，我们编写的Android代码之所以能够正常识别和动作，都要依赖这一层的支持。这一层也是由Java语言实现。 Native层这部分常见一些本地服务和一些链接库等。这一层的一个特点就是通过C和C++语言实现。比如我们现在要执行一个复杂运算，如果通过java代码去实现，那么效率会非常低，此时可以选择通过C或C++代码去实现，然后和我们上层的Java代码通信（这部分在android中称为jni机制）。又比如我们的设备需要运行，那么必然要和底层的硬件驱动交互，也要通过Native层。 Linux内核空间这部分顾名思义，就是Kernel部分哈~ 3. 加壳程序项目：DexShellTools通过对作者尼古拉斯赵四讲解的通读，加壳程序项目就是对源APK上进行加壳的操作，简单来说就是在源APK结束的末尾连接上给定的脱壳Dex，然后修改新Dex文件的文件的头信息。 在进行连接之前，为了源码的安全，需要用比较复杂的加密算法对其进行加密。 这里我们还需要两个输入文件： 1&gt;、源Apk文件：ForceApkObj.apk 源程序编译之后的apk文件 2&gt;、脱壳程序的Dex文件：ForceApkObj.dex 脱壳程序项目，在编译之后得到的classes.dex文件改个名字 4. 脱壳程序项目：ReforceApk]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>52破解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[machine learning-1]]></title>
    <url>%2F2019%2F07%2F08%2Fmachine%20learning-1%2F</url>
    <content type="text"><![CDATA[What is machine learning? 举个栗子 machine learning type supervised learning What is machine learning?我的理解：机器学习就是计算机通过算法对已知数据进行解析，得出相应的规律，然后对之后的事情进行预测和判定。 机器学习是人工智能的一个分支。 深度学习是机器学习的一个子集。 具体认识来自小白教程https://blog.csdn.net/qq_28168421/article/details/81351321 老师的讲解： 其中的三要素就是：Task T，Performance measure P，Training Experience E 举个栗子e.g-1 让机器识别手写的文字，其中Task T就是识别分类图像中的手写单词，Performance measureP就是单词正确分类百分比，Training Experience E就是手写单词分类数据库 e-g-2 机器学习的目标是让机器学会下象棋。 machine learning typesupervised learning:监督学习 就像从老师那里学习 unsupervised learning:不监督学习 没有老师监督的学习 Reinforcement learning:强化学习 learning with a “lazy” teacher supervised learning 再举个例子？ 一辆家庭轿车。 运用假设类分析的方法，根据已知的数据点，将其分为积极的和消极的，然后画出一个矩形，在矩形里面的是有用的，可以进一步将矩形的大小进行缩小 然后接下来的一部分是进行了两个模型的介绍，一个是线性模型，另一个是K-NN方法 讲的variance和bias，没太明白，最后这个比较记忆一下好了，之后在进行数学推导。 接着是增加维度的方法，仍然没明白想要讲点啥？ 然后还有一个文法树的结构 最后爱啥啥，我要睡觉，明天有空接着来]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>machine learning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Windows和Linux双系统的初尝试]]></title>
    <url>%2F2019%2F07%2F03%2FWindows%E5%92%8CLinux%E5%8F%8C%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%88%9D%E5%B0%9D%E8%AF%95%2F</url>
    <content type="text"><![CDATA[Windows和Linux双系统的初尝试 UEFI模式 如何知道自己的电脑是哪种启动模式 准备工具 1. Unbutu18.04.1 LTS镜像 2. UltraIOS 3. 装机U盘 4. 制作装机系统U盘 5. 磁盘分区 6. 设置BIOS 7. 开始安装Ubuntu 8. 优化设置 9. 页面美化 整了两天，终于把自己的网站给简单的搭建并且美化了一下，顺便感谢一下 Orange 大佬的支持和寝室两只小可爱的美学指导 本身想着继续进行科学上网的探索，然鹅突然爆出我校某同学因为不当言论被处分，吓得我赶快放弃这个念头，但是小学期就要造作啊 ~所以经过暗中观察，本宝宝决定尝试安装双系统 首先，第一次尝试，生怕把系统整崩，本着数据无价的观点，我毫不犹豫地将除了win10系统之外的全部数据进行了备份。 再次强烈建议，如果大家都是造作的人，没事还是把数据备份一下吧。然后嘛，嘿嘿~~ 在正式记录之前，先放几个教程： —中间的图似乎没有上传成功，直接点击链接去 1.https://www.jianshu.com/p/fe4e3915495e 2.https://www.jianshu.com/p/8079ce5057d3 3.https://blog.csdn.net/mt1123456/article/details/89786111 特此声明，我大体是根据教程1来安装，根据教程2来进行优化，根据教程3来进行中文输入法的配置 Windows和Linux双系统的初尝试UEFI模式首先必须说明的是，有两种不同的启动模式，在安装双系统的时候的操作也不尽相同，本文是针对UEFI启动模式的安装双系统的成功案例。如果您的计算机的启动模式是Legacy，请参考其他文章。 如何知道自己的电脑是哪种启动模式找到“运行” -&gt; 在“运行”中输入：msinfo32 -&gt; 查看右边的信息，找到“BIOS模式”，如果后边是“UEFI”，那么这篇文章就可以应用到你的计算机上啦 -&gt; 顺便看一下计算机的“已安装的物理内存（RAM）”，这个数字会对你有所帮助。 准备工具1. Unbutu18.04.1 LTS镜像到Ubuntu官方网站下载最新版Ubuntu LTS镜像： https://www.ubuntu.com/download/desktop 2. UltraIOS这是一个用于将镜像写入U盘制作系统安装盘，到官方网站下载（试用版足够）：https://cn.ultraiso.net/xiazai.html 3. 装机U盘一个大于2G的空U盘，并且提前将U盘内容备份，U盘需要格式化，格式化后其中的所有东西将被删除。 之后将U盘格式化：在插入的U盘上右键选择“格式化” -&gt; 文件系统选择FAT32（默认） -&gt; 开始 4. 制作装机系统U盘插入我们格式化好的U盘，打开UltraIOS，点击上方的“打开”图标，选择刚刚下载的Ubuntu18.04镜像文件 制作装机系统U盘 看到打开之后的内容大概如下： 点击“启动” -&gt; “写入硬盘映像” 这时可以看到上边出现了我们的U盘选项，如果还有别的选项，千万不要选错， 一定要点击我们的U盘！ 下边的写入方式是“USB-HDD+”，右下角是“便捷启动”。检查好这三项之后点击下边的“写入”。经过确认之后会进入等待阶段。 制作装机系统U盘 制作装机系统U盘 制作装机系统U盘 直到出现了“刻录成功”，直接点击“返回”即可。 5. 磁盘分区在“此电脑”上邮件打开“管理” 点击左边的“磁盘管理” -&gt; 出现右边的磁盘分区详情 你需要选择将你的一个磁盘分出来一部分空间用来安装双系统，根据你的实际情况选择使用哪个磁盘以及分出多大的空间，我刚开始分出了50G（1G=1024M）。在选择好的磁盘上右键，选择“压缩卷”。（最后我分出了100G） 磁盘分区过程 填写你要分出的大小， （这里的图片和后续步骤有差异，因为整个过程笔者做了两遍，第一次分配了如图所示的50G空间发现不够用后来第二次更改成了90G）单位是M，点击“压缩”。 只要你刚刚压缩出来的区域显示“未分配”，说明你压缩成功了！ 6. 设置BIOS此时可以关机重启，在按下电源后及时按住快捷键进入BIOS（联想拯救者是F2，华硕笔记本是F2）。 联想拯救者：将“安全启动”和“快速启动”都关闭（Disable），将“USB启动”设置为开启（Enable） 华硕： 进入BIOS后按方向键选择security选项，然后在这里选择boot menu。 把secure boot 这里以及control全部设置为disable，即禁止启动的意思。然后按方向键选择BIOS顶部boot选项，把launch csm设置为enble，即开启的意思。 这个时候把启动U盘插入到电脑上，按一下键盘上面的f10，保存退出设置。选择OK即可。 7. 开始安装Ubuntu联想：关机，插入U盘。然后选择USB启动那一项。 选择boot从U盘启动 华硕： 然后在黑屏瞬间按住ESC不动，看到图二选择你的U盘进行启动。如果没有掌握这个方法，则先关机后按住ESC，再按一下开机键开机。 之后会进入一个黑底白字的页面，可以默认选择第一个（TryUbuntu）进入Ubuntu的试用页面。此时可以随便体验一下，然后可以点击桌面上的安装程序安装Ubuntu系统。 选择语言，我这里选择的英语，可以根据自己的需求选择，接下来的教程中也是英语模式，如果你不懂英语，可以直接看位置，每个窗口的分布和每个窗口的位置都是相同的。 选择键盘模式，我们当然选择English(US) 然后会让你选择连接网络，你可以选择连接与不连接。（如果你有一个比较好的网络环境，我倒是建议你可以直接联网，网上说联网环境下安装需要下载比较多的东西，会卡死或者很慢，不过我现在没有遇到这个问题，Ubuntu在国内的服务线路也比较完善了，应该不必担心） 安装方式可以选择“最小安装”，因为这样可以安装一个干净整洁的系统，没有多余的软件，而且安装快，不用边安边下载。下边的“其他选项”根据自己的情况选择，如果联网了可以选择第一个，如果没有联网是没有可选项的。 但是我选择的是正常安装，因为以后的使用可能很多，万一哪个功能不全，现安多麻烦。还有就是Linux系统很小的，安装之后不会很占硬盘。 安装方式！重中之重！一定要选择最下边的“其他方式”（Something else）！一定要选择最下边的“其他方式”（Something else）！一定要选择最下边的“其他方式”（Something else）！否则你可能会删除原有的Win10系统！ 再三确认之后，进入下一步，可以在这里找到你刚刚分出来的“空闲空间”，对照一下后边的大小是否是你分出来的大小，选好它之后点击下边的“+”号。 接下来就是分区了，每一次分区有四到五个可选项。 挂载“/”，类型为“EXT4日志文件系统”，选中“主分区”和“空间起始位置”。这个空间可以理解成共用空间，尽量大一些，因为有些软件是无法更改他的安装位置到自己的个人目录下的，只能放在这个空间里边。 swap交换空间，这个也就是虚拟内存的地方，选择“逻辑分区”和“空间起始位置”。其大小最好和你的物理内存相等。 新建EFI系统分区，选中“逻辑分区”和“空间起始位置”，大小最好不要小于256MB，系统引导文件都会在里面，可以给512MB。重点！分配完之后去上边的列表里找一下，刚刚这个分区的盘符一会儿会用到哦 挂载“/home”，类型为“EXT4日志文件系统”，选中“逻辑分区”和“空间起始位置”，这个相当于你的个人文件夹，类似Windows里的User，建议最好能分配稍微大点，因为你的图片、视频、下载内容、有些自定义的软件安装路径基本都在这里面，这些东西可不像在Win上面你想移动就能移动的。 重点来了！此时千万不要点“安装”！找到你刚刚EFI分区的盘符（对照一下后边的大小是否是刚刚分配的大小，然后看看上下文是你分出来的其他分区，再三确认！）记住你的分区的名字，比如我的是图中的“/dev/sda8”更改下边的“安装引导启动器的设备”！千万不要用默认的！改为你刚刚记下的EFI分区的盘符！更改下边的“安装引导启动器的设备”！千万不要用默认的！改为你刚刚记下的EFI分区的盘符！更改下边的“安装引导启动器的设备”！千万不要用默认的！改为你刚刚记下的EFI分区的盘符！ 可以点击“安装”了，再次确认一下你的分区。 下一步，选择时区 最后一步，填一下你的用户名、设备名、密码等等 好了，最终进入了你的安装过程 一定的等待时间之后，就会提示安装完毕要求重启，点击重启计算机即可。 8. 优化设置grub引导的设置文件是 /etc/default/grub ，对其进行修改可以得到我们想要的结果。 在命令行中输入：如果你会使用vim： sudo vim /etc/default/grub 或者如果你不会使用vim：sudo gedit /etc/default/grub 然后我们就可以对设置文件进行编辑了 一般我们需要更改其中的GRUB_DEFAULT（默认启动项：这个编号是你开机时看到的若干个启动项从上到下的依次编号，记住！程序员世界的编号从来都是从0开始的，意思是，第一项是0，第二项是1，以此类推）、GRUB_TIMEOUT_STYLE（是否显示倒计时，hidden的属性表示不会显示倒计时）、GRUB_TIMEOUT（等待时间，单位是秒）、GRUB_GFXMODE（屏幕的显示像素，可以不用管这一项） 按照自己的需求更改，其他的很多配置如果你还需要更改可以去查询每一项的具体含义和属性值。 注意一点，如果你更改的属性语句前边有#符号，一定要将其去掉这一句才会起作用。 完成后记得保存离开，然后再命令行输入： sudo update-grub ，对刚才的设置进行更新。整体下来大概是这个样子： 9. 页面美化这个黑底白字的启动引导页面说实话还是极其丑陋的，不过好在我们可以对其进行美化。如果你是可以完成自己修改源码或者加上样式的大神，不用我多说，但是如果你想省事或者不会自己写页面样式，可以去这里下载一款你喜欢的风格的页面样式给自己使用就好，点击左侧的GRUBThemes 这里你就可以看到各种各样的主题了，选择自己喜欢的一个，我以这个“Poly lignt”为例，选择它并下载 百度云分享：https://pan.baidu.com/s/1HEhEGK_qK9-0o826CePqrQ 提取码：x1hl 下载好后得到了一个压缩包，将其解压 创建一个文件夹：sudo mkdir /boot/grub/themes/ 将整个解压出来的文件夹拷贝到刚刚创建的文件夹下：sudo cp -R poly-light-master /boot/grub/themes/ 接下来编辑文件：/etc/grub.d/00_header，即输入命令：sudo gedit /etc/grub.d/00_header 如果你发现自己更改内容之后无法保存文件，说明你权限不够，可以进入root权限再次编辑 在打开的 00_header 文件中，加入如下两行： 12GRUB_THEME=”/boot/grub/themes/poly-light-master/theme.txt” GRUB_GFXMODE=”1920×1080” 第一句根据你下载的主题改成自己刚刚拷贝到themes文件夹下的主题包中的theme.txt文件，第二句是你屏幕的分辨率。 保存后记得要更新一下grub： sudo update-grub 好了，此时再次重启你的电脑就可以看到好看的开机页面啦！]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>搭建博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[奇怪的bug-1]]></title>
    <url>%2F2019%2F07%2F01%2F%E5%A5%87%E6%80%AA%E7%9A%84bug-1%2F</url>
    <content type="text"><![CDATA[每次在编写程序的过程中，总是会遇见奇奇怪怪的问题，然后DEBUG几个小时，昨天被室友一嘲笑，决定记录下这些惨绝人寰的错误 已经解决的：1. 还未彻底解决的：1.Troublshooting “The type parameter T is hiding the type T”waring在编写软件构造实验二中的P2的过程中，由于要求使用P1中的泛型，所以就模仿P1中的ConcreteEdgesGraph 进行implimentsGraph,将T变为Person类型，然后就华丽丽的报错了~~显示根本查找不到我在同一个包中编写的另一个函数小注： Graph是个接口https://stackoverflow.com/questions/10011758/troubleshooting-the-type-parameter-t-is-hiding-the-type-t-warning看了这个网址吧，我也没太明白。有说让把class删除的？初步的解决方法是在下面重新定义大概就是这个鬼样子 Graph friendGraph = new ConcreteEdgesGraph();不管怎样，反正目前是好使 未解决的：1.Person.java文件不清楚原因的无法建立这可以算是这次实验的绝症了，而且是反复出现的，于是乎我就搞笑的建了Person1,Person2,Person3….，我到目前为止还没有好的解决方案。然后最绝的是后来连我的FriendshipGraph都出现问题了，最后将整个项目删除重建，才解决的问题。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[UML学习笔记-1]]></title>
    <url>%2F2019%2F07%2F01%2FUML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0-1%2F</url>
    <content type="text"><![CDATA[类的表示方法（属性和方法） 1.类名，属性和方法 2. 属性方法 3. 属性的完整表示方式： 4. 方法的完整表示形式： 类与类之间的关系 1. 关联关系 2. 聚合关系 3. 组合关系 4. 依赖关系 5.继承关系（泛化关系） 6.接口实现关系 主要参考网址：http://www.uml.org.cn/oobject/201211231.asp 比较详细https://www.cnblogs.com/shindo/p/5579191.html 简单粗暴 具体的图示就没有粘过来 类的表示方法（属性和方法）1.类名，属性和方法在UML图中，类的使用包含类名，属性和方法，这三者用带有分割线的矩形进行分割 2. 属性方法注意到属性方法名称前面会有加减号，是用来表示可见性123* public ： + * private ： - * friendly ： # 3. 属性的完整表示方式：1可见性 名称 ：类型 【 = 缺省值】 12中括号中的内容表示是可选的缺省值对应属性的初始值 4. 方法的完整表示形式：123可见性 名称（参数列表）【 ： 返回类型】 中括号中的内容表示是可选的 返回类型 ： 基本数据类型，用户自定义的数据类型 void 没有返回类型（构造方法） 类与类之间的关系1. 关联关系1234567891011 - 自关联 ： 自己包含自己 * 带箭头的直线 - 单向关联 ：一方为另一方的成员变量 * 带箭头的直线 箭头指向成员变量 - 双向关联 ：双方各自持有对方类型的变量 * 不带箭头的直线 - 多重性关联 ： 两个对象在关联数量上的关系 * 在关联直线上用数字或者数字范围表示 ``` ###### 2. 聚合关系 整体包含部分，但是部分能脱离整体而存在 空心菱形和箭头 12 ###### 3. 组合关系 部分脱离整体便不存在 实心菱形和箭头 12###### 4. 依赖关系 没看明白 方法只有传入对象才能发挥作用 带箭头的虚线 12 ###### 5.继承关系（泛化关系） 对应的是extend关键字 带空心三角形的直线 12###### 6.接口实现关系 对应implement关键字 带空心三角形的虚线``` 英文好的还可以参考：https://www.visual-paradigm.com/guide/uml-unified-modeling-language/uml-aggregation-vs-composition/https://www.visual-paradigm.com/guide/uml-unified-modeling-language/what-is-class-diagram/]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[错误关掉任务管理器导致的开机黑屏]]></title>
    <url>%2F2019%2F07%2F01%2F%E9%94%99%E8%AF%AF%E5%85%B3%E6%8E%89%E4%BB%BB%E5%8A%A1%E7%AE%A1%E7%90%86%E5%99%A8%E5%AF%BC%E8%87%B4%E7%9A%84%E5%BC%80%E6%9C%BA%E9%BB%91%E5%B1%8F%2F</url>
    <content type="text"><![CDATA[沙雕经过 解决方法 沙雕经过肝了一下午的实验，然后脑子十分不清醒的我，看着自己电脑上N多的窗口，默默的任务栏—&gt;右键—&gt;任务管理器—&gt;任务管理器—&gt;结束任务，然后华丽丽的让电脑黑屏了。想起社团大佬的教诲，默默的强制关机，好使。接着登陆界面出现，嗯，也是对的。然后输入密码，帅气的敲击enter，刷的又黑屏了。内心真的是？??????? 解决方法登陆之后看着自己的黑屏，默默的吸气，吐气，再吸气，再吐气。并不是意念开电脑，而是让自己冷静。现在可以CTRL+ALT+DELETE，调出任务管理器，选择左上角的文件，进而运行新任务。这时会出现和win+R一样的窗口，输入explorer，确定即可。]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>黑科技</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Collection简介]]></title>
    <url>%2F2019%2F06%2F30%2FCollection%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[1. Collections简介 2. Collections类的使用 2.1 字段摘要 2.2 Collections提供以下方法对List进行操作 2.2.1 排序操作 2.2.2 查找及替换操作 2.2.3 同步控制 2.2.4 不可变（只读）的集合，以及几何相应的只读视图。 2.2.5 其他 转载地址：https://blog.csdn.net/zengxiantao1994/article/details/80306669 1. Collections简介 public class Collections extends Object，此类完全由在 collection 上进行操作或返回 collection 的静态方法组成。它包含在collection 上操作的多态算法，即“包装器”，包装器返回由指定collection 支持的新 collection，以及少数其他内容。 如果为此类的方法所提供的collection 或类对象为 null，则这些方法都将抛出NullPointerException。 此类中所含多态算法的文档通常包括对实现的简短描述。应该将这类描述视为实现注意事项，而不是规范的一部分。实现者应该可以随意使用其他算法替代，只要遵循规范本身即可。（例如，sort使用的算法不一定是合并排序算法，但它必须是稳定的。） 此类中包含的“破坏性”算法，即可修改其所操作的 collection 的算法，该算法被指定在collection 不支持适当的可变基元（比如 set 方法）时抛出UnsupportedOperationException。如果调用不会对collection 产生任何影响，那么这些算法可能（但不要求）抛出此异常。例如，在已经排序的、不可修改列表上调用sort 方法可能会（也可能不会）抛出 UnsupportedOperationException。 此类是Java Collections Framework 的成员。 2. Collections类的使用2.1 字段摘要 1、static List EMPTY_LIST：空的列表（不可变的）。 2、static Map EMPTY_MAP：空的映射（不可变的）。 3、static Set EMPTY_SET：空的 set（不可变的）。排序操作 2.2 Collections提供以下方法对List进行操作2.2.1 排序操作 static void reverse(List&lt;?&gt; list)：反转指定列表中元素的顺序。 static void shuffle(List&lt;?&gt; list)：使用默认随机源对指定列表进行置换。即随机排序。 static void shuffle(List&lt;?&gt; list, Random rnd)：使用指定的随机源对指定列表进行置换。 static]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
        <tag>java模块学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse无法打开或找到 Eclipse MarketPlace的解决办法]]></title>
    <url>%2F2019%2F05%2F19%2FEclipse%E6%97%A0%E6%B3%95%E6%89%93%E5%BC%80%E6%88%96%E6%89%BE%E5%88%B0%20Eclipse%20MarketPlace%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1. 问题详情： 2. 解决方法： 1. 问题详情：想要修改eclipse的主题的时候发现无法找到eclipse market space，进而无法搜索theme来进行主题的更换 2. 解决方法：重新安装一下 epp MarketPlace 点击help–&gt;install new software 地址栏输入一下链接： http://download.eclipse.org/mpc/photon/ 安装完成后 重启Eclipse即可打开MarketPlace 解决方案来自https://blog.csdn.net/qq_28773851/article/details/81007880]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>转载</tag>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Eclipse中的3种弥补措施]]></title>
    <url>%2F2019%2F04%2F05%2FEclipse%E4%B8%AD%E7%9A%843%E7%A7%8D%E5%BC%A5%E8%A1%A5%E6%8E%AA%E6%96%BD%2F</url>
    <content type="text"><![CDATA[1.一不小心删除了？ 2.一不小心回退多了？ 3.一不小心把package/.java文件删除了？ 1.一不小心删除了？ctrl+z返回上一步执行的操作 2.一不小心回退多了？ctrl+y执行下一步操作 3.一不小心把package/.java文件删除了？==注意时效性==右击该工程，选择“Restore from Local History…”，从本地历史中恢复 然后就会出现 选择你想要恢复的文件之后，确定就行啦]]></content>
      <categories>
        <category>解决方案</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>java</tag>
      </tags>
  </entry>
</search>
